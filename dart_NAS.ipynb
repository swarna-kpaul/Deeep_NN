{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/swarna-kpaul/Deeep_NN/blob/master/dart_NAS.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VFr92xKKY2zJ",
        "outputId": "e3df2698-3402-4f03-c04d-bdb1aede71fc"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Cloning into 'nni'...\n",
            "remote: Enumerating objects: 59739, done.\u001b[K\n",
            "remote: Total 59739 (delta 0), reused 0 (delta 0), pack-reused 59739\u001b[K\n",
            "Receiving objects: 100% (59739/59739), 122.37 MiB | 10.02 MiB/s, done.\n",
            "Resolving deltas: 100% (35940/35940), done.\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/microsoft/nni"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-ihIhTpyVbJm",
        "outputId": "33a4ae01-63cb-4905-ffec-7daf08cba83c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting nni\n",
            "  Downloading nni-2.10-py3-none-manylinux1_x86_64.whl (56.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.0/56.0 MB\u001b[0m \u001b[31m14.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: prettytable in /usr/local/lib/python3.8/dist-packages (from nni) (3.6.0)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.8/dist-packages (from nni) (1.7.3)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.8/dist-packages (from nni) (21.3)\n",
            "Requirement already satisfied: typeguard in /usr/local/lib/python3.8/dist-packages (from nni) (2.7.1)\n",
            "Requirement already satisfied: typing-extensions>=4.0.0 in /usr/local/lib/python3.8/dist-packages (from nni) (4.4.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.8/dist-packages (from nni) (3.9.0)\n",
            "Collecting schema\n",
            "  Downloading schema-0.7.5-py2.py3-none-any.whl (17 kB)\n",
            "Requirement already satisfied: pyyaml>=5.4 in /usr/local/lib/python3.8/dist-packages (from nni) (6.0)\n",
            "Collecting websockets>=10.1\n",
            "  Downloading websockets-10.4-cp38-cp38-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (106 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m107.0/107.0 KB\u001b[0m \u001b[31m15.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting PythonWebHDFS\n",
            "  Downloading PythonWebHDFS-0.2.3-py3-none-any.whl (10 kB)\n",
            "Collecting colorama\n",
            "  Downloading colorama-0.4.6-py2.py3-none-any.whl (25 kB)\n",
            "Collecting responses\n",
            "  Downloading responses-0.22.0-py3-none-any.whl (51 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m51.1/51.1 KB\u001b[0m \u001b[31m7.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.8/dist-packages (from nni) (1.21.6)\n",
            "Requirement already satisfied: cloudpickle in /usr/local/lib/python3.8/dist-packages (from nni) (2.2.0)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.8/dist-packages (from nni) (5.4.8)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.8/dist-packages (from nni) (1.3.5)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.8/dist-packages (from nni) (2.25.1)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.8/dist-packages (from nni) (4.64.1)\n",
            "Requirement already satisfied: scikit-learn>=0.24.1 in /usr/local/lib/python3.8/dist-packages (from nni) (1.0.2)\n",
            "Collecting json-tricks>=3.15.5\n",
            "  Downloading json_tricks-3.16.1-py2.py3-none-any.whl (27 kB)\n",
            "Requirement already satisfied: astor in /usr/local/lib/python3.8/dist-packages (from nni) (0.8.1)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.8/dist-packages (from scikit-learn>=0.24.1->nni) (1.2.0)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.8/dist-packages (from scikit-learn>=0.24.1->nni) (3.1.0)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.8/dist-packages (from packaging->nni) (3.0.9)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.8/dist-packages (from pandas->nni) (2022.7)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.8/dist-packages (from pandas->nni) (2.8.2)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.8/dist-packages (from prettytable->nni) (0.2.5)\n",
            "Collecting simplejson\n",
            "  Downloading simplejson-3.18.1-cp38-cp38-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (135 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m135.5/135.5 KB\u001b[0m \u001b[31m19.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests->nni) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests->nni) (2022.12.7)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests->nni) (2.10)\n",
            "Requirement already satisfied: chardet<5,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests->nni) (4.0.0)\n",
            "Collecting urllib3<1.27,>=1.21.1\n",
            "  Downloading urllib3-1.26.14-py2.py3-none-any.whl (140 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m140.6/140.6 KB\u001b[0m \u001b[31m21.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: toml in /usr/local/lib/python3.8/dist-packages (from responses->nni) (0.10.2)\n",
            "Collecting types-toml\n",
            "  Downloading types_toml-0.10.8.1-py3-none-any.whl (4.5 kB)\n",
            "Requirement already satisfied: contextlib2>=0.5.5 in /usr/local/lib/python3.8/dist-packages (from schema->nni) (0.5.5)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.8/dist-packages (from python-dateutil>=2.7.3->pandas->nni) (1.15.0)\n",
            "Installing collected packages: types-toml, json-tricks, websockets, urllib3, simplejson, schema, colorama, responses, PythonWebHDFS, nni\n",
            "  Attempting uninstall: urllib3\n",
            "    Found existing installation: urllib3 1.24.3\n",
            "    Uninstalling urllib3-1.24.3:\n",
            "      Successfully uninstalled urllib3-1.24.3\n",
            "Successfully installed PythonWebHDFS-0.2.3 colorama-0.4.6 json-tricks-3.16.1 nni-2.10 responses-0.22.0 schema-0.7.5 simplejson-3.18.1 types-toml-0.10.8.1 urllib3-1.26.14 websockets-10.4\n"
          ]
        }
      ],
      "source": [
        "! pip install nni # install nni"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EqhFCdDi24wn",
        "outputId": "e562f041-da24-470f-beed-e388a9ba6512"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting pytorch_lightning\n",
            "  Downloading pytorch_lightning-1.8.6-py3-none-any.whl (800 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m800.3/800.3 KB\u001b[0m \u001b[31m20.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting tensorboardX>=2.2\n",
            "  Downloading tensorboardX-2.5.1-py2.py3-none-any.whl (125 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m125.4/125.4 KB\u001b[0m \u001b[31m15.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: fsspec[http]>2021.06.0 in /usr/local/lib/python3.8/dist-packages (from pytorch_lightning) (2022.11.0)\n",
            "Requirement already satisfied: numpy>=1.17.2 in /usr/local/lib/python3.8/dist-packages (from pytorch_lightning) (1.21.6)\n",
            "Requirement already satisfied: packaging>=17.0 in /usr/local/lib/python3.8/dist-packages (from pytorch_lightning) (21.3)\n",
            "Collecting lightning-utilities!=0.4.0,>=0.3.0\n",
            "  Downloading lightning_utilities-0.5.0-py3-none-any.whl (18 kB)\n",
            "Requirement already satisfied: typing-extensions>=4.0.0 in /usr/local/lib/python3.8/dist-packages (from pytorch_lightning) (4.4.0)\n",
            "Requirement already satisfied: torch>=1.9.0 in /usr/local/lib/python3.8/dist-packages (from pytorch_lightning) (1.13.1+cu116)\n",
            "Requirement already satisfied: PyYAML>=5.4 in /usr/local/lib/python3.8/dist-packages (from pytorch_lightning) (6.0)\n",
            "Requirement already satisfied: tqdm>=4.57.0 in /usr/local/lib/python3.8/dist-packages (from pytorch_lightning) (4.64.1)\n",
            "Collecting torchmetrics>=0.7.0\n",
            "  Downloading torchmetrics-0.11.0-py3-none-any.whl (512 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m512.4/512.4 KB\u001b[0m \u001b[31m49.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.8/dist-packages (from fsspec[http]>2021.06.0->pytorch_lightning) (2.25.1)\n",
            "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /usr/local/lib/python3.8/dist-packages (from fsspec[http]>2021.06.0->pytorch_lightning) (3.8.3)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.8/dist-packages (from packaging>=17.0->pytorch_lightning) (3.0.9)\n",
            "Requirement already satisfied: protobuf<=3.20.1,>=3.8.0 in /usr/local/lib/python3.8/dist-packages (from tensorboardX>=2.2->pytorch_lightning) (3.19.6)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.8/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>2021.06.0->pytorch_lightning) (6.0.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /usr/local/lib/python3.8/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>2021.06.0->pytorch_lightning) (4.0.2)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.8/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>2021.06.0->pytorch_lightning) (1.3.3)\n",
            "Requirement already satisfied: charset-normalizer<3.0,>=2.0 in /usr/local/lib/python3.8/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>2021.06.0->pytorch_lightning) (2.1.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.8/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>2021.06.0->pytorch_lightning) (22.2.0)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.8/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>2021.06.0->pytorch_lightning) (1.8.2)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.8/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>2021.06.0->pytorch_lightning) (1.3.1)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests->fsspec[http]>2021.06.0->pytorch_lightning) (2022.12.7)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests->fsspec[http]>2021.06.0->pytorch_lightning) (2.10)\n",
            "Requirement already satisfied: chardet<5,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests->fsspec[http]>2021.06.0->pytorch_lightning) (4.0.0)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests->fsspec[http]>2021.06.0->pytorch_lightning) (1.26.14)\n",
            "Installing collected packages: tensorboardX, torchmetrics, lightning-utilities, pytorch_lightning\n",
            "Successfully installed lightning-utilities-0.5.0 pytorch_lightning-1.8.6 tensorboardX-2.5.1 torchmetrics-0.11.0\n"
          ]
        }
      ],
      "source": [
        "!pip install pytorch_lightning "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dQhMEz45Iqmr"
      },
      "source": [
        "### Load the CIFAR10 dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 132,
          "referenced_widgets": [
            "838ac074a4044eef98c91a32f28f6825",
            "a7733d25dfe24108b41bb5e195ecabf9",
            "3990f04987e8493eb28834a49f508de1",
            "d669faa08c284fcab3f6d229dc59df0d",
            "4c48e6d9983049f499494b114e6c9c72",
            "0aeba8524f5e4142996fc02aa4b4e4a6",
            "3817ed9bd11d4d4bbe9768a2ea1928e4",
            "c201d78bbbe4443db2ad74ea1872925b",
            "228a2886fa1547d293d8423f77020517",
            "35c4a4107b1c4038bb8cdac3284d262a",
            "1bf3ae7f6a1940ff9626403fec836291"
          ]
        },
        "id": "eFjx9uW4IwJM",
        "outputId": "f9ec871f-9b47-4f8a-d40d-e668cb4d1f3e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to ./data/cifar-10-python.tar.gz\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "838ac074a4044eef98c91a32f28f6825",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/170498071 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Extracting ./data/cifar-10-python.tar.gz to ./data\n"
          ]
        }
      ],
      "source": [
        "from torchvision import transforms\n",
        "from torchvision.datasets import CIFAR10\n",
        "\n",
        "\n",
        "transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
        "train_dataset = CIFAR10(root=\"./data\", train=True, download=True, transform=transform)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ly5CmsWPIgTR"
      },
      "source": [
        "### Define the supergraph "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9poWiHG2b86T",
        "outputId": "4c614c0d-5c41-41ef-cb3c-ce832e21b05f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n",
            "/usr/local/lib/python3.8/dist-packages/torch/utils/data/dataloader.py:554: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n",
            "[2023-01-12 15:08:08] \u001b[32mEpoch [1/2] Step [1/391]  acc1 0.093750 (0.093750)  loss 2.325025 (2.325025)\u001b[0m\n",
            "INFO:nni.retiarii.oneshot.pytorch.darts:Epoch [1/2] Step [1/391]  acc1 0.093750 (0.093750)  loss 2.325025 (2.325025)\n",
            "[2023-01-12 15:08:21] \u001b[32mEpoch [1/2] Step [11/391]  acc1 0.140625 (0.146307)  loss 2.252611 (2.261288)\u001b[0m\n",
            "INFO:nni.retiarii.oneshot.pytorch.darts:Epoch [1/2] Step [11/391]  acc1 0.140625 (0.146307)  loss 2.252611 (2.261288)\n",
            "[2023-01-12 15:08:35] \u001b[32mEpoch [1/2] Step [21/391]  acc1 0.265625 (0.190476)  loss 1.993528 (2.177278)\u001b[0m\n",
            "INFO:nni.retiarii.oneshot.pytorch.darts:Epoch [1/2] Step [21/391]  acc1 0.265625 (0.190476)  loss 1.993528 (2.177278)\n",
            "[2023-01-12 15:08:49] \u001b[32mEpoch [1/2] Step [31/391]  acc1 0.171875 (0.202621)  loss 1.972495 (2.104162)\u001b[0m\n",
            "INFO:nni.retiarii.oneshot.pytorch.darts:Epoch [1/2] Step [31/391]  acc1 0.171875 (0.202621)  loss 1.972495 (2.104162)\n",
            "[2023-01-12 15:09:03] \u001b[32mEpoch [1/2] Step [41/391]  acc1 0.312500 (0.219131)  loss 1.814376 (2.054789)\u001b[0m\n",
            "INFO:nni.retiarii.oneshot.pytorch.darts:Epoch [1/2] Step [41/391]  acc1 0.312500 (0.219131)  loss 1.814376 (2.054789)\n",
            "[2023-01-12 15:09:17] \u001b[32mEpoch [1/2] Step [51/391]  acc1 0.312500 (0.233762)  loss 1.922975 (2.010876)\u001b[0m\n",
            "INFO:nni.retiarii.oneshot.pytorch.darts:Epoch [1/2] Step [51/391]  acc1 0.312500 (0.233762)  loss 1.922975 (2.010876)\n",
            "[2023-01-12 15:09:31] \u001b[32mEpoch [1/2] Step [61/391]  acc1 0.421875 (0.247695)  loss 1.644584 (1.969535)\u001b[0m\n",
            "INFO:nni.retiarii.oneshot.pytorch.darts:Epoch [1/2] Step [61/391]  acc1 0.421875 (0.247695)  loss 1.644584 (1.969535)\n",
            "[2023-01-12 15:09:45] \u001b[32mEpoch [1/2] Step [71/391]  acc1 0.218750 (0.256602)  loss 1.878355 (1.949468)\u001b[0m\n",
            "INFO:nni.retiarii.oneshot.pytorch.darts:Epoch [1/2] Step [71/391]  acc1 0.218750 (0.256602)  loss 1.878355 (1.949468)\n",
            "[2023-01-12 15:09:59] \u001b[32mEpoch [1/2] Step [81/391]  acc1 0.359375 (0.263310)  loss 1.592396 (1.927939)\u001b[0m\n",
            "INFO:nni.retiarii.oneshot.pytorch.darts:Epoch [1/2] Step [81/391]  acc1 0.359375 (0.263310)  loss 1.592396 (1.927939)\n",
            "[2023-01-12 15:10:12] \u001b[32mEpoch [1/2] Step [91/391]  acc1 0.343750 (0.269059)  loss 1.717942 (1.906529)\u001b[0m\n",
            "INFO:nni.retiarii.oneshot.pytorch.darts:Epoch [1/2] Step [91/391]  acc1 0.343750 (0.269059)  loss 1.717942 (1.906529)\n",
            "[2023-01-12 15:10:26] \u001b[32mEpoch [1/2] Step [101/391]  acc1 0.328125 (0.277382)  loss 1.674942 (1.884406)\u001b[0m\n",
            "INFO:nni.retiarii.oneshot.pytorch.darts:Epoch [1/2] Step [101/391]  acc1 0.328125 (0.277382)  loss 1.674942 (1.884406)\n",
            "[2023-01-12 15:10:40] \u001b[32mEpoch [1/2] Step [111/391]  acc1 0.312500 (0.284628)  loss 1.716893 (1.864941)\u001b[0m\n",
            "INFO:nni.retiarii.oneshot.pytorch.darts:Epoch [1/2] Step [111/391]  acc1 0.312500 (0.284628)  loss 1.716893 (1.864941)\n",
            "[2023-01-12 15:10:54] \u001b[32mEpoch [1/2] Step [121/391]  acc1 0.343750 (0.289256)  loss 1.736657 (1.847783)\u001b[0m\n",
            "INFO:nni.retiarii.oneshot.pytorch.darts:Epoch [1/2] Step [121/391]  acc1 0.343750 (0.289256)  loss 1.736657 (1.847783)\n",
            "[2023-01-12 15:11:08] \u001b[32mEpoch [1/2] Step [131/391]  acc1 0.281250 (0.294967)  loss 1.748434 (1.833258)\u001b[0m\n",
            "INFO:nni.retiarii.oneshot.pytorch.darts:Epoch [1/2] Step [131/391]  acc1 0.281250 (0.294967)  loss 1.748434 (1.833258)\n",
            "[2023-01-12 15:11:21] \u001b[32mEpoch [1/2] Step [141/391]  acc1 0.250000 (0.302859)  loss 1.674682 (1.815978)\u001b[0m\n",
            "INFO:nni.retiarii.oneshot.pytorch.darts:Epoch [1/2] Step [141/391]  acc1 0.250000 (0.302859)  loss 1.674682 (1.815978)\n",
            "[2023-01-12 15:11:35] \u001b[32mEpoch [1/2] Step [151/391]  acc1 0.437500 (0.311569)  loss 1.460072 (1.798679)\u001b[0m\n",
            "INFO:nni.retiarii.oneshot.pytorch.darts:Epoch [1/2] Step [151/391]  acc1 0.437500 (0.311569)  loss 1.460072 (1.798679)\n",
            "[2023-01-12 15:11:49] \u001b[32mEpoch [1/2] Step [161/391]  acc1 0.421875 (0.317838)  loss 1.483249 (1.782627)\u001b[0m\n",
            "INFO:nni.retiarii.oneshot.pytorch.darts:Epoch [1/2] Step [161/391]  acc1 0.421875 (0.317838)  loss 1.483249 (1.782627)\n",
            "[2023-01-12 15:12:03] \u001b[32mEpoch [1/2] Step [171/391]  acc1 0.562500 (0.323465)  loss 1.550856 (1.768865)\u001b[0m\n",
            "INFO:nni.retiarii.oneshot.pytorch.darts:Epoch [1/2] Step [171/391]  acc1 0.562500 (0.323465)  loss 1.550856 (1.768865)\n",
            "[2023-01-12 15:12:17] \u001b[32mEpoch [1/2] Step [181/391]  acc1 0.421875 (0.329593)  loss 1.451035 (1.753371)\u001b[0m\n",
            "INFO:nni.retiarii.oneshot.pytorch.darts:Epoch [1/2] Step [181/391]  acc1 0.421875 (0.329593)  loss 1.451035 (1.753371)\n",
            "[2023-01-12 15:12:31] \u001b[32mEpoch [1/2] Step [191/391]  acc1 0.453125 (0.335079)  loss 1.294507 (1.740635)\u001b[0m\n",
            "INFO:nni.retiarii.oneshot.pytorch.darts:Epoch [1/2] Step [191/391]  acc1 0.453125 (0.335079)  loss 1.294507 (1.740635)\n",
            "[2023-01-12 15:12:45] \u001b[32mEpoch [1/2] Step [201/391]  acc1 0.468750 (0.339475)  loss 1.411463 (1.730144)\u001b[0m\n",
            "INFO:nni.retiarii.oneshot.pytorch.darts:Epoch [1/2] Step [201/391]  acc1 0.468750 (0.339475)  loss 1.411463 (1.730144)\n",
            "[2023-01-12 15:12:59] \u001b[32mEpoch [1/2] Step [211/391]  acc1 0.468750 (0.345749)  loss 1.448782 (1.719233)\u001b[0m\n",
            "INFO:nni.retiarii.oneshot.pytorch.darts:Epoch [1/2] Step [211/391]  acc1 0.468750 (0.345749)  loss 1.448782 (1.719233)\n",
            "[2023-01-12 15:13:13] \u001b[32mEpoch [1/2] Step [221/391]  acc1 0.312500 (0.348840)  loss 1.592057 (1.710695)\u001b[0m\n",
            "INFO:nni.retiarii.oneshot.pytorch.darts:Epoch [1/2] Step [221/391]  acc1 0.312500 (0.348840)  loss 1.592057 (1.710695)\n",
            "[2023-01-12 15:13:26] \u001b[32mEpoch [1/2] Step [231/391]  acc1 0.484375 (0.352746)  loss 1.408344 (1.700510)\u001b[0m\n",
            "INFO:nni.retiarii.oneshot.pytorch.darts:Epoch [1/2] Step [231/391]  acc1 0.484375 (0.352746)  loss 1.408344 (1.700510)\n",
            "[2023-01-12 15:13:40] \u001b[32mEpoch [1/2] Step [241/391]  acc1 0.484375 (0.358013)  loss 1.402494 (1.691081)\u001b[0m\n",
            "INFO:nni.retiarii.oneshot.pytorch.darts:Epoch [1/2] Step [241/391]  acc1 0.484375 (0.358013)  loss 1.402494 (1.691081)\n",
            "[2023-01-12 15:13:54] \u001b[32mEpoch [1/2] Step [251/391]  acc1 0.390625 (0.362114)  loss 1.614459 (1.682802)\u001b[0m\n",
            "INFO:nni.retiarii.oneshot.pytorch.darts:Epoch [1/2] Step [251/391]  acc1 0.390625 (0.362114)  loss 1.614459 (1.682802)\n",
            "[2023-01-12 15:14:08] \u001b[32mEpoch [1/2] Step [261/391]  acc1 0.515625 (0.366619)  loss 1.175579 (1.671874)\u001b[0m\n",
            "INFO:nni.retiarii.oneshot.pytorch.darts:Epoch [1/2] Step [261/391]  acc1 0.515625 (0.366619)  loss 1.175579 (1.671874)\n",
            "[2023-01-12 15:14:22] \u001b[32mEpoch [1/2] Step [271/391]  acc1 0.453125 (0.371252)  loss 1.354249 (1.661594)\u001b[0m\n",
            "INFO:nni.retiarii.oneshot.pytorch.darts:Epoch [1/2] Step [271/391]  acc1 0.453125 (0.371252)  loss 1.354249 (1.661594)\n",
            "[2023-01-12 15:14:35] \u001b[32mEpoch [1/2] Step [281/391]  acc1 0.328125 (0.374944)  loss 1.432504 (1.652337)\u001b[0m\n",
            "INFO:nni.retiarii.oneshot.pytorch.darts:Epoch [1/2] Step [281/391]  acc1 0.328125 (0.374944)  loss 1.432504 (1.652337)\n",
            "[2023-01-12 15:14:49] \u001b[32mEpoch [1/2] Step [291/391]  acc1 0.500000 (0.378007)  loss 1.373685 (1.643472)\u001b[0m\n",
            "INFO:nni.retiarii.oneshot.pytorch.darts:Epoch [1/2] Step [291/391]  acc1 0.500000 (0.378007)  loss 1.373685 (1.643472)\n",
            "[2023-01-12 15:15:03] \u001b[32mEpoch [1/2] Step [301/391]  acc1 0.500000 (0.381177)  loss 1.332281 (1.635183)\u001b[0m\n",
            "INFO:nni.retiarii.oneshot.pytorch.darts:Epoch [1/2] Step [301/391]  acc1 0.500000 (0.381177)  loss 1.332281 (1.635183)\n",
            "[2023-01-12 15:15:17] \u001b[32mEpoch [1/2] Step [311/391]  acc1 0.562500 (0.385199)  loss 1.244575 (1.624980)\u001b[0m\n",
            "INFO:nni.retiarii.oneshot.pytorch.darts:Epoch [1/2] Step [311/391]  acc1 0.562500 (0.385199)  loss 1.244575 (1.624980)\n",
            "[2023-01-12 15:15:30] \u001b[32mEpoch [1/2] Step [321/391]  acc1 0.500000 (0.387850)  loss 1.280852 (1.616683)\u001b[0m\n",
            "INFO:nni.retiarii.oneshot.pytorch.darts:Epoch [1/2] Step [321/391]  acc1 0.500000 (0.387850)  loss 1.280852 (1.616683)\n",
            "[2023-01-12 15:15:44] \u001b[32mEpoch [1/2] Step [331/391]  acc1 0.656250 (0.391852)  loss 1.149802 (1.607788)\u001b[0m\n",
            "INFO:nni.retiarii.oneshot.pytorch.darts:Epoch [1/2] Step [331/391]  acc1 0.656250 (0.391852)  loss 1.149802 (1.607788)\n",
            "[2023-01-12 15:15:58] \u001b[32mEpoch [1/2] Step [341/391]  acc1 0.640625 (0.395986)  loss 1.150435 (1.600271)\u001b[0m\n",
            "INFO:nni.retiarii.oneshot.pytorch.darts:Epoch [1/2] Step [341/391]  acc1 0.640625 (0.395986)  loss 1.150435 (1.600271)\n",
            "[2023-01-12 15:16:12] \u001b[32mEpoch [1/2] Step [351/391]  acc1 0.468750 (0.399573)  loss 1.387545 (1.591676)\u001b[0m\n",
            "INFO:nni.retiarii.oneshot.pytorch.darts:Epoch [1/2] Step [351/391]  acc1 0.468750 (0.399573)  loss 1.387545 (1.591676)\n",
            "[2023-01-12 15:16:26] \u001b[32mEpoch [1/2] Step [361/391]  acc1 0.546875 (0.402441)  loss 1.305741 (1.585695)\u001b[0m\n",
            "INFO:nni.retiarii.oneshot.pytorch.darts:Epoch [1/2] Step [361/391]  acc1 0.546875 (0.402441)  loss 1.305741 (1.585695)\n",
            "[2023-01-12 15:16:39] \u001b[32mEpoch [1/2] Step [371/391]  acc1 0.593750 (0.406545)  loss 1.297472 (1.577509)\u001b[0m\n",
            "INFO:nni.retiarii.oneshot.pytorch.darts:Epoch [1/2] Step [371/391]  acc1 0.593750 (0.406545)  loss 1.297472 (1.577509)\n",
            "[2023-01-12 15:16:53] \u001b[32mEpoch [1/2] Step [381/391]  acc1 0.578125 (0.409695)  loss 1.271655 (1.569835)\u001b[0m\n",
            "INFO:nni.retiarii.oneshot.pytorch.darts:Epoch [1/2] Step [381/391]  acc1 0.578125 (0.409695)  loss 1.271655 (1.569835)\n",
            "[2023-01-12 15:17:06] \u001b[32mEpoch [1/2] Step [391/391]  acc1 0.475000 (0.412700)  loss 1.427800 (1.563306)\u001b[0m\n",
            "INFO:nni.retiarii.oneshot.pytorch.darts:Epoch [1/2] Step [391/391]  acc1 0.475000 (0.412700)  loss 1.427800 (1.563306)\n",
            "[2023-01-12 15:17:09] \u001b[32mEpoch [2/2] Step [1/391]  acc1 0.484375 (0.484375)  loss 1.274284 (1.274284)\u001b[0m\n",
            "INFO:nni.retiarii.oneshot.pytorch.darts:Epoch [2/2] Step [1/391]  acc1 0.484375 (0.484375)  loss 1.274284 (1.274284)\n",
            "[2023-01-12 15:17:23] \u001b[32mEpoch [2/2] Step [11/391]  acc1 0.515625 (0.521307)  loss 1.405203 (1.282541)\u001b[0m\n",
            "INFO:nni.retiarii.oneshot.pytorch.darts:Epoch [2/2] Step [11/391]  acc1 0.515625 (0.521307)  loss 1.405203 (1.282541)\n",
            "[2023-01-12 15:17:37] \u001b[32mEpoch [2/2] Step [21/391]  acc1 0.578125 (0.512649)  loss 1.208980 (1.301412)\u001b[0m\n",
            "INFO:nni.retiarii.oneshot.pytorch.darts:Epoch [2/2] Step [21/391]  acc1 0.578125 (0.512649)  loss 1.208980 (1.301412)\n",
            "[2023-01-12 15:17:50] \u001b[32mEpoch [2/2] Step [31/391]  acc1 0.609375 (0.529234)  loss 1.242723 (1.279315)\u001b[0m\n",
            "INFO:nni.retiarii.oneshot.pytorch.darts:Epoch [2/2] Step [31/391]  acc1 0.609375 (0.529234)  loss 1.242723 (1.279315)\n",
            "[2023-01-12 15:18:05] \u001b[32mEpoch [2/2] Step [41/391]  acc1 0.484375 (0.538872)  loss 1.414391 (1.260628)\u001b[0m\n",
            "INFO:nni.retiarii.oneshot.pytorch.darts:Epoch [2/2] Step [41/391]  acc1 0.484375 (0.538872)  loss 1.414391 (1.260628)\n",
            "[2023-01-12 15:18:19] \u001b[32mEpoch [2/2] Step [51/391]  acc1 0.703125 (0.542279)  loss 1.051193 (1.249028)\u001b[0m\n",
            "INFO:nni.retiarii.oneshot.pytorch.darts:Epoch [2/2] Step [51/391]  acc1 0.703125 (0.542279)  loss 1.051193 (1.249028)\n",
            "[2023-01-12 15:18:33] \u001b[32mEpoch [2/2] Step [61/391]  acc1 0.562500 (0.542264)  loss 1.125068 (1.248299)\u001b[0m\n",
            "INFO:nni.retiarii.oneshot.pytorch.darts:Epoch [2/2] Step [61/391]  acc1 0.562500 (0.542264)  loss 1.125068 (1.248299)\n",
            "[2023-01-12 15:18:47] \u001b[32mEpoch [2/2] Step [71/391]  acc1 0.546875 (0.545995)  loss 1.167754 (1.237644)\u001b[0m\n",
            "INFO:nni.retiarii.oneshot.pytorch.darts:Epoch [2/2] Step [71/391]  acc1 0.546875 (0.545995)  loss 1.167754 (1.237644)\n",
            "[2023-01-12 15:19:01] \u001b[32mEpoch [2/2] Step [81/391]  acc1 0.500000 (0.548804)  loss 1.256192 (1.227507)\u001b[0m\n",
            "INFO:nni.retiarii.oneshot.pytorch.darts:Epoch [2/2] Step [81/391]  acc1 0.500000 (0.548804)  loss 1.256192 (1.227507)\n",
            "[2023-01-12 15:19:14] \u001b[32mEpoch [2/2] Step [91/391]  acc1 0.546875 (0.553915)  loss 1.046689 (1.216629)\u001b[0m\n",
            "INFO:nni.retiarii.oneshot.pytorch.darts:Epoch [2/2] Step [91/391]  acc1 0.546875 (0.553915)  loss 1.046689 (1.216629)\n",
            "[2023-01-12 15:19:28] \u001b[32mEpoch [2/2] Step [101/391]  acc1 0.593750 (0.555848)  loss 1.189914 (1.215421)\u001b[0m\n",
            "INFO:nni.retiarii.oneshot.pytorch.darts:Epoch [2/2] Step [101/391]  acc1 0.593750 (0.555848)  loss 1.189914 (1.215421)\n",
            "[2023-01-12 15:19:42] \u001b[32mEpoch [2/2] Step [111/391]  acc1 0.609375 (0.556025)  loss 1.226803 (1.216210)\u001b[0m\n",
            "INFO:nni.retiarii.oneshot.pytorch.darts:Epoch [2/2] Step [111/391]  acc1 0.609375 (0.556025)  loss 1.226803 (1.216210)\n",
            "[2023-01-12 15:19:56] \u001b[32mEpoch [2/2] Step [121/391]  acc1 0.578125 (0.553719)  loss 1.233730 (1.224690)\u001b[0m\n",
            "INFO:nni.retiarii.oneshot.pytorch.darts:Epoch [2/2] Step [121/391]  acc1 0.578125 (0.553719)  loss 1.233730 (1.224690)\n",
            "[2023-01-12 15:20:10] \u001b[32mEpoch [2/2] Step [131/391]  acc1 0.546875 (0.553077)  loss 1.336968 (1.220640)\u001b[0m\n",
            "INFO:nni.retiarii.oneshot.pytorch.darts:Epoch [2/2] Step [131/391]  acc1 0.546875 (0.553077)  loss 1.336968 (1.220640)\n",
            "[2023-01-12 15:20:24] \u001b[32mEpoch [2/2] Step [141/391]  acc1 0.578125 (0.556627)  loss 1.126225 (1.214403)\u001b[0m\n",
            "INFO:nni.retiarii.oneshot.pytorch.darts:Epoch [2/2] Step [141/391]  acc1 0.578125 (0.556627)  loss 1.126225 (1.214403)\n",
            "[2023-01-12 15:20:37] \u001b[32mEpoch [2/2] Step [151/391]  acc1 0.515625 (0.558878)  loss 1.175728 (1.210329)\u001b[0m\n",
            "INFO:nni.retiarii.oneshot.pytorch.darts:Epoch [2/2] Step [151/391]  acc1 0.515625 (0.558878)  loss 1.175728 (1.210329)\n",
            "[2023-01-12 15:20:51] \u001b[32mEpoch [2/2] Step [161/391]  acc1 0.609375 (0.561432)  loss 1.036757 (1.204860)\u001b[0m\n",
            "INFO:nni.retiarii.oneshot.pytorch.darts:Epoch [2/2] Step [161/391]  acc1 0.609375 (0.561432)  loss 1.036757 (1.204860)\n",
            "[2023-01-12 15:21:05] \u001b[32mEpoch [2/2] Step [171/391]  acc1 0.640625 (0.561221)  loss 0.949542 (1.203163)\u001b[0m\n",
            "INFO:nni.retiarii.oneshot.pytorch.darts:Epoch [2/2] Step [171/391]  acc1 0.640625 (0.561221)  loss 0.949542 (1.203163)\n",
            "[2023-01-12 15:21:19] \u001b[32mEpoch [2/2] Step [181/391]  acc1 0.703125 (0.563191)  loss 0.993324 (1.200848)\u001b[0m\n",
            "INFO:nni.retiarii.oneshot.pytorch.darts:Epoch [2/2] Step [181/391]  acc1 0.703125 (0.563191)  loss 0.993324 (1.200848)\n",
            "[2023-01-12 15:21:33] \u001b[32mEpoch [2/2] Step [191/391]  acc1 0.656250 (0.565281)  loss 1.113521 (1.194298)\u001b[0m\n",
            "INFO:nni.retiarii.oneshot.pytorch.darts:Epoch [2/2] Step [191/391]  acc1 0.656250 (0.565281)  loss 1.113521 (1.194298)\n",
            "[2023-01-12 15:21:46] \u001b[32mEpoch [2/2] Step [201/391]  acc1 0.609375 (0.567164)  loss 1.117557 (1.189252)\u001b[0m\n",
            "INFO:nni.retiarii.oneshot.pytorch.darts:Epoch [2/2] Step [201/391]  acc1 0.609375 (0.567164)  loss 1.117557 (1.189252)\n",
            "[2023-01-12 15:22:00] \u001b[32mEpoch [2/2] Step [211/391]  acc1 0.531250 (0.567610)  loss 1.227235 (1.186783)\u001b[0m\n",
            "INFO:nni.retiarii.oneshot.pytorch.darts:Epoch [2/2] Step [211/391]  acc1 0.531250 (0.567610)  loss 1.227235 (1.186783)\n",
            "[2023-01-12 15:22:14] \u001b[32mEpoch [2/2] Step [221/391]  acc1 0.562500 (0.566318)  loss 1.196938 (1.189331)\u001b[0m\n",
            "INFO:nni.retiarii.oneshot.pytorch.darts:Epoch [2/2] Step [221/391]  acc1 0.562500 (0.566318)  loss 1.196938 (1.189331)\n",
            "[2023-01-12 15:22:28] \u001b[32mEpoch [2/2] Step [231/391]  acc1 0.500000 (0.567911)  loss 1.250031 (1.184891)\u001b[0m\n",
            "INFO:nni.retiarii.oneshot.pytorch.darts:Epoch [2/2] Step [231/391]  acc1 0.500000 (0.567911)  loss 1.250031 (1.184891)\n",
            "[2023-01-12 15:22:42] \u001b[32mEpoch [2/2] Step [241/391]  acc1 0.750000 (0.570150)  loss 0.968046 (1.178952)\u001b[0m\n",
            "INFO:nni.retiarii.oneshot.pytorch.darts:Epoch [2/2] Step [241/391]  acc1 0.750000 (0.570150)  loss 0.968046 (1.178952)\n",
            "[2023-01-12 15:23:09] \u001b[32mEpoch [2/2] Step [261/391]  acc1 0.515625 (0.572258)  loss 1.262882 (1.176296)\u001b[0m\n",
            "INFO:nni.retiarii.oneshot.pytorch.darts:Epoch [2/2] Step [261/391]  acc1 0.515625 (0.572258)  loss 1.262882 (1.176296)\n",
            "[2023-01-12 15:23:23] \u001b[32mEpoch [2/2] Step [271/391]  acc1 0.671875 (0.574147)  loss 1.152547 (1.173720)\u001b[0m\n",
            "INFO:nni.retiarii.oneshot.pytorch.darts:Epoch [2/2] Step [271/391]  acc1 0.671875 (0.574147)  loss 1.152547 (1.173720)\n",
            "[2023-01-12 15:23:37] \u001b[32mEpoch [2/2] Step [281/391]  acc1 0.640625 (0.574900)  loss 1.150602 (1.170845)\u001b[0m\n",
            "INFO:nni.retiarii.oneshot.pytorch.darts:Epoch [2/2] Step [281/391]  acc1 0.640625 (0.574900)  loss 1.150602 (1.170845)\n",
            "[2023-01-12 15:23:51] \u001b[32mEpoch [2/2] Step [291/391]  acc1 0.484375 (0.575762)  loss 1.262098 (1.169050)\u001b[0m\n",
            "INFO:nni.retiarii.oneshot.pytorch.darts:Epoch [2/2] Step [291/391]  acc1 0.484375 (0.575762)  loss 1.262098 (1.169050)\n",
            "[2023-01-12 15:24:05] \u001b[32mEpoch [2/2] Step [301/391]  acc1 0.562500 (0.576775)  loss 1.382029 (1.165490)\u001b[0m\n",
            "INFO:nni.retiarii.oneshot.pytorch.darts:Epoch [2/2] Step [301/391]  acc1 0.562500 (0.576775)  loss 1.382029 (1.165490)\n",
            "[2023-01-12 15:24:19] \u001b[32mEpoch [2/2] Step [311/391]  acc1 0.718750 (0.578025)  loss 0.825911 (1.162290)\u001b[0m\n",
            "INFO:nni.retiarii.oneshot.pytorch.darts:Epoch [2/2] Step [311/391]  acc1 0.718750 (0.578025)  loss 0.825911 (1.162290)\n",
            "[2023-01-12 15:24:33] \u001b[32mEpoch [2/2] Step [321/391]  acc1 0.718750 (0.580169)  loss 1.032239 (1.157186)\u001b[0m\n",
            "INFO:nni.retiarii.oneshot.pytorch.darts:Epoch [2/2] Step [321/391]  acc1 0.718750 (0.580169)  loss 1.032239 (1.157186)\n",
            "[2023-01-12 15:24:47] \u001b[32mEpoch [2/2] Step [331/391]  acc1 0.625000 (0.581665)  loss 1.051364 (1.153353)\u001b[0m\n",
            "INFO:nni.retiarii.oneshot.pytorch.darts:Epoch [2/2] Step [331/391]  acc1 0.625000 (0.581665)  loss 1.051364 (1.153353)\n",
            "[2023-01-12 15:25:00] \u001b[32mEpoch [2/2] Step [341/391]  acc1 0.609375 (0.581882)  loss 0.975958 (1.152639)\u001b[0m\n",
            "INFO:nni.retiarii.oneshot.pytorch.darts:Epoch [2/2] Step [341/391]  acc1 0.609375 (0.581882)  loss 0.975958 (1.152639)\n",
            "[2023-01-12 15:25:14] \u001b[32mEpoch [2/2] Step [351/391]  acc1 0.687500 (0.583200)  loss 0.960665 (1.149641)\u001b[0m\n",
            "INFO:nni.retiarii.oneshot.pytorch.darts:Epoch [2/2] Step [351/391]  acc1 0.687500 (0.583200)  loss 0.960665 (1.149641)\n",
            "[2023-01-12 15:25:28] \u001b[32mEpoch [2/2] Step [361/391]  acc1 0.671875 (0.584531)  loss 0.969331 (1.146933)\u001b[0m\n",
            "INFO:nni.retiarii.oneshot.pytorch.darts:Epoch [2/2] Step [361/391]  acc1 0.671875 (0.584531)  loss 0.969331 (1.146933)\n",
            "[2023-01-12 15:25:42] \u001b[32mEpoch [2/2] Step [371/391]  acc1 0.500000 (0.585622)  loss 1.291717 (1.143855)\u001b[0m\n",
            "INFO:nni.retiarii.oneshot.pytorch.darts:Epoch [2/2] Step [371/391]  acc1 0.500000 (0.585622)  loss 1.291717 (1.143855)\n",
            "[2023-01-12 15:25:56] \u001b[32mEpoch [2/2] Step [381/391]  acc1 0.640625 (0.587065)  loss 1.118164 (1.140878)\u001b[0m\n",
            "INFO:nni.retiarii.oneshot.pytorch.darts:Epoch [2/2] Step [381/391]  acc1 0.640625 (0.587065)  loss 1.118164 (1.140878)\n",
            "[2023-01-12 15:26:09] \u001b[32mEpoch [2/2] Step [391/391]  acc1 0.600000 (0.587772)  loss 0.938599 (1.139237)\u001b[0m\n",
            "INFO:nni.retiarii.oneshot.pytorch.darts:Epoch [2/2] Step [391/391]  acc1 0.600000 (0.587772)  loss 0.938599 (1.139237)\n",
            "Final architecture: {'normal_n2_p0': 'maxpool', 'normal_n2_p1': 'maxpool', 'normal_n3_p0': 'maxpool', 'normal_n3_p1': 'maxpool', 'normal_n3_p2': 'maxpool', 'normal_n4_p0': 'maxpool', 'normal_n4_p1': 'maxpool', 'normal_n4_p2': 'maxpool', 'normal_n4_p3': 'maxpool', 'normal_n5_p0': 'maxpool', 'normal_n5_p1': 'maxpool', 'normal_n5_p2': 'maxpool', 'normal_n5_p3': 'maxpool', 'normal_n5_p4': 'maxpool', 'reduce_n2_p0': 'maxpool', 'reduce_n2_p1': 'sepconv3x3', 'reduce_n3_p0': 'maxpool', 'reduce_n3_p1': 'sepconv5x5', 'reduce_n3_p2': 'dilconv5x5', 'reduce_n4_p0': 'maxpool', 'reduce_n4_p1': 'sepconv5x5', 'reduce_n4_p2': 'dilconv5x5', 'reduce_n4_p3': 'sepconv5x5', 'reduce_n5_p0': 'maxpool', 'reduce_n5_p1': 'dilconv5x5', 'reduce_n5_p2': 'maxpool', 'reduce_n5_p3': 'sepconv5x5', 'reduce_n5_p4': 'maxpool', 'normal_n2_switch': [0, 1], 'normal_n3_switch': [1, 0], 'normal_n4_switch': [2, 0], 'normal_n5_switch': [2, 1], 'reduce_n2_switch': [0, 1], 'reduce_n3_switch': [0, 2], 'reduce_n4_switch': [0, 2], 'reduce_n5_switch': [4, 3]}\n"
          ]
        }
      ],
      "source": [
        "!python examples/nas/oneshot/darts/search.py --epochs 2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "hyfk6AtBYbUY",
        "outputId": "4505f38a-2bfc-4db7-fdd7-8307d7886431"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to ./data/cifar-10-python.tar.gz\n",
            "100% 170498071/170498071 [00:05<00:00, 29270724.58it/s]\n",
            "Extracting ./data/cifar-10-python.tar.gz to ./data\n",
            "Files already downloaded and verified\n",
            "[2023-01-12 15:41:15] \u001b[32mFixed architecture: {'normal_n2_p0': 'maxpool', 'normal_n2_p1': 'maxpool', 'normal_n3_p0': 'maxpool', 'normal_n3_p1': 'maxpool', 'normal_n3_p2': 'maxpool', 'normal_n4_p0': 'maxpool', 'normal_n4_p1': 'maxpool', 'normal_n4_p2': 'maxpool', 'normal_n4_p3': 'maxpool', 'normal_n5_p0': 'maxpool', 'normal_n5_p1': 'maxpool', 'normal_n5_p2': 'maxpool', 'normal_n5_p3': 'maxpool', 'normal_n5_p4': 'maxpool', 'reduce_n2_p0': 'maxpool', 'reduce_n2_p1': 'sepconv3x3', 'reduce_n3_p0': 'maxpool', 'reduce_n3_p1': 'sepconv5x5', 'reduce_n3_p2': 'dilconv5x5', 'reduce_n4_p0': 'maxpool', 'reduce_n4_p1': 'sepconv5x5', 'reduce_n4_p2': 'dilconv5x5', 'reduce_n4_p3': 'sepconv5x5', 'reduce_n5_p0': 'maxpool', 'reduce_n5_p1': 'dilconv5x5', 'reduce_n5_p2': 'maxpool', 'reduce_n5_p3': 'sepconv5x5', 'reduce_n5_p4': 'maxpool', 'normal_n2_switch': [0, 1], 'normal_n3_switch': [1, 0], 'normal_n4_switch': [2, 0], 'normal_n5_switch': [2, 1], 'reduce_n2_switch': [0, 1], 'reduce_n3_switch': [0, 2], 'reduce_n4_switch': [0, 2], 'reduce_n5_switch': [4, 3]}\u001b[0m\n",
            "INFO:nni.nas.fixed:Fixed architecture: {'normal_n2_p0': 'maxpool', 'normal_n2_p1': 'maxpool', 'normal_n3_p0': 'maxpool', 'normal_n3_p1': 'maxpool', 'normal_n3_p2': 'maxpool', 'normal_n4_p0': 'maxpool', 'normal_n4_p1': 'maxpool', 'normal_n4_p2': 'maxpool', 'normal_n4_p3': 'maxpool', 'normal_n5_p0': 'maxpool', 'normal_n5_p1': 'maxpool', 'normal_n5_p2': 'maxpool', 'normal_n5_p3': 'maxpool', 'normal_n5_p4': 'maxpool', 'reduce_n2_p0': 'maxpool', 'reduce_n2_p1': 'sepconv3x3', 'reduce_n3_p0': 'maxpool', 'reduce_n3_p1': 'sepconv5x5', 'reduce_n3_p2': 'dilconv5x5', 'reduce_n4_p0': 'maxpool', 'reduce_n4_p1': 'sepconv5x5', 'reduce_n4_p2': 'dilconv5x5', 'reduce_n4_p3': 'sepconv5x5', 'reduce_n5_p0': 'maxpool', 'reduce_n5_p1': 'dilconv5x5', 'reduce_n5_p2': 'maxpool', 'reduce_n5_p3': 'sepconv5x5', 'reduce_n5_p4': 'maxpool', 'normal_n2_switch': [0, 1], 'normal_n3_switch': [1, 0], 'normal_n4_switch': [2, 0], 'normal_n5_switch': [2, 1], 'reduce_n2_switch': [0, 1], 'reduce_n3_switch': [0, 2], 'reduce_n4_switch': [0, 2], 'reduce_n5_switch': [4, 3]}\n",
            "/usr/local/lib/python3.8/dist-packages/torch/utils/data/dataloader.py:554: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n",
            "[2023-01-12 15:41:18] \u001b[32mEpoch 0 LR 0.025000\u001b[0m\n",
            "INFO:nni:Epoch 0 LR 0.025000\n",
            "[2023-01-12 15:41:21] \u001b[32mTrain: [  1/600] Step 000/520 Loss 3.387 Prec@(1,5) (10.4%, 58.3%)\u001b[0m\n",
            "INFO:nni:Train: [  1/600] Step 000/520 Loss 3.387 Prec@(1,5) (10.4%, 58.3%)\n",
            "[2023-01-12 15:41:25] \u001b[32mTrain: [  1/600] Step 010/520 Loss 3.362 Prec@(1,5) (14.8%, 59.8%)\u001b[0m\n",
            "INFO:nni:Train: [  1/600] Step 010/520 Loss 3.362 Prec@(1,5) (14.8%, 59.8%)\n",
            "[2023-01-12 15:41:29] \u001b[32mTrain: [  1/600] Step 020/520 Loss 3.328 Prec@(1,5) (15.4%, 61.0%)\u001b[0m\n",
            "INFO:nni:Train: [  1/600] Step 020/520 Loss 3.328 Prec@(1,5) (15.4%, 61.0%)\n",
            "[2023-01-12 15:41:32] \u001b[32mTrain: [  1/600] Step 030/520 Loss 3.340 Prec@(1,5) (16.2%, 63.4%)\u001b[0m\n",
            "INFO:nni:Train: [  1/600] Step 030/520 Loss 3.340 Prec@(1,5) (16.2%, 63.4%)\n",
            "[2023-01-12 15:41:36] \u001b[32mTrain: [  1/600] Step 040/520 Loss 3.333 Prec@(1,5) (16.8%, 65.5%)\u001b[0m\n",
            "INFO:nni:Train: [  1/600] Step 040/520 Loss 3.333 Prec@(1,5) (16.8%, 65.5%)\n",
            "[2023-01-12 15:41:40] \u001b[32mTrain: [  1/600] Step 050/520 Loss 3.304 Prec@(1,5) (17.8%, 67.5%)\u001b[0m\n",
            "INFO:nni:Train: [  1/600] Step 050/520 Loss 3.304 Prec@(1,5) (17.8%, 67.5%)\n",
            "[2023-01-12 15:41:44] \u001b[32mTrain: [  1/600] Step 060/520 Loss 3.257 Prec@(1,5) (18.6%, 69.6%)\u001b[0m\n",
            "INFO:nni:Train: [  1/600] Step 060/520 Loss 3.257 Prec@(1,5) (18.6%, 69.6%)\n",
            "[2023-01-12 15:41:48] \u001b[32mTrain: [  1/600] Step 070/520 Loss 3.240 Prec@(1,5) (19.3%, 70.5%)\u001b[0m\n",
            "INFO:nni:Train: [  1/600] Step 070/520 Loss 3.240 Prec@(1,5) (19.3%, 70.5%)\n",
            "[2023-01-12 15:41:52] \u001b[32mTrain: [  1/600] Step 080/520 Loss 3.234 Prec@(1,5) (19.8%, 71.6%)\u001b[0m\n",
            "INFO:nni:Train: [  1/600] Step 080/520 Loss 3.234 Prec@(1,5) (19.8%, 71.6%)\n",
            "[2023-01-12 15:41:56] \u001b[32mTrain: [  1/600] Step 090/520 Loss 3.227 Prec@(1,5) (20.3%, 72.3%)\u001b[0m\n",
            "INFO:nni:Train: [  1/600] Step 090/520 Loss 3.227 Prec@(1,5) (20.3%, 72.3%)\n",
            "[2023-01-12 15:42:00] \u001b[32mTrain: [  1/600] Step 100/520 Loss 3.206 Prec@(1,5) (20.9%, 73.2%)\u001b[0m\n",
            "INFO:nni:Train: [  1/600] Step 100/520 Loss 3.206 Prec@(1,5) (20.9%, 73.2%)\n",
            "[2023-01-12 15:42:04] \u001b[32mTrain: [  1/600] Step 110/520 Loss 3.178 Prec@(1,5) (21.5%, 73.8%)\u001b[0m\n",
            "INFO:nni:Train: [  1/600] Step 110/520 Loss 3.178 Prec@(1,5) (21.5%, 73.8%)\n",
            "[2023-01-12 15:42:08] \u001b[32mTrain: [  1/600] Step 120/520 Loss 3.161 Prec@(1,5) (22.2%, 74.4%)\u001b[0m\n",
            "INFO:nni:Train: [  1/600] Step 120/520 Loss 3.161 Prec@(1,5) (22.2%, 74.4%)\n",
            "[2023-01-12 15:42:12] \u001b[32mTrain: [  1/600] Step 130/520 Loss 3.145 Prec@(1,5) (22.6%, 75.0%)\u001b[0m\n",
            "INFO:nni:Train: [  1/600] Step 130/520 Loss 3.145 Prec@(1,5) (22.6%, 75.0%)\n",
            "[2023-01-12 15:42:16] \u001b[32mTrain: [  1/600] Step 140/520 Loss 3.142 Prec@(1,5) (23.0%, 75.5%)\u001b[0m\n",
            "INFO:nni:Train: [  1/600] Step 140/520 Loss 3.142 Prec@(1,5) (23.0%, 75.5%)\n",
            "[2023-01-12 15:42:20] \u001b[32mTrain: [  1/600] Step 150/520 Loss 3.128 Prec@(1,5) (23.5%, 76.0%)\u001b[0m\n",
            "INFO:nni:Train: [  1/600] Step 150/520 Loss 3.128 Prec@(1,5) (23.5%, 76.0%)\n",
            "[2023-01-12 15:42:24] \u001b[32mTrain: [  1/600] Step 160/520 Loss 3.122 Prec@(1,5) (23.8%, 76.4%)\u001b[0m\n",
            "INFO:nni:Train: [  1/600] Step 160/520 Loss 3.122 Prec@(1,5) (23.8%, 76.4%)\n",
            "[2023-01-12 15:42:28] \u001b[32mTrain: [  1/600] Step 170/520 Loss 3.132 Prec@(1,5) (24.1%, 76.6%)\u001b[0m\n",
            "INFO:nni:Train: [  1/600] Step 170/520 Loss 3.132 Prec@(1,5) (24.1%, 76.6%)\n",
            "[2023-01-12 15:42:32] \u001b[32mTrain: [  1/600] Step 180/520 Loss 3.116 Prec@(1,5) (24.4%, 77.0%)\u001b[0m\n",
            "INFO:nni:Train: [  1/600] Step 180/520 Loss 3.116 Prec@(1,5) (24.4%, 77.0%)\n",
            "[2023-01-12 15:42:36] \u001b[32mTrain: [  1/600] Step 190/520 Loss 3.097 Prec@(1,5) (24.7%, 77.3%)\u001b[0m\n",
            "INFO:nni:Train: [  1/600] Step 190/520 Loss 3.097 Prec@(1,5) (24.7%, 77.3%)\n",
            "[2023-01-12 15:42:40] \u001b[32mTrain: [  1/600] Step 200/520 Loss 3.083 Prec@(1,5) (24.9%, 77.6%)\u001b[0m\n",
            "INFO:nni:Train: [  1/600] Step 200/520 Loss 3.083 Prec@(1,5) (24.9%, 77.6%)\n",
            "[2023-01-12 15:42:44] \u001b[32mTrain: [  1/600] Step 210/520 Loss 3.064 Prec@(1,5) (25.1%, 77.9%)\u001b[0m\n",
            "INFO:nni:Train: [  1/600] Step 210/520 Loss 3.064 Prec@(1,5) (25.1%, 77.9%)\n",
            "[2023-01-12 15:42:48] \u001b[32mTrain: [  1/600] Step 220/520 Loss 3.065 Prec@(1,5) (25.4%, 78.2%)\u001b[0m\n",
            "INFO:nni:Train: [  1/600] Step 220/520 Loss 3.065 Prec@(1,5) (25.4%, 78.2%)\n",
            "[2023-01-12 15:42:52] \u001b[32mTrain: [  1/600] Step 230/520 Loss 3.049 Prec@(1,5) (25.6%, 78.5%)\u001b[0m\n",
            "INFO:nni:Train: [  1/600] Step 230/520 Loss 3.049 Prec@(1,5) (25.6%, 78.5%)\n",
            "[2023-01-12 15:42:55] \u001b[32mTrain: [  1/600] Step 240/520 Loss 3.045 Prec@(1,5) (25.9%, 78.8%)\u001b[0m\n",
            "INFO:nni:Train: [  1/600] Step 240/520 Loss 3.045 Prec@(1,5) (25.9%, 78.8%)\n",
            "[2023-01-12 15:42:59] \u001b[32mTrain: [  1/600] Step 250/520 Loss 3.029 Prec@(1,5) (26.1%, 79.0%)\u001b[0m\n",
            "INFO:nni:Train: [  1/600] Step 250/520 Loss 3.029 Prec@(1,5) (26.1%, 79.0%)\n",
            "[2023-01-12 15:43:03] \u001b[32mTrain: [  1/600] Step 260/520 Loss 3.015 Prec@(1,5) (26.3%, 79.2%)\u001b[0m\n",
            "INFO:nni:Train: [  1/600] Step 260/520 Loss 3.015 Prec@(1,5) (26.3%, 79.2%)\n",
            "[2023-01-12 15:43:07] \u001b[32mTrain: [  1/600] Step 270/520 Loss 3.001 Prec@(1,5) (26.6%, 79.5%)\u001b[0m\n",
            "INFO:nni:Train: [  1/600] Step 270/520 Loss 3.001 Prec@(1,5) (26.6%, 79.5%)\n",
            "[2023-01-12 15:43:11] \u001b[32mTrain: [  1/600] Step 280/520 Loss 2.985 Prec@(1,5) (26.7%, 79.7%)\u001b[0m\n",
            "INFO:nni:Train: [  1/600] Step 280/520 Loss 2.985 Prec@(1,5) (26.7%, 79.7%)\n",
            "[2023-01-12 15:43:15] \u001b[32mTrain: [  1/600] Step 290/520 Loss 2.976 Prec@(1,5) (27.0%, 80.0%)\u001b[0m\n",
            "INFO:nni:Train: [  1/600] Step 290/520 Loss 2.976 Prec@(1,5) (27.0%, 80.0%)\n",
            "[2023-01-12 15:43:19] \u001b[32mTrain: [  1/600] Step 300/520 Loss 2.983 Prec@(1,5) (27.1%, 80.1%)\u001b[0m\n",
            "INFO:nni:Train: [  1/600] Step 300/520 Loss 2.983 Prec@(1,5) (27.1%, 80.1%)\n",
            "[2023-01-12 15:43:23] \u001b[32mTrain: [  1/600] Step 310/520 Loss 2.972 Prec@(1,5) (27.5%, 80.3%)\u001b[0m\n",
            "INFO:nni:Train: [  1/600] Step 310/520 Loss 2.972 Prec@(1,5) (27.5%, 80.3%)\n",
            "[2023-01-12 15:43:27] \u001b[32mTrain: [  1/600] Step 320/520 Loss 2.961 Prec@(1,5) (27.6%, 80.5%)\u001b[0m\n",
            "INFO:nni:Train: [  1/600] Step 320/520 Loss 2.961 Prec@(1,5) (27.6%, 80.5%)\n",
            "[2023-01-12 15:43:31] \u001b[32mTrain: [  1/600] Step 330/520 Loss 2.949 Prec@(1,5) (27.9%, 80.7%)\u001b[0m\n",
            "INFO:nni:Train: [  1/600] Step 330/520 Loss 2.949 Prec@(1,5) (27.9%, 80.7%)\n",
            "[2023-01-12 15:43:35] \u001b[32mTrain: [  1/600] Step 340/520 Loss 2.947 Prec@(1,5) (28.1%, 80.9%)\u001b[0m\n",
            "INFO:nni:Train: [  1/600] Step 340/520 Loss 2.947 Prec@(1,5) (28.1%, 80.9%)\n",
            "[2023-01-12 15:43:39] \u001b[32mTrain: [  1/600] Step 350/520 Loss 2.945 Prec@(1,5) (28.2%, 81.0%)\u001b[0m\n",
            "INFO:nni:Train: [  1/600] Step 350/520 Loss 2.945 Prec@(1,5) (28.2%, 81.0%)\n",
            "[2023-01-12 15:43:43] \u001b[32mTrain: [  1/600] Step 360/520 Loss 2.941 Prec@(1,5) (28.3%, 81.2%)\u001b[0m\n",
            "INFO:nni:Train: [  1/600] Step 360/520 Loss 2.941 Prec@(1,5) (28.3%, 81.2%)\n",
            "[2023-01-12 15:43:47] \u001b[32mTrain: [  1/600] Step 370/520 Loss 2.936 Prec@(1,5) (28.3%, 81.2%)\u001b[0m\n",
            "INFO:nni:Train: [  1/600] Step 370/520 Loss 2.936 Prec@(1,5) (28.3%, 81.2%)\n",
            "[2023-01-12 15:43:51] \u001b[32mTrain: [  1/600] Step 380/520 Loss 2.932 Prec@(1,5) (28.5%, 81.3%)\u001b[0m\n",
            "INFO:nni:Train: [  1/600] Step 380/520 Loss 2.932 Prec@(1,5) (28.5%, 81.3%)\n",
            "[2023-01-12 15:43:55] \u001b[32mTrain: [  1/600] Step 390/520 Loss 2.929 Prec@(1,5) (28.5%, 81.4%)\u001b[0m\n",
            "INFO:nni:Train: [  1/600] Step 390/520 Loss 2.929 Prec@(1,5) (28.5%, 81.4%)\n",
            "[2023-01-12 15:43:59] \u001b[32mTrain: [  1/600] Step 400/520 Loss 2.921 Prec@(1,5) (28.6%, 81.5%)\u001b[0m\n",
            "INFO:nni:Train: [  1/600] Step 400/520 Loss 2.921 Prec@(1,5) (28.6%, 81.5%)\n",
            "[2023-01-12 15:44:03] \u001b[32mTrain: [  1/600] Step 410/520 Loss 2.916 Prec@(1,5) (28.7%, 81.6%)\u001b[0m\n",
            "INFO:nni:Train: [  1/600] Step 410/520 Loss 2.916 Prec@(1,5) (28.7%, 81.6%)\n",
            "[2023-01-12 15:44:06] \u001b[32mTrain: [  1/600] Step 420/520 Loss 2.909 Prec@(1,5) (28.9%, 81.7%)\u001b[0m\n",
            "INFO:nni:Train: [  1/600] Step 420/520 Loss 2.909 Prec@(1,5) (28.9%, 81.7%)\n",
            "[2023-01-12 15:44:10] \u001b[32mTrain: [  1/600] Step 430/520 Loss 2.901 Prec@(1,5) (29.1%, 81.8%)\u001b[0m\n",
            "INFO:nni:Train: [  1/600] Step 430/520 Loss 2.901 Prec@(1,5) (29.1%, 81.8%)\n",
            "[2023-01-12 15:44:14] \u001b[32mTrain: [  1/600] Step 440/520 Loss 2.895 Prec@(1,5) (29.2%, 81.8%)\u001b[0m\n",
            "INFO:nni:Train: [  1/600] Step 440/520 Loss 2.895 Prec@(1,5) (29.2%, 81.8%)\n",
            "[2023-01-12 15:44:18] \u001b[32mTrain: [  1/600] Step 450/520 Loss 2.885 Prec@(1,5) (29.4%, 82.0%)\u001b[0m\n",
            "INFO:nni:Train: [  1/600] Step 450/520 Loss 2.885 Prec@(1,5) (29.4%, 82.0%)\n",
            "[2023-01-12 15:44:22] \u001b[32mTrain: [  1/600] Step 460/520 Loss 2.876 Prec@(1,5) (29.6%, 82.1%)\u001b[0m\n",
            "INFO:nni:Train: [  1/600] Step 460/520 Loss 2.876 Prec@(1,5) (29.6%, 82.1%)\n",
            "[2023-01-12 15:44:26] \u001b[32mTrain: [  1/600] Step 470/520 Loss 2.867 Prec@(1,5) (29.8%, 82.2%)\u001b[0m\n",
            "INFO:nni:Train: [  1/600] Step 470/520 Loss 2.867 Prec@(1,5) (29.8%, 82.2%)\n",
            "[2023-01-12 15:44:30] \u001b[32mTrain: [  1/600] Step 480/520 Loss 2.859 Prec@(1,5) (29.9%, 82.3%)\u001b[0m\n",
            "INFO:nni:Train: [  1/600] Step 480/520 Loss 2.859 Prec@(1,5) (29.9%, 82.3%)\n",
            "[2023-01-12 15:44:34] \u001b[32mTrain: [  1/600] Step 490/520 Loss 2.852 Prec@(1,5) (30.1%, 82.4%)\u001b[0m\n",
            "INFO:nni:Train: [  1/600] Step 490/520 Loss 2.852 Prec@(1,5) (30.1%, 82.4%)\n",
            "[2023-01-12 15:44:38] \u001b[32mTrain: [  1/600] Step 500/520 Loss 2.844 Prec@(1,5) (30.2%, 82.5%)\u001b[0m\n",
            "INFO:nni:Train: [  1/600] Step 500/520 Loss 2.844 Prec@(1,5) (30.2%, 82.5%)\n",
            "[2023-01-12 15:44:42] \u001b[32mTrain: [  1/600] Step 510/520 Loss 2.835 Prec@(1,5) (30.4%, 82.6%)\u001b[0m\n",
            "INFO:nni:Train: [  1/600] Step 510/520 Loss 2.835 Prec@(1,5) (30.4%, 82.6%)\n",
            "[2023-01-12 15:44:46] \u001b[32mTrain: [  1/600] Step 520/520 Loss 2.831 Prec@(1,5) (30.5%, 82.8%)\u001b[0m\n",
            "INFO:nni:Train: [  1/600] Step 520/520 Loss 2.831 Prec@(1,5) (30.5%, 82.8%)\n",
            "[2023-01-12 15:44:46] \u001b[32mTrain: [  1/600] Final Prec@1 30.5140%\u001b[0m\n",
            "INFO:nni:Train: [  1/600] Final Prec@1 30.5140%\n",
            "[2023-01-12 15:44:46] \u001b[32mValid: [  1/600] Step 000/104 Loss 7.421 Prec@(1,5) (29.2%, 83.3%)\u001b[0m\n",
            "INFO:nni:Valid: [  1/600] Step 000/104 Loss 7.421 Prec@(1,5) (29.2%, 83.3%)\n",
            "[2023-01-12 15:44:48] \u001b[32mValid: [  1/600] Step 010/104 Loss 4.662 Prec@(1,5) (31.3%, 86.2%)\u001b[0m\n",
            "INFO:nni:Valid: [  1/600] Step 010/104 Loss 4.662 Prec@(1,5) (31.3%, 86.2%)\n",
            "[2023-01-12 15:44:49] \u001b[32mValid: [  1/600] Step 020/104 Loss 4.387 Prec@(1,5) (32.3%, 85.7%)\u001b[0m\n",
            "INFO:nni:Valid: [  1/600] Step 020/104 Loss 4.387 Prec@(1,5) (32.3%, 85.7%)\n",
            "[2023-01-12 15:44:51] \u001b[32mValid: [  1/600] Step 030/104 Loss 4.581 Prec@(1,5) (32.8%, 85.4%)\u001b[0m\n",
            "INFO:nni:Valid: [  1/600] Step 030/104 Loss 4.581 Prec@(1,5) (32.8%, 85.4%)\n",
            "[2023-01-12 15:44:52] \u001b[32mValid: [  1/600] Step 040/104 Loss 4.481 Prec@(1,5) (33.5%, 85.7%)\u001b[0m\n",
            "INFO:nni:Valid: [  1/600] Step 040/104 Loss 4.481 Prec@(1,5) (33.5%, 85.7%)\n",
            "[2023-01-12 15:44:53] \u001b[32mValid: [  1/600] Step 050/104 Loss 4.558 Prec@(1,5) (33.8%, 85.8%)\u001b[0m\n",
            "INFO:nni:Valid: [  1/600] Step 050/104 Loss 4.558 Prec@(1,5) (33.8%, 85.8%)\n",
            "[2023-01-12 15:44:55] \u001b[32mValid: [  1/600] Step 060/104 Loss 4.705 Prec@(1,5) (34.2%, 85.6%)\u001b[0m\n",
            "INFO:nni:Valid: [  1/600] Step 060/104 Loss 4.705 Prec@(1,5) (34.2%, 85.6%)\n",
            "[2023-01-12 15:44:56] \u001b[32mValid: [  1/600] Step 070/104 Loss 4.727 Prec@(1,5) (34.4%, 85.5%)\u001b[0m\n",
            "INFO:nni:Valid: [  1/600] Step 070/104 Loss 4.727 Prec@(1,5) (34.4%, 85.5%)\n",
            "[2023-01-12 15:44:58] \u001b[32mValid: [  1/600] Step 080/104 Loss 4.723 Prec@(1,5) (34.8%, 85.7%)\u001b[0m\n",
            "INFO:nni:Valid: [  1/600] Step 080/104 Loss 4.723 Prec@(1,5) (34.8%, 85.7%)\n",
            "[2023-01-12 15:44:59] \u001b[32mValid: [  1/600] Step 090/104 Loss 4.667 Prec@(1,5) (34.6%, 85.5%)\u001b[0m\n",
            "INFO:nni:Valid: [  1/600] Step 090/104 Loss 4.667 Prec@(1,5) (34.6%, 85.5%)\n",
            "[2023-01-12 15:45:00] \u001b[32mValid: [  1/600] Step 100/104 Loss 4.788 Prec@(1,5) (34.8%, 85.4%)\u001b[0m\n",
            "INFO:nni:Valid: [  1/600] Step 100/104 Loss 4.788 Prec@(1,5) (34.8%, 85.4%)\n",
            "[2023-01-12 15:45:01] \u001b[32mValid: [  1/600] Step 104/104 Loss 4.781 Prec@(1,5) (34.7%, 85.5%)\u001b[0m\n",
            "INFO:nni:Valid: [  1/600] Step 104/104 Loss 4.781 Prec@(1,5) (34.7%, 85.5%)\n",
            "[2023-01-12 15:45:01] \u001b[32mValid: [  1/600] Final Prec@1 34.7200%\u001b[0m\n",
            "INFO:nni:Valid: [  1/600] Final Prec@1 34.7200%\n",
            "[2023-01-12 15:45:01] \u001b[32mEpoch 1 LR 0.025000\u001b[0m\n",
            "INFO:nni:Epoch 1 LR 0.025000\n",
            "[2023-01-12 15:45:02] \u001b[32mTrain: [  2/600] Step 000/520 Loss 2.478 Prec@(1,5) (41.7%, 89.6%)\u001b[0m\n",
            "INFO:nni:Train: [  2/600] Step 000/520 Loss 2.478 Prec@(1,5) (41.7%, 89.6%)\n",
            "[2023-01-12 15:45:06] \u001b[32mTrain: [  2/600] Step 010/520 Loss 2.438 Prec@(1,5) (37.2%, 90.1%)\u001b[0m\n",
            "INFO:nni:Train: [  2/600] Step 010/520 Loss 2.438 Prec@(1,5) (37.2%, 90.1%)\n",
            "[2023-01-12 15:45:11] \u001b[32mTrain: [  2/600] Step 020/520 Loss 2.487 Prec@(1,5) (36.7%, 88.8%)\u001b[0m\n",
            "INFO:nni:Train: [  2/600] Step 020/520 Loss 2.487 Prec@(1,5) (36.7%, 88.8%)\n",
            "[2023-01-12 15:45:15] \u001b[32mTrain: [  2/600] Step 030/520 Loss 2.514 Prec@(1,5) (36.1%, 87.8%)\u001b[0m\n",
            "INFO:nni:Train: [  2/600] Step 030/520 Loss 2.514 Prec@(1,5) (36.1%, 87.8%)\n",
            "[2023-01-12 15:45:20] \u001b[32mTrain: [  2/600] Step 040/520 Loss 2.504 Prec@(1,5) (36.0%, 87.6%)\u001b[0m\n",
            "INFO:nni:Train: [  2/600] Step 040/520 Loss 2.504 Prec@(1,5) (36.0%, 87.6%)\n",
            "[2023-01-12 15:45:24] \u001b[32mTrain: [  2/600] Step 050/520 Loss 2.500 Prec@(1,5) (35.8%, 87.8%)\u001b[0m\n",
            "INFO:nni:Train: [  2/600] Step 050/520 Loss 2.500 Prec@(1,5) (35.8%, 87.8%)\n",
            "[2023-01-12 15:45:29] \u001b[32mTrain: [  2/600] Step 060/520 Loss 2.502 Prec@(1,5) (35.8%, 87.9%)\u001b[0m\n",
            "INFO:nni:Train: [  2/600] Step 060/520 Loss 2.502 Prec@(1,5) (35.8%, 87.9%)\n",
            "[2023-01-12 15:45:33] \u001b[32mTrain: [  2/600] Step 070/520 Loss 2.521 Prec@(1,5) (35.8%, 87.6%)\u001b[0m\n",
            "INFO:nni:Train: [  2/600] Step 070/520 Loss 2.521 Prec@(1,5) (35.8%, 87.6%)\n",
            "[2023-01-12 15:45:38] \u001b[32mTrain: [  2/600] Step 080/520 Loss 2.520 Prec@(1,5) (35.8%, 87.4%)\u001b[0m\n",
            "INFO:nni:Train: [  2/600] Step 080/520 Loss 2.520 Prec@(1,5) (35.8%, 87.4%)\n",
            "[2023-01-12 15:45:42] \u001b[32mTrain: [  2/600] Step 090/520 Loss 2.511 Prec@(1,5) (35.9%, 87.3%)\u001b[0m\n",
            "INFO:nni:Train: [  2/600] Step 090/520 Loss 2.511 Prec@(1,5) (35.9%, 87.3%)\n",
            "[2023-01-12 15:45:47] \u001b[32mTrain: [  2/600] Step 100/520 Loss 2.495 Prec@(1,5) (36.3%, 87.4%)\u001b[0m\n",
            "INFO:nni:Train: [  2/600] Step 100/520 Loss 2.495 Prec@(1,5) (36.3%, 87.4%)\n",
            "[2023-01-12 15:45:51] \u001b[32mTrain: [  2/600] Step 110/520 Loss 2.489 Prec@(1,5) (36.5%, 87.5%)\u001b[0m\n",
            "INFO:nni:Train: [  2/600] Step 110/520 Loss 2.489 Prec@(1,5) (36.5%, 87.5%)\n",
            "[2023-01-12 15:45:56] \u001b[32mTrain: [  2/600] Step 120/520 Loss 2.470 Prec@(1,5) (37.0%, 87.7%)\u001b[0m\n",
            "INFO:nni:Train: [  2/600] Step 120/520 Loss 2.470 Prec@(1,5) (37.0%, 87.7%)\n",
            "[2023-01-12 15:46:00] \u001b[32mTrain: [  2/600] Step 130/520 Loss 2.461 Prec@(1,5) (37.3%, 87.9%)\u001b[0m\n",
            "INFO:nni:Train: [  2/600] Step 130/520 Loss 2.461 Prec@(1,5) (37.3%, 87.9%)\n",
            "[2023-01-12 15:46:05] \u001b[32mTrain: [  2/600] Step 140/520 Loss 2.453 Prec@(1,5) (37.3%, 88.1%)\u001b[0m\n",
            "INFO:nni:Train: [  2/600] Step 140/520 Loss 2.453 Prec@(1,5) (37.3%, 88.1%)\n",
            "[2023-01-12 15:46:09] \u001b[32mTrain: [  2/600] Step 150/520 Loss 2.445 Prec@(1,5) (37.6%, 88.3%)\u001b[0m\n",
            "INFO:nni:Train: [  2/600] Step 150/520 Loss 2.445 Prec@(1,5) (37.6%, 88.3%)\n",
            "[2023-01-12 15:46:14] \u001b[32mTrain: [  2/600] Step 160/520 Loss 2.437 Prec@(1,5) (37.7%, 88.3%)\u001b[0m\n",
            "INFO:nni:Train: [  2/600] Step 160/520 Loss 2.437 Prec@(1,5) (37.7%, 88.3%)\n",
            "[2023-01-12 15:46:18] \u001b[32mTrain: [  2/600] Step 170/520 Loss 2.426 Prec@(1,5) (38.1%, 88.4%)\u001b[0m\n",
            "INFO:nni:Train: [  2/600] Step 170/520 Loss 2.426 Prec@(1,5) (38.1%, 88.4%)\n",
            "[2023-01-12 15:46:23] \u001b[32mTrain: [  2/600] Step 180/520 Loss 2.427 Prec@(1,5) (38.1%, 88.4%)\u001b[0m\n",
            "INFO:nni:Train: [  2/600] Step 180/520 Loss 2.427 Prec@(1,5) (38.1%, 88.4%)\n",
            "[2023-01-12 15:46:28] \u001b[32mTrain: [  2/600] Step 190/520 Loss 2.422 Prec@(1,5) (38.3%, 88.5%)\u001b[0m\n",
            "INFO:nni:Train: [  2/600] Step 190/520 Loss 2.422 Prec@(1,5) (38.3%, 88.5%)\n",
            "[2023-01-12 15:46:32] \u001b[32mTrain: [  2/600] Step 200/520 Loss 2.419 Prec@(1,5) (38.4%, 88.4%)\u001b[0m\n",
            "INFO:nni:Train: [  2/600] Step 200/520 Loss 2.419 Prec@(1,5) (38.4%, 88.4%)\n",
            "[2023-01-12 15:46:37] \u001b[32mTrain: [  2/600] Step 210/520 Loss 2.412 Prec@(1,5) (38.7%, 88.5%)\u001b[0m\n",
            "INFO:nni:Train: [  2/600] Step 210/520 Loss 2.412 Prec@(1,5) (38.7%, 88.5%)\n",
            "[2023-01-12 15:46:41] \u001b[32mTrain: [  2/600] Step 220/520 Loss 2.413 Prec@(1,5) (38.7%, 88.5%)\u001b[0m\n",
            "INFO:nni:Train: [  2/600] Step 220/520 Loss 2.413 Prec@(1,5) (38.7%, 88.5%)\n",
            "[2023-01-12 15:46:46] \u001b[32mTrain: [  2/600] Step 230/520 Loss 2.404 Prec@(1,5) (39.0%, 88.6%)\u001b[0m\n",
            "INFO:nni:Train: [  2/600] Step 230/520 Loss 2.404 Prec@(1,5) (39.0%, 88.6%)\n",
            "[2023-01-12 15:46:50] \u001b[32mTrain: [  2/600] Step 240/520 Loss 2.398 Prec@(1,5) (39.1%, 88.6%)\u001b[0m\n",
            "INFO:nni:Train: [  2/600] Step 240/520 Loss 2.398 Prec@(1,5) (39.1%, 88.6%)\n",
            "[2023-01-12 15:46:55] \u001b[32mTrain: [  2/600] Step 250/520 Loss 2.393 Prec@(1,5) (39.2%, 88.6%)\u001b[0m\n",
            "INFO:nni:Train: [  2/600] Step 250/520 Loss 2.393 Prec@(1,5) (39.2%, 88.6%)\n",
            "[2023-01-12 15:46:59] \u001b[32mTrain: [  2/600] Step 260/520 Loss 2.390 Prec@(1,5) (39.3%, 88.6%)\u001b[0m\n",
            "INFO:nni:Train: [  2/600] Step 260/520 Loss 2.390 Prec@(1,5) (39.3%, 88.6%)\n",
            "[2023-01-12 15:47:04] \u001b[32mTrain: [  2/600] Step 270/520 Loss 2.380 Prec@(1,5) (39.5%, 88.7%)\u001b[0m\n",
            "INFO:nni:Train: [  2/600] Step 270/520 Loss 2.380 Prec@(1,5) (39.5%, 88.7%)\n",
            "[2023-01-12 15:47:08] \u001b[32mTrain: [  2/600] Step 280/520 Loss 2.371 Prec@(1,5) (39.8%, 88.7%)\u001b[0m\n",
            "INFO:nni:Train: [  2/600] Step 280/520 Loss 2.371 Prec@(1,5) (39.8%, 88.7%)\n",
            "[2023-01-12 15:47:13] \u001b[32mTrain: [  2/600] Step 290/520 Loss 2.362 Prec@(1,5) (40.0%, 88.8%)\u001b[0m\n",
            "INFO:nni:Train: [  2/600] Step 290/520 Loss 2.362 Prec@(1,5) (40.0%, 88.8%)\n",
            "[2023-01-12 15:47:17] \u001b[32mTrain: [  2/600] Step 300/520 Loss 2.353 Prec@(1,5) (40.1%, 88.9%)\u001b[0m\n",
            "INFO:nni:Train: [  2/600] Step 300/520 Loss 2.353 Prec@(1,5) (40.1%, 88.9%)\n",
            "[2023-01-12 15:47:22] \u001b[32mTrain: [  2/600] Step 310/520 Loss 2.347 Prec@(1,5) (40.2%, 89.0%)\u001b[0m\n",
            "INFO:nni:Train: [  2/600] Step 310/520 Loss 2.347 Prec@(1,5) (40.2%, 89.0%)\n",
            "[2023-01-12 15:47:26] \u001b[32mTrain: [  2/600] Step 320/520 Loss 2.341 Prec@(1,5) (40.3%, 89.1%)\u001b[0m\n",
            "INFO:nni:Train: [  2/600] Step 320/520 Loss 2.341 Prec@(1,5) (40.3%, 89.1%)\n",
            "[2023-01-12 15:47:31] \u001b[32mTrain: [  2/600] Step 330/520 Loss 2.334 Prec@(1,5) (40.4%, 89.2%)\u001b[0m\n",
            "INFO:nni:Train: [  2/600] Step 330/520 Loss 2.334 Prec@(1,5) (40.4%, 89.2%)\n",
            "[2023-01-12 15:47:35] \u001b[32mTrain: [  2/600] Step 340/520 Loss 2.329 Prec@(1,5) (40.6%, 89.3%)\u001b[0m\n",
            "INFO:nni:Train: [  2/600] Step 340/520 Loss 2.329 Prec@(1,5) (40.6%, 89.3%)\n",
            "[2023-01-12 15:47:40] \u001b[32mTrain: [  2/600] Step 350/520 Loss 2.325 Prec@(1,5) (40.6%, 89.3%)\u001b[0m\n",
            "INFO:nni:Train: [  2/600] Step 350/520 Loss 2.325 Prec@(1,5) (40.6%, 89.3%)\n",
            "[2023-01-12 15:47:44] \u001b[32mTrain: [  2/600] Step 360/520 Loss 2.319 Prec@(1,5) (40.8%, 89.4%)\u001b[0m\n",
            "INFO:nni:Train: [  2/600] Step 360/520 Loss 2.319 Prec@(1,5) (40.8%, 89.4%)\n",
            "[2023-01-12 15:47:49] \u001b[32mTrain: [  2/600] Step 370/520 Loss 2.313 Prec@(1,5) (40.8%, 89.5%)\u001b[0m\n",
            "INFO:nni:Train: [  2/600] Step 370/520 Loss 2.313 Prec@(1,5) (40.8%, 89.5%)\n",
            "[2023-01-12 15:47:53] \u001b[32mTrain: [  2/600] Step 380/520 Loss 2.310 Prec@(1,5) (40.9%, 89.5%)\u001b[0m\n",
            "INFO:nni:Train: [  2/600] Step 380/520 Loss 2.310 Prec@(1,5) (40.9%, 89.5%)\n",
            "[2023-01-12 15:47:58] \u001b[32mTrain: [  2/600] Step 390/520 Loss 2.303 Prec@(1,5) (41.1%, 89.6%)\u001b[0m\n",
            "INFO:nni:Train: [  2/600] Step 390/520 Loss 2.303 Prec@(1,5) (41.1%, 89.6%)\n",
            "[2023-01-12 15:48:02] \u001b[32mTrain: [  2/600] Step 400/520 Loss 2.298 Prec@(1,5) (41.1%, 89.7%)\u001b[0m\n",
            "INFO:nni:Train: [  2/600] Step 400/520 Loss 2.298 Prec@(1,5) (41.1%, 89.7%)\n",
            "[2023-01-12 15:48:07] \u001b[32mTrain: [  2/600] Step 410/520 Loss 2.295 Prec@(1,5) (41.2%, 89.7%)\u001b[0m\n",
            "INFO:nni:Train: [  2/600] Step 410/520 Loss 2.295 Prec@(1,5) (41.2%, 89.7%)\n",
            "[2023-01-12 15:48:11] \u001b[32mTrain: [  2/600] Step 420/520 Loss 2.288 Prec@(1,5) (41.4%, 89.8%)\u001b[0m\n",
            "INFO:nni:Train: [  2/600] Step 420/520 Loss 2.288 Prec@(1,5) (41.4%, 89.8%)\n",
            "[2023-01-12 15:48:16] \u001b[32mTrain: [  2/600] Step 430/520 Loss 2.286 Prec@(1,5) (41.5%, 89.8%)\u001b[0m\n",
            "INFO:nni:Train: [  2/600] Step 430/520 Loss 2.286 Prec@(1,5) (41.5%, 89.8%)\n",
            "[2023-01-12 15:48:20] \u001b[32mTrain: [  2/600] Step 440/520 Loss 2.279 Prec@(1,5) (41.6%, 89.9%)\u001b[0m\n",
            "INFO:nni:Train: [  2/600] Step 440/520 Loss 2.279 Prec@(1,5) (41.6%, 89.9%)\n",
            "[2023-01-12 15:48:25] \u001b[32mTrain: [  2/600] Step 450/520 Loss 2.277 Prec@(1,5) (41.7%, 89.9%)\u001b[0m\n",
            "INFO:nni:Train: [  2/600] Step 450/520 Loss 2.277 Prec@(1,5) (41.7%, 89.9%)\n",
            "[2023-01-12 15:48:29] \u001b[32mTrain: [  2/600] Step 460/520 Loss 2.272 Prec@(1,5) (41.8%, 89.9%)\u001b[0m\n",
            "INFO:nni:Train: [  2/600] Step 460/520 Loss 2.272 Prec@(1,5) (41.8%, 89.9%)\n",
            "[2023-01-12 15:48:34] \u001b[32mTrain: [  2/600] Step 470/520 Loss 2.265 Prec@(1,5) (42.0%, 90.0%)\u001b[0m\n",
            "INFO:nni:Train: [  2/600] Step 470/520 Loss 2.265 Prec@(1,5) (42.0%, 90.0%)\n",
            "[2023-01-12 15:48:38] \u001b[32mTrain: [  2/600] Step 480/520 Loss 2.258 Prec@(1,5) (42.1%, 90.1%)\u001b[0m\n",
            "INFO:nni:Train: [  2/600] Step 480/520 Loss 2.258 Prec@(1,5) (42.1%, 90.1%)\n",
            "[2023-01-12 15:48:43] \u001b[32mTrain: [  2/600] Step 490/520 Loss 2.252 Prec@(1,5) (42.2%, 90.1%)\u001b[0m\n",
            "INFO:nni:Train: [  2/600] Step 490/520 Loss 2.252 Prec@(1,5) (42.2%, 90.1%)\n",
            "[2023-01-12 15:48:48] \u001b[32mTrain: [  2/600] Step 500/520 Loss 2.245 Prec@(1,5) (42.4%, 90.2%)\u001b[0m\n",
            "INFO:nni:Train: [  2/600] Step 500/520 Loss 2.245 Prec@(1,5) (42.4%, 90.2%)\n",
            "[2023-01-12 15:48:52] \u001b[32mTrain: [  2/600] Step 510/520 Loss 2.241 Prec@(1,5) (42.4%, 90.2%)\u001b[0m\n",
            "INFO:nni:Train: [  2/600] Step 510/520 Loss 2.241 Prec@(1,5) (42.4%, 90.2%)\n",
            "[2023-01-12 15:48:56] \u001b[32mTrain: [  2/600] Step 520/520 Loss 2.236 Prec@(1,5) (42.6%, 90.2%)\u001b[0m\n",
            "INFO:nni:Train: [  2/600] Step 520/520 Loss 2.236 Prec@(1,5) (42.6%, 90.2%)\n",
            "[2023-01-12 15:48:57] \u001b[32mTrain: [  2/600] Final Prec@1 42.6120%\u001b[0m\n",
            "INFO:nni:Train: [  2/600] Final Prec@1 42.6120%\n",
            "[2023-01-12 15:48:57] \u001b[32mValid: [  2/600] Step 000/104 Loss 1.211 Prec@(1,5) (58.3%, 93.8%)\u001b[0m\n",
            "INFO:nni:Valid: [  2/600] Step 000/104 Loss 1.211 Prec@(1,5) (58.3%, 93.8%)\n",
            "[2023-01-12 15:48:58] \u001b[32mValid: [  2/600] Step 010/104 Loss 1.368 Prec@(1,5) (53.5%, 93.1%)\u001b[0m\n",
            "INFO:nni:Valid: [  2/600] Step 010/104 Loss 1.368 Prec@(1,5) (53.5%, 93.1%)\n",
            "[2023-01-12 15:49:00] \u001b[32mValid: [  2/600] Step 020/104 Loss 1.345 Prec@(1,5) (54.4%, 94.1%)\u001b[0m\n",
            "INFO:nni:Valid: [  2/600] Step 020/104 Loss 1.345 Prec@(1,5) (54.4%, 94.1%)\n",
            "[2023-01-12 15:49:01] \u001b[32mValid: [  2/600] Step 030/104 Loss 1.348 Prec@(1,5) (53.3%, 93.7%)\u001b[0m\n",
            "INFO:nni:Valid: [  2/600] Step 030/104 Loss 1.348 Prec@(1,5) (53.3%, 93.7%)\n",
            "[2023-01-12 15:49:03] \u001b[32mValid: [  2/600] Step 040/104 Loss 1.333 Prec@(1,5) (52.8%, 93.8%)\u001b[0m\n",
            "INFO:nni:Valid: [  2/600] Step 040/104 Loss 1.333 Prec@(1,5) (52.8%, 93.8%)\n",
            "[2023-01-12 15:49:04] \u001b[32mValid: [  2/600] Step 050/104 Loss 1.324 Prec@(1,5) (53.4%, 93.8%)\u001b[0m\n",
            "INFO:nni:Valid: [  2/600] Step 050/104 Loss 1.324 Prec@(1,5) (53.4%, 93.8%)\n",
            "[2023-01-12 15:49:05] \u001b[32mValid: [  2/600] Step 060/104 Loss 1.326 Prec@(1,5) (53.5%, 93.8%)\u001b[0m\n",
            "INFO:nni:Valid: [  2/600] Step 060/104 Loss 1.326 Prec@(1,5) (53.5%, 93.8%)\n",
            "[2023-01-12 15:49:07] \u001b[32mValid: [  2/600] Step 070/104 Loss 1.340 Prec@(1,5) (53.1%, 93.8%)\u001b[0m\n",
            "INFO:nni:Valid: [  2/600] Step 070/104 Loss 1.340 Prec@(1,5) (53.1%, 93.8%)\n",
            "[2023-01-12 15:49:08] \u001b[32mValid: [  2/600] Step 080/104 Loss 1.326 Prec@(1,5) (53.3%, 93.9%)\u001b[0m\n",
            "INFO:nni:Valid: [  2/600] Step 080/104 Loss 1.326 Prec@(1,5) (53.3%, 93.9%)\n",
            "[2023-01-12 15:49:10] \u001b[32mValid: [  2/600] Step 090/104 Loss 1.330 Prec@(1,5) (53.0%, 93.7%)\u001b[0m\n",
            "INFO:nni:Valid: [  2/600] Step 090/104 Loss 1.330 Prec@(1,5) (53.0%, 93.7%)\n",
            "[2023-01-12 15:49:11] \u001b[32mValid: [  2/600] Step 100/104 Loss 1.322 Prec@(1,5) (53.4%, 93.6%)\u001b[0m\n",
            "INFO:nni:Valid: [  2/600] Step 100/104 Loss 1.322 Prec@(1,5) (53.4%, 93.6%)\n",
            "[2023-01-12 15:49:12] \u001b[32mValid: [  2/600] Step 104/104 Loss 1.323 Prec@(1,5) (53.4%, 93.6%)\u001b[0m\n",
            "INFO:nni:Valid: [  2/600] Step 104/104 Loss 1.323 Prec@(1,5) (53.4%, 93.6%)\n",
            "[2023-01-12 15:49:12] \u001b[32mValid: [  2/600] Final Prec@1 53.3500%\u001b[0m\n",
            "INFO:nni:Valid: [  2/600] Final Prec@1 53.3500%\n",
            "[2023-01-12 15:49:12] \u001b[32mEpoch 2 LR 0.024999\u001b[0m\n",
            "INFO:nni:Epoch 2 LR 0.024999\n",
            "[2023-01-12 15:49:13] \u001b[32mTrain: [  3/600] Step 000/520 Loss 2.090 Prec@(1,5) (50.0%, 88.5%)\u001b[0m\n",
            "INFO:nni:Train: [  3/600] Step 000/520 Loss 2.090 Prec@(1,5) (50.0%, 88.5%)\n",
            "[2023-01-12 15:49:17] \u001b[32mTrain: [  3/600] Step 010/520 Loss 2.006 Prec@(1,5) (47.6%, 92.4%)\u001b[0m\n",
            "INFO:nni:Train: [  3/600] Step 010/520 Loss 2.006 Prec@(1,5) (47.6%, 92.4%)\n",
            "[2023-01-12 15:49:22] \u001b[32mTrain: [  3/600] Step 020/520 Loss 1.983 Prec@(1,5) (49.2%, 92.1%)\u001b[0m\n",
            "INFO:nni:Train: [  3/600] Step 020/520 Loss 1.983 Prec@(1,5) (49.2%, 92.1%)\n",
            "[2023-01-12 15:49:26] \u001b[32mTrain: [  3/600] Step 030/520 Loss 2.000 Prec@(1,5) (49.0%, 92.2%)\u001b[0m\n",
            "INFO:nni:Train: [  3/600] Step 030/520 Loss 2.000 Prec@(1,5) (49.0%, 92.2%)\n",
            "[2023-01-12 15:49:31] \u001b[32mTrain: [  3/600] Step 040/520 Loss 2.002 Prec@(1,5) (49.0%, 92.3%)\u001b[0m\n",
            "INFO:nni:Train: [  3/600] Step 040/520 Loss 2.002 Prec@(1,5) (49.0%, 92.3%)\n",
            "[2023-01-12 15:49:35] \u001b[32mTrain: [  3/600] Step 050/520 Loss 1.996 Prec@(1,5) (49.2%, 92.7%)\u001b[0m\n",
            "INFO:nni:Train: [  3/600] Step 050/520 Loss 1.996 Prec@(1,5) (49.2%, 92.7%)\n",
            "[2023-01-12 15:49:40] \u001b[32mTrain: [  3/600] Step 060/520 Loss 2.000 Prec@(1,5) (49.2%, 92.8%)\u001b[0m\n",
            "INFO:nni:Train: [  3/600] Step 060/520 Loss 2.000 Prec@(1,5) (49.2%, 92.8%)\n",
            "[2023-01-12 15:49:44] \u001b[32mTrain: [  3/600] Step 070/520 Loss 2.000 Prec@(1,5) (49.7%, 92.7%)\u001b[0m\n",
            "INFO:nni:Train: [  3/600] Step 070/520 Loss 2.000 Prec@(1,5) (49.7%, 92.7%)\n",
            "[2023-01-12 15:49:49] \u001b[32mTrain: [  3/600] Step 080/520 Loss 1.998 Prec@(1,5) (49.6%, 92.7%)\u001b[0m\n",
            "INFO:nni:Train: [  3/600] Step 080/520 Loss 1.998 Prec@(1,5) (49.6%, 92.7%)\n",
            "[2023-01-12 15:49:53] \u001b[32mTrain: [  3/600] Step 090/520 Loss 1.992 Prec@(1,5) (49.6%, 92.8%)\u001b[0m\n",
            "INFO:nni:Train: [  3/600] Step 090/520 Loss 1.992 Prec@(1,5) (49.6%, 92.8%)\n",
            "[2023-01-12 15:49:58] \u001b[32mTrain: [  3/600] Step 100/520 Loss 1.995 Prec@(1,5) (49.5%, 92.8%)\u001b[0m\n",
            "INFO:nni:Train: [  3/600] Step 100/520 Loss 1.995 Prec@(1,5) (49.5%, 92.8%)\n",
            "[2023-01-12 15:50:02] \u001b[32mTrain: [  3/600] Step 110/520 Loss 1.986 Prec@(1,5) (49.6%, 92.7%)\u001b[0m\n",
            "INFO:nni:Train: [  3/600] Step 110/520 Loss 1.986 Prec@(1,5) (49.6%, 92.7%)\n",
            "[2023-01-12 15:50:07] \u001b[32mTrain: [  3/600] Step 120/520 Loss 1.997 Prec@(1,5) (49.4%, 92.8%)\u001b[0m\n",
            "INFO:nni:Train: [  3/600] Step 120/520 Loss 1.997 Prec@(1,5) (49.4%, 92.8%)\n",
            "[2023-01-12 15:50:11] \u001b[32mTrain: [  3/600] Step 130/520 Loss 1.995 Prec@(1,5) (49.2%, 92.8%)\u001b[0m\n",
            "INFO:nni:Train: [  3/600] Step 130/520 Loss 1.995 Prec@(1,5) (49.2%, 92.8%)\n",
            "[2023-01-12 15:50:16] \u001b[32mTrain: [  3/600] Step 140/520 Loss 1.982 Prec@(1,5) (49.3%, 92.9%)\u001b[0m\n",
            "INFO:nni:Train: [  3/600] Step 140/520 Loss 1.982 Prec@(1,5) (49.3%, 92.9%)\n",
            "[2023-01-12 15:50:20] \u001b[32mTrain: [  3/600] Step 150/520 Loss 1.979 Prec@(1,5) (49.4%, 92.9%)\u001b[0m\n",
            "INFO:nni:Train: [  3/600] Step 150/520 Loss 1.979 Prec@(1,5) (49.4%, 92.9%)\n",
            "[2023-01-12 15:50:25] \u001b[32mTrain: [  3/600] Step 160/520 Loss 1.980 Prec@(1,5) (49.3%, 93.0%)\u001b[0m\n",
            "INFO:nni:Train: [  3/600] Step 160/520 Loss 1.980 Prec@(1,5) (49.3%, 93.0%)\n",
            "[2023-01-12 15:50:29] \u001b[32mTrain: [  3/600] Step 170/520 Loss 1.980 Prec@(1,5) (49.2%, 93.0%)\u001b[0m\n",
            "INFO:nni:Train: [  3/600] Step 170/520 Loss 1.980 Prec@(1,5) (49.2%, 93.0%)\n",
            "[2023-01-12 15:50:34] \u001b[32mTrain: [  3/600] Step 180/520 Loss 1.977 Prec@(1,5) (49.2%, 93.0%)\u001b[0m\n",
            "INFO:nni:Train: [  3/600] Step 180/520 Loss 1.977 Prec@(1,5) (49.2%, 93.0%)\n",
            "[2023-01-12 15:50:38] \u001b[32mTrain: [  3/600] Step 190/520 Loss 1.976 Prec@(1,5) (49.3%, 93.0%)\u001b[0m\n",
            "INFO:nni:Train: [  3/600] Step 190/520 Loss 1.976 Prec@(1,5) (49.3%, 93.0%)\n",
            "[2023-01-12 15:50:43] \u001b[32mTrain: [  3/600] Step 200/520 Loss 1.969 Prec@(1,5) (49.5%, 93.1%)\u001b[0m\n",
            "INFO:nni:Train: [  3/600] Step 200/520 Loss 1.969 Prec@(1,5) (49.5%, 93.1%)\n",
            "[2023-01-12 15:50:47] \u001b[32mTrain: [  3/600] Step 210/520 Loss 1.970 Prec@(1,5) (49.4%, 93.1%)\u001b[0m\n",
            "INFO:nni:Train: [  3/600] Step 210/520 Loss 1.970 Prec@(1,5) (49.4%, 93.1%)\n",
            "[2023-01-12 15:50:52] \u001b[32mTrain: [  3/600] Step 220/520 Loss 1.971 Prec@(1,5) (49.4%, 93.1%)\u001b[0m\n",
            "INFO:nni:Train: [  3/600] Step 220/520 Loss 1.971 Prec@(1,5) (49.4%, 93.1%)\n",
            "[2023-01-12 15:50:56] \u001b[32mTrain: [  3/600] Step 230/520 Loss 1.968 Prec@(1,5) (49.4%, 93.1%)\u001b[0m\n",
            "INFO:nni:Train: [  3/600] Step 230/520 Loss 1.968 Prec@(1,5) (49.4%, 93.1%)\n",
            "[2023-01-12 15:51:01] \u001b[32mTrain: [  3/600] Step 240/520 Loss 1.962 Prec@(1,5) (49.5%, 93.1%)\u001b[0m\n",
            "INFO:nni:Train: [  3/600] Step 240/520 Loss 1.962 Prec@(1,5) (49.5%, 93.1%)\n",
            "[2023-01-12 15:51:05] \u001b[32mTrain: [  3/600] Step 250/520 Loss 1.961 Prec@(1,5) (49.5%, 93.2%)\u001b[0m\n",
            "INFO:nni:Train: [  3/600] Step 250/520 Loss 1.961 Prec@(1,5) (49.5%, 93.2%)\n",
            "[2023-01-12 15:51:10] \u001b[32mTrain: [  3/600] Step 260/520 Loss 1.957 Prec@(1,5) (49.7%, 93.2%)\u001b[0m\n",
            "INFO:nni:Train: [  3/600] Step 260/520 Loss 1.957 Prec@(1,5) (49.7%, 93.2%)\n",
            "[2023-01-12 15:51:14] \u001b[32mTrain: [  3/600] Step 270/520 Loss 1.950 Prec@(1,5) (49.8%, 93.3%)\u001b[0m\n",
            "INFO:nni:Train: [  3/600] Step 270/520 Loss 1.950 Prec@(1,5) (49.8%, 93.3%)\n",
            "[2023-01-12 15:51:19] \u001b[32mTrain: [  3/600] Step 280/520 Loss 1.946 Prec@(1,5) (49.9%, 93.4%)\u001b[0m\n",
            "INFO:nni:Train: [  3/600] Step 280/520 Loss 1.946 Prec@(1,5) (49.9%, 93.4%)\n",
            "[2023-01-12 15:51:23] \u001b[32mTrain: [  3/600] Step 290/520 Loss 1.943 Prec@(1,5) (50.0%, 93.4%)\u001b[0m\n",
            "INFO:nni:Train: [  3/600] Step 290/520 Loss 1.943 Prec@(1,5) (50.0%, 93.4%)\n",
            "[2023-01-12 15:51:28] \u001b[32mTrain: [  3/600] Step 300/520 Loss 1.938 Prec@(1,5) (50.1%, 93.4%)\u001b[0m\n",
            "INFO:nni:Train: [  3/600] Step 300/520 Loss 1.938 Prec@(1,5) (50.1%, 93.4%)\n",
            "[2023-01-12 15:51:32] \u001b[32mTrain: [  3/600] Step 310/520 Loss 1.934 Prec@(1,5) (50.3%, 93.4%)\u001b[0m\n",
            "INFO:nni:Train: [  3/600] Step 310/520 Loss 1.934 Prec@(1,5) (50.3%, 93.4%)\n",
            "[2023-01-12 15:51:37] \u001b[32mTrain: [  3/600] Step 320/520 Loss 1.931 Prec@(1,5) (50.4%, 93.4%)\u001b[0m\n",
            "INFO:nni:Train: [  3/600] Step 320/520 Loss 1.931 Prec@(1,5) (50.4%, 93.4%)\n",
            "[2023-01-12 15:51:41] \u001b[32mTrain: [  3/600] Step 330/520 Loss 1.928 Prec@(1,5) (50.5%, 93.4%)\u001b[0m\n",
            "INFO:nni:Train: [  3/600] Step 330/520 Loss 1.928 Prec@(1,5) (50.5%, 93.4%)\n",
            "[2023-01-12 15:51:46] \u001b[32mTrain: [  3/600] Step 340/520 Loss 1.925 Prec@(1,5) (50.6%, 93.5%)\u001b[0m\n",
            "INFO:nni:Train: [  3/600] Step 340/520 Loss 1.925 Prec@(1,5) (50.6%, 93.5%)\n",
            "[2023-01-12 15:51:50] \u001b[32mTrain: [  3/600] Step 350/520 Loss 1.923 Prec@(1,5) (50.6%, 93.5%)\u001b[0m\n",
            "INFO:nni:Train: [  3/600] Step 350/520 Loss 1.923 Prec@(1,5) (50.6%, 93.5%)\n",
            "[2023-01-12 15:51:55] \u001b[32mTrain: [  3/600] Step 360/520 Loss 1.922 Prec@(1,5) (50.6%, 93.5%)\u001b[0m\n",
            "INFO:nni:Train: [  3/600] Step 360/520 Loss 1.922 Prec@(1,5) (50.6%, 93.5%)\n",
            "[2023-01-12 15:51:59] \u001b[32mTrain: [  3/600] Step 370/520 Loss 1.919 Prec@(1,5) (50.7%, 93.5%)\u001b[0m\n",
            "INFO:nni:Train: [  3/600] Step 370/520 Loss 1.919 Prec@(1,5) (50.7%, 93.5%)\n",
            "[2023-01-12 15:52:04] \u001b[32mTrain: [  3/600] Step 380/520 Loss 1.916 Prec@(1,5) (50.8%, 93.5%)\u001b[0m\n",
            "INFO:nni:Train: [  3/600] Step 380/520 Loss 1.916 Prec@(1,5) (50.8%, 93.5%)\n",
            "[2023-01-12 15:52:08] \u001b[32mTrain: [  3/600] Step 390/520 Loss 1.911 Prec@(1,5) (50.9%, 93.6%)\u001b[0m\n",
            "INFO:nni:Train: [  3/600] Step 390/520 Loss 1.911 Prec@(1,5) (50.9%, 93.6%)\n",
            "[2023-01-12 15:52:13] \u001b[32mTrain: [  3/600] Step 400/520 Loss 1.908 Prec@(1,5) (51.0%, 93.6%)\u001b[0m\n",
            "INFO:nni:Train: [  3/600] Step 400/520 Loss 1.908 Prec@(1,5) (51.0%, 93.6%)\n",
            "[2023-01-12 15:52:17] \u001b[32mTrain: [  3/600] Step 410/520 Loss 1.905 Prec@(1,5) (51.1%, 93.6%)\u001b[0m\n",
            "INFO:nni:Train: [  3/600] Step 410/520 Loss 1.905 Prec@(1,5) (51.1%, 93.6%)\n",
            "[2023-01-12 15:52:22] \u001b[32mTrain: [  3/600] Step 420/520 Loss 1.901 Prec@(1,5) (51.2%, 93.7%)\u001b[0m\n",
            "INFO:nni:Train: [  3/600] Step 420/520 Loss 1.901 Prec@(1,5) (51.2%, 93.7%)\n",
            "[2023-01-12 15:52:26] \u001b[32mTrain: [  3/600] Step 430/520 Loss 1.900 Prec@(1,5) (51.3%, 93.7%)\u001b[0m\n",
            "INFO:nni:Train: [  3/600] Step 430/520 Loss 1.900 Prec@(1,5) (51.3%, 93.7%)\n",
            "[2023-01-12 15:52:31] \u001b[32mTrain: [  3/600] Step 440/520 Loss 1.900 Prec@(1,5) (51.3%, 93.7%)\u001b[0m\n",
            "INFO:nni:Train: [  3/600] Step 440/520 Loss 1.900 Prec@(1,5) (51.3%, 93.7%)\n",
            "[2023-01-12 15:52:35] \u001b[32mTrain: [  3/600] Step 450/520 Loss 1.898 Prec@(1,5) (51.3%, 93.7%)\u001b[0m\n",
            "INFO:nni:Train: [  3/600] Step 450/520 Loss 1.898 Prec@(1,5) (51.3%, 93.7%)\n",
            "[2023-01-12 15:52:40] \u001b[32mTrain: [  3/600] Step 460/520 Loss 1.897 Prec@(1,5) (51.4%, 93.7%)\u001b[0m\n",
            "INFO:nni:Train: [  3/600] Step 460/520 Loss 1.897 Prec@(1,5) (51.4%, 93.7%)\n",
            "[2023-01-12 15:52:44] \u001b[32mTrain: [  3/600] Step 470/520 Loss 1.894 Prec@(1,5) (51.5%, 93.7%)\u001b[0m\n",
            "INFO:nni:Train: [  3/600] Step 470/520 Loss 1.894 Prec@(1,5) (51.5%, 93.7%)\n",
            "[2023-01-12 15:52:49] \u001b[32mTrain: [  3/600] Step 480/520 Loss 1.891 Prec@(1,5) (51.5%, 93.7%)\u001b[0m\n",
            "INFO:nni:Train: [  3/600] Step 480/520 Loss 1.891 Prec@(1,5) (51.5%, 93.7%)\n",
            "[2023-01-12 15:52:53] \u001b[32mTrain: [  3/600] Step 490/520 Loss 1.886 Prec@(1,5) (51.6%, 93.8%)\u001b[0m\n",
            "INFO:nni:Train: [  3/600] Step 490/520 Loss 1.886 Prec@(1,5) (51.6%, 93.8%)\n",
            "[2023-01-12 15:52:58] \u001b[32mTrain: [  3/600] Step 500/520 Loss 1.886 Prec@(1,5) (51.7%, 93.7%)\u001b[0m\n",
            "INFO:nni:Train: [  3/600] Step 500/520 Loss 1.886 Prec@(1,5) (51.7%, 93.7%)\n",
            "[2023-01-12 15:53:02] \u001b[32mTrain: [  3/600] Step 510/520 Loss 1.884 Prec@(1,5) (51.7%, 93.8%)\u001b[0m\n",
            "INFO:nni:Train: [  3/600] Step 510/520 Loss 1.884 Prec@(1,5) (51.7%, 93.8%)\n",
            "[2023-01-12 15:53:07] \u001b[32mTrain: [  3/600] Step 520/520 Loss 1.881 Prec@(1,5) (51.8%, 93.8%)\u001b[0m\n",
            "INFO:nni:Train: [  3/600] Step 520/520 Loss 1.881 Prec@(1,5) (51.8%, 93.8%)\n",
            "[2023-01-12 15:53:07] \u001b[32mTrain: [  3/600] Final Prec@1 51.7500%\u001b[0m\n",
            "INFO:nni:Train: [  3/600] Final Prec@1 51.7500%\n",
            "[2023-01-12 15:53:07] \u001b[32mValid: [  3/600] Step 000/104 Loss 1.097 Prec@(1,5) (62.5%, 93.8%)\u001b[0m\n",
            "INFO:nni:Valid: [  3/600] Step 000/104 Loss 1.097 Prec@(1,5) (62.5%, 93.8%)\n",
            "[2023-01-12 15:53:09] \u001b[32mValid: [  3/600] Step 010/104 Loss 1.284 Prec@(1,5) (55.5%, 94.5%)\u001b[0m\n",
            "INFO:nni:Valid: [  3/600] Step 010/104 Loss 1.284 Prec@(1,5) (55.5%, 94.5%)\n",
            "[2023-01-12 15:53:10] \u001b[32mValid: [  3/600] Step 020/104 Loss 1.289 Prec@(1,5) (57.3%, 94.5%)\u001b[0m\n",
            "INFO:nni:Valid: [  3/600] Step 020/104 Loss 1.289 Prec@(1,5) (57.3%, 94.5%)\n",
            "[2023-01-12 15:53:12] \u001b[32mValid: [  3/600] Step 030/104 Loss 1.298 Prec@(1,5) (56.3%, 94.3%)\u001b[0m\n",
            "INFO:nni:Valid: [  3/600] Step 030/104 Loss 1.298 Prec@(1,5) (56.3%, 94.3%)\n",
            "[2023-01-12 15:53:13] \u001b[32mValid: [  3/600] Step 040/104 Loss 1.295 Prec@(1,5) (56.3%, 94.5%)\u001b[0m\n",
            "INFO:nni:Valid: [  3/600] Step 040/104 Loss 1.295 Prec@(1,5) (56.3%, 94.5%)\n",
            "[2023-01-12 15:53:14] \u001b[32mValid: [  3/600] Step 050/104 Loss 1.286 Prec@(1,5) (56.8%, 94.7%)\u001b[0m\n",
            "INFO:nni:Valid: [  3/600] Step 050/104 Loss 1.286 Prec@(1,5) (56.8%, 94.7%)\n",
            "[2023-01-12 15:53:16] \u001b[32mValid: [  3/600] Step 060/104 Loss 1.285 Prec@(1,5) (56.3%, 94.8%)\u001b[0m\n",
            "INFO:nni:Valid: [  3/600] Step 060/104 Loss 1.285 Prec@(1,5) (56.3%, 94.8%)\n",
            "[2023-01-12 15:53:17] \u001b[32mValid: [  3/600] Step 070/104 Loss 1.293 Prec@(1,5) (56.4%, 94.8%)\u001b[0m\n",
            "INFO:nni:Valid: [  3/600] Step 070/104 Loss 1.293 Prec@(1,5) (56.4%, 94.8%)\n",
            "[2023-01-12 15:53:19] \u001b[32mValid: [  3/600] Step 080/104 Loss 1.296 Prec@(1,5) (56.3%, 94.9%)\u001b[0m\n",
            "INFO:nni:Valid: [  3/600] Step 080/104 Loss 1.296 Prec@(1,5) (56.3%, 94.9%)\n",
            "[2023-01-12 15:53:20] \u001b[32mValid: [  3/600] Step 090/104 Loss 1.295 Prec@(1,5) (56.1%, 94.9%)\u001b[0m\n",
            "INFO:nni:Valid: [  3/600] Step 090/104 Loss 1.295 Prec@(1,5) (56.1%, 94.9%)\n",
            "[2023-01-12 15:53:22] \u001b[32mValid: [  3/600] Step 100/104 Loss 1.298 Prec@(1,5) (56.6%, 94.8%)\u001b[0m\n",
            "INFO:nni:Valid: [  3/600] Step 100/104 Loss 1.298 Prec@(1,5) (56.6%, 94.8%)\n",
            "[2023-01-12 15:53:22] \u001b[32mValid: [  3/600] Step 104/104 Loss 1.316 Prec@(1,5) (56.5%, 94.8%)\u001b[0m\n",
            "INFO:nni:Valid: [  3/600] Step 104/104 Loss 1.316 Prec@(1,5) (56.5%, 94.8%)\n",
            "[2023-01-12 15:53:22] \u001b[32mValid: [  3/600] Final Prec@1 56.4700%\u001b[0m\n",
            "INFO:nni:Valid: [  3/600] Final Prec@1 56.4700%\n",
            "[2023-01-12 15:53:22] \u001b[32mEpoch 3 LR 0.024998\u001b[0m\n",
            "INFO:nni:Epoch 3 LR 0.024998\n",
            "[2023-01-12 15:53:23] \u001b[32mTrain: [  4/600] Step 000/520 Loss 1.752 Prec@(1,5) (57.3%, 95.8%)\u001b[0m\n",
            "INFO:nni:Train: [  4/600] Step 000/520 Loss 1.752 Prec@(1,5) (57.3%, 95.8%)\n",
            "[2023-01-12 15:53:27] \u001b[32mTrain: [  4/600] Step 010/520 Loss 1.780 Prec@(1,5) (53.9%, 95.3%)\u001b[0m\n",
            "INFO:nni:Train: [  4/600] Step 010/520 Loss 1.780 Prec@(1,5) (53.9%, 95.3%)\n",
            "[2023-01-12 15:53:32] \u001b[32mTrain: [  4/600] Step 020/520 Loss 1.733 Prec@(1,5) (56.4%, 95.0%)\u001b[0m\n",
            "INFO:nni:Train: [  4/600] Step 020/520 Loss 1.733 Prec@(1,5) (56.4%, 95.0%)\n",
            "[2023-01-12 15:53:36] \u001b[32mTrain: [  4/600] Step 030/520 Loss 1.753 Prec@(1,5) (55.7%, 95.0%)\u001b[0m\n",
            "INFO:nni:Train: [  4/600] Step 030/520 Loss 1.753 Prec@(1,5) (55.7%, 95.0%)\n",
            "[2023-01-12 15:53:41] \u001b[32mTrain: [  4/600] Step 040/520 Loss 1.771 Prec@(1,5) (55.1%, 94.8%)\u001b[0m\n",
            "INFO:nni:Train: [  4/600] Step 040/520 Loss 1.771 Prec@(1,5) (55.1%, 94.8%)\n",
            "[2023-01-12 15:53:45] \u001b[32mTrain: [  4/600] Step 050/520 Loss 1.761 Prec@(1,5) (55.4%, 94.7%)\u001b[0m\n",
            "INFO:nni:Train: [  4/600] Step 050/520 Loss 1.761 Prec@(1,5) (55.4%, 94.7%)\n",
            "[2023-01-12 15:53:50] \u001b[32mTrain: [  4/600] Step 060/520 Loss 1.746 Prec@(1,5) (55.8%, 94.9%)\u001b[0m\n",
            "INFO:nni:Train: [  4/600] Step 060/520 Loss 1.746 Prec@(1,5) (55.8%, 94.9%)\n",
            "[2023-01-12 15:53:54] \u001b[32mTrain: [  4/600] Step 070/520 Loss 1.737 Prec@(1,5) (55.7%, 95.0%)\u001b[0m\n",
            "INFO:nni:Train: [  4/600] Step 070/520 Loss 1.737 Prec@(1,5) (55.7%, 95.0%)\n",
            "[2023-01-12 15:53:59] \u001b[32mTrain: [  4/600] Step 080/520 Loss 1.726 Prec@(1,5) (55.9%, 95.1%)\u001b[0m\n",
            "INFO:nni:Train: [  4/600] Step 080/520 Loss 1.726 Prec@(1,5) (55.9%, 95.1%)\n",
            "[2023-01-12 15:54:04] \u001b[32mTrain: [  4/600] Step 090/520 Loss 1.714 Prec@(1,5) (56.1%, 95.1%)\u001b[0m\n",
            "INFO:nni:Train: [  4/600] Step 090/520 Loss 1.714 Prec@(1,5) (56.1%, 95.1%)\n",
            "[2023-01-12 15:54:08] \u001b[32mTrain: [  4/600] Step 100/520 Loss 1.709 Prec@(1,5) (56.2%, 95.0%)\u001b[0m\n",
            "INFO:nni:Train: [  4/600] Step 100/520 Loss 1.709 Prec@(1,5) (56.2%, 95.0%)\n",
            "[2023-01-12 15:54:13] \u001b[32mTrain: [  4/600] Step 110/520 Loss 1.706 Prec@(1,5) (56.2%, 95.1%)\u001b[0m\n",
            "INFO:nni:Train: [  4/600] Step 110/520 Loss 1.706 Prec@(1,5) (56.2%, 95.1%)\n",
            "[2023-01-12 15:54:17] \u001b[32mTrain: [  4/600] Step 120/520 Loss 1.711 Prec@(1,5) (56.3%, 95.2%)\u001b[0m\n",
            "INFO:nni:Train: [  4/600] Step 120/520 Loss 1.711 Prec@(1,5) (56.3%, 95.2%)\n",
            "[2023-01-12 15:54:22] \u001b[32mTrain: [  4/600] Step 130/520 Loss 1.709 Prec@(1,5) (56.5%, 95.2%)\u001b[0m\n",
            "INFO:nni:Train: [  4/600] Step 130/520 Loss 1.709 Prec@(1,5) (56.5%, 95.2%)\n",
            "[2023-01-12 15:54:26] \u001b[32mTrain: [  4/600] Step 140/520 Loss 1.706 Prec@(1,5) (56.5%, 95.3%)\u001b[0m\n",
            "INFO:nni:Train: [  4/600] Step 140/520 Loss 1.706 Prec@(1,5) (56.5%, 95.3%)\n",
            "[2023-01-12 15:54:31] \u001b[32mTrain: [  4/600] Step 150/520 Loss 1.708 Prec@(1,5) (56.5%, 95.2%)\u001b[0m\n",
            "INFO:nni:Train: [  4/600] Step 150/520 Loss 1.708 Prec@(1,5) (56.5%, 95.2%)\n",
            "[2023-01-12 15:54:35] \u001b[32mTrain: [  4/600] Step 160/520 Loss 1.703 Prec@(1,5) (56.6%, 95.2%)\u001b[0m\n",
            "INFO:nni:Train: [  4/600] Step 160/520 Loss 1.703 Prec@(1,5) (56.6%, 95.2%)\n",
            "[2023-01-12 15:54:40] \u001b[32mTrain: [  4/600] Step 170/520 Loss 1.702 Prec@(1,5) (56.6%, 95.2%)\u001b[0m\n",
            "INFO:nni:Train: [  4/600] Step 170/520 Loss 1.702 Prec@(1,5) (56.6%, 95.2%)\n",
            "[2023-01-12 15:54:44] \u001b[32mTrain: [  4/600] Step 180/520 Loss 1.701 Prec@(1,5) (56.6%, 95.2%)\u001b[0m\n",
            "INFO:nni:Train: [  4/600] Step 180/520 Loss 1.701 Prec@(1,5) (56.6%, 95.2%)\n",
            "[2023-01-12 15:54:49] \u001b[32mTrain: [  4/600] Step 190/520 Loss 1.698 Prec@(1,5) (56.6%, 95.1%)\u001b[0m\n",
            "INFO:nni:Train: [  4/600] Step 190/520 Loss 1.698 Prec@(1,5) (56.6%, 95.1%)\n",
            "[2023-01-12 15:54:53] \u001b[32mTrain: [  4/600] Step 200/520 Loss 1.697 Prec@(1,5) (56.7%, 95.1%)\u001b[0m\n",
            "INFO:nni:Train: [  4/600] Step 200/520 Loss 1.697 Prec@(1,5) (56.7%, 95.1%)\n",
            "[2023-01-12 15:54:58] \u001b[32mTrain: [  4/600] Step 210/520 Loss 1.693 Prec@(1,5) (56.7%, 95.2%)\u001b[0m\n",
            "INFO:nni:Train: [  4/600] Step 210/520 Loss 1.693 Prec@(1,5) (56.7%, 95.2%)\n",
            "[2023-01-12 15:55:02] \u001b[32mTrain: [  4/600] Step 220/520 Loss 1.692 Prec@(1,5) (56.7%, 95.1%)\u001b[0m\n",
            "INFO:nni:Train: [  4/600] Step 220/520 Loss 1.692 Prec@(1,5) (56.7%, 95.1%)\n",
            "[2023-01-12 15:55:07] \u001b[32mTrain: [  4/600] Step 230/520 Loss 1.690 Prec@(1,5) (56.7%, 95.1%)\u001b[0m\n",
            "INFO:nni:Train: [  4/600] Step 230/520 Loss 1.690 Prec@(1,5) (56.7%, 95.1%)\n",
            "[2023-01-12 15:55:11] \u001b[32mTrain: [  4/600] Step 240/520 Loss 1.691 Prec@(1,5) (56.7%, 95.1%)\u001b[0m\n",
            "INFO:nni:Train: [  4/600] Step 240/520 Loss 1.691 Prec@(1,5) (56.7%, 95.1%)\n",
            "[2023-01-12 15:55:16] \u001b[32mTrain: [  4/600] Step 250/520 Loss 1.687 Prec@(1,5) (56.8%, 95.1%)\u001b[0m\n",
            "INFO:nni:Train: [  4/600] Step 250/520 Loss 1.687 Prec@(1,5) (56.8%, 95.1%)\n",
            "[2023-01-12 15:55:20] \u001b[32mTrain: [  4/600] Step 260/520 Loss 1.685 Prec@(1,5) (56.8%, 95.1%)\u001b[0m\n",
            "INFO:nni:Train: [  4/600] Step 260/520 Loss 1.685 Prec@(1,5) (56.8%, 95.1%)\n",
            "[2023-01-12 15:55:25] \u001b[32mTrain: [  4/600] Step 270/520 Loss 1.683 Prec@(1,5) (56.8%, 95.1%)\u001b[0m\n",
            "INFO:nni:Train: [  4/600] Step 270/520 Loss 1.683 Prec@(1,5) (56.8%, 95.1%)\n",
            "[2023-01-12 15:55:29] \u001b[32mTrain: [  4/600] Step 280/520 Loss 1.678 Prec@(1,5) (56.8%, 95.2%)\u001b[0m\n",
            "INFO:nni:Train: [  4/600] Step 280/520 Loss 1.678 Prec@(1,5) (56.8%, 95.2%)\n",
            "[2023-01-12 15:55:34] \u001b[32mTrain: [  4/600] Step 290/520 Loss 1.677 Prec@(1,5) (56.9%, 95.2%)\u001b[0m\n",
            "INFO:nni:Train: [  4/600] Step 290/520 Loss 1.677 Prec@(1,5) (56.9%, 95.2%)\n",
            "[2023-01-12 15:55:38] \u001b[32mTrain: [  4/600] Step 300/520 Loss 1.679 Prec@(1,5) (56.9%, 95.1%)\u001b[0m\n",
            "INFO:nni:Train: [  4/600] Step 300/520 Loss 1.679 Prec@(1,5) (56.9%, 95.1%)\n",
            "[2023-01-12 15:55:43] \u001b[32mTrain: [  4/600] Step 310/520 Loss 1.675 Prec@(1,5) (56.9%, 95.2%)\u001b[0m\n",
            "INFO:nni:Train: [  4/600] Step 310/520 Loss 1.675 Prec@(1,5) (56.9%, 95.2%)\n",
            "[2023-01-12 15:55:47] \u001b[32mTrain: [  4/600] Step 320/520 Loss 1.670 Prec@(1,5) (57.1%, 95.2%)\u001b[0m\n",
            "INFO:nni:Train: [  4/600] Step 320/520 Loss 1.670 Prec@(1,5) (57.1%, 95.2%)\n",
            "[2023-01-12 15:55:52] \u001b[32mTrain: [  4/600] Step 330/520 Loss 1.673 Prec@(1,5) (57.0%, 95.1%)\u001b[0m\n",
            "INFO:nni:Train: [  4/600] Step 330/520 Loss 1.673 Prec@(1,5) (57.0%, 95.1%)\n",
            "[2023-01-12 15:55:56] \u001b[32mTrain: [  4/600] Step 340/520 Loss 1.670 Prec@(1,5) (57.1%, 95.2%)\u001b[0m\n",
            "INFO:nni:Train: [  4/600] Step 340/520 Loss 1.670 Prec@(1,5) (57.1%, 95.2%)\n",
            "[2023-01-12 15:56:01] \u001b[32mTrain: [  4/600] Step 350/520 Loss 1.670 Prec@(1,5) (57.1%, 95.2%)\u001b[0m\n",
            "INFO:nni:Train: [  4/600] Step 350/520 Loss 1.670 Prec@(1,5) (57.1%, 95.2%)\n",
            "[2023-01-12 15:56:05] \u001b[32mTrain: [  4/600] Step 360/520 Loss 1.669 Prec@(1,5) (57.1%, 95.2%)\u001b[0m\n",
            "INFO:nni:Train: [  4/600] Step 360/520 Loss 1.669 Prec@(1,5) (57.1%, 95.2%)\n",
            "[2023-01-12 15:56:10] \u001b[32mTrain: [  4/600] Step 370/520 Loss 1.671 Prec@(1,5) (57.1%, 95.2%)\u001b[0m\n",
            "INFO:nni:Train: [  4/600] Step 370/520 Loss 1.671 Prec@(1,5) (57.1%, 95.2%)\n",
            "[2023-01-12 15:56:14] \u001b[32mTrain: [  4/600] Step 380/520 Loss 1.668 Prec@(1,5) (57.2%, 95.2%)\u001b[0m\n",
            "INFO:nni:Train: [  4/600] Step 380/520 Loss 1.668 Prec@(1,5) (57.2%, 95.2%)\n",
            "[2023-01-12 15:56:19] \u001b[32mTrain: [  4/600] Step 390/520 Loss 1.670 Prec@(1,5) (57.1%, 95.2%)\u001b[0m\n",
            "INFO:nni:Train: [  4/600] Step 390/520 Loss 1.670 Prec@(1,5) (57.1%, 95.2%)\n",
            "[2023-01-12 15:56:23] \u001b[32mTrain: [  4/600] Step 400/520 Loss 1.669 Prec@(1,5) (57.2%, 95.2%)\u001b[0m\n",
            "INFO:nni:Train: [  4/600] Step 400/520 Loss 1.669 Prec@(1,5) (57.2%, 95.2%)\n",
            "[2023-01-12 15:56:28] \u001b[32mTrain: [  4/600] Step 410/520 Loss 1.667 Prec@(1,5) (57.2%, 95.2%)\u001b[0m\n",
            "INFO:nni:Train: [  4/600] Step 410/520 Loss 1.667 Prec@(1,5) (57.2%, 95.2%)\n",
            "[2023-01-12 15:56:32] \u001b[32mTrain: [  4/600] Step 420/520 Loss 1.663 Prec@(1,5) (57.3%, 95.3%)\u001b[0m\n",
            "INFO:nni:Train: [  4/600] Step 420/520 Loss 1.663 Prec@(1,5) (57.3%, 95.3%)\n",
            "[2023-01-12 15:56:37] \u001b[32mTrain: [  4/600] Step 430/520 Loss 1.661 Prec@(1,5) (57.4%, 95.3%)\u001b[0m\n",
            "INFO:nni:Train: [  4/600] Step 430/520 Loss 1.661 Prec@(1,5) (57.4%, 95.3%)\n",
            "[2023-01-12 15:56:41] \u001b[32mTrain: [  4/600] Step 440/520 Loss 1.660 Prec@(1,5) (57.4%, 95.3%)\u001b[0m\n",
            "INFO:nni:Train: [  4/600] Step 440/520 Loss 1.660 Prec@(1,5) (57.4%, 95.3%)\n",
            "[2023-01-12 15:56:46] \u001b[32mTrain: [  4/600] Step 450/520 Loss 1.659 Prec@(1,5) (57.4%, 95.3%)\u001b[0m\n",
            "INFO:nni:Train: [  4/600] Step 450/520 Loss 1.659 Prec@(1,5) (57.4%, 95.3%)\n",
            "[2023-01-12 15:56:50] \u001b[32mTrain: [  4/600] Step 460/520 Loss 1.658 Prec@(1,5) (57.4%, 95.3%)\u001b[0m\n",
            "INFO:nni:Train: [  4/600] Step 460/520 Loss 1.658 Prec@(1,5) (57.4%, 95.3%)\n",
            "[2023-01-12 15:56:55] \u001b[32mTrain: [  4/600] Step 470/520 Loss 1.657 Prec@(1,5) (57.4%, 95.3%)\u001b[0m\n",
            "INFO:nni:Train: [  4/600] Step 470/520 Loss 1.657 Prec@(1,5) (57.4%, 95.3%)\n",
            "[2023-01-12 15:57:00] \u001b[32mTrain: [  4/600] Step 480/520 Loss 1.656 Prec@(1,5) (57.5%, 95.3%)\u001b[0m\n",
            "INFO:nni:Train: [  4/600] Step 480/520 Loss 1.656 Prec@(1,5) (57.5%, 95.3%)\n",
            "[2023-01-12 15:57:04] \u001b[32mTrain: [  4/600] Step 490/520 Loss 1.654 Prec@(1,5) (57.5%, 95.3%)\u001b[0m\n",
            "INFO:nni:Train: [  4/600] Step 490/520 Loss 1.654 Prec@(1,5) (57.5%, 95.3%)\n",
            "[2023-01-12 15:57:09] \u001b[32mTrain: [  4/600] Step 500/520 Loss 1.653 Prec@(1,5) (57.6%, 95.3%)\u001b[0m\n",
            "INFO:nni:Train: [  4/600] Step 500/520 Loss 1.653 Prec@(1,5) (57.6%, 95.3%)\n",
            "[2023-01-12 15:57:13] \u001b[32mTrain: [  4/600] Step 510/520 Loss 1.651 Prec@(1,5) (57.6%, 95.4%)\u001b[0m\n",
            "INFO:nni:Train: [  4/600] Step 510/520 Loss 1.651 Prec@(1,5) (57.6%, 95.4%)\n",
            "[2023-01-12 15:57:18] \u001b[32mTrain: [  4/600] Step 520/520 Loss 1.649 Prec@(1,5) (57.7%, 95.4%)\u001b[0m\n",
            "INFO:nni:Train: [  4/600] Step 520/520 Loss 1.649 Prec@(1,5) (57.7%, 95.4%)\n",
            "[2023-01-12 15:57:18] \u001b[32mTrain: [  4/600] Final Prec@1 57.6800%\u001b[0m\n",
            "INFO:nni:Train: [  4/600] Final Prec@1 57.6800%\n",
            "[2023-01-12 15:57:18] \u001b[32mValid: [  4/600] Step 000/104 Loss 1.060 Prec@(1,5) (58.3%, 93.8%)\u001b[0m\n",
            "INFO:nni:Valid: [  4/600] Step 000/104 Loss 1.060 Prec@(1,5) (58.3%, 93.8%)\n",
            "[2023-01-12 15:57:19] \u001b[32mValid: [  4/600] Step 010/104 Loss 1.022 Prec@(1,5) (62.9%, 96.2%)\u001b[0m\n",
            "INFO:nni:Valid: [  4/600] Step 010/104 Loss 1.022 Prec@(1,5) (62.9%, 96.2%)\n",
            "[2023-01-12 15:57:21] \u001b[32mValid: [  4/600] Step 020/104 Loss 1.024 Prec@(1,5) (63.6%, 96.6%)\u001b[0m\n",
            "INFO:nni:Valid: [  4/600] Step 020/104 Loss 1.024 Prec@(1,5) (63.6%, 96.6%)\n",
            "[2023-01-12 15:57:22] \u001b[32mValid: [  4/600] Step 030/104 Loss 1.033 Prec@(1,5) (63.4%, 96.7%)\u001b[0m\n",
            "INFO:nni:Valid: [  4/600] Step 030/104 Loss 1.033 Prec@(1,5) (63.4%, 96.7%)\n",
            "[2023-01-12 15:57:24] \u001b[32mValid: [  4/600] Step 040/104 Loss 1.034 Prec@(1,5) (62.9%, 96.4%)\u001b[0m\n",
            "INFO:nni:Valid: [  4/600] Step 040/104 Loss 1.034 Prec@(1,5) (62.9%, 96.4%)\n",
            "[2023-01-12 15:57:25] \u001b[32mValid: [  4/600] Step 050/104 Loss 1.033 Prec@(1,5) (63.0%, 96.6%)\u001b[0m\n",
            "INFO:nni:Valid: [  4/600] Step 050/104 Loss 1.033 Prec@(1,5) (63.0%, 96.6%)\n",
            "[2023-01-12 15:57:26] \u001b[32mValid: [  4/600] Step 060/104 Loss 1.030 Prec@(1,5) (63.4%, 96.6%)\u001b[0m\n",
            "INFO:nni:Valid: [  4/600] Step 060/104 Loss 1.030 Prec@(1,5) (63.4%, 96.6%)\n",
            "[2023-01-12 15:57:28] \u001b[32mValid: [  4/600] Step 070/104 Loss 1.031 Prec@(1,5) (63.4%, 96.7%)\u001b[0m\n",
            "INFO:nni:Valid: [  4/600] Step 070/104 Loss 1.031 Prec@(1,5) (63.4%, 96.7%)\n",
            "[2023-01-12 15:57:29] \u001b[32mValid: [  4/600] Step 080/104 Loss 1.024 Prec@(1,5) (63.7%, 96.8%)\u001b[0m\n",
            "INFO:nni:Valid: [  4/600] Step 080/104 Loss 1.024 Prec@(1,5) (63.7%, 96.8%)\n",
            "[2023-01-12 15:57:31] \u001b[32mValid: [  4/600] Step 090/104 Loss 1.027 Prec@(1,5) (63.6%, 96.9%)\u001b[0m\n",
            "INFO:nni:Valid: [  4/600] Step 090/104 Loss 1.027 Prec@(1,5) (63.6%, 96.9%)\n",
            "[2023-01-12 15:57:32] \u001b[32mValid: [  4/600] Step 100/104 Loss 1.022 Prec@(1,5) (63.9%, 96.9%)\u001b[0m\n",
            "INFO:nni:Valid: [  4/600] Step 100/104 Loss 1.022 Prec@(1,5) (63.9%, 96.9%)\n",
            "[2023-01-12 15:57:33] \u001b[32mValid: [  4/600] Step 104/104 Loss 1.024 Prec@(1,5) (63.7%, 97.0%)\u001b[0m\n",
            "INFO:nni:Valid: [  4/600] Step 104/104 Loss 1.024 Prec@(1,5) (63.7%, 97.0%)\n",
            "[2023-01-12 15:57:33] \u001b[32mValid: [  4/600] Final Prec@1 63.6800%\u001b[0m\n",
            "INFO:nni:Valid: [  4/600] Final Prec@1 63.6800%\n",
            "[2023-01-12 15:57:33] \u001b[32mEpoch 4 LR 0.024997\u001b[0m\n",
            "INFO:nni:Epoch 4 LR 0.024997\n",
            "[2023-01-12 15:57:34] \u001b[32mTrain: [  5/600] Step 000/520 Loss 1.505 Prec@(1,5) (61.5%, 97.9%)\u001b[0m\n",
            "INFO:nni:Train: [  5/600] Step 000/520 Loss 1.505 Prec@(1,5) (61.5%, 97.9%)\n",
            "[2023-01-12 15:57:38] \u001b[32mTrain: [  5/600] Step 010/520 Loss 1.516 Prec@(1,5) (60.6%, 97.0%)\u001b[0m\n",
            "INFO:nni:Train: [  5/600] Step 010/520 Loss 1.516 Prec@(1,5) (60.6%, 97.0%)\n",
            "[2023-01-12 15:57:43] \u001b[32mTrain: [  5/600] Step 020/520 Loss 1.544 Prec@(1,5) (60.2%, 96.5%)\u001b[0m\n",
            "INFO:nni:Train: [  5/600] Step 020/520 Loss 1.544 Prec@(1,5) (60.2%, 96.5%)\n",
            "[2023-01-12 15:57:47] \u001b[32mTrain: [  5/600] Step 030/520 Loss 1.563 Prec@(1,5) (60.6%, 96.6%)\u001b[0m\n",
            "INFO:nni:Train: [  5/600] Step 030/520 Loss 1.563 Prec@(1,5) (60.6%, 96.6%)\n",
            "[2023-01-12 15:57:52] \u001b[32mTrain: [  5/600] Step 040/520 Loss 1.572 Prec@(1,5) (60.5%, 96.5%)\u001b[0m\n",
            "INFO:nni:Train: [  5/600] Step 040/520 Loss 1.572 Prec@(1,5) (60.5%, 96.5%)\n",
            "[2023-01-12 15:57:56] \u001b[32mTrain: [  5/600] Step 050/520 Loss 1.581 Prec@(1,5) (60.1%, 96.3%)\u001b[0m\n",
            "INFO:nni:Train: [  5/600] Step 050/520 Loss 1.581 Prec@(1,5) (60.1%, 96.3%)\n",
            "[2023-01-12 15:58:01] \u001b[32mTrain: [  5/600] Step 060/520 Loss 1.565 Prec@(1,5) (60.4%, 96.3%)\u001b[0m\n",
            "INFO:nni:Train: [  5/600] Step 060/520 Loss 1.565 Prec@(1,5) (60.4%, 96.3%)\n",
            "[2023-01-12 15:58:05] \u001b[32mTrain: [  5/600] Step 070/520 Loss 1.573 Prec@(1,5) (60.5%, 96.1%)\u001b[0m\n",
            "INFO:nni:Train: [  5/600] Step 070/520 Loss 1.573 Prec@(1,5) (60.5%, 96.1%)\n",
            "[2023-01-12 15:58:10] \u001b[32mTrain: [  5/600] Step 080/520 Loss 1.574 Prec@(1,5) (60.4%, 96.0%)\u001b[0m\n",
            "INFO:nni:Train: [  5/600] Step 080/520 Loss 1.574 Prec@(1,5) (60.4%, 96.0%)\n",
            "[2023-01-12 15:58:14] \u001b[32mTrain: [  5/600] Step 090/520 Loss 1.564 Prec@(1,5) (60.6%, 96.1%)\u001b[0m\n",
            "INFO:nni:Train: [  5/600] Step 090/520 Loss 1.564 Prec@(1,5) (60.6%, 96.1%)\n",
            "[2023-01-12 15:58:19] \u001b[32mTrain: [  5/600] Step 100/520 Loss 1.562 Prec@(1,5) (60.6%, 96.1%)\u001b[0m\n",
            "INFO:nni:Train: [  5/600] Step 100/520 Loss 1.562 Prec@(1,5) (60.6%, 96.1%)\n",
            "[2023-01-12 15:58:23] \u001b[32mTrain: [  5/600] Step 110/520 Loss 1.571 Prec@(1,5) (60.4%, 96.0%)\u001b[0m\n",
            "INFO:nni:Train: [  5/600] Step 110/520 Loss 1.571 Prec@(1,5) (60.4%, 96.0%)\n",
            "[2023-01-12 15:58:28] \u001b[32mTrain: [  5/600] Step 120/520 Loss 1.583 Prec@(1,5) (60.3%, 95.9%)\u001b[0m\n",
            "INFO:nni:Train: [  5/600] Step 120/520 Loss 1.583 Prec@(1,5) (60.3%, 95.9%)\n",
            "[2023-01-12 15:58:32] \u001b[32mTrain: [  5/600] Step 130/520 Loss 1.588 Prec@(1,5) (60.1%, 95.8%)\u001b[0m\n",
            "INFO:nni:Train: [  5/600] Step 130/520 Loss 1.588 Prec@(1,5) (60.1%, 95.8%)\n",
            "[2023-01-12 15:58:37] \u001b[32mTrain: [  5/600] Step 140/520 Loss 1.585 Prec@(1,5) (60.1%, 95.8%)\u001b[0m\n",
            "INFO:nni:Train: [  5/600] Step 140/520 Loss 1.585 Prec@(1,5) (60.1%, 95.8%)\n",
            "[2023-01-12 15:58:41] \u001b[32mTrain: [  5/600] Step 150/520 Loss 1.589 Prec@(1,5) (60.0%, 95.7%)\u001b[0m\n",
            "INFO:nni:Train: [  5/600] Step 150/520 Loss 1.589 Prec@(1,5) (60.0%, 95.7%)\n",
            "[2023-01-12 15:58:46] \u001b[32mTrain: [  5/600] Step 160/520 Loss 1.590 Prec@(1,5) (60.0%, 95.7%)\u001b[0m\n",
            "INFO:nni:Train: [  5/600] Step 160/520 Loss 1.590 Prec@(1,5) (60.0%, 95.7%)\n",
            "[2023-01-12 15:58:50] \u001b[32mTrain: [  5/600] Step 170/520 Loss 1.592 Prec@(1,5) (59.9%, 95.6%)\u001b[0m\n",
            "INFO:nni:Train: [  5/600] Step 170/520 Loss 1.592 Prec@(1,5) (59.9%, 95.6%)\n",
            "[2023-01-12 15:58:55] \u001b[32mTrain: [  5/600] Step 180/520 Loss 1.596 Prec@(1,5) (59.8%, 95.5%)\u001b[0m\n",
            "INFO:nni:Train: [  5/600] Step 180/520 Loss 1.596 Prec@(1,5) (59.8%, 95.5%)\n",
            "[2023-01-12 15:58:59] \u001b[32mTrain: [  5/600] Step 190/520 Loss 1.590 Prec@(1,5) (60.0%, 95.5%)\u001b[0m\n",
            "INFO:nni:Train: [  5/600] Step 190/520 Loss 1.590 Prec@(1,5) (60.0%, 95.5%)\n",
            "[2023-01-12 15:59:04] \u001b[32mTrain: [  5/600] Step 200/520 Loss 1.587 Prec@(1,5) (60.0%, 95.6%)\u001b[0m\n",
            "INFO:nni:Train: [  5/600] Step 200/520 Loss 1.587 Prec@(1,5) (60.0%, 95.6%)\n",
            "[2023-01-12 15:59:08] \u001b[32mTrain: [  5/600] Step 210/520 Loss 1.583 Prec@(1,5) (60.0%, 95.6%)\u001b[0m\n",
            "INFO:nni:Train: [  5/600] Step 210/520 Loss 1.583 Prec@(1,5) (60.0%, 95.6%)\n",
            "[2023-01-12 15:59:13] \u001b[32mTrain: [  5/600] Step 220/520 Loss 1.582 Prec@(1,5) (60.1%, 95.6%)\u001b[0m\n",
            "INFO:nni:Train: [  5/600] Step 220/520 Loss 1.582 Prec@(1,5) (60.1%, 95.6%)\n",
            "[2023-01-12 15:59:17] \u001b[32mTrain: [  5/600] Step 230/520 Loss 1.574 Prec@(1,5) (60.3%, 95.6%)\u001b[0m\n",
            "INFO:nni:Train: [  5/600] Step 230/520 Loss 1.574 Prec@(1,5) (60.3%, 95.6%)\n",
            "[2023-01-12 15:59:22] \u001b[32mTrain: [  5/600] Step 240/520 Loss 1.570 Prec@(1,5) (60.5%, 95.7%)\u001b[0m\n",
            "INFO:nni:Train: [  5/600] Step 240/520 Loss 1.570 Prec@(1,5) (60.5%, 95.7%)\n",
            "[2023-01-12 15:59:27] \u001b[32mTrain: [  5/600] Step 250/520 Loss 1.568 Prec@(1,5) (60.6%, 95.6%)\u001b[0m\n",
            "INFO:nni:Train: [  5/600] Step 250/520 Loss 1.568 Prec@(1,5) (60.6%, 95.6%)\n",
            "[2023-01-12 15:59:31] \u001b[32mTrain: [  5/600] Step 260/520 Loss 1.564 Prec@(1,5) (60.7%, 95.7%)\u001b[0m\n",
            "INFO:nni:Train: [  5/600] Step 260/520 Loss 1.564 Prec@(1,5) (60.7%, 95.7%)\n",
            "[2023-01-12 15:59:36] \u001b[32mTrain: [  5/600] Step 270/520 Loss 1.562 Prec@(1,5) (60.7%, 95.7%)\u001b[0m\n",
            "INFO:nni:Train: [  5/600] Step 270/520 Loss 1.562 Prec@(1,5) (60.7%, 95.7%)\n",
            "[2023-01-12 15:59:40] \u001b[32mTrain: [  5/600] Step 280/520 Loss 1.560 Prec@(1,5) (60.7%, 95.7%)\u001b[0m\n",
            "INFO:nni:Train: [  5/600] Step 280/520 Loss 1.560 Prec@(1,5) (60.7%, 95.7%)\n",
            "[2023-01-12 15:59:45] \u001b[32mTrain: [  5/600] Step 290/520 Loss 1.554 Prec@(1,5) (60.9%, 95.7%)\u001b[0m\n",
            "INFO:nni:Train: [  5/600] Step 290/520 Loss 1.554 Prec@(1,5) (60.9%, 95.7%)\n",
            "[2023-01-12 15:59:49] \u001b[32mTrain: [  5/600] Step 300/520 Loss 1.554 Prec@(1,5) (60.9%, 95.7%)\u001b[0m\n",
            "INFO:nni:Train: [  5/600] Step 300/520 Loss 1.554 Prec@(1,5) (60.9%, 95.7%)\n",
            "[2023-01-12 15:59:54] \u001b[32mTrain: [  5/600] Step 310/520 Loss 1.555 Prec@(1,5) (60.9%, 95.7%)\u001b[0m\n",
            "INFO:nni:Train: [  5/600] Step 310/520 Loss 1.555 Prec@(1,5) (60.9%, 95.7%)\n",
            "[2023-01-12 15:59:58] \u001b[32mTrain: [  5/600] Step 320/520 Loss 1.556 Prec@(1,5) (60.9%, 95.7%)\u001b[0m\n",
            "INFO:nni:Train: [  5/600] Step 320/520 Loss 1.556 Prec@(1,5) (60.9%, 95.7%)\n",
            "[2023-01-12 16:00:03] \u001b[32mTrain: [  5/600] Step 330/520 Loss 1.554 Prec@(1,5) (60.9%, 95.7%)\u001b[0m\n",
            "INFO:nni:Train: [  5/600] Step 330/520 Loss 1.554 Prec@(1,5) (60.9%, 95.7%)\n",
            "[2023-01-12 16:00:07] \u001b[32mTrain: [  5/600] Step 340/520 Loss 1.552 Prec@(1,5) (61.0%, 95.7%)\u001b[0m\n",
            "INFO:nni:Train: [  5/600] Step 340/520 Loss 1.552 Prec@(1,5) (61.0%, 95.7%)\n",
            "[2023-01-12 16:00:12] \u001b[32mTrain: [  5/600] Step 350/520 Loss 1.553 Prec@(1,5) (61.0%, 95.7%)\u001b[0m\n",
            "INFO:nni:Train: [  5/600] Step 350/520 Loss 1.553 Prec@(1,5) (61.0%, 95.7%)\n",
            "[2023-01-12 16:00:16] \u001b[32mTrain: [  5/600] Step 360/520 Loss 1.550 Prec@(1,5) (61.1%, 95.7%)\u001b[0m\n",
            "INFO:nni:Train: [  5/600] Step 360/520 Loss 1.550 Prec@(1,5) (61.1%, 95.7%)\n",
            "[2023-01-12 16:00:21] \u001b[32mTrain: [  5/600] Step 370/520 Loss 1.546 Prec@(1,5) (61.2%, 95.7%)\u001b[0m\n",
            "INFO:nni:Train: [  5/600] Step 370/520 Loss 1.546 Prec@(1,5) (61.2%, 95.7%)\n",
            "[2023-01-12 16:00:25] \u001b[32mTrain: [  5/600] Step 380/520 Loss 1.545 Prec@(1,5) (61.2%, 95.7%)\u001b[0m\n",
            "INFO:nni:Train: [  5/600] Step 380/520 Loss 1.545 Prec@(1,5) (61.2%, 95.7%)\n",
            "[2023-01-12 16:00:30] \u001b[32mTrain: [  5/600] Step 390/520 Loss 1.548 Prec@(1,5) (61.1%, 95.7%)\u001b[0m\n",
            "INFO:nni:Train: [  5/600] Step 390/520 Loss 1.548 Prec@(1,5) (61.1%, 95.7%)\n",
            "[2023-01-12 16:00:34] \u001b[32mTrain: [  5/600] Step 400/520 Loss 1.549 Prec@(1,5) (61.1%, 95.8%)\u001b[0m\n",
            "INFO:nni:Train: [  5/600] Step 400/520 Loss 1.549 Prec@(1,5) (61.1%, 95.8%)\n",
            "[2023-01-12 16:00:39] \u001b[32mTrain: [  5/600] Step 410/520 Loss 1.548 Prec@(1,5) (61.1%, 95.8%)\u001b[0m\n",
            "INFO:nni:Train: [  5/600] Step 410/520 Loss 1.548 Prec@(1,5) (61.1%, 95.8%)\n",
            "[2023-01-12 16:00:43] \u001b[32mTrain: [  5/600] Step 420/520 Loss 1.544 Prec@(1,5) (61.2%, 95.8%)\u001b[0m\n",
            "INFO:nni:Train: [  5/600] Step 420/520 Loss 1.544 Prec@(1,5) (61.2%, 95.8%)\n",
            "[2023-01-12 16:00:48] \u001b[32mTrain: [  5/600] Step 430/520 Loss 1.543 Prec@(1,5) (61.2%, 95.8%)\u001b[0m\n",
            "INFO:nni:Train: [  5/600] Step 430/520 Loss 1.543 Prec@(1,5) (61.2%, 95.8%)\n",
            "[2023-01-12 16:00:52] \u001b[32mTrain: [  5/600] Step 440/520 Loss 1.542 Prec@(1,5) (61.3%, 95.8%)\u001b[0m\n",
            "INFO:nni:Train: [  5/600] Step 440/520 Loss 1.542 Prec@(1,5) (61.3%, 95.8%)\n",
            "[2023-01-12 16:00:57] \u001b[32mTrain: [  5/600] Step 450/520 Loss 1.541 Prec@(1,5) (61.3%, 95.8%)\u001b[0m\n",
            "INFO:nni:Train: [  5/600] Step 450/520 Loss 1.541 Prec@(1,5) (61.3%, 95.8%)\n",
            "[2023-01-12 16:01:01] \u001b[32mTrain: [  5/600] Step 460/520 Loss 1.538 Prec@(1,5) (61.4%, 95.9%)\u001b[0m\n",
            "INFO:nni:Train: [  5/600] Step 460/520 Loss 1.538 Prec@(1,5) (61.4%, 95.9%)\n",
            "[2023-01-12 16:01:06] \u001b[32mTrain: [  5/600] Step 470/520 Loss 1.536 Prec@(1,5) (61.4%, 95.9%)\u001b[0m\n",
            "INFO:nni:Train: [  5/600] Step 470/520 Loss 1.536 Prec@(1,5) (61.4%, 95.9%)\n",
            "[2023-01-12 16:01:10] \u001b[32mTrain: [  5/600] Step 480/520 Loss 1.535 Prec@(1,5) (61.4%, 95.9%)\u001b[0m\n",
            "INFO:nni:Train: [  5/600] Step 480/520 Loss 1.535 Prec@(1,5) (61.4%, 95.9%)\n",
            "[2023-01-12 16:01:15] \u001b[32mTrain: [  5/600] Step 490/520 Loss 1.533 Prec@(1,5) (61.5%, 95.9%)\u001b[0m\n",
            "INFO:nni:Train: [  5/600] Step 490/520 Loss 1.533 Prec@(1,5) (61.5%, 95.9%)\n",
            "[2023-01-12 16:01:19] \u001b[32mTrain: [  5/600] Step 500/520 Loss 1.533 Prec@(1,5) (61.5%, 95.9%)\u001b[0m\n",
            "INFO:nni:Train: [  5/600] Step 500/520 Loss 1.533 Prec@(1,5) (61.5%, 95.9%)\n",
            "[2023-01-12 16:01:24] \u001b[32mTrain: [  5/600] Step 510/520 Loss 1.534 Prec@(1,5) (61.5%, 95.9%)\u001b[0m\n",
            "INFO:nni:Train: [  5/600] Step 510/520 Loss 1.534 Prec@(1,5) (61.5%, 95.9%)\n",
            "[2023-01-12 16:01:28] \u001b[32mTrain: [  5/600] Step 520/520 Loss 1.532 Prec@(1,5) (61.5%, 96.0%)\u001b[0m\n",
            "INFO:nni:Train: [  5/600] Step 520/520 Loss 1.532 Prec@(1,5) (61.5%, 96.0%)\n",
            "[2023-01-12 16:01:28] \u001b[32mTrain: [  5/600] Final Prec@1 61.5060%\u001b[0m\n",
            "INFO:nni:Train: [  5/600] Final Prec@1 61.5060%\n",
            "[2023-01-12 16:01:29] \u001b[32mValid: [  5/600] Step 000/104 Loss 0.834 Prec@(1,5) (72.9%, 96.9%)\u001b[0m\n",
            "INFO:nni:Valid: [  5/600] Step 000/104 Loss 0.834 Prec@(1,5) (72.9%, 96.9%)\n",
            "[2023-01-12 16:01:30] \u001b[32mValid: [  5/600] Step 010/104 Loss 0.931 Prec@(1,5) (67.2%, 97.3%)\u001b[0m\n",
            "INFO:nni:Valid: [  5/600] Step 010/104 Loss 0.931 Prec@(1,5) (67.2%, 97.3%)\n",
            "[2023-01-12 16:01:32] \u001b[32mValid: [  5/600] Step 020/104 Loss 0.935 Prec@(1,5) (66.4%, 97.2%)\u001b[0m\n",
            "INFO:nni:Valid: [  5/600] Step 020/104 Loss 0.935 Prec@(1,5) (66.4%, 97.2%)\n",
            "[2023-01-12 16:01:33] \u001b[32mValid: [  5/600] Step 030/104 Loss 0.938 Prec@(1,5) (66.7%, 97.1%)\u001b[0m\n",
            "INFO:nni:Valid: [  5/600] Step 030/104 Loss 0.938 Prec@(1,5) (66.7%, 97.1%)\n",
            "[2023-01-12 16:01:35] \u001b[32mValid: [  5/600] Step 040/104 Loss 0.949 Prec@(1,5) (66.5%, 97.0%)\u001b[0m\n",
            "INFO:nni:Valid: [  5/600] Step 040/104 Loss 0.949 Prec@(1,5) (66.5%, 97.0%)\n",
            "[2023-01-12 16:01:36] \u001b[32mValid: [  5/600] Step 050/104 Loss 0.935 Prec@(1,5) (67.2%, 97.0%)\u001b[0m\n",
            "INFO:nni:Valid: [  5/600] Step 050/104 Loss 0.935 Prec@(1,5) (67.2%, 97.0%)\n",
            "[2023-01-12 16:01:37] \u001b[32mValid: [  5/600] Step 060/104 Loss 0.936 Prec@(1,5) (67.3%, 97.0%)\u001b[0m\n",
            "INFO:nni:Valid: [  5/600] Step 060/104 Loss 0.936 Prec@(1,5) (67.3%, 97.0%)\n",
            "[2023-01-12 16:01:39] \u001b[32mValid: [  5/600] Step 070/104 Loss 0.940 Prec@(1,5) (67.0%, 97.0%)\u001b[0m\n",
            "INFO:nni:Valid: [  5/600] Step 070/104 Loss 0.940 Prec@(1,5) (67.0%, 97.0%)\n",
            "[2023-01-12 16:01:40] \u001b[32mValid: [  5/600] Step 080/104 Loss 0.933 Prec@(1,5) (67.2%, 97.1%)\u001b[0m\n",
            "INFO:nni:Valid: [  5/600] Step 080/104 Loss 0.933 Prec@(1,5) (67.2%, 97.1%)\n",
            "[2023-01-12 16:01:42] \u001b[32mValid: [  5/600] Step 090/104 Loss 0.935 Prec@(1,5) (67.1%, 97.1%)\u001b[0m\n",
            "INFO:nni:Valid: [  5/600] Step 090/104 Loss 0.935 Prec@(1,5) (67.1%, 97.1%)\n",
            "[2023-01-12 16:01:43] \u001b[32mValid: [  5/600] Step 100/104 Loss 0.933 Prec@(1,5) (67.2%, 97.1%)\u001b[0m\n",
            "INFO:nni:Valid: [  5/600] Step 100/104 Loss 0.933 Prec@(1,5) (67.2%, 97.1%)\n",
            "[2023-01-12 16:01:43] \u001b[32mValid: [  5/600] Step 104/104 Loss 0.936 Prec@(1,5) (67.1%, 97.1%)\u001b[0m\n",
            "INFO:nni:Valid: [  5/600] Step 104/104 Loss 0.936 Prec@(1,5) (67.1%, 97.1%)\n",
            "[2023-01-12 16:01:44] \u001b[32mValid: [  5/600] Final Prec@1 67.0900%\u001b[0m\n",
            "INFO:nni:Valid: [  5/600] Final Prec@1 67.0900%\n",
            "[2023-01-12 16:01:44] \u001b[32mEpoch 5 LR 0.024996\u001b[0m\n",
            "INFO:nni:Epoch 5 LR 0.024996\n",
            "[2023-01-12 16:01:44] \u001b[32mTrain: [  6/600] Step 000/520 Loss 1.396 Prec@(1,5) (69.8%, 95.8%)\u001b[0m\n",
            "INFO:nni:Train: [  6/600] Step 000/520 Loss 1.396 Prec@(1,5) (69.8%, 95.8%)\n",
            "[2023-01-12 16:01:49] \u001b[32mTrain: [  6/600] Step 010/520 Loss 1.497 Prec@(1,5) (62.1%, 95.5%)\u001b[0m\n",
            "INFO:nni:Train: [  6/600] Step 010/520 Loss 1.497 Prec@(1,5) (62.1%, 95.5%)\n",
            "[2023-01-12 16:01:53] \u001b[32mTrain: [  6/600] Step 020/520 Loss 1.490 Prec@(1,5) (62.0%, 96.0%)\u001b[0m\n",
            "INFO:nni:Train: [  6/600] Step 020/520 Loss 1.490 Prec@(1,5) (62.0%, 96.0%)\n",
            "[2023-01-12 16:01:58] \u001b[32mTrain: [  6/600] Step 030/520 Loss 1.487 Prec@(1,5) (61.8%, 96.0%)\u001b[0m\n",
            "INFO:nni:Train: [  6/600] Step 030/520 Loss 1.487 Prec@(1,5) (61.8%, 96.0%)\n",
            "[2023-01-12 16:02:02] \u001b[32mTrain: [  6/600] Step 040/520 Loss 1.480 Prec@(1,5) (62.3%, 96.2%)\u001b[0m\n",
            "INFO:nni:Train: [  6/600] Step 040/520 Loss 1.480 Prec@(1,5) (62.3%, 96.2%)\n",
            "[2023-01-12 16:02:07] \u001b[32mTrain: [  6/600] Step 050/520 Loss 1.468 Prec@(1,5) (62.6%, 96.2%)\u001b[0m\n",
            "INFO:nni:Train: [  6/600] Step 050/520 Loss 1.468 Prec@(1,5) (62.6%, 96.2%)\n",
            "[2023-01-12 16:02:12] \u001b[32mTrain: [  6/600] Step 060/520 Loss 1.475 Prec@(1,5) (62.3%, 96.1%)\u001b[0m\n",
            "INFO:nni:Train: [  6/600] Step 060/520 Loss 1.475 Prec@(1,5) (62.3%, 96.1%)\n",
            "[2023-01-12 16:02:16] \u001b[32mTrain: [  6/600] Step 070/520 Loss 1.465 Prec@(1,5) (62.6%, 96.3%)\u001b[0m\n",
            "INFO:nni:Train: [  6/600] Step 070/520 Loss 1.465 Prec@(1,5) (62.6%, 96.3%)\n",
            "[2023-01-12 16:02:21] \u001b[32mTrain: [  6/600] Step 080/520 Loss 1.470 Prec@(1,5) (62.6%, 96.2%)\u001b[0m\n",
            "INFO:nni:Train: [  6/600] Step 080/520 Loss 1.470 Prec@(1,5) (62.6%, 96.2%)\n",
            "[2023-01-12 16:02:25] \u001b[32mTrain: [  6/600] Step 090/520 Loss 1.464 Prec@(1,5) (62.9%, 96.3%)\u001b[0m\n",
            "INFO:nni:Train: [  6/600] Step 090/520 Loss 1.464 Prec@(1,5) (62.9%, 96.3%)\n",
            "[2023-01-12 16:02:30] \u001b[32mTrain: [  6/600] Step 100/520 Loss 1.453 Prec@(1,5) (63.1%, 96.3%)\u001b[0m\n",
            "INFO:nni:Train: [  6/600] Step 100/520 Loss 1.453 Prec@(1,5) (63.1%, 96.3%)\n",
            "[2023-01-12 16:02:34] \u001b[32mTrain: [  6/600] Step 110/520 Loss 1.452 Prec@(1,5) (63.3%, 96.4%)\u001b[0m\n",
            "INFO:nni:Train: [  6/600] Step 110/520 Loss 1.452 Prec@(1,5) (63.3%, 96.4%)\n",
            "[2023-01-12 16:02:39] \u001b[32mTrain: [  6/600] Step 120/520 Loss 1.456 Prec@(1,5) (63.0%, 96.3%)\u001b[0m\n",
            "INFO:nni:Train: [  6/600] Step 120/520 Loss 1.456 Prec@(1,5) (63.0%, 96.3%)\n",
            "[2023-01-12 16:02:43] \u001b[32mTrain: [  6/600] Step 130/520 Loss 1.456 Prec@(1,5) (63.1%, 96.4%)\u001b[0m\n",
            "INFO:nni:Train: [  6/600] Step 130/520 Loss 1.456 Prec@(1,5) (63.1%, 96.4%)\n",
            "[2023-01-12 16:02:48] \u001b[32mTrain: [  6/600] Step 140/520 Loss 1.454 Prec@(1,5) (63.1%, 96.4%)\u001b[0m\n",
            "INFO:nni:Train: [  6/600] Step 140/520 Loss 1.454 Prec@(1,5) (63.1%, 96.4%)\n",
            "[2023-01-12 16:02:52] \u001b[32mTrain: [  6/600] Step 150/520 Loss 1.452 Prec@(1,5) (63.1%, 96.5%)\u001b[0m\n",
            "INFO:nni:Train: [  6/600] Step 150/520 Loss 1.452 Prec@(1,5) (63.1%, 96.5%)\n",
            "[2023-01-12 16:02:57] \u001b[32mTrain: [  6/600] Step 160/520 Loss 1.450 Prec@(1,5) (63.3%, 96.4%)\u001b[0m\n",
            "INFO:nni:Train: [  6/600] Step 160/520 Loss 1.450 Prec@(1,5) (63.3%, 96.4%)\n",
            "[2023-01-12 16:03:01] \u001b[32mTrain: [  6/600] Step 170/520 Loss 1.447 Prec@(1,5) (63.3%, 96.5%)\u001b[0m\n",
            "INFO:nni:Train: [  6/600] Step 170/520 Loss 1.447 Prec@(1,5) (63.3%, 96.5%)\n",
            "[2023-01-12 16:03:06] \u001b[32mTrain: [  6/600] Step 180/520 Loss 1.442 Prec@(1,5) (63.4%, 96.5%)\u001b[0m\n",
            "INFO:nni:Train: [  6/600] Step 180/520 Loss 1.442 Prec@(1,5) (63.4%, 96.5%)\n",
            "[2023-01-12 16:03:10] \u001b[32mTrain: [  6/600] Step 190/520 Loss 1.436 Prec@(1,5) (63.7%, 96.5%)\u001b[0m\n",
            "INFO:nni:Train: [  6/600] Step 190/520 Loss 1.436 Prec@(1,5) (63.7%, 96.5%)\n",
            "[2023-01-12 16:03:15] \u001b[32mTrain: [  6/600] Step 200/520 Loss 1.438 Prec@(1,5) (63.6%, 96.5%)\u001b[0m\n",
            "INFO:nni:Train: [  6/600] Step 200/520 Loss 1.438 Prec@(1,5) (63.6%, 96.5%)\n",
            "[2023-01-12 16:03:19] \u001b[32mTrain: [  6/600] Step 210/520 Loss 1.438 Prec@(1,5) (63.7%, 96.5%)\u001b[0m\n",
            "INFO:nni:Train: [  6/600] Step 210/520 Loss 1.438 Prec@(1,5) (63.7%, 96.5%)\n",
            "[2023-01-12 16:03:24] \u001b[32mTrain: [  6/600] Step 220/520 Loss 1.432 Prec@(1,5) (63.8%, 96.5%)\u001b[0m\n",
            "INFO:nni:Train: [  6/600] Step 220/520 Loss 1.432 Prec@(1,5) (63.8%, 96.5%)\n",
            "[2023-01-12 16:03:28] \u001b[32mTrain: [  6/600] Step 230/520 Loss 1.430 Prec@(1,5) (63.9%, 96.5%)\u001b[0m\n",
            "INFO:nni:Train: [  6/600] Step 230/520 Loss 1.430 Prec@(1,5) (63.9%, 96.5%)\n",
            "[2023-01-12 16:03:33] \u001b[32mTrain: [  6/600] Step 240/520 Loss 1.427 Prec@(1,5) (63.9%, 96.6%)\u001b[0m\n",
            "INFO:nni:Train: [  6/600] Step 240/520 Loss 1.427 Prec@(1,5) (63.9%, 96.6%)\n",
            "[2023-01-12 16:03:37] \u001b[32mTrain: [  6/600] Step 250/520 Loss 1.429 Prec@(1,5) (64.0%, 96.5%)\u001b[0m\n",
            "INFO:nni:Train: [  6/600] Step 250/520 Loss 1.429 Prec@(1,5) (64.0%, 96.5%)\n",
            "[2023-01-12 16:03:42] \u001b[32mTrain: [  6/600] Step 260/520 Loss 1.428 Prec@(1,5) (64.0%, 96.5%)\u001b[0m\n",
            "INFO:nni:Train: [  6/600] Step 260/520 Loss 1.428 Prec@(1,5) (64.0%, 96.5%)\n",
            "[2023-01-12 16:03:46] \u001b[32mTrain: [  6/600] Step 270/520 Loss 1.429 Prec@(1,5) (64.0%, 96.5%)\u001b[0m\n",
            "INFO:nni:Train: [  6/600] Step 270/520 Loss 1.429 Prec@(1,5) (64.0%, 96.5%)\n",
            "[2023-01-12 16:03:51] \u001b[32mTrain: [  6/600] Step 280/520 Loss 1.428 Prec@(1,5) (64.1%, 96.5%)\u001b[0m\n",
            "INFO:nni:Train: [  6/600] Step 280/520 Loss 1.428 Prec@(1,5) (64.1%, 96.5%)\n",
            "[2023-01-12 16:03:55] \u001b[32mTrain: [  6/600] Step 290/520 Loss 1.428 Prec@(1,5) (64.1%, 96.5%)\u001b[0m\n",
            "INFO:nni:Train: [  6/600] Step 290/520 Loss 1.428 Prec@(1,5) (64.1%, 96.5%)\n",
            "[2023-01-12 16:04:00] \u001b[32mTrain: [  6/600] Step 300/520 Loss 1.427 Prec@(1,5) (64.1%, 96.5%)\u001b[0m\n",
            "INFO:nni:Train: [  6/600] Step 300/520 Loss 1.427 Prec@(1,5) (64.1%, 96.5%)\n",
            "[2023-01-12 16:04:04] \u001b[32mTrain: [  6/600] Step 310/520 Loss 1.429 Prec@(1,5) (64.1%, 96.5%)\u001b[0m\n",
            "INFO:nni:Train: [  6/600] Step 310/520 Loss 1.429 Prec@(1,5) (64.1%, 96.5%)\n",
            "[2023-01-12 16:04:09] \u001b[32mTrain: [  6/600] Step 320/520 Loss 1.428 Prec@(1,5) (64.1%, 96.6%)\u001b[0m\n",
            "INFO:nni:Train: [  6/600] Step 320/520 Loss 1.428 Prec@(1,5) (64.1%, 96.6%)\n",
            "[2023-01-12 16:04:13] \u001b[32mTrain: [  6/600] Step 330/520 Loss 1.425 Prec@(1,5) (64.2%, 96.6%)\u001b[0m\n",
            "INFO:nni:Train: [  6/600] Step 330/520 Loss 1.425 Prec@(1,5) (64.2%, 96.6%)\n",
            "[2023-01-12 16:04:18] \u001b[32mTrain: [  6/600] Step 340/520 Loss 1.424 Prec@(1,5) (64.2%, 96.6%)\u001b[0m\n",
            "INFO:nni:Train: [  6/600] Step 340/520 Loss 1.424 Prec@(1,5) (64.2%, 96.6%)\n",
            "[2023-01-12 16:04:23] \u001b[32mTrain: [  6/600] Step 350/520 Loss 1.426 Prec@(1,5) (64.2%, 96.6%)\u001b[0m\n",
            "INFO:nni:Train: [  6/600] Step 350/520 Loss 1.426 Prec@(1,5) (64.2%, 96.6%)\n",
            "[2023-01-12 16:04:27] \u001b[32mTrain: [  6/600] Step 360/520 Loss 1.425 Prec@(1,5) (64.2%, 96.6%)\u001b[0m\n",
            "INFO:nni:Train: [  6/600] Step 360/520 Loss 1.425 Prec@(1,5) (64.2%, 96.6%)\n",
            "[2023-01-12 16:04:32] \u001b[32mTrain: [  6/600] Step 370/520 Loss 1.422 Prec@(1,5) (64.2%, 96.6%)\u001b[0m\n",
            "INFO:nni:Train: [  6/600] Step 370/520 Loss 1.422 Prec@(1,5) (64.2%, 96.6%)\n",
            "[2023-01-12 16:04:36] \u001b[32mTrain: [  6/600] Step 380/520 Loss 1.419 Prec@(1,5) (64.3%, 96.6%)\u001b[0m\n",
            "INFO:nni:Train: [  6/600] Step 380/520 Loss 1.419 Prec@(1,5) (64.3%, 96.6%)\n",
            "[2023-01-12 16:04:41] \u001b[32mTrain: [  6/600] Step 390/520 Loss 1.418 Prec@(1,5) (64.4%, 96.6%)\u001b[0m\n",
            "INFO:nni:Train: [  6/600] Step 390/520 Loss 1.418 Prec@(1,5) (64.4%, 96.6%)\n",
            "[2023-01-12 16:04:45] \u001b[32mTrain: [  6/600] Step 400/520 Loss 1.419 Prec@(1,5) (64.3%, 96.6%)\u001b[0m\n",
            "INFO:nni:Train: [  6/600] Step 400/520 Loss 1.419 Prec@(1,5) (64.3%, 96.6%)\n",
            "[2023-01-12 16:04:50] \u001b[32mTrain: [  6/600] Step 410/520 Loss 1.421 Prec@(1,5) (64.3%, 96.6%)\u001b[0m\n",
            "INFO:nni:Train: [  6/600] Step 410/520 Loss 1.421 Prec@(1,5) (64.3%, 96.6%)\n",
            "[2023-01-12 16:04:54] \u001b[32mTrain: [  6/600] Step 420/520 Loss 1.419 Prec@(1,5) (64.4%, 96.6%)\u001b[0m\n",
            "INFO:nni:Train: [  6/600] Step 420/520 Loss 1.419 Prec@(1,5) (64.4%, 96.6%)\n",
            "[2023-01-12 16:04:59] \u001b[32mTrain: [  6/600] Step 430/520 Loss 1.419 Prec@(1,5) (64.5%, 96.6%)\u001b[0m\n",
            "INFO:nni:Train: [  6/600] Step 430/520 Loss 1.419 Prec@(1,5) (64.5%, 96.6%)\n",
            "[2023-01-12 16:05:03] \u001b[32mTrain: [  6/600] Step 440/520 Loss 1.416 Prec@(1,5) (64.5%, 96.7%)\u001b[0m\n",
            "INFO:nni:Train: [  6/600] Step 440/520 Loss 1.416 Prec@(1,5) (64.5%, 96.7%)\n",
            "[2023-01-12 16:05:08] \u001b[32mTrain: [  6/600] Step 450/520 Loss 1.417 Prec@(1,5) (64.5%, 96.7%)\u001b[0m\n",
            "INFO:nni:Train: [  6/600] Step 450/520 Loss 1.417 Prec@(1,5) (64.5%, 96.7%)\n",
            "[2023-01-12 16:05:12] \u001b[32mTrain: [  6/600] Step 460/520 Loss 1.418 Prec@(1,5) (64.4%, 96.7%)\u001b[0m\n",
            "INFO:nni:Train: [  6/600] Step 460/520 Loss 1.418 Prec@(1,5) (64.4%, 96.7%)\n",
            "[2023-01-12 16:05:17] \u001b[32mTrain: [  6/600] Step 470/520 Loss 1.416 Prec@(1,5) (64.5%, 96.7%)\u001b[0m\n",
            "INFO:nni:Train: [  6/600] Step 470/520 Loss 1.416 Prec@(1,5) (64.5%, 96.7%)\n",
            "[2023-01-12 16:05:21] \u001b[32mTrain: [  6/600] Step 480/520 Loss 1.415 Prec@(1,5) (64.5%, 96.7%)\u001b[0m\n",
            "INFO:nni:Train: [  6/600] Step 480/520 Loss 1.415 Prec@(1,5) (64.5%, 96.7%)\n",
            "[2023-01-12 16:05:26] \u001b[32mTrain: [  6/600] Step 490/520 Loss 1.416 Prec@(1,5) (64.6%, 96.7%)\u001b[0m\n",
            "INFO:nni:Train: [  6/600] Step 490/520 Loss 1.416 Prec@(1,5) (64.6%, 96.7%)\n",
            "[2023-01-12 16:05:30] \u001b[32mTrain: [  6/600] Step 500/520 Loss 1.415 Prec@(1,5) (64.6%, 96.7%)\u001b[0m\n",
            "INFO:nni:Train: [  6/600] Step 500/520 Loss 1.415 Prec@(1,5) (64.6%, 96.7%)\n",
            "[2023-01-12 16:05:35] \u001b[32mTrain: [  6/600] Step 510/520 Loss 1.415 Prec@(1,5) (64.5%, 96.7%)\u001b[0m\n",
            "INFO:nni:Train: [  6/600] Step 510/520 Loss 1.415 Prec@(1,5) (64.5%, 96.7%)\n",
            "[2023-01-12 16:05:39] \u001b[32mTrain: [  6/600] Step 520/520 Loss 1.414 Prec@(1,5) (64.5%, 96.7%)\u001b[0m\n",
            "INFO:nni:Train: [  6/600] Step 520/520 Loss 1.414 Prec@(1,5) (64.5%, 96.7%)\n",
            "[2023-01-12 16:05:39] \u001b[32mTrain: [  6/600] Final Prec@1 64.5220%\u001b[0m\n",
            "INFO:nni:Train: [  6/600] Final Prec@1 64.5220%\n",
            "[2023-01-12 16:05:40] \u001b[32mValid: [  6/600] Step 000/104 Loss 0.949 Prec@(1,5) (60.4%, 99.0%)\u001b[0m\n",
            "INFO:nni:Valid: [  6/600] Step 000/104 Loss 0.949 Prec@(1,5) (60.4%, 99.0%)\n",
            "[2023-01-12 16:05:41] \u001b[32mValid: [  6/600] Step 010/104 Loss 0.988 Prec@(1,5) (63.6%, 97.9%)\u001b[0m\n",
            "INFO:nni:Valid: [  6/600] Step 010/104 Loss 0.988 Prec@(1,5) (63.6%, 97.9%)\n",
            "[2023-01-12 16:05:43] \u001b[32mValid: [  6/600] Step 020/104 Loss 0.976 Prec@(1,5) (65.1%, 97.7%)\u001b[0m\n",
            "INFO:nni:Valid: [  6/600] Step 020/104 Loss 0.976 Prec@(1,5) (65.1%, 97.7%)\n",
            "[2023-01-12 16:05:44] \u001b[32mValid: [  6/600] Step 030/104 Loss 0.970 Prec@(1,5) (65.4%, 97.5%)\u001b[0m\n",
            "INFO:nni:Valid: [  6/600] Step 030/104 Loss 0.970 Prec@(1,5) (65.4%, 97.5%)\n",
            "[2023-01-12 16:05:45] \u001b[32mValid: [  6/600] Step 040/104 Loss 0.984 Prec@(1,5) (65.1%, 97.3%)\u001b[0m\n",
            "INFO:nni:Valid: [  6/600] Step 040/104 Loss 0.984 Prec@(1,5) (65.1%, 97.3%)\n",
            "[2023-01-12 16:05:47] \u001b[32mValid: [  6/600] Step 050/104 Loss 0.974 Prec@(1,5) (65.4%, 97.5%)\u001b[0m\n",
            "INFO:nni:Valid: [  6/600] Step 050/104 Loss 0.974 Prec@(1,5) (65.4%, 97.5%)\n",
            "[2023-01-12 16:05:48] \u001b[32mValid: [  6/600] Step 060/104 Loss 0.978 Prec@(1,5) (65.2%, 97.6%)\u001b[0m\n",
            "INFO:nni:Valid: [  6/600] Step 060/104 Loss 0.978 Prec@(1,5) (65.2%, 97.6%)\n",
            "[2023-01-12 16:05:50] \u001b[32mValid: [  6/600] Step 070/104 Loss 0.987 Prec@(1,5) (65.1%, 97.6%)\u001b[0m\n",
            "INFO:nni:Valid: [  6/600] Step 070/104 Loss 0.987 Prec@(1,5) (65.1%, 97.6%)\n",
            "[2023-01-12 16:05:51] \u001b[32mValid: [  6/600] Step 080/104 Loss 0.981 Prec@(1,5) (65.2%, 97.7%)\u001b[0m\n",
            "INFO:nni:Valid: [  6/600] Step 080/104 Loss 0.981 Prec@(1,5) (65.2%, 97.7%)\n",
            "[2023-01-12 16:05:52] \u001b[32mValid: [  6/600] Step 090/104 Loss 0.982 Prec@(1,5) (65.2%, 97.6%)\u001b[0m\n",
            "INFO:nni:Valid: [  6/600] Step 090/104 Loss 0.982 Prec@(1,5) (65.2%, 97.6%)\n",
            "[2023-01-12 16:05:54] \u001b[32mValid: [  6/600] Step 100/104 Loss 0.976 Prec@(1,5) (65.5%, 97.6%)\u001b[0m\n",
            "INFO:nni:Valid: [  6/600] Step 100/104 Loss 0.976 Prec@(1,5) (65.5%, 97.6%)\n",
            "[2023-01-12 16:05:54] \u001b[32mValid: [  6/600] Step 104/104 Loss 0.975 Prec@(1,5) (65.5%, 97.7%)\u001b[0m\n",
            "INFO:nni:Valid: [  6/600] Step 104/104 Loss 0.975 Prec@(1,5) (65.5%, 97.7%)\n",
            "[2023-01-12 16:05:54] \u001b[32mValid: [  6/600] Final Prec@1 65.5200%\u001b[0m\n",
            "INFO:nni:Valid: [  6/600] Final Prec@1 65.5200%\n",
            "[2023-01-12 16:05:54] \u001b[32mEpoch 6 LR 0.024994\u001b[0m\n",
            "INFO:nni:Epoch 6 LR 0.024994\n",
            "[2023-01-12 16:05:55] \u001b[32mTrain: [  7/600] Step 000/520 Loss 1.177 Prec@(1,5) (69.8%, 99.0%)\u001b[0m\n",
            "INFO:nni:Train: [  7/600] Step 000/520 Loss 1.177 Prec@(1,5) (69.8%, 99.0%)\n",
            "[2023-01-12 16:06:00] \u001b[32mTrain: [  7/600] Step 010/520 Loss 1.333 Prec@(1,5) (67.6%, 96.4%)\u001b[0m\n",
            "INFO:nni:Train: [  7/600] Step 010/520 Loss 1.333 Prec@(1,5) (67.6%, 96.4%)\n",
            "[2023-01-12 16:06:04] \u001b[32mTrain: [  7/600] Step 020/520 Loss 1.342 Prec@(1,5) (67.3%, 96.7%)\u001b[0m\n",
            "INFO:nni:Train: [  7/600] Step 020/520 Loss 1.342 Prec@(1,5) (67.3%, 96.7%)\n",
            "[2023-01-12 16:06:09] \u001b[32mTrain: [  7/600] Step 030/520 Loss 1.344 Prec@(1,5) (66.6%, 96.7%)\u001b[0m\n",
            "INFO:nni:Train: [  7/600] Step 030/520 Loss 1.344 Prec@(1,5) (66.6%, 96.7%)\n",
            "[2023-01-12 16:06:13] \u001b[32mTrain: [  7/600] Step 040/520 Loss 1.359 Prec@(1,5) (66.2%, 96.7%)\u001b[0m\n",
            "INFO:nni:Train: [  7/600] Step 040/520 Loss 1.359 Prec@(1,5) (66.2%, 96.7%)\n",
            "[2023-01-12 16:06:18] \u001b[32mTrain: [  7/600] Step 050/520 Loss 1.340 Prec@(1,5) (66.6%, 96.8%)\u001b[0m\n",
            "INFO:nni:Train: [  7/600] Step 050/520 Loss 1.340 Prec@(1,5) (66.6%, 96.8%)\n",
            "[2023-01-12 16:06:22] \u001b[32mTrain: [  7/600] Step 060/520 Loss 1.335 Prec@(1,5) (66.8%, 96.9%)\u001b[0m\n",
            "INFO:nni:Train: [  7/600] Step 060/520 Loss 1.335 Prec@(1,5) (66.8%, 96.9%)\n",
            "[2023-01-12 16:06:27] \u001b[32mTrain: [  7/600] Step 070/520 Loss 1.335 Prec@(1,5) (66.8%, 97.0%)\u001b[0m\n",
            "INFO:nni:Train: [  7/600] Step 070/520 Loss 1.335 Prec@(1,5) (66.8%, 97.0%)\n",
            "[2023-01-12 16:06:31] \u001b[32mTrain: [  7/600] Step 080/520 Loss 1.333 Prec@(1,5) (66.9%, 97.0%)\u001b[0m\n",
            "INFO:nni:Train: [  7/600] Step 080/520 Loss 1.333 Prec@(1,5) (66.9%, 97.0%)\n",
            "[2023-01-12 16:06:36] \u001b[32mTrain: [  7/600] Step 090/520 Loss 1.332 Prec@(1,5) (66.8%, 97.0%)\u001b[0m\n",
            "INFO:nni:Train: [  7/600] Step 090/520 Loss 1.332 Prec@(1,5) (66.8%, 97.0%)\n",
            "[2023-01-12 16:06:40] \u001b[32mTrain: [  7/600] Step 100/520 Loss 1.339 Prec@(1,5) (66.6%, 97.0%)\u001b[0m\n",
            "INFO:nni:Train: [  7/600] Step 100/520 Loss 1.339 Prec@(1,5) (66.6%, 97.0%)\n",
            "[2023-01-12 16:06:45] \u001b[32mTrain: [  7/600] Step 110/520 Loss 1.336 Prec@(1,5) (66.6%, 97.1%)\u001b[0m\n",
            "INFO:nni:Train: [  7/600] Step 110/520 Loss 1.336 Prec@(1,5) (66.6%, 97.1%)\n",
            "[2023-01-12 16:06:49] \u001b[32mTrain: [  7/600] Step 120/520 Loss 1.347 Prec@(1,5) (66.3%, 97.0%)\u001b[0m\n",
            "INFO:nni:Train: [  7/600] Step 120/520 Loss 1.347 Prec@(1,5) (66.3%, 97.0%)\n",
            "[2023-01-12 16:06:54] \u001b[32mTrain: [  7/600] Step 130/520 Loss 1.348 Prec@(1,5) (66.3%, 97.1%)\u001b[0m\n",
            "INFO:nni:Train: [  7/600] Step 130/520 Loss 1.348 Prec@(1,5) (66.3%, 97.1%)\n",
            "[2023-01-12 16:06:58] \u001b[32mTrain: [  7/600] Step 140/520 Loss 1.340 Prec@(1,5) (66.5%, 97.1%)\u001b[0m\n",
            "INFO:nni:Train: [  7/600] Step 140/520 Loss 1.340 Prec@(1,5) (66.5%, 97.1%)\n",
            "[2023-01-12 16:07:03] \u001b[32mTrain: [  7/600] Step 150/520 Loss 1.347 Prec@(1,5) (66.3%, 97.0%)\u001b[0m\n",
            "INFO:nni:Train: [  7/600] Step 150/520 Loss 1.347 Prec@(1,5) (66.3%, 97.0%)\n",
            "[2023-01-12 16:07:08] \u001b[32mTrain: [  7/600] Step 160/520 Loss 1.346 Prec@(1,5) (66.3%, 97.0%)\u001b[0m\n",
            "INFO:nni:Train: [  7/600] Step 160/520 Loss 1.346 Prec@(1,5) (66.3%, 97.0%)\n",
            "[2023-01-12 16:07:12] \u001b[32mTrain: [  7/600] Step 170/520 Loss 1.345 Prec@(1,5) (66.4%, 97.0%)\u001b[0m\n",
            "INFO:nni:Train: [  7/600] Step 170/520 Loss 1.345 Prec@(1,5) (66.4%, 97.0%)\n",
            "[2023-01-12 16:07:17] \u001b[32mTrain: [  7/600] Step 180/520 Loss 1.340 Prec@(1,5) (66.6%, 97.0%)\u001b[0m\n",
            "INFO:nni:Train: [  7/600] Step 180/520 Loss 1.340 Prec@(1,5) (66.6%, 97.0%)\n",
            "[2023-01-12 16:07:21] \u001b[32mTrain: [  7/600] Step 190/520 Loss 1.342 Prec@(1,5) (66.5%, 97.0%)\u001b[0m\n",
            "INFO:nni:Train: [  7/600] Step 190/520 Loss 1.342 Prec@(1,5) (66.5%, 97.0%)\n",
            "[2023-01-12 16:07:26] \u001b[32mTrain: [  7/600] Step 200/520 Loss 1.344 Prec@(1,5) (66.4%, 96.9%)\u001b[0m\n",
            "INFO:nni:Train: [  7/600] Step 200/520 Loss 1.344 Prec@(1,5) (66.4%, 96.9%)\n",
            "[2023-01-12 16:07:30] \u001b[32mTrain: [  7/600] Step 210/520 Loss 1.340 Prec@(1,5) (66.4%, 97.0%)\u001b[0m\n",
            "INFO:nni:Train: [  7/600] Step 210/520 Loss 1.340 Prec@(1,5) (66.4%, 97.0%)\n",
            "[2023-01-12 16:07:35] \u001b[32mTrain: [  7/600] Step 220/520 Loss 1.338 Prec@(1,5) (66.4%, 97.0%)\u001b[0m\n",
            "INFO:nni:Train: [  7/600] Step 220/520 Loss 1.338 Prec@(1,5) (66.4%, 97.0%)\n",
            "[2023-01-12 16:07:39] \u001b[32mTrain: [  7/600] Step 230/520 Loss 1.340 Prec@(1,5) (66.4%, 97.0%)\u001b[0m\n",
            "INFO:nni:Train: [  7/600] Step 230/520 Loss 1.340 Prec@(1,5) (66.4%, 97.0%)\n",
            "[2023-01-12 16:07:44] \u001b[32mTrain: [  7/600] Step 240/520 Loss 1.335 Prec@(1,5) (66.5%, 97.0%)\u001b[0m\n",
            "INFO:nni:Train: [  7/600] Step 240/520 Loss 1.335 Prec@(1,5) (66.5%, 97.0%)\n",
            "[2023-01-12 16:07:48] \u001b[32mTrain: [  7/600] Step 250/520 Loss 1.329 Prec@(1,5) (66.7%, 97.0%)\u001b[0m\n",
            "INFO:nni:Train: [  7/600] Step 250/520 Loss 1.329 Prec@(1,5) (66.7%, 97.0%)\n",
            "[2023-01-12 16:07:53] \u001b[32mTrain: [  7/600] Step 260/520 Loss 1.328 Prec@(1,5) (66.7%, 97.0%)\u001b[0m\n",
            "INFO:nni:Train: [  7/600] Step 260/520 Loss 1.328 Prec@(1,5) (66.7%, 97.0%)\n",
            "[2023-01-12 16:07:57] \u001b[32mTrain: [  7/600] Step 270/520 Loss 1.329 Prec@(1,5) (66.7%, 97.1%)\u001b[0m\n",
            "INFO:nni:Train: [  7/600] Step 270/520 Loss 1.329 Prec@(1,5) (66.7%, 97.1%)\n",
            "[2023-01-12 16:08:02] \u001b[32mTrain: [  7/600] Step 280/520 Loss 1.328 Prec@(1,5) (66.7%, 97.1%)\u001b[0m\n",
            "INFO:nni:Train: [  7/600] Step 280/520 Loss 1.328 Prec@(1,5) (66.7%, 97.1%)\n",
            "[2023-01-12 16:08:06] \u001b[32mTrain: [  7/600] Step 290/520 Loss 1.329 Prec@(1,5) (66.8%, 97.1%)\u001b[0m\n",
            "INFO:nni:Train: [  7/600] Step 290/520 Loss 1.329 Prec@(1,5) (66.8%, 97.1%)\n",
            "[2023-01-12 16:08:11] \u001b[32mTrain: [  7/600] Step 300/520 Loss 1.332 Prec@(1,5) (66.7%, 97.1%)\u001b[0m\n",
            "INFO:nni:Train: [  7/600] Step 300/520 Loss 1.332 Prec@(1,5) (66.7%, 97.1%)\n",
            "[2023-01-12 16:08:15] \u001b[32mTrain: [  7/600] Step 310/520 Loss 1.334 Prec@(1,5) (66.6%, 97.0%)\u001b[0m\n",
            "INFO:nni:Train: [  7/600] Step 310/520 Loss 1.334 Prec@(1,5) (66.6%, 97.0%)\n",
            "[2023-01-12 16:08:20] \u001b[32mTrain: [  7/600] Step 320/520 Loss 1.335 Prec@(1,5) (66.6%, 97.0%)\u001b[0m\n",
            "INFO:nni:Train: [  7/600] Step 320/520 Loss 1.335 Prec@(1,5) (66.6%, 97.0%)\n",
            "[2023-01-12 16:08:24] \u001b[32mTrain: [  7/600] Step 330/520 Loss 1.335 Prec@(1,5) (66.6%, 97.0%)\u001b[0m\n",
            "INFO:nni:Train: [  7/600] Step 330/520 Loss 1.335 Prec@(1,5) (66.6%, 97.0%)\n",
            "[2023-01-12 16:08:29] \u001b[32mTrain: [  7/600] Step 340/520 Loss 1.336 Prec@(1,5) (66.6%, 97.0%)\u001b[0m\n",
            "INFO:nni:Train: [  7/600] Step 340/520 Loss 1.336 Prec@(1,5) (66.6%, 97.0%)\n",
            "[2023-01-12 16:08:33] \u001b[32mTrain: [  7/600] Step 350/520 Loss 1.335 Prec@(1,5) (66.6%, 97.0%)\u001b[0m\n",
            "INFO:nni:Train: [  7/600] Step 350/520 Loss 1.335 Prec@(1,5) (66.6%, 97.0%)\n",
            "[2023-01-12 16:08:38] \u001b[32mTrain: [  7/600] Step 360/520 Loss 1.334 Prec@(1,5) (66.6%, 97.0%)\u001b[0m\n",
            "INFO:nni:Train: [  7/600] Step 360/520 Loss 1.334 Prec@(1,5) (66.6%, 97.0%)\n",
            "[2023-01-12 16:08:42] \u001b[32mTrain: [  7/600] Step 370/520 Loss 1.334 Prec@(1,5) (66.6%, 97.0%)\u001b[0m\n",
            "INFO:nni:Train: [  7/600] Step 370/520 Loss 1.334 Prec@(1,5) (66.6%, 97.0%)\n",
            "[2023-01-12 16:08:47] \u001b[32mTrain: [  7/600] Step 380/520 Loss 1.332 Prec@(1,5) (66.7%, 97.0%)\u001b[0m\n",
            "INFO:nni:Train: [  7/600] Step 380/520 Loss 1.332 Prec@(1,5) (66.7%, 97.0%)\n",
            "[2023-01-12 16:08:51] \u001b[32mTrain: [  7/600] Step 390/520 Loss 1.331 Prec@(1,5) (66.7%, 97.0%)\u001b[0m\n",
            "INFO:nni:Train: [  7/600] Step 390/520 Loss 1.331 Prec@(1,5) (66.7%, 97.0%)\n",
            "[2023-01-12 16:08:56] \u001b[32mTrain: [  7/600] Step 400/520 Loss 1.331 Prec@(1,5) (66.7%, 97.0%)\u001b[0m\n",
            "INFO:nni:Train: [  7/600] Step 400/520 Loss 1.331 Prec@(1,5) (66.7%, 97.0%)\n",
            "[2023-01-12 16:09:00] \u001b[32mTrain: [  7/600] Step 410/520 Loss 1.331 Prec@(1,5) (66.7%, 97.0%)\u001b[0m\n",
            "INFO:nni:Train: [  7/600] Step 410/520 Loss 1.331 Prec@(1,5) (66.7%, 97.0%)\n",
            "[2023-01-12 16:09:05] \u001b[32mTrain: [  7/600] Step 420/520 Loss 1.329 Prec@(1,5) (66.7%, 97.0%)\u001b[0m\n",
            "INFO:nni:Train: [  7/600] Step 420/520 Loss 1.329 Prec@(1,5) (66.7%, 97.0%)\n",
            "[2023-01-12 16:09:09] \u001b[32mTrain: [  7/600] Step 430/520 Loss 1.327 Prec@(1,5) (66.7%, 97.0%)\u001b[0m\n",
            "INFO:nni:Train: [  7/600] Step 430/520 Loss 1.327 Prec@(1,5) (66.7%, 97.0%)\n",
            "[2023-01-12 16:09:14] \u001b[32mTrain: [  7/600] Step 440/520 Loss 1.325 Prec@(1,5) (66.8%, 97.0%)\u001b[0m\n",
            "INFO:nni:Train: [  7/600] Step 440/520 Loss 1.325 Prec@(1,5) (66.8%, 97.0%)\n",
            "[2023-01-12 16:09:18] \u001b[32mTrain: [  7/600] Step 450/520 Loss 1.326 Prec@(1,5) (66.8%, 97.0%)\u001b[0m\n",
            "INFO:nni:Train: [  7/600] Step 450/520 Loss 1.326 Prec@(1,5) (66.8%, 97.0%)\n",
            "[2023-01-12 16:09:23] \u001b[32mTrain: [  7/600] Step 460/520 Loss 1.324 Prec@(1,5) (66.8%, 97.0%)\u001b[0m\n",
            "INFO:nni:Train: [  7/600] Step 460/520 Loss 1.324 Prec@(1,5) (66.8%, 97.0%)\n",
            "[2023-01-12 16:09:28] \u001b[32mTrain: [  7/600] Step 470/520 Loss 1.323 Prec@(1,5) (66.8%, 97.0%)\u001b[0m\n",
            "INFO:nni:Train: [  7/600] Step 470/520 Loss 1.323 Prec@(1,5) (66.8%, 97.0%)\n",
            "[2023-01-12 16:09:32] \u001b[32mTrain: [  7/600] Step 480/520 Loss 1.320 Prec@(1,5) (66.9%, 97.1%)\u001b[0m\n",
            "INFO:nni:Train: [  7/600] Step 480/520 Loss 1.320 Prec@(1,5) (66.9%, 97.1%)\n",
            "[2023-01-12 16:09:37] \u001b[32mTrain: [  7/600] Step 490/520 Loss 1.318 Prec@(1,5) (66.9%, 97.1%)\u001b[0m\n",
            "INFO:nni:Train: [  7/600] Step 490/520 Loss 1.318 Prec@(1,5) (66.9%, 97.1%)\n",
            "[2023-01-12 16:09:41] \u001b[32mTrain: [  7/600] Step 500/520 Loss 1.316 Prec@(1,5) (67.0%, 97.1%)\u001b[0m\n",
            "INFO:nni:Train: [  7/600] Step 500/520 Loss 1.316 Prec@(1,5) (67.0%, 97.1%)\n",
            "[2023-01-12 16:09:46] \u001b[32mTrain: [  7/600] Step 510/520 Loss 1.315 Prec@(1,5) (67.0%, 97.1%)\u001b[0m\n",
            "INFO:nni:Train: [  7/600] Step 510/520 Loss 1.315 Prec@(1,5) (67.0%, 97.1%)\n",
            "[2023-01-12 16:09:50] \u001b[32mTrain: [  7/600] Step 520/520 Loss 1.315 Prec@(1,5) (67.0%, 97.1%)\u001b[0m\n",
            "INFO:nni:Train: [  7/600] Step 520/520 Loss 1.315 Prec@(1,5) (67.0%, 97.1%)\n",
            "[2023-01-12 16:09:50] \u001b[32mTrain: [  7/600] Final Prec@1 66.9720%\u001b[0m\n",
            "INFO:nni:Train: [  7/600] Final Prec@1 66.9720%\n",
            "[2023-01-12 16:09:51] \u001b[32mValid: [  7/600] Step 000/104 Loss 0.866 Prec@(1,5) (67.7%, 96.9%)\u001b[0m\n",
            "INFO:nni:Valid: [  7/600] Step 000/104 Loss 0.866 Prec@(1,5) (67.7%, 96.9%)\n",
            "[2023-01-12 16:09:52] \u001b[32mValid: [  7/600] Step 010/104 Loss 0.895 Prec@(1,5) (68.9%, 96.7%)\u001b[0m\n",
            "INFO:nni:Valid: [  7/600] Step 010/104 Loss 0.895 Prec@(1,5) (68.9%, 96.7%)\n",
            "[2023-01-12 16:09:53] \u001b[32mValid: [  7/600] Step 020/104 Loss 0.886 Prec@(1,5) (69.2%, 96.8%)\u001b[0m\n",
            "INFO:nni:Valid: [  7/600] Step 020/104 Loss 0.886 Prec@(1,5) (69.2%, 96.8%)\n",
            "[2023-01-12 16:09:55] \u001b[32mValid: [  7/600] Step 030/104 Loss 0.899 Prec@(1,5) (68.9%, 97.1%)\u001b[0m\n",
            "INFO:nni:Valid: [  7/600] Step 030/104 Loss 0.899 Prec@(1,5) (68.9%, 97.1%)\n",
            "[2023-01-12 16:09:56] \u001b[32mValid: [  7/600] Step 040/104 Loss 0.898 Prec@(1,5) (69.0%, 97.2%)\u001b[0m\n",
            "INFO:nni:Valid: [  7/600] Step 040/104 Loss 0.898 Prec@(1,5) (69.0%, 97.2%)\n",
            "[2023-01-12 16:09:58] \u001b[32mValid: [  7/600] Step 050/104 Loss 0.888 Prec@(1,5) (69.8%, 97.3%)\u001b[0m\n",
            "INFO:nni:Valid: [  7/600] Step 050/104 Loss 0.888 Prec@(1,5) (69.8%, 97.3%)\n",
            "[2023-01-12 16:09:59] \u001b[32mValid: [  7/600] Step 060/104 Loss 0.899 Prec@(1,5) (69.6%, 97.1%)\u001b[0m\n",
            "INFO:nni:Valid: [  7/600] Step 060/104 Loss 0.899 Prec@(1,5) (69.6%, 97.1%)\n",
            "[2023-01-12 16:10:00] \u001b[32mValid: [  7/600] Step 070/104 Loss 0.906 Prec@(1,5) (69.1%, 97.1%)\u001b[0m\n",
            "INFO:nni:Valid: [  7/600] Step 070/104 Loss 0.906 Prec@(1,5) (69.1%, 97.1%)\n",
            "[2023-01-12 16:10:02] \u001b[32mValid: [  7/600] Step 080/104 Loss 0.901 Prec@(1,5) (69.2%, 97.2%)\u001b[0m\n",
            "INFO:nni:Valid: [  7/600] Step 080/104 Loss 0.901 Prec@(1,5) (69.2%, 97.2%)\n",
            "[2023-01-12 16:10:03] \u001b[32mValid: [  7/600] Step 090/104 Loss 0.905 Prec@(1,5) (69.1%, 97.1%)\u001b[0m\n",
            "INFO:nni:Valid: [  7/600] Step 090/104 Loss 0.905 Prec@(1,5) (69.1%, 97.1%)\n",
            "[2023-01-12 16:10:05] \u001b[32mValid: [  7/600] Step 100/104 Loss 0.900 Prec@(1,5) (69.0%, 97.2%)\u001b[0m\n",
            "INFO:nni:Valid: [  7/600] Step 100/104 Loss 0.900 Prec@(1,5) (69.0%, 97.2%)\n",
            "[2023-01-12 16:10:05] \u001b[32mValid: [  7/600] Step 104/104 Loss 0.902 Prec@(1,5) (69.0%, 97.2%)\u001b[0m\n",
            "INFO:nni:Valid: [  7/600] Step 104/104 Loss 0.902 Prec@(1,5) (69.0%, 97.2%)\n",
            "[2023-01-12 16:10:05] \u001b[32mValid: [  7/600] Final Prec@1 68.9700%\u001b[0m\n",
            "INFO:nni:Valid: [  7/600] Final Prec@1 68.9700%\n",
            "[2023-01-12 16:10:05] \u001b[32mEpoch 7 LR 0.024992\u001b[0m\n",
            "INFO:nni:Epoch 7 LR 0.024992\n",
            "[2023-01-12 16:10:06] \u001b[32mTrain: [  8/600] Step 000/520 Loss 1.054 Prec@(1,5) (75.0%, 100.0%)\u001b[0m\n",
            "INFO:nni:Train: [  8/600] Step 000/520 Loss 1.054 Prec@(1,5) (75.0%, 100.0%)\n",
            "[2023-01-12 16:10:11] \u001b[32mTrain: [  8/600] Step 010/520 Loss 1.336 Prec@(1,5) (65.4%, 97.4%)\u001b[0m\n",
            "INFO:nni:Train: [  8/600] Step 010/520 Loss 1.336 Prec@(1,5) (65.4%, 97.4%)\n",
            "[2023-01-12 16:10:15] \u001b[32mTrain: [  8/600] Step 020/520 Loss 1.274 Prec@(1,5) (68.0%, 97.5%)\u001b[0m\n",
            "INFO:nni:Train: [  8/600] Step 020/520 Loss 1.274 Prec@(1,5) (68.0%, 97.5%)\n",
            "[2023-01-12 16:10:20] \u001b[32mTrain: [  8/600] Step 030/520 Loss 1.259 Prec@(1,5) (68.2%, 97.4%)\u001b[0m\n",
            "INFO:nni:Train: [  8/600] Step 030/520 Loss 1.259 Prec@(1,5) (68.2%, 97.4%)\n",
            "[2023-01-12 16:10:24] \u001b[32mTrain: [  8/600] Step 040/520 Loss 1.255 Prec@(1,5) (68.2%, 97.5%)\u001b[0m\n",
            "INFO:nni:Train: [  8/600] Step 040/520 Loss 1.255 Prec@(1,5) (68.2%, 97.5%)\n",
            "[2023-01-12 16:10:29] \u001b[32mTrain: [  8/600] Step 050/520 Loss 1.263 Prec@(1,5) (68.1%, 97.5%)\u001b[0m\n",
            "INFO:nni:Train: [  8/600] Step 050/520 Loss 1.263 Prec@(1,5) (68.1%, 97.5%)\n",
            "[2023-01-12 16:10:33] \u001b[32mTrain: [  8/600] Step 060/520 Loss 1.255 Prec@(1,5) (68.3%, 97.4%)\u001b[0m\n",
            "INFO:nni:Train: [  8/600] Step 060/520 Loss 1.255 Prec@(1,5) (68.3%, 97.4%)\n",
            "[2023-01-12 16:10:38] \u001b[32mTrain: [  8/600] Step 070/520 Loss 1.254 Prec@(1,5) (68.3%, 97.4%)\u001b[0m\n",
            "INFO:nni:Train: [  8/600] Step 070/520 Loss 1.254 Prec@(1,5) (68.3%, 97.4%)\n",
            "[2023-01-12 16:10:42] \u001b[32mTrain: [  8/600] Step 080/520 Loss 1.246 Prec@(1,5) (68.5%, 97.5%)\u001b[0m\n",
            "INFO:nni:Train: [  8/600] Step 080/520 Loss 1.246 Prec@(1,5) (68.5%, 97.5%)\n",
            "[2023-01-12 16:10:47] \u001b[32mTrain: [  8/600] Step 090/520 Loss 1.238 Prec@(1,5) (68.8%, 97.5%)\u001b[0m\n",
            "INFO:nni:Train: [  8/600] Step 090/520 Loss 1.238 Prec@(1,5) (68.8%, 97.5%)\n",
            "[2023-01-12 16:10:51] \u001b[32mTrain: [  8/600] Step 100/520 Loss 1.244 Prec@(1,5) (68.9%, 97.4%)\u001b[0m\n",
            "INFO:nni:Train: [  8/600] Step 100/520 Loss 1.244 Prec@(1,5) (68.9%, 97.4%)\n",
            "[2023-01-12 16:10:56] \u001b[32mTrain: [  8/600] Step 110/520 Loss 1.240 Prec@(1,5) (68.9%, 97.5%)\u001b[0m\n",
            "INFO:nni:Train: [  8/600] Step 110/520 Loss 1.240 Prec@(1,5) (68.9%, 97.5%)\n",
            "[2023-01-12 16:11:00] \u001b[32mTrain: [  8/600] Step 120/520 Loss 1.248 Prec@(1,5) (68.7%, 97.5%)\u001b[0m\n",
            "INFO:nni:Train: [  8/600] Step 120/520 Loss 1.248 Prec@(1,5) (68.7%, 97.5%)\n",
            "[2023-01-12 16:11:05] \u001b[32mTrain: [  8/600] Step 130/520 Loss 1.244 Prec@(1,5) (68.8%, 97.5%)\u001b[0m\n",
            "INFO:nni:Train: [  8/600] Step 130/520 Loss 1.244 Prec@(1,5) (68.8%, 97.5%)\n",
            "[2023-01-12 16:11:09] \u001b[32mTrain: [  8/600] Step 140/520 Loss 1.238 Prec@(1,5) (69.0%, 97.5%)\u001b[0m\n",
            "INFO:nni:Train: [  8/600] Step 140/520 Loss 1.238 Prec@(1,5) (69.0%, 97.5%)\n",
            "[2023-01-12 16:11:14] \u001b[32mTrain: [  8/600] Step 150/520 Loss 1.239 Prec@(1,5) (68.9%, 97.5%)\u001b[0m\n",
            "INFO:nni:Train: [  8/600] Step 150/520 Loss 1.239 Prec@(1,5) (68.9%, 97.5%)\n",
            "[2023-01-12 16:11:18] \u001b[32mTrain: [  8/600] Step 160/520 Loss 1.239 Prec@(1,5) (69.0%, 97.5%)\u001b[0m\n",
            "INFO:nni:Train: [  8/600] Step 160/520 Loss 1.239 Prec@(1,5) (69.0%, 97.5%)\n",
            "[2023-01-12 16:11:23] \u001b[32mTrain: [  8/600] Step 170/520 Loss 1.239 Prec@(1,5) (69.0%, 97.5%)\u001b[0m\n",
            "INFO:nni:Train: [  8/600] Step 170/520 Loss 1.239 Prec@(1,5) (69.0%, 97.5%)\n",
            "[2023-01-12 16:11:27] \u001b[32mTrain: [  8/600] Step 180/520 Loss 1.240 Prec@(1,5) (69.0%, 97.5%)\u001b[0m\n",
            "INFO:nni:Train: [  8/600] Step 180/520 Loss 1.240 Prec@(1,5) (69.0%, 97.5%)\n",
            "[2023-01-12 16:11:32] \u001b[32mTrain: [  8/600] Step 190/520 Loss 1.239 Prec@(1,5) (68.9%, 97.5%)\u001b[0m\n",
            "INFO:nni:Train: [  8/600] Step 190/520 Loss 1.239 Prec@(1,5) (68.9%, 97.5%)\n",
            "[2023-01-12 16:11:36] \u001b[32mTrain: [  8/600] Step 200/520 Loss 1.243 Prec@(1,5) (69.0%, 97.5%)\u001b[0m\n",
            "INFO:nni:Train: [  8/600] Step 200/520 Loss 1.243 Prec@(1,5) (69.0%, 97.5%)\n",
            "[2023-01-12 16:11:41] \u001b[32mTrain: [  8/600] Step 210/520 Loss 1.245 Prec@(1,5) (68.8%, 97.5%)\u001b[0m\n",
            "INFO:nni:Train: [  8/600] Step 210/520 Loss 1.245 Prec@(1,5) (68.8%, 97.5%)\n",
            "[2023-01-12 16:11:45] \u001b[32mTrain: [  8/600] Step 220/520 Loss 1.251 Prec@(1,5) (68.8%, 97.5%)\u001b[0m\n",
            "INFO:nni:Train: [  8/600] Step 220/520 Loss 1.251 Prec@(1,5) (68.8%, 97.5%)\n",
            "[2023-01-12 16:11:50] \u001b[32mTrain: [  8/600] Step 230/520 Loss 1.252 Prec@(1,5) (68.7%, 97.5%)\u001b[0m\n",
            "INFO:nni:Train: [  8/600] Step 230/520 Loss 1.252 Prec@(1,5) (68.7%, 97.5%)\n",
            "[2023-01-12 16:11:55] \u001b[32mTrain: [  8/600] Step 240/520 Loss 1.250 Prec@(1,5) (68.8%, 97.5%)\u001b[0m\n",
            "INFO:nni:Train: [  8/600] Step 240/520 Loss 1.250 Prec@(1,5) (68.8%, 97.5%)\n",
            "[2023-01-12 16:11:59] \u001b[32mTrain: [  8/600] Step 250/520 Loss 1.247 Prec@(1,5) (68.9%, 97.5%)\u001b[0m\n",
            "INFO:nni:Train: [  8/600] Step 250/520 Loss 1.247 Prec@(1,5) (68.9%, 97.5%)\n",
            "[2023-01-12 16:12:04] \u001b[32mTrain: [  8/600] Step 260/520 Loss 1.248 Prec@(1,5) (68.8%, 97.5%)\u001b[0m\n",
            "INFO:nni:Train: [  8/600] Step 260/520 Loss 1.248 Prec@(1,5) (68.8%, 97.5%)\n",
            "[2023-01-12 16:12:08] \u001b[32mTrain: [  8/600] Step 270/520 Loss 1.248 Prec@(1,5) (68.8%, 97.5%)\u001b[0m\n",
            "INFO:nni:Train: [  8/600] Step 270/520 Loss 1.248 Prec@(1,5) (68.8%, 97.5%)\n",
            "[2023-01-12 16:12:13] \u001b[32mTrain: [  8/600] Step 280/520 Loss 1.246 Prec@(1,5) (68.9%, 97.5%)\u001b[0m\n",
            "INFO:nni:Train: [  8/600] Step 280/520 Loss 1.246 Prec@(1,5) (68.9%, 97.5%)\n",
            "[2023-01-12 16:12:17] \u001b[32mTrain: [  8/600] Step 290/520 Loss 1.251 Prec@(1,5) (68.9%, 97.5%)\u001b[0m\n",
            "INFO:nni:Train: [  8/600] Step 290/520 Loss 1.251 Prec@(1,5) (68.9%, 97.5%)\n",
            "[2023-01-12 16:12:22] \u001b[32mTrain: [  8/600] Step 300/520 Loss 1.251 Prec@(1,5) (68.9%, 97.5%)\u001b[0m\n",
            "INFO:nni:Train: [  8/600] Step 300/520 Loss 1.251 Prec@(1,5) (68.9%, 97.5%)\n",
            "[2023-01-12 16:12:26] \u001b[32mTrain: [  8/600] Step 310/520 Loss 1.252 Prec@(1,5) (68.8%, 97.5%)\u001b[0m\n",
            "INFO:nni:Train: [  8/600] Step 310/520 Loss 1.252 Prec@(1,5) (68.8%, 97.5%)\n",
            "[2023-01-12 16:12:31] \u001b[32mTrain: [  8/600] Step 320/520 Loss 1.254 Prec@(1,5) (68.8%, 97.5%)\u001b[0m\n",
            "INFO:nni:Train: [  8/600] Step 320/520 Loss 1.254 Prec@(1,5) (68.8%, 97.5%)\n",
            "[2023-01-12 16:12:35] \u001b[32mTrain: [  8/600] Step 330/520 Loss 1.254 Prec@(1,5) (68.8%, 97.5%)\u001b[0m\n",
            "INFO:nni:Train: [  8/600] Step 330/520 Loss 1.254 Prec@(1,5) (68.8%, 97.5%)\n",
            "[2023-01-12 16:12:40] \u001b[32mTrain: [  8/600] Step 340/520 Loss 1.253 Prec@(1,5) (68.8%, 97.5%)\u001b[0m\n",
            "INFO:nni:Train: [  8/600] Step 340/520 Loss 1.253 Prec@(1,5) (68.8%, 97.5%)\n",
            "[2023-01-12 16:12:44] \u001b[32mTrain: [  8/600] Step 350/520 Loss 1.251 Prec@(1,5) (68.9%, 97.5%)\u001b[0m\n",
            "INFO:nni:Train: [  8/600] Step 350/520 Loss 1.251 Prec@(1,5) (68.9%, 97.5%)\n",
            "[2023-01-12 16:12:49] \u001b[32mTrain: [  8/600] Step 360/520 Loss 1.249 Prec@(1,5) (69.0%, 97.4%)\u001b[0m\n",
            "INFO:nni:Train: [  8/600] Step 360/520 Loss 1.249 Prec@(1,5) (69.0%, 97.4%)\n",
            "[2023-01-12 16:12:53] \u001b[32mTrain: [  8/600] Step 370/520 Loss 1.248 Prec@(1,5) (69.0%, 97.5%)\u001b[0m\n",
            "INFO:nni:Train: [  8/600] Step 370/520 Loss 1.248 Prec@(1,5) (69.0%, 97.5%)\n",
            "[2023-01-12 16:12:58] \u001b[32mTrain: [  8/600] Step 380/520 Loss 1.247 Prec@(1,5) (69.0%, 97.5%)\u001b[0m\n",
            "INFO:nni:Train: [  8/600] Step 380/520 Loss 1.247 Prec@(1,5) (69.0%, 97.5%)\n",
            "[2023-01-12 16:13:02] \u001b[32mTrain: [  8/600] Step 390/520 Loss 1.246 Prec@(1,5) (69.0%, 97.5%)\u001b[0m\n",
            "INFO:nni:Train: [  8/600] Step 390/520 Loss 1.246 Prec@(1,5) (69.0%, 97.5%)\n",
            "[2023-01-12 16:13:07] \u001b[32mTrain: [  8/600] Step 400/520 Loss 1.246 Prec@(1,5) (69.0%, 97.4%)\u001b[0m\n",
            "INFO:nni:Train: [  8/600] Step 400/520 Loss 1.246 Prec@(1,5) (69.0%, 97.4%)\n",
            "[2023-01-12 16:13:11] \u001b[32mTrain: [  8/600] Step 410/520 Loss 1.246 Prec@(1,5) (69.0%, 97.5%)\u001b[0m\n",
            "INFO:nni:Train: [  8/600] Step 410/520 Loss 1.246 Prec@(1,5) (69.0%, 97.5%)\n",
            "[2023-01-12 16:13:16] \u001b[32mTrain: [  8/600] Step 420/520 Loss 1.244 Prec@(1,5) (69.1%, 97.4%)\u001b[0m\n",
            "INFO:nni:Train: [  8/600] Step 420/520 Loss 1.244 Prec@(1,5) (69.1%, 97.4%)\n",
            "[2023-01-12 16:13:20] \u001b[32mTrain: [  8/600] Step 430/520 Loss 1.245 Prec@(1,5) (69.1%, 97.4%)\u001b[0m\n",
            "INFO:nni:Train: [  8/600] Step 430/520 Loss 1.245 Prec@(1,5) (69.1%, 97.4%)\n",
            "[2023-01-12 16:13:25] \u001b[32mTrain: [  8/600] Step 440/520 Loss 1.246 Prec@(1,5) (69.0%, 97.4%)\u001b[0m\n",
            "INFO:nni:Train: [  8/600] Step 440/520 Loss 1.246 Prec@(1,5) (69.0%, 97.4%)\n",
            "[2023-01-12 16:13:29] \u001b[32mTrain: [  8/600] Step 450/520 Loss 1.246 Prec@(1,5) (69.0%, 97.5%)\u001b[0m\n",
            "INFO:nni:Train: [  8/600] Step 450/520 Loss 1.246 Prec@(1,5) (69.0%, 97.5%)\n",
            "[2023-01-12 16:13:34] \u001b[32mTrain: [  8/600] Step 460/520 Loss 1.249 Prec@(1,5) (68.9%, 97.4%)\u001b[0m\n",
            "INFO:nni:Train: [  8/600] Step 460/520 Loss 1.249 Prec@(1,5) (68.9%, 97.4%)\n",
            "[2023-01-12 16:13:38] \u001b[32mTrain: [  8/600] Step 470/520 Loss 1.249 Prec@(1,5) (69.0%, 97.4%)\u001b[0m\n",
            "INFO:nni:Train: [  8/600] Step 470/520 Loss 1.249 Prec@(1,5) (69.0%, 97.4%)\n",
            "[2023-01-12 16:13:43] \u001b[32mTrain: [  8/600] Step 480/520 Loss 1.248 Prec@(1,5) (69.0%, 97.4%)\u001b[0m\n",
            "INFO:nni:Train: [  8/600] Step 480/520 Loss 1.248 Prec@(1,5) (69.0%, 97.4%)\n",
            "[2023-01-12 16:13:47] \u001b[32mTrain: [  8/600] Step 490/520 Loss 1.247 Prec@(1,5) (69.0%, 97.4%)\u001b[0m\n",
            "INFO:nni:Train: [  8/600] Step 490/520 Loss 1.247 Prec@(1,5) (69.0%, 97.4%)\n",
            "[2023-01-12 16:13:52] \u001b[32mTrain: [  8/600] Step 500/520 Loss 1.246 Prec@(1,5) (69.0%, 97.4%)\u001b[0m\n",
            "INFO:nni:Train: [  8/600] Step 500/520 Loss 1.246 Prec@(1,5) (69.0%, 97.4%)\n",
            "[2023-01-12 16:13:56] \u001b[32mTrain: [  8/600] Step 510/520 Loss 1.246 Prec@(1,5) (69.0%, 97.4%)\u001b[0m\n",
            "INFO:nni:Train: [  8/600] Step 510/520 Loss 1.246 Prec@(1,5) (69.0%, 97.4%)\n",
            "[2023-01-12 16:14:01] \u001b[32mTrain: [  8/600] Step 520/520 Loss 1.246 Prec@(1,5) (69.0%, 97.4%)\u001b[0m\n",
            "INFO:nni:Train: [  8/600] Step 520/520 Loss 1.246 Prec@(1,5) (69.0%, 97.4%)\n",
            "[2023-01-12 16:14:01] \u001b[32mTrain: [  8/600] Final Prec@1 68.9860%\u001b[0m\n",
            "INFO:nni:Train: [  8/600] Final Prec@1 68.9860%\n",
            "[2023-01-12 16:14:01] \u001b[32mValid: [  8/600] Step 000/104 Loss 0.807 Prec@(1,5) (71.9%, 97.9%)\u001b[0m\n",
            "INFO:nni:Valid: [  8/600] Step 000/104 Loss 0.807 Prec@(1,5) (71.9%, 97.9%)\n",
            "[2023-01-12 16:14:03] \u001b[32mValid: [  8/600] Step 010/104 Loss 0.849 Prec@(1,5) (69.5%, 97.0%)\u001b[0m\n",
            "INFO:nni:Valid: [  8/600] Step 010/104 Loss 0.849 Prec@(1,5) (69.5%, 97.0%)\n",
            "[2023-01-12 16:14:04] \u001b[32mValid: [  8/600] Step 020/104 Loss 0.812 Prec@(1,5) (71.2%, 97.6%)\u001b[0m\n",
            "INFO:nni:Valid: [  8/600] Step 020/104 Loss 0.812 Prec@(1,5) (71.2%, 97.6%)\n",
            "[2023-01-12 16:14:06] \u001b[32mValid: [  8/600] Step 030/104 Loss 0.815 Prec@(1,5) (71.4%, 97.8%)\u001b[0m\n",
            "INFO:nni:Valid: [  8/600] Step 030/104 Loss 0.815 Prec@(1,5) (71.4%, 97.8%)\n",
            "[2023-01-12 16:14:07] \u001b[32mValid: [  8/600] Step 040/104 Loss 0.830 Prec@(1,5) (70.6%, 97.6%)\u001b[0m\n",
            "INFO:nni:Valid: [  8/600] Step 040/104 Loss 0.830 Prec@(1,5) (70.6%, 97.6%)\n",
            "[2023-01-12 16:14:08] \u001b[32mValid: [  8/600] Step 050/104 Loss 0.813 Prec@(1,5) (71.2%, 97.7%)\u001b[0m\n",
            "INFO:nni:Valid: [  8/600] Step 050/104 Loss 0.813 Prec@(1,5) (71.2%, 97.7%)\n",
            "[2023-01-12 16:14:10] \u001b[32mValid: [  8/600] Step 060/104 Loss 0.817 Prec@(1,5) (70.9%, 97.8%)\u001b[0m\n",
            "INFO:nni:Valid: [  8/600] Step 060/104 Loss 0.817 Prec@(1,5) (70.9%, 97.8%)\n",
            "[2023-01-12 16:14:11] \u001b[32mValid: [  8/600] Step 070/104 Loss 0.818 Prec@(1,5) (71.0%, 97.8%)\u001b[0m\n",
            "INFO:nni:Valid: [  8/600] Step 070/104 Loss 0.818 Prec@(1,5) (71.0%, 97.8%)\n",
            "[2023-01-12 16:14:13] \u001b[32mValid: [  8/600] Step 080/104 Loss 0.817 Prec@(1,5) (71.1%, 97.8%)\u001b[0m\n",
            "INFO:nni:Valid: [  8/600] Step 080/104 Loss 0.817 Prec@(1,5) (71.1%, 97.8%)\n",
            "[2023-01-12 16:14:14] \u001b[32mValid: [  8/600] Step 090/104 Loss 0.823 Prec@(1,5) (71.1%, 97.7%)\u001b[0m\n",
            "INFO:nni:Valid: [  8/600] Step 090/104 Loss 0.823 Prec@(1,5) (71.1%, 97.7%)\n",
            "[2023-01-12 16:14:15] \u001b[32mValid: [  8/600] Step 100/104 Loss 0.819 Prec@(1,5) (71.3%, 97.7%)\u001b[0m\n",
            "INFO:nni:Valid: [  8/600] Step 100/104 Loss 0.819 Prec@(1,5) (71.3%, 97.7%)\n",
            "[2023-01-12 16:14:16] \u001b[32mValid: [  8/600] Step 104/104 Loss 0.821 Prec@(1,5) (71.2%, 97.8%)\u001b[0m\n",
            "INFO:nni:Valid: [  8/600] Step 104/104 Loss 0.821 Prec@(1,5) (71.2%, 97.8%)\n",
            "[2023-01-12 16:14:16] \u001b[32mValid: [  8/600] Final Prec@1 71.1600%\u001b[0m\n",
            "INFO:nni:Valid: [  8/600] Final Prec@1 71.1600%\n",
            "[2023-01-12 16:14:16] \u001b[32mEpoch 8 LR 0.024989\u001b[0m\n",
            "INFO:nni:Epoch 8 LR 0.024989\n",
            "[2023-01-12 16:14:17] \u001b[32mTrain: [  9/600] Step 000/520 Loss 1.211 Prec@(1,5) (71.9%, 99.0%)\u001b[0m\n",
            "INFO:nni:Train: [  9/600] Step 000/520 Loss 1.211 Prec@(1,5) (71.9%, 99.0%)\n",
            "[2023-01-12 16:14:21] \u001b[32mTrain: [  9/600] Step 010/520 Loss 1.196 Prec@(1,5) (69.7%, 97.8%)\u001b[0m\n",
            "INFO:nni:Train: [  9/600] Step 010/520 Loss 1.196 Prec@(1,5) (69.7%, 97.8%)\n",
            "[2023-01-12 16:14:26] \u001b[32mTrain: [  9/600] Step 020/520 Loss 1.186 Prec@(1,5) (69.4%, 98.0%)\u001b[0m\n",
            "INFO:nni:Train: [  9/600] Step 020/520 Loss 1.186 Prec@(1,5) (69.4%, 98.0%)\n",
            "[2023-01-12 16:14:30] \u001b[32mTrain: [  9/600] Step 030/520 Loss 1.175 Prec@(1,5) (70.5%, 98.0%)\u001b[0m\n",
            "INFO:nni:Train: [  9/600] Step 030/520 Loss 1.175 Prec@(1,5) (70.5%, 98.0%)\n",
            "[2023-01-12 16:14:35] \u001b[32mTrain: [  9/600] Step 040/520 Loss 1.194 Prec@(1,5) (70.4%, 97.9%)\u001b[0m\n",
            "INFO:nni:Train: [  9/600] Step 040/520 Loss 1.194 Prec@(1,5) (70.4%, 97.9%)\n",
            "[2023-01-12 16:14:39] \u001b[32mTrain: [  9/600] Step 050/520 Loss 1.192 Prec@(1,5) (70.5%, 97.9%)\u001b[0m\n",
            "INFO:nni:Train: [  9/600] Step 050/520 Loss 1.192 Prec@(1,5) (70.5%, 97.9%)\n",
            "[2023-01-12 16:14:44] \u001b[32mTrain: [  9/600] Step 060/520 Loss 1.193 Prec@(1,5) (70.3%, 97.9%)\u001b[0m\n",
            "INFO:nni:Train: [  9/600] Step 060/520 Loss 1.193 Prec@(1,5) (70.3%, 97.9%)\n",
            "[2023-01-12 16:14:48] \u001b[32mTrain: [  9/600] Step 070/520 Loss 1.187 Prec@(1,5) (70.6%, 97.9%)\u001b[0m\n",
            "INFO:nni:Train: [  9/600] Step 070/520 Loss 1.187 Prec@(1,5) (70.6%, 97.9%)\n",
            "[2023-01-12 16:14:53] \u001b[32mTrain: [  9/600] Step 080/520 Loss 1.183 Prec@(1,5) (70.8%, 97.9%)\u001b[0m\n",
            "INFO:nni:Train: [  9/600] Step 080/520 Loss 1.183 Prec@(1,5) (70.8%, 97.9%)\n",
            "[2023-01-12 16:14:57] \u001b[32mTrain: [  9/600] Step 090/520 Loss 1.195 Prec@(1,5) (70.5%, 97.8%)\u001b[0m\n",
            "INFO:nni:Train: [  9/600] Step 090/520 Loss 1.195 Prec@(1,5) (70.5%, 97.8%)\n",
            "[2023-01-12 16:15:02] \u001b[32mTrain: [  9/600] Step 100/520 Loss 1.198 Prec@(1,5) (70.4%, 97.8%)\u001b[0m\n",
            "INFO:nni:Train: [  9/600] Step 100/520 Loss 1.198 Prec@(1,5) (70.4%, 97.8%)\n",
            "[2023-01-12 16:15:07] \u001b[32mTrain: [  9/600] Step 110/520 Loss 1.200 Prec@(1,5) (70.2%, 97.8%)\u001b[0m\n",
            "INFO:nni:Train: [  9/600] Step 110/520 Loss 1.200 Prec@(1,5) (70.2%, 97.8%)\n",
            "[2023-01-12 16:15:11] \u001b[32mTrain: [  9/600] Step 120/520 Loss 1.202 Prec@(1,5) (70.1%, 97.8%)\u001b[0m\n",
            "INFO:nni:Train: [  9/600] Step 120/520 Loss 1.202 Prec@(1,5) (70.1%, 97.8%)\n",
            "[2023-01-12 16:15:16] \u001b[32mTrain: [  9/600] Step 130/520 Loss 1.196 Prec@(1,5) (70.2%, 97.8%)\u001b[0m\n",
            "INFO:nni:Train: [  9/600] Step 130/520 Loss 1.196 Prec@(1,5) (70.2%, 97.8%)\n",
            "[2023-01-12 16:15:20] \u001b[32mTrain: [  9/600] Step 140/520 Loss 1.192 Prec@(1,5) (70.3%, 97.8%)\u001b[0m\n",
            "INFO:nni:Train: [  9/600] Step 140/520 Loss 1.192 Prec@(1,5) (70.3%, 97.8%)\n",
            "[2023-01-12 16:15:25] \u001b[32mTrain: [  9/600] Step 150/520 Loss 1.188 Prec@(1,5) (70.3%, 97.8%)\u001b[0m\n",
            "INFO:nni:Train: [  9/600] Step 150/520 Loss 1.188 Prec@(1,5) (70.3%, 97.8%)\n",
            "[2023-01-12 16:15:29] \u001b[32mTrain: [  9/600] Step 160/520 Loss 1.186 Prec@(1,5) (70.4%, 97.9%)\u001b[0m\n",
            "INFO:nni:Train: [  9/600] Step 160/520 Loss 1.186 Prec@(1,5) (70.4%, 97.9%)\n",
            "[2023-01-12 16:15:34] \u001b[32mTrain: [  9/600] Step 170/520 Loss 1.180 Prec@(1,5) (70.5%, 97.9%)\u001b[0m\n",
            "INFO:nni:Train: [  9/600] Step 170/520 Loss 1.180 Prec@(1,5) (70.5%, 97.9%)\n",
            "[2023-01-12 16:15:38] \u001b[32mTrain: [  9/600] Step 180/520 Loss 1.176 Prec@(1,5) (70.6%, 97.9%)\u001b[0m\n",
            "INFO:nni:Train: [  9/600] Step 180/520 Loss 1.176 Prec@(1,5) (70.6%, 97.9%)\n",
            "[2023-01-12 16:15:43] \u001b[32mTrain: [  9/600] Step 190/520 Loss 1.178 Prec@(1,5) (70.6%, 97.9%)\u001b[0m\n",
            "INFO:nni:Train: [  9/600] Step 190/520 Loss 1.178 Prec@(1,5) (70.6%, 97.9%)\n",
            "[2023-01-12 16:15:47] \u001b[32mTrain: [  9/600] Step 200/520 Loss 1.178 Prec@(1,5) (70.5%, 98.0%)\u001b[0m\n",
            "INFO:nni:Train: [  9/600] Step 200/520 Loss 1.178 Prec@(1,5) (70.5%, 98.0%)\n",
            "[2023-01-12 16:15:52] \u001b[32mTrain: [  9/600] Step 210/520 Loss 1.183 Prec@(1,5) (70.3%, 97.9%)\u001b[0m\n",
            "INFO:nni:Train: [  9/600] Step 210/520 Loss 1.183 Prec@(1,5) (70.3%, 97.9%)\n",
            "[2023-01-12 16:15:56] \u001b[32mTrain: [  9/600] Step 220/520 Loss 1.187 Prec@(1,5) (70.1%, 97.9%)\u001b[0m\n",
            "INFO:nni:Train: [  9/600] Step 220/520 Loss 1.187 Prec@(1,5) (70.1%, 97.9%)\n",
            "[2023-01-12 16:16:01] \u001b[32mTrain: [  9/600] Step 230/520 Loss 1.186 Prec@(1,5) (70.2%, 97.9%)\u001b[0m\n",
            "INFO:nni:Train: [  9/600] Step 230/520 Loss 1.186 Prec@(1,5) (70.2%, 97.9%)\n",
            "[2023-01-12 16:16:05] \u001b[32mTrain: [  9/600] Step 240/520 Loss 1.185 Prec@(1,5) (70.3%, 97.9%)\u001b[0m\n",
            "INFO:nni:Train: [  9/600] Step 240/520 Loss 1.185 Prec@(1,5) (70.3%, 97.9%)\n",
            "[2023-01-12 16:16:10] \u001b[32mTrain: [  9/600] Step 250/520 Loss 1.181 Prec@(1,5) (70.3%, 97.8%)\u001b[0m\n",
            "INFO:nni:Train: [  9/600] Step 250/520 Loss 1.181 Prec@(1,5) (70.3%, 97.8%)\n",
            "[2023-01-12 16:16:14] \u001b[32mTrain: [  9/600] Step 260/520 Loss 1.186 Prec@(1,5) (70.2%, 97.8%)\u001b[0m\n",
            "INFO:nni:Train: [  9/600] Step 260/520 Loss 1.186 Prec@(1,5) (70.2%, 97.8%)\n",
            "[2023-01-12 16:16:19] \u001b[32mTrain: [  9/600] Step 270/520 Loss 1.186 Prec@(1,5) (70.2%, 97.8%)\u001b[0m\n",
            "INFO:nni:Train: [  9/600] Step 270/520 Loss 1.186 Prec@(1,5) (70.2%, 97.8%)\n",
            "[2023-01-12 16:16:23] \u001b[32mTrain: [  9/600] Step 280/520 Loss 1.187 Prec@(1,5) (70.3%, 97.8%)\u001b[0m\n",
            "INFO:nni:Train: [  9/600] Step 280/520 Loss 1.187 Prec@(1,5) (70.3%, 97.8%)\n",
            "[2023-01-12 16:16:28] \u001b[32mTrain: [  9/600] Step 290/520 Loss 1.188 Prec@(1,5) (70.2%, 97.8%)\u001b[0m\n",
            "INFO:nni:Train: [  9/600] Step 290/520 Loss 1.188 Prec@(1,5) (70.2%, 97.8%)\n",
            "[2023-01-12 16:16:32] \u001b[32mTrain: [  9/600] Step 300/520 Loss 1.185 Prec@(1,5) (70.3%, 97.8%)\u001b[0m\n",
            "INFO:nni:Train: [  9/600] Step 300/520 Loss 1.185 Prec@(1,5) (70.3%, 97.8%)\n",
            "[2023-01-12 16:16:37] \u001b[32mTrain: [  9/600] Step 310/520 Loss 1.184 Prec@(1,5) (70.3%, 97.8%)\u001b[0m\n",
            "INFO:nni:Train: [  9/600] Step 310/520 Loss 1.184 Prec@(1,5) (70.3%, 97.8%)\n",
            "[2023-01-12 16:16:41] \u001b[32mTrain: [  9/600] Step 320/520 Loss 1.182 Prec@(1,5) (70.4%, 97.8%)\u001b[0m\n",
            "INFO:nni:Train: [  9/600] Step 320/520 Loss 1.182 Prec@(1,5) (70.4%, 97.8%)\n",
            "[2023-01-12 16:16:46] \u001b[32mTrain: [  9/600] Step 330/520 Loss 1.181 Prec@(1,5) (70.4%, 97.8%)\u001b[0m\n",
            "INFO:nni:Train: [  9/600] Step 330/520 Loss 1.181 Prec@(1,5) (70.4%, 97.8%)\n",
            "[2023-01-12 16:16:50] \u001b[32mTrain: [  9/600] Step 340/520 Loss 1.182 Prec@(1,5) (70.4%, 97.8%)\u001b[0m\n",
            "INFO:nni:Train: [  9/600] Step 340/520 Loss 1.182 Prec@(1,5) (70.4%, 97.8%)\n",
            "[2023-01-12 16:16:55] \u001b[32mTrain: [  9/600] Step 350/520 Loss 1.181 Prec@(1,5) (70.4%, 97.8%)\u001b[0m\n",
            "INFO:nni:Train: [  9/600] Step 350/520 Loss 1.181 Prec@(1,5) (70.4%, 97.8%)\n",
            "[2023-01-12 16:16:59] \u001b[32mTrain: [  9/600] Step 360/520 Loss 1.181 Prec@(1,5) (70.5%, 97.8%)\u001b[0m\n",
            "INFO:nni:Train: [  9/600] Step 360/520 Loss 1.181 Prec@(1,5) (70.5%, 97.8%)\n",
            "[2023-01-12 16:17:04] \u001b[32mTrain: [  9/600] Step 370/520 Loss 1.181 Prec@(1,5) (70.5%, 97.8%)\u001b[0m\n",
            "INFO:nni:Train: [  9/600] Step 370/520 Loss 1.181 Prec@(1,5) (70.5%, 97.8%)\n",
            "[2023-01-12 16:17:09] \u001b[32mTrain: [  9/600] Step 380/520 Loss 1.181 Prec@(1,5) (70.5%, 97.8%)\u001b[0m\n",
            "INFO:nni:Train: [  9/600] Step 380/520 Loss 1.181 Prec@(1,5) (70.5%, 97.8%)\n",
            "[2023-01-12 16:17:13] \u001b[32mTrain: [  9/600] Step 390/520 Loss 1.181 Prec@(1,5) (70.5%, 97.8%)\u001b[0m\n",
            "INFO:nni:Train: [  9/600] Step 390/520 Loss 1.181 Prec@(1,5) (70.5%, 97.8%)\n",
            "[2023-01-12 16:17:18] \u001b[32mTrain: [  9/600] Step 400/520 Loss 1.180 Prec@(1,5) (70.5%, 97.8%)\u001b[0m\n",
            "INFO:nni:Train: [  9/600] Step 400/520 Loss 1.180 Prec@(1,5) (70.5%, 97.8%)\n",
            "[2023-01-12 16:17:22] \u001b[32mTrain: [  9/600] Step 410/520 Loss 1.181 Prec@(1,5) (70.6%, 97.7%)\u001b[0m\n",
            "INFO:nni:Train: [  9/600] Step 410/520 Loss 1.181 Prec@(1,5) (70.6%, 97.7%)\n",
            "[2023-01-12 16:17:27] \u001b[32mTrain: [  9/600] Step 420/520 Loss 1.180 Prec@(1,5) (70.6%, 97.7%)\u001b[0m\n",
            "INFO:nni:Train: [  9/600] Step 420/520 Loss 1.180 Prec@(1,5) (70.6%, 97.7%)\n",
            "[2023-01-12 16:17:31] \u001b[32mTrain: [  9/600] Step 430/520 Loss 1.180 Prec@(1,5) (70.6%, 97.7%)\u001b[0m\n",
            "INFO:nni:Train: [  9/600] Step 430/520 Loss 1.180 Prec@(1,5) (70.6%, 97.7%)\n",
            "[2023-01-12 16:17:36] \u001b[32mTrain: [  9/600] Step 440/520 Loss 1.179 Prec@(1,5) (70.6%, 97.7%)\u001b[0m\n",
            "INFO:nni:Train: [  9/600] Step 440/520 Loss 1.179 Prec@(1,5) (70.6%, 97.7%)\n",
            "[2023-01-12 16:17:40] \u001b[32mTrain: [  9/600] Step 450/520 Loss 1.178 Prec@(1,5) (70.7%, 97.8%)\u001b[0m\n",
            "INFO:nni:Train: [  9/600] Step 450/520 Loss 1.178 Prec@(1,5) (70.7%, 97.8%)\n",
            "[2023-01-12 16:17:45] \u001b[32mTrain: [  9/600] Step 460/520 Loss 1.177 Prec@(1,5) (70.7%, 97.8%)\u001b[0m\n",
            "INFO:nni:Train: [  9/600] Step 460/520 Loss 1.177 Prec@(1,5) (70.7%, 97.8%)\n",
            "[2023-01-12 16:17:49] \u001b[32mTrain: [  9/600] Step 470/520 Loss 1.178 Prec@(1,5) (70.7%, 97.7%)\u001b[0m\n",
            "INFO:nni:Train: [  9/600] Step 470/520 Loss 1.178 Prec@(1,5) (70.7%, 97.7%)\n",
            "[2023-01-12 16:17:54] \u001b[32mTrain: [  9/600] Step 480/520 Loss 1.175 Prec@(1,5) (70.7%, 97.7%)\u001b[0m\n",
            "INFO:nni:Train: [  9/600] Step 480/520 Loss 1.175 Prec@(1,5) (70.7%, 97.7%)\n",
            "[2023-01-12 16:17:58] \u001b[32mTrain: [  9/600] Step 490/520 Loss 1.176 Prec@(1,5) (70.7%, 97.7%)\u001b[0m\n",
            "INFO:nni:Train: [  9/600] Step 490/520 Loss 1.176 Prec@(1,5) (70.7%, 97.7%)\n",
            "[2023-01-12 16:18:03] \u001b[32mTrain: [  9/600] Step 500/520 Loss 1.176 Prec@(1,5) (70.7%, 97.7%)\u001b[0m\n",
            "INFO:nni:Train: [  9/600] Step 500/520 Loss 1.176 Prec@(1,5) (70.7%, 97.7%)\n",
            "[2023-01-12 16:18:07] \u001b[32mTrain: [  9/600] Step 510/520 Loss 1.174 Prec@(1,5) (70.7%, 97.7%)\u001b[0m\n",
            "INFO:nni:Train: [  9/600] Step 510/520 Loss 1.174 Prec@(1,5) (70.7%, 97.7%)\n",
            "[2023-01-12 16:18:12] \u001b[32mTrain: [  9/600] Step 520/520 Loss 1.175 Prec@(1,5) (70.7%, 97.7%)\u001b[0m\n",
            "INFO:nni:Train: [  9/600] Step 520/520 Loss 1.175 Prec@(1,5) (70.7%, 97.7%)\n",
            "[2023-01-12 16:18:12] \u001b[32mTrain: [  9/600] Final Prec@1 70.6680%\u001b[0m\n",
            "INFO:nni:Train: [  9/600] Final Prec@1 70.6680%\n",
            "[2023-01-12 16:18:12] \u001b[32mValid: [  9/600] Step 000/104 Loss 0.872 Prec@(1,5) (71.9%, 97.9%)\u001b[0m\n",
            "INFO:nni:Valid: [  9/600] Step 000/104 Loss 0.872 Prec@(1,5) (71.9%, 97.9%)\n",
            "[2023-01-12 16:18:14] \u001b[32mValid: [  9/600] Step 010/104 Loss 1.252 Prec@(1,5) (67.8%, 98.1%)\u001b[0m\n",
            "INFO:nni:Valid: [  9/600] Step 010/104 Loss 1.252 Prec@(1,5) (67.8%, 98.1%)\n",
            "[2023-01-12 16:18:15] \u001b[32mValid: [  9/600] Step 020/104 Loss 1.143 Prec@(1,5) (68.9%, 98.2%)\u001b[0m\n",
            "INFO:nni:Valid: [  9/600] Step 020/104 Loss 1.143 Prec@(1,5) (68.9%, 98.2%)\n",
            "[2023-01-12 16:18:16] \u001b[32mValid: [  9/600] Step 030/104 Loss 1.098 Prec@(1,5) (69.5%, 98.2%)\u001b[0m\n",
            "INFO:nni:Valid: [  9/600] Step 030/104 Loss 1.098 Prec@(1,5) (69.5%, 98.2%)\n",
            "[2023-01-12 16:18:18] \u001b[32mValid: [  9/600] Step 040/104 Loss 1.132 Prec@(1,5) (69.5%, 98.0%)\u001b[0m\n",
            "INFO:nni:Valid: [  9/600] Step 040/104 Loss 1.132 Prec@(1,5) (69.5%, 98.0%)\n",
            "[2023-01-12 16:18:19] \u001b[32mValid: [  9/600] Step 050/104 Loss 1.128 Prec@(1,5) (70.0%, 98.1%)\u001b[0m\n",
            "INFO:nni:Valid: [  9/600] Step 050/104 Loss 1.128 Prec@(1,5) (70.0%, 98.1%)\n",
            "[2023-01-12 16:18:21] \u001b[32mValid: [  9/600] Step 060/104 Loss 1.137 Prec@(1,5) (69.9%, 98.1%)\u001b[0m\n",
            "INFO:nni:Valid: [  9/600] Step 060/104 Loss 1.137 Prec@(1,5) (69.9%, 98.1%)\n",
            "[2023-01-12 16:18:22] \u001b[32mValid: [  9/600] Step 070/104 Loss 1.161 Prec@(1,5) (69.5%, 98.1%)\u001b[0m\n",
            "INFO:nni:Valid: [  9/600] Step 070/104 Loss 1.161 Prec@(1,5) (69.5%, 98.1%)\n",
            "[2023-01-12 16:18:23] \u001b[32mValid: [  9/600] Step 080/104 Loss 1.164 Prec@(1,5) (69.7%, 98.1%)\u001b[0m\n",
            "INFO:nni:Valid: [  9/600] Step 080/104 Loss 1.164 Prec@(1,5) (69.7%, 98.1%)\n",
            "[2023-01-12 16:18:25] \u001b[32mValid: [  9/600] Step 090/104 Loss 1.159 Prec@(1,5) (70.0%, 98.1%)\u001b[0m\n",
            "INFO:nni:Valid: [  9/600] Step 090/104 Loss 1.159 Prec@(1,5) (70.0%, 98.1%)\n",
            "[2023-01-12 16:18:26] \u001b[32mValid: [  9/600] Step 100/104 Loss 1.163 Prec@(1,5) (70.0%, 98.1%)\u001b[0m\n",
            "INFO:nni:Valid: [  9/600] Step 100/104 Loss 1.163 Prec@(1,5) (70.0%, 98.1%)\n",
            "[2023-01-12 16:18:27] \u001b[32mValid: [  9/600] Step 104/104 Loss 1.159 Prec@(1,5) (70.1%, 98.1%)\u001b[0m\n",
            "INFO:nni:Valid: [  9/600] Step 104/104 Loss 1.159 Prec@(1,5) (70.1%, 98.1%)\n",
            "[2023-01-12 16:18:27] \u001b[32mValid: [  9/600] Final Prec@1 70.0700%\u001b[0m\n",
            "INFO:nni:Valid: [  9/600] Final Prec@1 70.0700%\n",
            "[2023-01-12 16:18:27] \u001b[32mEpoch 9 LR 0.024986\u001b[0m\n",
            "INFO:nni:Epoch 9 LR 0.024986\n",
            "[2023-01-12 16:18:28] \u001b[32mTrain: [ 10/600] Step 000/520 Loss 0.969 Prec@(1,5) (70.8%, 99.0%)\u001b[0m\n",
            "INFO:nni:Train: [ 10/600] Step 000/520 Loss 0.969 Prec@(1,5) (70.8%, 99.0%)\n",
            "[2023-01-12 16:18:32] \u001b[32mTrain: [ 10/600] Step 010/520 Loss 1.197 Prec@(1,5) (68.6%, 97.9%)\u001b[0m\n",
            "INFO:nni:Train: [ 10/600] Step 010/520 Loss 1.197 Prec@(1,5) (68.6%, 97.9%)\n",
            "[2023-01-12 16:18:37] \u001b[32mTrain: [ 10/600] Step 020/520 Loss 1.151 Prec@(1,5) (70.5%, 97.9%)\u001b[0m\n",
            "INFO:nni:Train: [ 10/600] Step 020/520 Loss 1.151 Prec@(1,5) (70.5%, 97.9%)\n",
            "[2023-01-12 16:18:41] \u001b[32mTrain: [ 10/600] Step 030/520 Loss 1.147 Prec@(1,5) (70.8%, 98.0%)\u001b[0m\n",
            "INFO:nni:Train: [ 10/600] Step 030/520 Loss 1.147 Prec@(1,5) (70.8%, 98.0%)\n",
            "[2023-01-12 16:18:46] \u001b[32mTrain: [ 10/600] Step 040/520 Loss 1.145 Prec@(1,5) (71.0%, 98.0%)\u001b[0m\n",
            "INFO:nni:Train: [ 10/600] Step 040/520 Loss 1.145 Prec@(1,5) (71.0%, 98.0%)\n",
            "[2023-01-12 16:18:50] \u001b[32mTrain: [ 10/600] Step 050/520 Loss 1.146 Prec@(1,5) (71.2%, 98.1%)\u001b[0m\n",
            "INFO:nni:Train: [ 10/600] Step 050/520 Loss 1.146 Prec@(1,5) (71.2%, 98.1%)\n",
            "[2023-01-12 16:18:55] \u001b[32mTrain: [ 10/600] Step 060/520 Loss 1.147 Prec@(1,5) (71.1%, 98.1%)\u001b[0m\n",
            "INFO:nni:Train: [ 10/600] Step 060/520 Loss 1.147 Prec@(1,5) (71.1%, 98.1%)\n",
            "[2023-01-12 16:18:59] \u001b[32mTrain: [ 10/600] Step 070/520 Loss 1.160 Prec@(1,5) (70.8%, 98.0%)\u001b[0m\n",
            "INFO:nni:Train: [ 10/600] Step 070/520 Loss 1.160 Prec@(1,5) (70.8%, 98.0%)\n",
            "[2023-01-12 16:19:04] \u001b[32mTrain: [ 10/600] Step 080/520 Loss 1.156 Prec@(1,5) (70.9%, 97.9%)\u001b[0m\n",
            "INFO:nni:Train: [ 10/600] Step 080/520 Loss 1.156 Prec@(1,5) (70.9%, 97.9%)\n",
            "[2023-01-12 16:19:08] \u001b[32mTrain: [ 10/600] Step 090/520 Loss 1.162 Prec@(1,5) (70.7%, 97.8%)\u001b[0m\n",
            "INFO:nni:Train: [ 10/600] Step 090/520 Loss 1.162 Prec@(1,5) (70.7%, 97.8%)\n",
            "[2023-01-12 16:19:13] \u001b[32mTrain: [ 10/600] Step 100/520 Loss 1.156 Prec@(1,5) (70.9%, 97.9%)\u001b[0m\n",
            "INFO:nni:Train: [ 10/600] Step 100/520 Loss 1.156 Prec@(1,5) (70.9%, 97.9%)\n",
            "[2023-01-12 16:19:17] \u001b[32mTrain: [ 10/600] Step 110/520 Loss 1.150 Prec@(1,5) (71.1%, 97.9%)\u001b[0m\n",
            "INFO:nni:Train: [ 10/600] Step 110/520 Loss 1.150 Prec@(1,5) (71.1%, 97.9%)\n",
            "[2023-01-12 16:19:22] \u001b[32mTrain: [ 10/600] Step 120/520 Loss 1.145 Prec@(1,5) (71.1%, 97.9%)\u001b[0m\n",
            "INFO:nni:Train: [ 10/600] Step 120/520 Loss 1.145 Prec@(1,5) (71.1%, 97.9%)\n",
            "[2023-01-12 16:19:26] \u001b[32mTrain: [ 10/600] Step 130/520 Loss 1.146 Prec@(1,5) (71.1%, 97.9%)\u001b[0m\n",
            "INFO:nni:Train: [ 10/600] Step 130/520 Loss 1.146 Prec@(1,5) (71.1%, 97.9%)\n",
            "[2023-01-12 16:19:31] \u001b[32mTrain: [ 10/600] Step 140/520 Loss 1.139 Prec@(1,5) (71.3%, 97.9%)\u001b[0m\n",
            "INFO:nni:Train: [ 10/600] Step 140/520 Loss 1.139 Prec@(1,5) (71.3%, 97.9%)\n",
            "[2023-01-12 16:19:35] \u001b[32mTrain: [ 10/600] Step 150/520 Loss 1.136 Prec@(1,5) (71.5%, 97.9%)\u001b[0m\n",
            "INFO:nni:Train: [ 10/600] Step 150/520 Loss 1.136 Prec@(1,5) (71.5%, 97.9%)\n",
            "[2023-01-12 16:19:40] \u001b[32mTrain: [ 10/600] Step 160/520 Loss 1.135 Prec@(1,5) (71.5%, 97.9%)\u001b[0m\n",
            "INFO:nni:Train: [ 10/600] Step 160/520 Loss 1.135 Prec@(1,5) (71.5%, 97.9%)\n",
            "[2023-01-12 16:19:44] \u001b[32mTrain: [ 10/600] Step 170/520 Loss 1.138 Prec@(1,5) (71.6%, 97.9%)\u001b[0m\n",
            "INFO:nni:Train: [ 10/600] Step 170/520 Loss 1.138 Prec@(1,5) (71.6%, 97.9%)\n",
            "[2023-01-12 16:19:49] \u001b[32mTrain: [ 10/600] Step 180/520 Loss 1.142 Prec@(1,5) (71.5%, 97.9%)\u001b[0m\n",
            "INFO:nni:Train: [ 10/600] Step 180/520 Loss 1.142 Prec@(1,5) (71.5%, 97.9%)\n",
            "[2023-01-12 16:19:53] \u001b[32mTrain: [ 10/600] Step 190/520 Loss 1.144 Prec@(1,5) (71.5%, 97.8%)\u001b[0m\n",
            "INFO:nni:Train: [ 10/600] Step 190/520 Loss 1.144 Prec@(1,5) (71.5%, 97.8%)\n",
            "[2023-01-12 16:19:58] \u001b[32mTrain: [ 10/600] Step 200/520 Loss 1.140 Prec@(1,5) (71.5%, 97.9%)\u001b[0m\n",
            "INFO:nni:Train: [ 10/600] Step 200/520 Loss 1.140 Prec@(1,5) (71.5%, 97.9%)\n",
            "[2023-01-12 16:20:02] \u001b[32mTrain: [ 10/600] Step 210/520 Loss 1.137 Prec@(1,5) (71.6%, 97.9%)\u001b[0m\n",
            "INFO:nni:Train: [ 10/600] Step 210/520 Loss 1.137 Prec@(1,5) (71.6%, 97.9%)\n",
            "[2023-01-12 16:20:07] \u001b[32mTrain: [ 10/600] Step 220/520 Loss 1.136 Prec@(1,5) (71.6%, 97.9%)\u001b[0m\n",
            "INFO:nni:Train: [ 10/600] Step 220/520 Loss 1.136 Prec@(1,5) (71.6%, 97.9%)\n",
            "[2023-01-12 16:20:12] \u001b[32mTrain: [ 10/600] Step 230/520 Loss 1.135 Prec@(1,5) (71.7%, 97.9%)\u001b[0m\n",
            "INFO:nni:Train: [ 10/600] Step 230/520 Loss 1.135 Prec@(1,5) (71.7%, 97.9%)\n",
            "[2023-01-12 16:20:16] \u001b[32mTrain: [ 10/600] Step 240/520 Loss 1.132 Prec@(1,5) (71.7%, 97.9%)\u001b[0m\n",
            "INFO:nni:Train: [ 10/600] Step 240/520 Loss 1.132 Prec@(1,5) (71.7%, 97.9%)\n",
            "[2023-01-12 16:20:21] \u001b[32mTrain: [ 10/600] Step 250/520 Loss 1.134 Prec@(1,5) (71.7%, 97.9%)\u001b[0m\n",
            "INFO:nni:Train: [ 10/600] Step 250/520 Loss 1.134 Prec@(1,5) (71.7%, 97.9%)\n",
            "[2023-01-12 16:20:25] \u001b[32mTrain: [ 10/600] Step 260/520 Loss 1.136 Prec@(1,5) (71.6%, 97.9%)\u001b[0m\n",
            "INFO:nni:Train: [ 10/600] Step 260/520 Loss 1.136 Prec@(1,5) (71.6%, 97.9%)\n",
            "[2023-01-12 16:20:30] \u001b[32mTrain: [ 10/600] Step 270/520 Loss 1.137 Prec@(1,5) (71.6%, 97.9%)\u001b[0m\n",
            "INFO:nni:Train: [ 10/600] Step 270/520 Loss 1.137 Prec@(1,5) (71.6%, 97.9%)\n",
            "[2023-01-12 16:20:34] \u001b[32mTrain: [ 10/600] Step 280/520 Loss 1.135 Prec@(1,5) (71.6%, 97.9%)\u001b[0m\n",
            "INFO:nni:Train: [ 10/600] Step 280/520 Loss 1.135 Prec@(1,5) (71.6%, 97.9%)\n",
            "[2023-01-12 16:20:39] \u001b[32mTrain: [ 10/600] Step 290/520 Loss 1.131 Prec@(1,5) (71.6%, 97.9%)\u001b[0m\n",
            "INFO:nni:Train: [ 10/600] Step 290/520 Loss 1.131 Prec@(1,5) (71.6%, 97.9%)\n",
            "[2023-01-12 16:20:43] \u001b[32mTrain: [ 10/600] Step 300/520 Loss 1.133 Prec@(1,5) (71.6%, 97.9%)\u001b[0m\n",
            "INFO:nni:Train: [ 10/600] Step 300/520 Loss 1.133 Prec@(1,5) (71.6%, 97.9%)\n",
            "[2023-01-12 16:20:48] \u001b[32mTrain: [ 10/600] Step 310/520 Loss 1.135 Prec@(1,5) (71.7%, 97.8%)\u001b[0m\n",
            "INFO:nni:Train: [ 10/600] Step 310/520 Loss 1.135 Prec@(1,5) (71.7%, 97.8%)\n",
            "[2023-01-12 16:20:52] \u001b[32mTrain: [ 10/600] Step 320/520 Loss 1.133 Prec@(1,5) (71.7%, 97.8%)\u001b[0m\n",
            "INFO:nni:Train: [ 10/600] Step 320/520 Loss 1.133 Prec@(1,5) (71.7%, 97.8%)\n",
            "[2023-01-12 16:20:57] \u001b[32mTrain: [ 10/600] Step 330/520 Loss 1.135 Prec@(1,5) (71.7%, 97.8%)\u001b[0m\n",
            "INFO:nni:Train: [ 10/600] Step 330/520 Loss 1.135 Prec@(1,5) (71.7%, 97.8%)\n",
            "[2023-01-12 16:21:01] \u001b[32mTrain: [ 10/600] Step 340/520 Loss 1.136 Prec@(1,5) (71.7%, 97.9%)\u001b[0m\n",
            "INFO:nni:Train: [ 10/600] Step 340/520 Loss 1.136 Prec@(1,5) (71.7%, 97.9%)\n",
            "[2023-01-12 16:21:06] \u001b[32mTrain: [ 10/600] Step 350/520 Loss 1.136 Prec@(1,5) (71.7%, 97.9%)\u001b[0m\n",
            "INFO:nni:Train: [ 10/600] Step 350/520 Loss 1.136 Prec@(1,5) (71.7%, 97.9%)\n",
            "[2023-01-12 16:21:10] \u001b[32mTrain: [ 10/600] Step 360/520 Loss 1.135 Prec@(1,5) (71.7%, 97.9%)\u001b[0m\n",
            "INFO:nni:Train: [ 10/600] Step 360/520 Loss 1.135 Prec@(1,5) (71.7%, 97.9%)\n",
            "[2023-01-12 16:21:15] \u001b[32mTrain: [ 10/600] Step 370/520 Loss 1.136 Prec@(1,5) (71.7%, 97.9%)\u001b[0m\n",
            "INFO:nni:Train: [ 10/600] Step 370/520 Loss 1.136 Prec@(1,5) (71.7%, 97.9%)\n",
            "[2023-01-12 16:21:19] \u001b[32mTrain: [ 10/600] Step 380/520 Loss 1.135 Prec@(1,5) (71.8%, 97.9%)\u001b[0m\n",
            "INFO:nni:Train: [ 10/600] Step 380/520 Loss 1.135 Prec@(1,5) (71.8%, 97.9%)\n",
            "[2023-01-12 16:21:24] \u001b[32mTrain: [ 10/600] Step 390/520 Loss 1.136 Prec@(1,5) (71.8%, 97.9%)\u001b[0m\n",
            "INFO:nni:Train: [ 10/600] Step 390/520 Loss 1.136 Prec@(1,5) (71.8%, 97.9%)\n",
            "[2023-01-12 16:21:28] \u001b[32mTrain: [ 10/600] Step 400/520 Loss 1.138 Prec@(1,5) (71.8%, 97.9%)\u001b[0m\n",
            "INFO:nni:Train: [ 10/600] Step 400/520 Loss 1.138 Prec@(1,5) (71.8%, 97.9%)\n",
            "[2023-01-12 16:21:33] \u001b[32mTrain: [ 10/600] Step 410/520 Loss 1.138 Prec@(1,5) (71.7%, 97.9%)\u001b[0m\n",
            "INFO:nni:Train: [ 10/600] Step 410/520 Loss 1.138 Prec@(1,5) (71.7%, 97.9%)\n",
            "[2023-01-12 16:21:37] \u001b[32mTrain: [ 10/600] Step 420/520 Loss 1.139 Prec@(1,5) (71.7%, 97.9%)\u001b[0m\n",
            "INFO:nni:Train: [ 10/600] Step 420/520 Loss 1.139 Prec@(1,5) (71.7%, 97.9%)\n",
            "[2023-01-12 16:21:42] \u001b[32mTrain: [ 10/600] Step 430/520 Loss 1.137 Prec@(1,5) (71.8%, 97.9%)\u001b[0m\n",
            "INFO:nni:Train: [ 10/600] Step 430/520 Loss 1.137 Prec@(1,5) (71.8%, 97.9%)\n",
            "[2023-01-12 16:21:46] \u001b[32mTrain: [ 10/600] Step 440/520 Loss 1.137 Prec@(1,5) (71.7%, 97.9%)\u001b[0m\n",
            "INFO:nni:Train: [ 10/600] Step 440/520 Loss 1.137 Prec@(1,5) (71.7%, 97.9%)\n",
            "[2023-01-12 16:21:51] \u001b[32mTrain: [ 10/600] Step 450/520 Loss 1.135 Prec@(1,5) (71.8%, 97.9%)\u001b[0m\n",
            "INFO:nni:Train: [ 10/600] Step 450/520 Loss 1.135 Prec@(1,5) (71.8%, 97.9%)\n",
            "[2023-01-12 16:21:56] \u001b[32mTrain: [ 10/600] Step 460/520 Loss 1.134 Prec@(1,5) (71.8%, 97.9%)\u001b[0m\n",
            "INFO:nni:Train: [ 10/600] Step 460/520 Loss 1.134 Prec@(1,5) (71.8%, 97.9%)\n",
            "[2023-01-12 16:22:00] \u001b[32mTrain: [ 10/600] Step 470/520 Loss 1.134 Prec@(1,5) (71.7%, 97.9%)\u001b[0m\n",
            "INFO:nni:Train: [ 10/600] Step 470/520 Loss 1.134 Prec@(1,5) (71.7%, 97.9%)\n",
            "[2023-01-12 16:22:05] \u001b[32mTrain: [ 10/600] Step 480/520 Loss 1.134 Prec@(1,5) (71.7%, 97.9%)\u001b[0m\n",
            "INFO:nni:Train: [ 10/600] Step 480/520 Loss 1.134 Prec@(1,5) (71.7%, 97.9%)\n",
            "[2023-01-12 16:22:09] \u001b[32mTrain: [ 10/600] Step 490/520 Loss 1.132 Prec@(1,5) (71.8%, 97.9%)\u001b[0m\n",
            "INFO:nni:Train: [ 10/600] Step 490/520 Loss 1.132 Prec@(1,5) (71.8%, 97.9%)\n",
            "[2023-01-12 16:22:14] \u001b[32mTrain: [ 10/600] Step 500/520 Loss 1.131 Prec@(1,5) (71.8%, 97.9%)\u001b[0m\n",
            "INFO:nni:Train: [ 10/600] Step 500/520 Loss 1.131 Prec@(1,5) (71.8%, 97.9%)\n",
            "[2023-01-12 16:22:18] \u001b[32mTrain: [ 10/600] Step 510/520 Loss 1.129 Prec@(1,5) (71.8%, 97.9%)\u001b[0m\n",
            "INFO:nni:Train: [ 10/600] Step 510/520 Loss 1.129 Prec@(1,5) (71.8%, 97.9%)\n",
            "[2023-01-12 16:22:23] \u001b[32mTrain: [ 10/600] Step 520/520 Loss 1.129 Prec@(1,5) (71.9%, 97.9%)\u001b[0m\n",
            "INFO:nni:Train: [ 10/600] Step 520/520 Loss 1.129 Prec@(1,5) (71.9%, 97.9%)\n",
            "[2023-01-12 16:22:23] \u001b[32mTrain: [ 10/600] Final Prec@1 71.8540%\u001b[0m\n",
            "INFO:nni:Train: [ 10/600] Final Prec@1 71.8540%\n",
            "[2023-01-12 16:22:23] \u001b[32mValid: [ 10/600] Step 000/104 Loss 0.639 Prec@(1,5) (75.0%, 99.0%)\u001b[0m\n",
            "INFO:nni:Valid: [ 10/600] Step 000/104 Loss 0.639 Prec@(1,5) (75.0%, 99.0%)\n",
            "[2023-01-12 16:22:25] \u001b[32mValid: [ 10/600] Step 010/104 Loss 0.644 Prec@(1,5) (78.2%, 98.7%)\u001b[0m\n",
            "INFO:nni:Valid: [ 10/600] Step 010/104 Loss 0.644 Prec@(1,5) (78.2%, 98.7%)\n",
            "[2023-01-12 16:22:26] \u001b[32mValid: [ 10/600] Step 020/104 Loss 0.641 Prec@(1,5) (78.2%, 98.7%)\u001b[0m\n",
            "INFO:nni:Valid: [ 10/600] Step 020/104 Loss 0.641 Prec@(1,5) (78.2%, 98.7%)\n",
            "[2023-01-12 16:22:27] \u001b[32mValid: [ 10/600] Step 030/104 Loss 0.649 Prec@(1,5) (77.6%, 98.5%)\u001b[0m\n",
            "INFO:nni:Valid: [ 10/600] Step 030/104 Loss 0.649 Prec@(1,5) (77.6%, 98.5%)\n",
            "[2023-01-12 16:22:29] \u001b[32mValid: [ 10/600] Step 040/104 Loss 0.657 Prec@(1,5) (77.1%, 98.5%)\u001b[0m\n",
            "INFO:nni:Valid: [ 10/600] Step 040/104 Loss 0.657 Prec@(1,5) (77.1%, 98.5%)\n",
            "[2023-01-12 16:22:30] \u001b[32mValid: [ 10/600] Step 050/104 Loss 0.646 Prec@(1,5) (77.7%, 98.6%)\u001b[0m\n",
            "INFO:nni:Valid: [ 10/600] Step 050/104 Loss 0.646 Prec@(1,5) (77.7%, 98.6%)\n",
            "[2023-01-12 16:22:32] \u001b[32mValid: [ 10/600] Step 060/104 Loss 0.647 Prec@(1,5) (77.9%, 98.5%)\u001b[0m\n",
            "INFO:nni:Valid: [ 10/600] Step 060/104 Loss 0.647 Prec@(1,5) (77.9%, 98.5%)\n",
            "[2023-01-12 16:22:33] \u001b[32mValid: [ 10/600] Step 070/104 Loss 0.653 Prec@(1,5) (77.6%, 98.5%)\u001b[0m\n",
            "INFO:nni:Valid: [ 10/600] Step 070/104 Loss 0.653 Prec@(1,5) (77.6%, 98.5%)\n",
            "[2023-01-12 16:22:34] \u001b[32mValid: [ 10/600] Step 080/104 Loss 0.653 Prec@(1,5) (77.7%, 98.5%)\u001b[0m\n",
            "INFO:nni:Valid: [ 10/600] Step 080/104 Loss 0.653 Prec@(1,5) (77.7%, 98.5%)\n",
            "[2023-01-12 16:22:36] \u001b[32mValid: [ 10/600] Step 090/104 Loss 0.656 Prec@(1,5) (77.6%, 98.5%)\u001b[0m\n",
            "INFO:nni:Valid: [ 10/600] Step 090/104 Loss 0.656 Prec@(1,5) (77.6%, 98.5%)\n",
            "[2023-01-12 16:22:37] \u001b[32mValid: [ 10/600] Step 100/104 Loss 0.650 Prec@(1,5) (77.7%, 98.6%)\u001b[0m\n",
            "INFO:nni:Valid: [ 10/600] Step 100/104 Loss 0.650 Prec@(1,5) (77.7%, 98.6%)\n",
            "[2023-01-12 16:22:38] \u001b[32mValid: [ 10/600] Step 104/104 Loss 0.653 Prec@(1,5) (77.6%, 98.6%)\u001b[0m\n",
            "INFO:nni:Valid: [ 10/600] Step 104/104 Loss 0.653 Prec@(1,5) (77.6%, 98.6%)\n",
            "[2023-01-12 16:22:38] \u001b[32mValid: [ 10/600] Final Prec@1 77.6000%\u001b[0m\n",
            "INFO:nni:Valid: [ 10/600] Final Prec@1 77.6000%\n",
            "[2023-01-12 16:22:38] \u001b[32mEpoch 10 LR 0.024983\u001b[0m\n",
            "INFO:nni:Epoch 10 LR 0.024983\n",
            "[2023-01-12 16:22:39] \u001b[32mTrain: [ 11/600] Step 000/520 Loss 1.160 Prec@(1,5) (70.8%, 97.9%)\u001b[0m\n",
            "INFO:nni:Train: [ 11/600] Step 000/520 Loss 1.160 Prec@(1,5) (70.8%, 97.9%)\n",
            "[2023-01-12 16:22:43] \u001b[32mTrain: [ 11/600] Step 010/520 Loss 1.083 Prec@(1,5) (73.5%, 98.3%)\u001b[0m\n",
            "INFO:nni:Train: [ 11/600] Step 010/520 Loss 1.083 Prec@(1,5) (73.5%, 98.3%)\n",
            "[2023-01-12 16:22:48] \u001b[32mTrain: [ 11/600] Step 020/520 Loss 1.085 Prec@(1,5) (73.8%, 98.2%)\u001b[0m\n",
            "INFO:nni:Train: [ 11/600] Step 020/520 Loss 1.085 Prec@(1,5) (73.8%, 98.2%)\n",
            "[2023-01-12 16:22:52] \u001b[32mTrain: [ 11/600] Step 030/520 Loss 1.089 Prec@(1,5) (72.9%, 97.8%)\u001b[0m\n",
            "INFO:nni:Train: [ 11/600] Step 030/520 Loss 1.089 Prec@(1,5) (72.9%, 97.8%)\n",
            "[2023-01-12 16:22:57] \u001b[32mTrain: [ 11/600] Step 040/520 Loss 1.078 Prec@(1,5) (72.8%, 97.9%)\u001b[0m\n",
            "INFO:nni:Train: [ 11/600] Step 040/520 Loss 1.078 Prec@(1,5) (72.8%, 97.9%)\n",
            "[2023-01-12 16:23:01] \u001b[32mTrain: [ 11/600] Step 050/520 Loss 1.079 Prec@(1,5) (72.8%, 97.9%)\u001b[0m\n",
            "INFO:nni:Train: [ 11/600] Step 050/520 Loss 1.079 Prec@(1,5) (72.8%, 97.9%)\n",
            "[2023-01-12 16:23:06] \u001b[32mTrain: [ 11/600] Step 060/520 Loss 1.092 Prec@(1,5) (72.4%, 97.9%)\u001b[0m\n",
            "INFO:nni:Train: [ 11/600] Step 060/520 Loss 1.092 Prec@(1,5) (72.4%, 97.9%)\n",
            "[2023-01-12 16:23:10] \u001b[32mTrain: [ 11/600] Step 070/520 Loss 1.083 Prec@(1,5) (72.7%, 98.0%)\u001b[0m\n",
            "INFO:nni:Train: [ 11/600] Step 070/520 Loss 1.083 Prec@(1,5) (72.7%, 98.0%)\n",
            "[2023-01-12 16:23:15] \u001b[32mTrain: [ 11/600] Step 080/520 Loss 1.080 Prec@(1,5) (72.8%, 97.9%)\u001b[0m\n",
            "INFO:nni:Train: [ 11/600] Step 080/520 Loss 1.080 Prec@(1,5) (72.8%, 97.9%)\n",
            "[2023-01-12 16:23:19] \u001b[32mTrain: [ 11/600] Step 090/520 Loss 1.079 Prec@(1,5) (72.9%, 97.9%)\u001b[0m\n",
            "INFO:nni:Train: [ 11/600] Step 090/520 Loss 1.079 Prec@(1,5) (72.9%, 97.9%)\n",
            "[2023-01-12 16:23:24] \u001b[32mTrain: [ 11/600] Step 100/520 Loss 1.081 Prec@(1,5) (72.8%, 97.9%)\u001b[0m\n",
            "INFO:nni:Train: [ 11/600] Step 100/520 Loss 1.081 Prec@(1,5) (72.8%, 97.9%)\n",
            "[2023-01-12 16:23:28] \u001b[32mTrain: [ 11/600] Step 110/520 Loss 1.082 Prec@(1,5) (72.7%, 98.0%)\u001b[0m\n",
            "INFO:nni:Train: [ 11/600] Step 110/520 Loss 1.082 Prec@(1,5) (72.7%, 98.0%)\n",
            "[2023-01-12 16:23:33] \u001b[32mTrain: [ 11/600] Step 120/520 Loss 1.087 Prec@(1,5) (72.6%, 97.9%)\u001b[0m\n",
            "INFO:nni:Train: [ 11/600] Step 120/520 Loss 1.087 Prec@(1,5) (72.6%, 97.9%)\n",
            "[2023-01-12 16:23:37] \u001b[32mTrain: [ 11/600] Step 130/520 Loss 1.094 Prec@(1,5) (72.4%, 97.9%)\u001b[0m\n",
            "INFO:nni:Train: [ 11/600] Step 130/520 Loss 1.094 Prec@(1,5) (72.4%, 97.9%)\n",
            "[2023-01-12 16:23:42] \u001b[32mTrain: [ 11/600] Step 140/520 Loss 1.100 Prec@(1,5) (72.2%, 97.9%)\u001b[0m\n",
            "INFO:nni:Train: [ 11/600] Step 140/520 Loss 1.100 Prec@(1,5) (72.2%, 97.9%)\n",
            "[2023-01-12 16:23:47] \u001b[32mTrain: [ 11/600] Step 150/520 Loss 1.103 Prec@(1,5) (72.2%, 97.9%)\u001b[0m\n",
            "INFO:nni:Train: [ 11/600] Step 150/520 Loss 1.103 Prec@(1,5) (72.2%, 97.9%)\n",
            "[2023-01-12 16:23:51] \u001b[32mTrain: [ 11/600] Step 160/520 Loss 1.106 Prec@(1,5) (72.1%, 97.9%)\u001b[0m\n",
            "INFO:nni:Train: [ 11/600] Step 160/520 Loss 1.106 Prec@(1,5) (72.1%, 97.9%)\n",
            "[2023-01-12 16:23:56] \u001b[32mTrain: [ 11/600] Step 170/520 Loss 1.103 Prec@(1,5) (72.1%, 97.9%)\u001b[0m\n",
            "INFO:nni:Train: [ 11/600] Step 170/520 Loss 1.103 Prec@(1,5) (72.1%, 97.9%)\n",
            "[2023-01-12 16:24:00] \u001b[32mTrain: [ 11/600] Step 180/520 Loss 1.106 Prec@(1,5) (72.1%, 97.9%)\u001b[0m\n",
            "INFO:nni:Train: [ 11/600] Step 180/520 Loss 1.106 Prec@(1,5) (72.1%, 97.9%)\n",
            "[2023-01-12 16:24:05] \u001b[32mTrain: [ 11/600] Step 190/520 Loss 1.102 Prec@(1,5) (72.1%, 97.9%)\u001b[0m\n",
            "INFO:nni:Train: [ 11/600] Step 190/520 Loss 1.102 Prec@(1,5) (72.1%, 97.9%)\n",
            "[2023-01-12 16:24:09] \u001b[32mTrain: [ 11/600] Step 200/520 Loss 1.100 Prec@(1,5) (72.3%, 97.9%)\u001b[0m\n",
            "INFO:nni:Train: [ 11/600] Step 200/520 Loss 1.100 Prec@(1,5) (72.3%, 97.9%)\n",
            "[2023-01-12 16:24:14] \u001b[32mTrain: [ 11/600] Step 210/520 Loss 1.100 Prec@(1,5) (72.3%, 98.0%)\u001b[0m\n",
            "INFO:nni:Train: [ 11/600] Step 210/520 Loss 1.100 Prec@(1,5) (72.3%, 98.0%)\n",
            "[2023-01-12 16:24:18] \u001b[32mTrain: [ 11/600] Step 220/520 Loss 1.100 Prec@(1,5) (72.3%, 98.0%)\u001b[0m\n",
            "INFO:nni:Train: [ 11/600] Step 220/520 Loss 1.100 Prec@(1,5) (72.3%, 98.0%)\n",
            "[2023-01-12 16:24:23] \u001b[32mTrain: [ 11/600] Step 230/520 Loss 1.099 Prec@(1,5) (72.3%, 98.0%)\u001b[0m\n",
            "INFO:nni:Train: [ 11/600] Step 230/520 Loss 1.099 Prec@(1,5) (72.3%, 98.0%)\n",
            "[2023-01-12 16:24:27] \u001b[32mTrain: [ 11/600] Step 240/520 Loss 1.099 Prec@(1,5) (72.3%, 98.0%)\u001b[0m\n",
            "INFO:nni:Train: [ 11/600] Step 240/520 Loss 1.099 Prec@(1,5) (72.3%, 98.0%)\n",
            "[2023-01-12 16:24:32] \u001b[32mTrain: [ 11/600] Step 250/520 Loss 1.096 Prec@(1,5) (72.4%, 98.0%)\u001b[0m\n",
            "INFO:nni:Train: [ 11/600] Step 250/520 Loss 1.096 Prec@(1,5) (72.4%, 98.0%)\n",
            "[2023-01-12 16:24:36] \u001b[32mTrain: [ 11/600] Step 260/520 Loss 1.096 Prec@(1,5) (72.5%, 97.9%)\u001b[0m\n",
            "INFO:nni:Train: [ 11/600] Step 260/520 Loss 1.096 Prec@(1,5) (72.5%, 97.9%)\n",
            "[2023-01-12 16:24:41] \u001b[32mTrain: [ 11/600] Step 270/520 Loss 1.094 Prec@(1,5) (72.5%, 98.0%)\u001b[0m\n",
            "INFO:nni:Train: [ 11/600] Step 270/520 Loss 1.094 Prec@(1,5) (72.5%, 98.0%)\n",
            "[2023-01-12 16:24:45] \u001b[32mTrain: [ 11/600] Step 280/520 Loss 1.092 Prec@(1,5) (72.7%, 98.0%)\u001b[0m\n",
            "INFO:nni:Train: [ 11/600] Step 280/520 Loss 1.092 Prec@(1,5) (72.7%, 98.0%)\n",
            "[2023-01-12 16:24:50] \u001b[32mTrain: [ 11/600] Step 290/520 Loss 1.092 Prec@(1,5) (72.7%, 98.0%)\u001b[0m\n",
            "INFO:nni:Train: [ 11/600] Step 290/520 Loss 1.092 Prec@(1,5) (72.7%, 98.0%)\n",
            "[2023-01-12 16:24:54] \u001b[32mTrain: [ 11/600] Step 300/520 Loss 1.090 Prec@(1,5) (72.7%, 98.0%)\u001b[0m\n",
            "INFO:nni:Train: [ 11/600] Step 300/520 Loss 1.090 Prec@(1,5) (72.7%, 98.0%)\n",
            "[2023-01-12 16:24:59] \u001b[32mTrain: [ 11/600] Step 310/520 Loss 1.091 Prec@(1,5) (72.7%, 98.0%)\u001b[0m\n",
            "INFO:nni:Train: [ 11/600] Step 310/520 Loss 1.091 Prec@(1,5) (72.7%, 98.0%)\n",
            "[2023-01-12 16:25:03] \u001b[32mTrain: [ 11/600] Step 320/520 Loss 1.091 Prec@(1,5) (72.7%, 98.0%)\u001b[0m\n",
            "INFO:nni:Train: [ 11/600] Step 320/520 Loss 1.091 Prec@(1,5) (72.7%, 98.0%)\n",
            "[2023-01-12 16:25:08] \u001b[32mTrain: [ 11/600] Step 330/520 Loss 1.090 Prec@(1,5) (72.7%, 98.0%)\u001b[0m\n",
            "INFO:nni:Train: [ 11/600] Step 330/520 Loss 1.090 Prec@(1,5) (72.7%, 98.0%)\n",
            "[2023-01-12 16:25:12] \u001b[32mTrain: [ 11/600] Step 340/520 Loss 1.089 Prec@(1,5) (72.7%, 98.0%)\u001b[0m\n",
            "INFO:nni:Train: [ 11/600] Step 340/520 Loss 1.089 Prec@(1,5) (72.7%, 98.0%)\n",
            "[2023-01-12 16:25:17] \u001b[32mTrain: [ 11/600] Step 350/520 Loss 1.091 Prec@(1,5) (72.7%, 98.0%)\u001b[0m\n",
            "INFO:nni:Train: [ 11/600] Step 350/520 Loss 1.091 Prec@(1,5) (72.7%, 98.0%)\n",
            "[2023-01-12 16:25:21] \u001b[32mTrain: [ 11/600] Step 360/520 Loss 1.092 Prec@(1,5) (72.7%, 98.0%)\u001b[0m\n",
            "INFO:nni:Train: [ 11/600] Step 360/520 Loss 1.092 Prec@(1,5) (72.7%, 98.0%)\n",
            "[2023-01-12 16:25:26] \u001b[32mTrain: [ 11/600] Step 370/520 Loss 1.093 Prec@(1,5) (72.6%, 98.0%)\u001b[0m\n",
            "INFO:nni:Train: [ 11/600] Step 370/520 Loss 1.093 Prec@(1,5) (72.6%, 98.0%)\n",
            "[2023-01-12 16:25:30] \u001b[32mTrain: [ 11/600] Step 380/520 Loss 1.094 Prec@(1,5) (72.6%, 98.0%)\u001b[0m\n",
            "INFO:nni:Train: [ 11/600] Step 380/520 Loss 1.094 Prec@(1,5) (72.6%, 98.0%)\n",
            "[2023-01-12 16:25:35] \u001b[32mTrain: [ 11/600] Step 390/520 Loss 1.094 Prec@(1,5) (72.6%, 98.0%)\u001b[0m\n",
            "INFO:nni:Train: [ 11/600] Step 390/520 Loss 1.094 Prec@(1,5) (72.6%, 98.0%)\n",
            "[2023-01-12 16:25:40] \u001b[32mTrain: [ 11/600] Step 400/520 Loss 1.095 Prec@(1,5) (72.6%, 98.0%)\u001b[0m\n",
            "INFO:nni:Train: [ 11/600] Step 400/520 Loss 1.095 Prec@(1,5) (72.6%, 98.0%)\n",
            "[2023-01-12 16:25:44] \u001b[32mTrain: [ 11/600] Step 410/520 Loss 1.093 Prec@(1,5) (72.6%, 98.0%)\u001b[0m\n",
            "INFO:nni:Train: [ 11/600] Step 410/520 Loss 1.093 Prec@(1,5) (72.6%, 98.0%)\n",
            "[2023-01-12 16:25:49] \u001b[32mTrain: [ 11/600] Step 420/520 Loss 1.096 Prec@(1,5) (72.6%, 98.0%)\u001b[0m\n",
            "INFO:nni:Train: [ 11/600] Step 420/520 Loss 1.096 Prec@(1,5) (72.6%, 98.0%)\n",
            "[2023-01-12 16:25:53] \u001b[32mTrain: [ 11/600] Step 430/520 Loss 1.095 Prec@(1,5) (72.6%, 98.0%)\u001b[0m\n",
            "INFO:nni:Train: [ 11/600] Step 430/520 Loss 1.095 Prec@(1,5) (72.6%, 98.0%)\n",
            "[2023-01-12 16:25:58] \u001b[32mTrain: [ 11/600] Step 440/520 Loss 1.097 Prec@(1,5) (72.5%, 98.0%)\u001b[0m\n",
            "INFO:nni:Train: [ 11/600] Step 440/520 Loss 1.097 Prec@(1,5) (72.5%, 98.0%)\n",
            "[2023-01-12 16:26:02] \u001b[32mTrain: [ 11/600] Step 450/520 Loss 1.099 Prec@(1,5) (72.5%, 98.0%)\u001b[0m\n",
            "INFO:nni:Train: [ 11/600] Step 450/520 Loss 1.099 Prec@(1,5) (72.5%, 98.0%)\n",
            "[2023-01-12 16:26:07] \u001b[32mTrain: [ 11/600] Step 460/520 Loss 1.096 Prec@(1,5) (72.6%, 98.0%)\u001b[0m\n",
            "INFO:nni:Train: [ 11/600] Step 460/520 Loss 1.096 Prec@(1,5) (72.6%, 98.0%)\n",
            "[2023-01-12 16:26:11] \u001b[32mTrain: [ 11/600] Step 470/520 Loss 1.097 Prec@(1,5) (72.6%, 98.0%)\u001b[0m\n",
            "INFO:nni:Train: [ 11/600] Step 470/520 Loss 1.097 Prec@(1,5) (72.6%, 98.0%)\n",
            "[2023-01-12 16:26:16] \u001b[32mTrain: [ 11/600] Step 480/520 Loss 1.100 Prec@(1,5) (72.5%, 98.0%)\u001b[0m\n",
            "INFO:nni:Train: [ 11/600] Step 480/520 Loss 1.100 Prec@(1,5) (72.5%, 98.0%)\n",
            "[2023-01-12 16:26:20] \u001b[32mTrain: [ 11/600] Step 490/520 Loss 1.099 Prec@(1,5) (72.5%, 98.0%)\u001b[0m\n",
            "INFO:nni:Train: [ 11/600] Step 490/520 Loss 1.099 Prec@(1,5) (72.5%, 98.0%)\n",
            "[2023-01-12 16:26:25] \u001b[32mTrain: [ 11/600] Step 500/520 Loss 1.098 Prec@(1,5) (72.5%, 98.0%)\u001b[0m\n",
            "INFO:nni:Train: [ 11/600] Step 500/520 Loss 1.098 Prec@(1,5) (72.5%, 98.0%)\n",
            "[2023-01-12 16:26:29] \u001b[32mTrain: [ 11/600] Step 510/520 Loss 1.098 Prec@(1,5) (72.5%, 98.0%)\u001b[0m\n",
            "INFO:nni:Train: [ 11/600] Step 510/520 Loss 1.098 Prec@(1,5) (72.5%, 98.0%)\n",
            "[2023-01-12 16:26:34] \u001b[32mTrain: [ 11/600] Step 520/520 Loss 1.097 Prec@(1,5) (72.6%, 98.0%)\u001b[0m\n",
            "INFO:nni:Train: [ 11/600] Step 520/520 Loss 1.097 Prec@(1,5) (72.6%, 98.0%)\n",
            "[2023-01-12 16:26:34] \u001b[32mTrain: [ 11/600] Final Prec@1 72.5820%\u001b[0m\n",
            "INFO:nni:Train: [ 11/600] Final Prec@1 72.5820%\n",
            "[2023-01-12 16:26:34] \u001b[32mValid: [ 11/600] Step 000/104 Loss 0.739 Prec@(1,5) (77.1%, 95.8%)\u001b[0m\n",
            "INFO:nni:Valid: [ 11/600] Step 000/104 Loss 0.739 Prec@(1,5) (77.1%, 95.8%)\n",
            "[2023-01-12 16:26:36] \u001b[32mValid: [ 11/600] Step 010/104 Loss 0.766 Prec@(1,5) (72.9%, 97.9%)\u001b[0m\n",
            "INFO:nni:Valid: [ 11/600] Step 010/104 Loss 0.766 Prec@(1,5) (72.9%, 97.9%)\n",
            "[2023-01-12 16:26:37] \u001b[32mValid: [ 11/600] Step 020/104 Loss 0.767 Prec@(1,5) (73.7%, 98.0%)\u001b[0m\n",
            "INFO:nni:Valid: [ 11/600] Step 020/104 Loss 0.767 Prec@(1,5) (73.7%, 98.0%)\n",
            "[2023-01-12 16:26:39] \u001b[32mValid: [ 11/600] Step 030/104 Loss 0.774 Prec@(1,5) (73.9%, 98.1%)\u001b[0m\n",
            "INFO:nni:Valid: [ 11/600] Step 030/104 Loss 0.774 Prec@(1,5) (73.9%, 98.1%)\n",
            "[2023-01-12 16:26:40] \u001b[32mValid: [ 11/600] Step 040/104 Loss 0.772 Prec@(1,5) (73.6%, 98.1%)\u001b[0m\n",
            "INFO:nni:Valid: [ 11/600] Step 040/104 Loss 0.772 Prec@(1,5) (73.6%, 98.1%)\n",
            "[2023-01-12 16:26:41] \u001b[32mValid: [ 11/600] Step 050/104 Loss 0.754 Prec@(1,5) (74.5%, 98.1%)\u001b[0m\n",
            "INFO:nni:Valid: [ 11/600] Step 050/104 Loss 0.754 Prec@(1,5) (74.5%, 98.1%)\n",
            "[2023-01-12 16:26:43] \u001b[32mValid: [ 11/600] Step 060/104 Loss 0.761 Prec@(1,5) (74.4%, 98.1%)\u001b[0m\n",
            "INFO:nni:Valid: [ 11/600] Step 060/104 Loss 0.761 Prec@(1,5) (74.4%, 98.1%)\n",
            "[2023-01-12 16:26:44] \u001b[32mValid: [ 11/600] Step 070/104 Loss 0.758 Prec@(1,5) (74.4%, 98.1%)\u001b[0m\n",
            "INFO:nni:Valid: [ 11/600] Step 070/104 Loss 0.758 Prec@(1,5) (74.4%, 98.1%)\n",
            "[2023-01-12 16:26:46] \u001b[32mValid: [ 11/600] Step 080/104 Loss 0.756 Prec@(1,5) (74.5%, 98.1%)\u001b[0m\n",
            "INFO:nni:Valid: [ 11/600] Step 080/104 Loss 0.756 Prec@(1,5) (74.5%, 98.1%)\n",
            "[2023-01-12 16:26:47] \u001b[32mValid: [ 11/600] Step 090/104 Loss 0.762 Prec@(1,5) (74.4%, 98.2%)\u001b[0m\n",
            "INFO:nni:Valid: [ 11/600] Step 090/104 Loss 0.762 Prec@(1,5) (74.4%, 98.2%)\n",
            "[2023-01-12 16:26:48] \u001b[32mValid: [ 11/600] Step 100/104 Loss 0.756 Prec@(1,5) (74.6%, 98.3%)\u001b[0m\n",
            "INFO:nni:Valid: [ 11/600] Step 100/104 Loss 0.756 Prec@(1,5) (74.6%, 98.3%)\n",
            "[2023-01-12 16:26:49] \u001b[32mValid: [ 11/600] Step 104/104 Loss 0.759 Prec@(1,5) (74.4%, 98.3%)\u001b[0m\n",
            "INFO:nni:Valid: [ 11/600] Step 104/104 Loss 0.759 Prec@(1,5) (74.4%, 98.3%)\n",
            "[2023-01-12 16:26:49] \u001b[32mValid: [ 11/600] Final Prec@1 74.3600%\u001b[0m\n",
            "INFO:nni:Valid: [ 11/600] Final Prec@1 74.3600%\n",
            "[2023-01-12 16:26:49] \u001b[32mEpoch 11 LR 0.024979\u001b[0m\n",
            "INFO:nni:Epoch 11 LR 0.024979\n",
            "[2023-01-12 16:26:50] \u001b[32mTrain: [ 12/600] Step 000/520 Loss 1.030 Prec@(1,5) (70.8%, 97.9%)\u001b[0m\n",
            "INFO:nni:Train: [ 12/600] Step 000/520 Loss 1.030 Prec@(1,5) (70.8%, 97.9%)\n",
            "[2023-01-12 16:26:54] \u001b[32mTrain: [ 12/600] Step 010/520 Loss 1.059 Prec@(1,5) (73.4%, 98.6%)\u001b[0m\n",
            "INFO:nni:Train: [ 12/600] Step 010/520 Loss 1.059 Prec@(1,5) (73.4%, 98.6%)\n",
            "[2023-01-12 16:26:59] \u001b[32mTrain: [ 12/600] Step 020/520 Loss 1.057 Prec@(1,5) (73.0%, 98.4%)\u001b[0m\n",
            "INFO:nni:Train: [ 12/600] Step 020/520 Loss 1.057 Prec@(1,5) (73.0%, 98.4%)\n",
            "[2023-01-12 16:27:03] \u001b[32mTrain: [ 12/600] Step 030/520 Loss 1.058 Prec@(1,5) (72.8%, 98.3%)\u001b[0m\n",
            "INFO:nni:Train: [ 12/600] Step 030/520 Loss 1.058 Prec@(1,5) (72.8%, 98.3%)\n",
            "[2023-01-12 16:27:08] \u001b[32mTrain: [ 12/600] Step 040/520 Loss 1.064 Prec@(1,5) (73.2%, 98.2%)\u001b[0m\n",
            "INFO:nni:Train: [ 12/600] Step 040/520 Loss 1.064 Prec@(1,5) (73.2%, 98.2%)\n",
            "[2023-01-12 16:27:12] \u001b[32mTrain: [ 12/600] Step 050/520 Loss 1.059 Prec@(1,5) (73.3%, 98.2%)\u001b[0m\n",
            "INFO:nni:Train: [ 12/600] Step 050/520 Loss 1.059 Prec@(1,5) (73.3%, 98.2%)\n",
            "[2023-01-12 16:27:17] \u001b[32mTrain: [ 12/600] Step 060/520 Loss 1.055 Prec@(1,5) (73.4%, 98.3%)\u001b[0m\n",
            "INFO:nni:Train: [ 12/600] Step 060/520 Loss 1.055 Prec@(1,5) (73.4%, 98.3%)\n",
            "[2023-01-12 16:27:21] \u001b[32mTrain: [ 12/600] Step 070/520 Loss 1.057 Prec@(1,5) (73.5%, 98.2%)\u001b[0m\n",
            "INFO:nni:Train: [ 12/600] Step 070/520 Loss 1.057 Prec@(1,5) (73.5%, 98.2%)\n",
            "[2023-01-12 16:27:26] \u001b[32mTrain: [ 12/600] Step 080/520 Loss 1.049 Prec@(1,5) (74.0%, 98.1%)\u001b[0m\n",
            "INFO:nni:Train: [ 12/600] Step 080/520 Loss 1.049 Prec@(1,5) (74.0%, 98.1%)\n",
            "[2023-01-12 16:27:31] \u001b[32mTrain: [ 12/600] Step 090/520 Loss 1.044 Prec@(1,5) (74.3%, 98.2%)\u001b[0m\n",
            "INFO:nni:Train: [ 12/600] Step 090/520 Loss 1.044 Prec@(1,5) (74.3%, 98.2%)\n",
            "[2023-01-12 16:27:35] \u001b[32mTrain: [ 12/600] Step 100/520 Loss 1.043 Prec@(1,5) (74.3%, 98.2%)\u001b[0m\n",
            "INFO:nni:Train: [ 12/600] Step 100/520 Loss 1.043 Prec@(1,5) (74.3%, 98.2%)\n",
            "[2023-01-12 16:27:40] \u001b[32mTrain: [ 12/600] Step 110/520 Loss 1.051 Prec@(1,5) (74.1%, 98.2%)\u001b[0m\n",
            "INFO:nni:Train: [ 12/600] Step 110/520 Loss 1.051 Prec@(1,5) (74.1%, 98.2%)\n",
            "[2023-01-12 16:27:44] \u001b[32mTrain: [ 12/600] Step 120/520 Loss 1.062 Prec@(1,5) (73.7%, 98.2%)\u001b[0m\n",
            "INFO:nni:Train: [ 12/600] Step 120/520 Loss 1.062 Prec@(1,5) (73.7%, 98.2%)\n",
            "[2023-01-12 16:27:49] \u001b[32mTrain: [ 12/600] Step 130/520 Loss 1.066 Prec@(1,5) (73.7%, 98.2%)\u001b[0m\n",
            "INFO:nni:Train: [ 12/600] Step 130/520 Loss 1.066 Prec@(1,5) (73.7%, 98.2%)\n",
            "[2023-01-12 16:27:53] \u001b[32mTrain: [ 12/600] Step 140/520 Loss 1.074 Prec@(1,5) (73.5%, 98.2%)\u001b[0m\n",
            "INFO:nni:Train: [ 12/600] Step 140/520 Loss 1.074 Prec@(1,5) (73.5%, 98.2%)\n",
            "[2023-01-12 16:27:58] \u001b[32mTrain: [ 12/600] Step 150/520 Loss 1.071 Prec@(1,5) (73.5%, 98.1%)\u001b[0m\n",
            "INFO:nni:Train: [ 12/600] Step 150/520 Loss 1.071 Prec@(1,5) (73.5%, 98.1%)\n",
            "[2023-01-12 16:28:02] \u001b[32mTrain: [ 12/600] Step 160/520 Loss 1.068 Prec@(1,5) (73.6%, 98.2%)\u001b[0m\n",
            "INFO:nni:Train: [ 12/600] Step 160/520 Loss 1.068 Prec@(1,5) (73.6%, 98.2%)\n",
            "[2023-01-12 16:28:07] \u001b[32mTrain: [ 12/600] Step 170/520 Loss 1.064 Prec@(1,5) (73.8%, 98.2%)\u001b[0m\n",
            "INFO:nni:Train: [ 12/600] Step 170/520 Loss 1.064 Prec@(1,5) (73.8%, 98.2%)\n",
            "[2023-01-12 16:28:11] \u001b[32mTrain: [ 12/600] Step 180/520 Loss 1.059 Prec@(1,5) (73.9%, 98.2%)\u001b[0m\n",
            "INFO:nni:Train: [ 12/600] Step 180/520 Loss 1.059 Prec@(1,5) (73.9%, 98.2%)\n",
            "[2023-01-12 16:28:16] \u001b[32mTrain: [ 12/600] Step 190/520 Loss 1.058 Prec@(1,5) (73.9%, 98.2%)\u001b[0m\n",
            "INFO:nni:Train: [ 12/600] Step 190/520 Loss 1.058 Prec@(1,5) (73.9%, 98.2%)\n",
            "[2023-01-12 16:28:20] \u001b[32mTrain: [ 12/600] Step 200/520 Loss 1.056 Prec@(1,5) (74.1%, 98.2%)\u001b[0m\n",
            "INFO:nni:Train: [ 12/600] Step 200/520 Loss 1.056 Prec@(1,5) (74.1%, 98.2%)\n",
            "[2023-01-12 16:28:25] \u001b[32mTrain: [ 12/600] Step 210/520 Loss 1.055 Prec@(1,5) (74.2%, 98.2%)\u001b[0m\n",
            "INFO:nni:Train: [ 12/600] Step 210/520 Loss 1.055 Prec@(1,5) (74.2%, 98.2%)\n",
            "[2023-01-12 16:28:29] \u001b[32mTrain: [ 12/600] Step 220/520 Loss 1.059 Prec@(1,5) (74.1%, 98.2%)\u001b[0m\n",
            "INFO:nni:Train: [ 12/600] Step 220/520 Loss 1.059 Prec@(1,5) (74.1%, 98.2%)\n",
            "[2023-01-12 16:28:34] \u001b[32mTrain: [ 12/600] Step 230/520 Loss 1.059 Prec@(1,5) (74.1%, 98.2%)\u001b[0m\n",
            "INFO:nni:Train: [ 12/600] Step 230/520 Loss 1.059 Prec@(1,5) (74.1%, 98.2%)\n",
            "[2023-01-12 16:28:38] \u001b[32mTrain: [ 12/600] Step 240/520 Loss 1.060 Prec@(1,5) (74.0%, 98.2%)\u001b[0m\n",
            "INFO:nni:Train: [ 12/600] Step 240/520 Loss 1.060 Prec@(1,5) (74.0%, 98.2%)\n",
            "[2023-01-12 16:28:43] \u001b[32mTrain: [ 12/600] Step 250/520 Loss 1.063 Prec@(1,5) (73.9%, 98.2%)\u001b[0m\n",
            "INFO:nni:Train: [ 12/600] Step 250/520 Loss 1.063 Prec@(1,5) (73.9%, 98.2%)\n",
            "[2023-01-12 16:28:47] \u001b[32mTrain: [ 12/600] Step 260/520 Loss 1.069 Prec@(1,5) (73.8%, 98.2%)\u001b[0m\n",
            "INFO:nni:Train: [ 12/600] Step 260/520 Loss 1.069 Prec@(1,5) (73.8%, 98.2%)\n",
            "[2023-01-12 16:28:52] \u001b[32mTrain: [ 12/600] Step 270/520 Loss 1.068 Prec@(1,5) (73.8%, 98.2%)\u001b[0m\n",
            "INFO:nni:Train: [ 12/600] Step 270/520 Loss 1.068 Prec@(1,5) (73.8%, 98.2%)\n",
            "[2023-01-12 16:28:56] \u001b[32mTrain: [ 12/600] Step 280/520 Loss 1.071 Prec@(1,5) (73.7%, 98.1%)\u001b[0m\n",
            "INFO:nni:Train: [ 12/600] Step 280/520 Loss 1.071 Prec@(1,5) (73.7%, 98.1%)\n",
            "[2023-01-12 16:29:01] \u001b[32mTrain: [ 12/600] Step 290/520 Loss 1.068 Prec@(1,5) (73.8%, 98.2%)\u001b[0m\n",
            "INFO:nni:Train: [ 12/600] Step 290/520 Loss 1.068 Prec@(1,5) (73.8%, 98.2%)\n",
            "[2023-01-12 16:29:05] \u001b[32mTrain: [ 12/600] Step 300/520 Loss 1.066 Prec@(1,5) (73.9%, 98.2%)\u001b[0m\n",
            "INFO:nni:Train: [ 12/600] Step 300/520 Loss 1.066 Prec@(1,5) (73.9%, 98.2%)\n",
            "[2023-01-12 16:29:10] \u001b[32mTrain: [ 12/600] Step 310/520 Loss 1.065 Prec@(1,5) (73.9%, 98.1%)\u001b[0m\n",
            "INFO:nni:Train: [ 12/600] Step 310/520 Loss 1.065 Prec@(1,5) (73.9%, 98.1%)\n",
            "[2023-01-12 16:29:14] \u001b[32mTrain: [ 12/600] Step 320/520 Loss 1.067 Prec@(1,5) (73.8%, 98.1%)\u001b[0m\n",
            "INFO:nni:Train: [ 12/600] Step 320/520 Loss 1.067 Prec@(1,5) (73.8%, 98.1%)\n",
            "[2023-01-12 16:29:19] \u001b[32mTrain: [ 12/600] Step 330/520 Loss 1.067 Prec@(1,5) (73.8%, 98.1%)\u001b[0m\n",
            "INFO:nni:Train: [ 12/600] Step 330/520 Loss 1.067 Prec@(1,5) (73.8%, 98.1%)\n",
            "[2023-01-12 16:29:24] \u001b[32mTrain: [ 12/600] Step 340/520 Loss 1.065 Prec@(1,5) (73.9%, 98.2%)\u001b[0m\n",
            "INFO:nni:Train: [ 12/600] Step 340/520 Loss 1.065 Prec@(1,5) (73.9%, 98.2%)\n",
            "[2023-01-12 16:29:28] \u001b[32mTrain: [ 12/600] Step 350/520 Loss 1.062 Prec@(1,5) (73.9%, 98.2%)\u001b[0m\n",
            "INFO:nni:Train: [ 12/600] Step 350/520 Loss 1.062 Prec@(1,5) (73.9%, 98.2%)\n",
            "[2023-01-12 16:29:33] \u001b[32mTrain: [ 12/600] Step 360/520 Loss 1.063 Prec@(1,5) (73.8%, 98.2%)\u001b[0m\n",
            "INFO:nni:Train: [ 12/600] Step 360/520 Loss 1.063 Prec@(1,5) (73.8%, 98.2%)\n",
            "[2023-01-12 16:29:37] \u001b[32mTrain: [ 12/600] Step 370/520 Loss 1.063 Prec@(1,5) (73.8%, 98.2%)\u001b[0m\n",
            "INFO:nni:Train: [ 12/600] Step 370/520 Loss 1.063 Prec@(1,5) (73.8%, 98.2%)\n",
            "[2023-01-12 16:29:42] \u001b[32mTrain: [ 12/600] Step 380/520 Loss 1.063 Prec@(1,5) (73.8%, 98.2%)\u001b[0m\n",
            "INFO:nni:Train: [ 12/600] Step 380/520 Loss 1.063 Prec@(1,5) (73.8%, 98.2%)\n",
            "[2023-01-12 16:29:46] \u001b[32mTrain: [ 12/600] Step 390/520 Loss 1.065 Prec@(1,5) (73.8%, 98.2%)\u001b[0m\n",
            "INFO:nni:Train: [ 12/600] Step 390/520 Loss 1.065 Prec@(1,5) (73.8%, 98.2%)\n",
            "[2023-01-12 16:29:51] \u001b[32mTrain: [ 12/600] Step 400/520 Loss 1.063 Prec@(1,5) (73.8%, 98.2%)\u001b[0m\n",
            "INFO:nni:Train: [ 12/600] Step 400/520 Loss 1.063 Prec@(1,5) (73.8%, 98.2%)\n",
            "[2023-01-12 16:29:55] \u001b[32mTrain: [ 12/600] Step 410/520 Loss 1.062 Prec@(1,5) (73.8%, 98.2%)\u001b[0m\n",
            "INFO:nni:Train: [ 12/600] Step 410/520 Loss 1.062 Prec@(1,5) (73.8%, 98.2%)\n",
            "[2023-01-12 16:30:00] \u001b[32mTrain: [ 12/600] Step 420/520 Loss 1.060 Prec@(1,5) (73.9%, 98.2%)\u001b[0m\n",
            "INFO:nni:Train: [ 12/600] Step 420/520 Loss 1.060 Prec@(1,5) (73.9%, 98.2%)\n",
            "[2023-01-12 16:30:04] \u001b[32mTrain: [ 12/600] Step 430/520 Loss 1.060 Prec@(1,5) (73.9%, 98.2%)\u001b[0m\n",
            "INFO:nni:Train: [ 12/600] Step 430/520 Loss 1.060 Prec@(1,5) (73.9%, 98.2%)\n",
            "[2023-01-12 16:30:09] \u001b[32mTrain: [ 12/600] Step 440/520 Loss 1.060 Prec@(1,5) (73.9%, 98.2%)\u001b[0m\n",
            "INFO:nni:Train: [ 12/600] Step 440/520 Loss 1.060 Prec@(1,5) (73.9%, 98.2%)\n",
            "[2023-01-12 16:30:13] \u001b[32mTrain: [ 12/600] Step 450/520 Loss 1.060 Prec@(1,5) (73.9%, 98.2%)\u001b[0m\n",
            "INFO:nni:Train: [ 12/600] Step 450/520 Loss 1.060 Prec@(1,5) (73.9%, 98.2%)\n",
            "[2023-01-12 16:30:18] \u001b[32mTrain: [ 12/600] Step 460/520 Loss 1.062 Prec@(1,5) (73.8%, 98.2%)\u001b[0m\n",
            "INFO:nni:Train: [ 12/600] Step 460/520 Loss 1.062 Prec@(1,5) (73.8%, 98.2%)\n",
            "[2023-01-12 16:30:22] \u001b[32mTrain: [ 12/600] Step 470/520 Loss 1.061 Prec@(1,5) (73.8%, 98.2%)\u001b[0m\n",
            "INFO:nni:Train: [ 12/600] Step 470/520 Loss 1.061 Prec@(1,5) (73.8%, 98.2%)\n",
            "[2023-01-12 16:30:27] \u001b[32mTrain: [ 12/600] Step 480/520 Loss 1.060 Prec@(1,5) (73.8%, 98.2%)\u001b[0m\n",
            "INFO:nni:Train: [ 12/600] Step 480/520 Loss 1.060 Prec@(1,5) (73.8%, 98.2%)\n",
            "[2023-01-12 16:30:31] \u001b[32mTrain: [ 12/600] Step 490/520 Loss 1.060 Prec@(1,5) (73.8%, 98.2%)\u001b[0m\n",
            "INFO:nni:Train: [ 12/600] Step 490/520 Loss 1.060 Prec@(1,5) (73.8%, 98.2%)\n",
            "[2023-01-12 16:30:36] \u001b[32mTrain: [ 12/600] Step 500/520 Loss 1.059 Prec@(1,5) (73.8%, 98.2%)\u001b[0m\n",
            "INFO:nni:Train: [ 12/600] Step 500/520 Loss 1.059 Prec@(1,5) (73.8%, 98.2%)\n",
            "[2023-01-12 16:30:40] \u001b[32mTrain: [ 12/600] Step 510/520 Loss 1.061 Prec@(1,5) (73.8%, 98.2%)\u001b[0m\n",
            "INFO:nni:Train: [ 12/600] Step 510/520 Loss 1.061 Prec@(1,5) (73.8%, 98.2%)\n",
            "[2023-01-12 16:30:45] \u001b[32mTrain: [ 12/600] Step 520/520 Loss 1.060 Prec@(1,5) (73.8%, 98.2%)\u001b[0m\n",
            "INFO:nni:Train: [ 12/600] Step 520/520 Loss 1.060 Prec@(1,5) (73.8%, 98.2%)\n",
            "[2023-01-12 16:30:45] \u001b[32mTrain: [ 12/600] Final Prec@1 73.8100%\u001b[0m\n",
            "INFO:nni:Train: [ 12/600] Final Prec@1 73.8100%\n",
            "[2023-01-12 16:30:45] \u001b[32mValid: [ 12/600] Step 000/104 Loss 0.578 Prec@(1,5) (77.1%, 100.0%)\u001b[0m\n",
            "INFO:nni:Valid: [ 12/600] Step 000/104 Loss 0.578 Prec@(1,5) (77.1%, 100.0%)\n",
            "[2023-01-12 16:30:47] \u001b[32mValid: [ 12/600] Step 010/104 Loss 0.601 Prec@(1,5) (78.0%, 99.3%)\u001b[0m\n",
            "INFO:nni:Valid: [ 12/600] Step 010/104 Loss 0.601 Prec@(1,5) (78.0%, 99.3%)\n",
            "[2023-01-12 16:30:48] \u001b[32mValid: [ 12/600] Step 020/104 Loss 0.604 Prec@(1,5) (78.2%, 99.0%)\u001b[0m\n",
            "INFO:nni:Valid: [ 12/600] Step 020/104 Loss 0.604 Prec@(1,5) (78.2%, 99.0%)\n",
            "[2023-01-12 16:30:50] \u001b[32mValid: [ 12/600] Step 030/104 Loss 0.618 Prec@(1,5) (78.1%, 98.9%)\u001b[0m\n",
            "INFO:nni:Valid: [ 12/600] Step 030/104 Loss 0.618 Prec@(1,5) (78.1%, 98.9%)\n",
            "[2023-01-12 16:30:51] \u001b[32mValid: [ 12/600] Step 040/104 Loss 0.626 Prec@(1,5) (77.8%, 98.8%)\u001b[0m\n",
            "INFO:nni:Valid: [ 12/600] Step 040/104 Loss 0.626 Prec@(1,5) (77.8%, 98.8%)\n",
            "[2023-01-12 16:30:52] \u001b[32mValid: [ 12/600] Step 050/104 Loss 0.616 Prec@(1,5) (78.0%, 98.8%)\u001b[0m\n",
            "INFO:nni:Valid: [ 12/600] Step 050/104 Loss 0.616 Prec@(1,5) (78.0%, 98.8%)\n",
            "[2023-01-12 16:30:54] \u001b[32mValid: [ 12/600] Step 060/104 Loss 0.631 Prec@(1,5) (78.0%, 98.8%)\u001b[0m\n",
            "INFO:nni:Valid: [ 12/600] Step 060/104 Loss 0.631 Prec@(1,5) (78.0%, 98.8%)\n",
            "[2023-01-12 16:30:55] \u001b[32mValid: [ 12/600] Step 070/104 Loss 0.641 Prec@(1,5) (77.7%, 98.7%)\u001b[0m\n",
            "INFO:nni:Valid: [ 12/600] Step 070/104 Loss 0.641 Prec@(1,5) (77.7%, 98.7%)\n",
            "[2023-01-12 16:30:57] \u001b[32mValid: [ 12/600] Step 080/104 Loss 0.641 Prec@(1,5) (77.7%, 98.7%)\u001b[0m\n",
            "INFO:nni:Valid: [ 12/600] Step 080/104 Loss 0.641 Prec@(1,5) (77.7%, 98.7%)\n",
            "[2023-01-12 16:30:58] \u001b[32mValid: [ 12/600] Step 090/104 Loss 0.644 Prec@(1,5) (77.6%, 98.7%)\u001b[0m\n",
            "INFO:nni:Valid: [ 12/600] Step 090/104 Loss 0.644 Prec@(1,5) (77.6%, 98.7%)\n",
            "[2023-01-12 16:30:59] \u001b[32mValid: [ 12/600] Step 100/104 Loss 0.637 Prec@(1,5) (77.8%, 98.7%)\u001b[0m\n",
            "INFO:nni:Valid: [ 12/600] Step 100/104 Loss 0.637 Prec@(1,5) (77.8%, 98.7%)\n",
            "[2023-01-12 16:31:00] \u001b[32mValid: [ 12/600] Step 104/104 Loss 0.643 Prec@(1,5) (77.7%, 98.7%)\u001b[0m\n",
            "INFO:nni:Valid: [ 12/600] Step 104/104 Loss 0.643 Prec@(1,5) (77.7%, 98.7%)\n",
            "[2023-01-12 16:31:00] \u001b[32mValid: [ 12/600] Final Prec@1 77.7000%\u001b[0m\n",
            "INFO:nni:Valid: [ 12/600] Final Prec@1 77.7000%\n",
            "[2023-01-12 16:31:00] \u001b[32mEpoch 12 LR 0.024975\u001b[0m\n",
            "INFO:nni:Epoch 12 LR 0.024975\n",
            "[2023-01-12 16:31:01] \u001b[32mTrain: [ 13/600] Step 000/520 Loss 0.984 Prec@(1,5) (72.9%, 99.0%)\u001b[0m\n",
            "INFO:nni:Train: [ 13/600] Step 000/520 Loss 0.984 Prec@(1,5) (72.9%, 99.0%)\n",
            "[2023-01-12 16:31:05] \u001b[32mTrain: [ 13/600] Step 010/520 Loss 0.968 Prec@(1,5) (75.2%, 98.9%)\u001b[0m\n",
            "INFO:nni:Train: [ 13/600] Step 010/520 Loss 0.968 Prec@(1,5) (75.2%, 98.9%)\n",
            "[2023-01-12 16:31:10] \u001b[32mTrain: [ 13/600] Step 020/520 Loss 0.968 Prec@(1,5) (75.8%, 98.8%)\u001b[0m\n",
            "INFO:nni:Train: [ 13/600] Step 020/520 Loss 0.968 Prec@(1,5) (75.8%, 98.8%)\n",
            "[2023-01-12 16:31:14] \u001b[32mTrain: [ 13/600] Step 030/520 Loss 0.971 Prec@(1,5) (75.7%, 98.5%)\u001b[0m\n",
            "INFO:nni:Train: [ 13/600] Step 030/520 Loss 0.971 Prec@(1,5) (75.7%, 98.5%)\n",
            "[2023-01-12 16:31:19] \u001b[32mTrain: [ 13/600] Step 040/520 Loss 0.999 Prec@(1,5) (74.9%, 98.5%)\u001b[0m\n",
            "INFO:nni:Train: [ 13/600] Step 040/520 Loss 0.999 Prec@(1,5) (74.9%, 98.5%)\n",
            "[2023-01-12 16:31:23] \u001b[32mTrain: [ 13/600] Step 050/520 Loss 1.006 Prec@(1,5) (75.1%, 98.4%)\u001b[0m\n",
            "INFO:nni:Train: [ 13/600] Step 050/520 Loss 1.006 Prec@(1,5) (75.1%, 98.4%)\n",
            "[2023-01-12 16:31:28] \u001b[32mTrain: [ 13/600] Step 060/520 Loss 1.016 Prec@(1,5) (74.8%, 98.3%)\u001b[0m\n",
            "INFO:nni:Train: [ 13/600] Step 060/520 Loss 1.016 Prec@(1,5) (74.8%, 98.3%)\n",
            "[2023-01-12 16:31:32] \u001b[32mTrain: [ 13/600] Step 070/520 Loss 1.020 Prec@(1,5) (74.7%, 98.3%)\u001b[0m\n",
            "INFO:nni:Train: [ 13/600] Step 070/520 Loss 1.020 Prec@(1,5) (74.7%, 98.3%)\n",
            "[2023-01-12 16:31:37] \u001b[32mTrain: [ 13/600] Step 080/520 Loss 1.014 Prec@(1,5) (74.7%, 98.4%)\u001b[0m\n",
            "INFO:nni:Train: [ 13/600] Step 080/520 Loss 1.014 Prec@(1,5) (74.7%, 98.4%)\n",
            "[2023-01-12 16:31:41] \u001b[32mTrain: [ 13/600] Step 090/520 Loss 1.024 Prec@(1,5) (74.3%, 98.4%)\u001b[0m\n",
            "INFO:nni:Train: [ 13/600] Step 090/520 Loss 1.024 Prec@(1,5) (74.3%, 98.4%)\n",
            "[2023-01-12 16:31:46] \u001b[32mTrain: [ 13/600] Step 100/520 Loss 1.024 Prec@(1,5) (74.4%, 98.4%)\u001b[0m\n",
            "INFO:nni:Train: [ 13/600] Step 100/520 Loss 1.024 Prec@(1,5) (74.4%, 98.4%)\n",
            "[2023-01-12 16:31:51] \u001b[32mTrain: [ 13/600] Step 110/520 Loss 1.025 Prec@(1,5) (74.6%, 98.3%)\u001b[0m\n",
            "INFO:nni:Train: [ 13/600] Step 110/520 Loss 1.025 Prec@(1,5) (74.6%, 98.3%)\n",
            "[2023-01-12 16:31:55] \u001b[32mTrain: [ 13/600] Step 120/520 Loss 1.024 Prec@(1,5) (74.5%, 98.3%)\u001b[0m\n",
            "INFO:nni:Train: [ 13/600] Step 120/520 Loss 1.024 Prec@(1,5) (74.5%, 98.3%)\n",
            "[2023-01-12 16:32:00] \u001b[32mTrain: [ 13/600] Step 130/520 Loss 1.023 Prec@(1,5) (74.5%, 98.3%)\u001b[0m\n",
            "INFO:nni:Train: [ 13/600] Step 130/520 Loss 1.023 Prec@(1,5) (74.5%, 98.3%)\n",
            "[2023-01-12 16:32:04] \u001b[32mTrain: [ 13/600] Step 140/520 Loss 1.022 Prec@(1,5) (74.5%, 98.3%)\u001b[0m\n",
            "INFO:nni:Train: [ 13/600] Step 140/520 Loss 1.022 Prec@(1,5) (74.5%, 98.3%)\n",
            "[2023-01-12 16:32:09] \u001b[32mTrain: [ 13/600] Step 150/520 Loss 1.019 Prec@(1,5) (74.7%, 98.3%)\u001b[0m\n",
            "INFO:nni:Train: [ 13/600] Step 150/520 Loss 1.019 Prec@(1,5) (74.7%, 98.3%)\n",
            "[2023-01-12 16:32:13] \u001b[32mTrain: [ 13/600] Step 160/520 Loss 1.021 Prec@(1,5) (74.6%, 98.3%)\u001b[0m\n",
            "INFO:nni:Train: [ 13/600] Step 160/520 Loss 1.021 Prec@(1,5) (74.6%, 98.3%)\n",
            "[2023-01-12 16:32:18] \u001b[32mTrain: [ 13/600] Step 170/520 Loss 1.018 Prec@(1,5) (74.6%, 98.3%)\u001b[0m\n",
            "INFO:nni:Train: [ 13/600] Step 170/520 Loss 1.018 Prec@(1,5) (74.6%, 98.3%)\n",
            "[2023-01-12 16:32:22] \u001b[32mTrain: [ 13/600] Step 180/520 Loss 1.019 Prec@(1,5) (74.6%, 98.3%)\u001b[0m\n",
            "INFO:nni:Train: [ 13/600] Step 180/520 Loss 1.019 Prec@(1,5) (74.6%, 98.3%)\n",
            "[2023-01-12 16:32:27] \u001b[32mTrain: [ 13/600] Step 190/520 Loss 1.018 Prec@(1,5) (74.6%, 98.3%)\u001b[0m\n",
            "INFO:nni:Train: [ 13/600] Step 190/520 Loss 1.018 Prec@(1,5) (74.6%, 98.3%)\n",
            "[2023-01-12 16:32:31] \u001b[32mTrain: [ 13/600] Step 200/520 Loss 1.020 Prec@(1,5) (74.5%, 98.4%)\u001b[0m\n",
            "INFO:nni:Train: [ 13/600] Step 200/520 Loss 1.020 Prec@(1,5) (74.5%, 98.4%)\n",
            "[2023-01-12 16:32:36] \u001b[32mTrain: [ 13/600] Step 210/520 Loss 1.019 Prec@(1,5) (74.6%, 98.3%)\u001b[0m\n",
            "INFO:nni:Train: [ 13/600] Step 210/520 Loss 1.019 Prec@(1,5) (74.6%, 98.3%)\n",
            "[2023-01-12 16:32:40] \u001b[32mTrain: [ 13/600] Step 220/520 Loss 1.021 Prec@(1,5) (74.6%, 98.3%)\u001b[0m\n",
            "INFO:nni:Train: [ 13/600] Step 220/520 Loss 1.021 Prec@(1,5) (74.6%, 98.3%)\n",
            "[2023-01-12 16:32:45] \u001b[32mTrain: [ 13/600] Step 230/520 Loss 1.024 Prec@(1,5) (74.6%, 98.3%)\u001b[0m\n",
            "INFO:nni:Train: [ 13/600] Step 230/520 Loss 1.024 Prec@(1,5) (74.6%, 98.3%)\n",
            "[2023-01-12 16:32:49] \u001b[32mTrain: [ 13/600] Step 240/520 Loss 1.023 Prec@(1,5) (74.6%, 98.3%)\u001b[0m\n",
            "INFO:nni:Train: [ 13/600] Step 240/520 Loss 1.023 Prec@(1,5) (74.6%, 98.3%)\n",
            "[2023-01-12 16:32:54] \u001b[32mTrain: [ 13/600] Step 250/520 Loss 1.021 Prec@(1,5) (74.7%, 98.3%)\u001b[0m\n",
            "INFO:nni:Train: [ 13/600] Step 250/520 Loss 1.021 Prec@(1,5) (74.7%, 98.3%)\n",
            "[2023-01-12 16:32:58] \u001b[32mTrain: [ 13/600] Step 260/520 Loss 1.022 Prec@(1,5) (74.7%, 98.3%)\u001b[0m\n",
            "INFO:nni:Train: [ 13/600] Step 260/520 Loss 1.022 Prec@(1,5) (74.7%, 98.3%)\n",
            "[2023-01-12 16:33:03] \u001b[32mTrain: [ 13/600] Step 270/520 Loss 1.020 Prec@(1,5) (74.8%, 98.4%)\u001b[0m\n",
            "INFO:nni:Train: [ 13/600] Step 270/520 Loss 1.020 Prec@(1,5) (74.8%, 98.4%)\n",
            "[2023-01-12 16:33:07] \u001b[32mTrain: [ 13/600] Step 280/520 Loss 1.022 Prec@(1,5) (74.7%, 98.4%)\u001b[0m\n",
            "INFO:nni:Train: [ 13/600] Step 280/520 Loss 1.022 Prec@(1,5) (74.7%, 98.4%)\n",
            "[2023-01-12 16:33:12] \u001b[32mTrain: [ 13/600] Step 290/520 Loss 1.022 Prec@(1,5) (74.7%, 98.3%)\u001b[0m\n",
            "INFO:nni:Train: [ 13/600] Step 290/520 Loss 1.022 Prec@(1,5) (74.7%, 98.3%)\n",
            "[2023-01-12 16:33:16] \u001b[32mTrain: [ 13/600] Step 300/520 Loss 1.021 Prec@(1,5) (74.7%, 98.3%)\u001b[0m\n",
            "INFO:nni:Train: [ 13/600] Step 300/520 Loss 1.021 Prec@(1,5) (74.7%, 98.3%)\n",
            "[2023-01-12 16:33:21] \u001b[32mTrain: [ 13/600] Step 310/520 Loss 1.023 Prec@(1,5) (74.7%, 98.3%)\u001b[0m\n",
            "INFO:nni:Train: [ 13/600] Step 310/520 Loss 1.023 Prec@(1,5) (74.7%, 98.3%)\n",
            "[2023-01-12 16:33:25] \u001b[32mTrain: [ 13/600] Step 320/520 Loss 1.022 Prec@(1,5) (74.7%, 98.4%)\u001b[0m\n",
            "INFO:nni:Train: [ 13/600] Step 320/520 Loss 1.022 Prec@(1,5) (74.7%, 98.4%)\n",
            "[2023-01-12 16:33:30] \u001b[32mTrain: [ 13/600] Step 330/520 Loss 1.021 Prec@(1,5) (74.8%, 98.4%)\u001b[0m\n",
            "INFO:nni:Train: [ 13/600] Step 330/520 Loss 1.021 Prec@(1,5) (74.8%, 98.4%)\n",
            "[2023-01-12 16:33:34] \u001b[32mTrain: [ 13/600] Step 340/520 Loss 1.022 Prec@(1,5) (74.7%, 98.3%)\u001b[0m\n",
            "INFO:nni:Train: [ 13/600] Step 340/520 Loss 1.022 Prec@(1,5) (74.7%, 98.3%)\n",
            "[2023-01-12 16:33:39] \u001b[32mTrain: [ 13/600] Step 350/520 Loss 1.024 Prec@(1,5) (74.7%, 98.3%)\u001b[0m\n",
            "INFO:nni:Train: [ 13/600] Step 350/520 Loss 1.024 Prec@(1,5) (74.7%, 98.3%)\n",
            "[2023-01-12 16:33:43] \u001b[32mTrain: [ 13/600] Step 360/520 Loss 1.024 Prec@(1,5) (74.7%, 98.3%)\u001b[0m\n",
            "INFO:nni:Train: [ 13/600] Step 360/520 Loss 1.024 Prec@(1,5) (74.7%, 98.3%)\n",
            "[2023-01-12 16:33:48] \u001b[32mTrain: [ 13/600] Step 370/520 Loss 1.024 Prec@(1,5) (74.7%, 98.3%)\u001b[0m\n",
            "INFO:nni:Train: [ 13/600] Step 370/520 Loss 1.024 Prec@(1,5) (74.7%, 98.3%)\n",
            "[2023-01-12 16:33:52] \u001b[32mTrain: [ 13/600] Step 380/520 Loss 1.023 Prec@(1,5) (74.7%, 98.3%)\u001b[0m\n",
            "INFO:nni:Train: [ 13/600] Step 380/520 Loss 1.023 Prec@(1,5) (74.7%, 98.3%)\n",
            "[2023-01-12 16:33:57] \u001b[32mTrain: [ 13/600] Step 390/520 Loss 1.023 Prec@(1,5) (74.7%, 98.3%)\u001b[0m\n",
            "INFO:nni:Train: [ 13/600] Step 390/520 Loss 1.023 Prec@(1,5) (74.7%, 98.3%)\n",
            "[2023-01-12 16:34:02] \u001b[32mTrain: [ 13/600] Step 400/520 Loss 1.020 Prec@(1,5) (74.8%, 98.3%)\u001b[0m\n",
            "INFO:nni:Train: [ 13/600] Step 400/520 Loss 1.020 Prec@(1,5) (74.8%, 98.3%)\n",
            "[2023-01-12 16:34:06] \u001b[32mTrain: [ 13/600] Step 410/520 Loss 1.020 Prec@(1,5) (74.8%, 98.3%)\u001b[0m\n",
            "INFO:nni:Train: [ 13/600] Step 410/520 Loss 1.020 Prec@(1,5) (74.8%, 98.3%)\n",
            "[2023-01-12 16:34:11] \u001b[32mTrain: [ 13/600] Step 420/520 Loss 1.019 Prec@(1,5) (74.8%, 98.3%)\u001b[0m\n",
            "INFO:nni:Train: [ 13/600] Step 420/520 Loss 1.019 Prec@(1,5) (74.8%, 98.3%)\n",
            "[2023-01-12 16:34:15] \u001b[32mTrain: [ 13/600] Step 430/520 Loss 1.019 Prec@(1,5) (74.8%, 98.4%)\u001b[0m\n",
            "INFO:nni:Train: [ 13/600] Step 430/520 Loss 1.019 Prec@(1,5) (74.8%, 98.4%)\n",
            "[2023-01-12 16:34:20] \u001b[32mTrain: [ 13/600] Step 440/520 Loss 1.020 Prec@(1,5) (74.8%, 98.3%)\u001b[0m\n",
            "INFO:nni:Train: [ 13/600] Step 440/520 Loss 1.020 Prec@(1,5) (74.8%, 98.3%)\n",
            "[2023-01-12 16:34:24] \u001b[32mTrain: [ 13/600] Step 450/520 Loss 1.021 Prec@(1,5) (74.8%, 98.3%)\u001b[0m\n",
            "INFO:nni:Train: [ 13/600] Step 450/520 Loss 1.021 Prec@(1,5) (74.8%, 98.3%)\n",
            "[2023-01-12 16:34:29] \u001b[32mTrain: [ 13/600] Step 460/520 Loss 1.021 Prec@(1,5) (74.7%, 98.3%)\u001b[0m\n",
            "INFO:nni:Train: [ 13/600] Step 460/520 Loss 1.021 Prec@(1,5) (74.7%, 98.3%)\n",
            "[2023-01-12 16:34:33] \u001b[32mTrain: [ 13/600] Step 470/520 Loss 1.020 Prec@(1,5) (74.7%, 98.3%)\u001b[0m\n",
            "INFO:nni:Train: [ 13/600] Step 470/520 Loss 1.020 Prec@(1,5) (74.7%, 98.3%)\n",
            "[2023-01-12 16:34:38] \u001b[32mTrain: [ 13/600] Step 480/520 Loss 1.020 Prec@(1,5) (74.8%, 98.3%)\u001b[0m\n",
            "INFO:nni:Train: [ 13/600] Step 480/520 Loss 1.020 Prec@(1,5) (74.8%, 98.3%)\n",
            "[2023-01-12 16:34:42] \u001b[32mTrain: [ 13/600] Step 490/520 Loss 1.019 Prec@(1,5) (74.8%, 98.3%)\u001b[0m\n",
            "INFO:nni:Train: [ 13/600] Step 490/520 Loss 1.019 Prec@(1,5) (74.8%, 98.3%)\n",
            "[2023-01-12 16:34:47] \u001b[32mTrain: [ 13/600] Step 500/520 Loss 1.018 Prec@(1,5) (74.8%, 98.4%)\u001b[0m\n",
            "INFO:nni:Train: [ 13/600] Step 500/520 Loss 1.018 Prec@(1,5) (74.8%, 98.4%)\n",
            "[2023-01-12 16:34:51] \u001b[32mTrain: [ 13/600] Step 510/520 Loss 1.015 Prec@(1,5) (74.9%, 98.4%)\u001b[0m\n",
            "INFO:nni:Train: [ 13/600] Step 510/520 Loss 1.015 Prec@(1,5) (74.9%, 98.4%)\n",
            "[2023-01-12 16:34:56] \u001b[32mTrain: [ 13/600] Step 520/520 Loss 1.015 Prec@(1,5) (74.9%, 98.4%)\u001b[0m\n",
            "INFO:nni:Train: [ 13/600] Step 520/520 Loss 1.015 Prec@(1,5) (74.9%, 98.4%)\n",
            "[2023-01-12 16:34:56] \u001b[32mTrain: [ 13/600] Final Prec@1 74.8740%\u001b[0m\n",
            "INFO:nni:Train: [ 13/600] Final Prec@1 74.8740%\n",
            "[2023-01-12 16:34:56] \u001b[32mValid: [ 13/600] Step 000/104 Loss 0.608 Prec@(1,5) (77.1%, 99.0%)\u001b[0m\n",
            "INFO:nni:Valid: [ 13/600] Step 000/104 Loss 0.608 Prec@(1,5) (77.1%, 99.0%)\n",
            "[2023-01-12 16:34:58] \u001b[32mValid: [ 13/600] Step 010/104 Loss 0.609 Prec@(1,5) (77.9%, 98.9%)\u001b[0m\n",
            "INFO:nni:Valid: [ 13/600] Step 010/104 Loss 0.609 Prec@(1,5) (77.9%, 98.9%)\n",
            "[2023-01-12 16:34:59] \u001b[32mValid: [ 13/600] Step 020/104 Loss 0.608 Prec@(1,5) (78.5%, 99.0%)\u001b[0m\n",
            "INFO:nni:Valid: [ 13/600] Step 020/104 Loss 0.608 Prec@(1,5) (78.5%, 99.0%)\n",
            "[2023-01-12 16:35:00] \u001b[32mValid: [ 13/600] Step 030/104 Loss 0.604 Prec@(1,5) (79.0%, 99.0%)\u001b[0m\n",
            "INFO:nni:Valid: [ 13/600] Step 030/104 Loss 0.604 Prec@(1,5) (79.0%, 99.0%)\n",
            "[2023-01-12 16:35:02] \u001b[32mValid: [ 13/600] Step 040/104 Loss 0.606 Prec@(1,5) (78.9%, 98.9%)\u001b[0m\n",
            "INFO:nni:Valid: [ 13/600] Step 040/104 Loss 0.606 Prec@(1,5) (78.9%, 98.9%)\n",
            "[2023-01-12 16:35:03] \u001b[32mValid: [ 13/600] Step 050/104 Loss 0.597 Prec@(1,5) (79.2%, 99.0%)\u001b[0m\n",
            "INFO:nni:Valid: [ 13/600] Step 050/104 Loss 0.597 Prec@(1,5) (79.2%, 99.0%)\n",
            "[2023-01-12 16:35:05] \u001b[32mValid: [ 13/600] Step 060/104 Loss 0.602 Prec@(1,5) (79.2%, 99.0%)\u001b[0m\n",
            "INFO:nni:Valid: [ 13/600] Step 060/104 Loss 0.602 Prec@(1,5) (79.2%, 99.0%)\n",
            "[2023-01-12 16:35:06] \u001b[32mValid: [ 13/600] Step 070/104 Loss 0.606 Prec@(1,5) (79.1%, 99.0%)\u001b[0m\n",
            "INFO:nni:Valid: [ 13/600] Step 070/104 Loss 0.606 Prec@(1,5) (79.1%, 99.0%)\n",
            "[2023-01-12 16:35:07] \u001b[32mValid: [ 13/600] Step 080/104 Loss 0.607 Prec@(1,5) (79.2%, 98.9%)\u001b[0m\n",
            "INFO:nni:Valid: [ 13/600] Step 080/104 Loss 0.607 Prec@(1,5) (79.2%, 98.9%)\n",
            "[2023-01-12 16:35:09] \u001b[32mValid: [ 13/600] Step 090/104 Loss 0.607 Prec@(1,5) (79.1%, 98.9%)\u001b[0m\n",
            "INFO:nni:Valid: [ 13/600] Step 090/104 Loss 0.607 Prec@(1,5) (79.1%, 98.9%)\n",
            "[2023-01-12 16:35:10] \u001b[32mValid: [ 13/600] Step 100/104 Loss 0.599 Prec@(1,5) (79.4%, 99.0%)\u001b[0m\n",
            "INFO:nni:Valid: [ 13/600] Step 100/104 Loss 0.599 Prec@(1,5) (79.4%, 99.0%)\n",
            "[2023-01-12 16:35:11] \u001b[32mValid: [ 13/600] Step 104/104 Loss 0.601 Prec@(1,5) (79.4%, 99.0%)\u001b[0m\n",
            "INFO:nni:Valid: [ 13/600] Step 104/104 Loss 0.601 Prec@(1,5) (79.4%, 99.0%)\n",
            "[2023-01-12 16:35:11] \u001b[32mValid: [ 13/600] Final Prec@1 79.3800%\u001b[0m\n",
            "INFO:nni:Valid: [ 13/600] Final Prec@1 79.3800%\n",
            "[2023-01-12 16:35:11] \u001b[32mEpoch 13 LR 0.024971\u001b[0m\n",
            "INFO:nni:Epoch 13 LR 0.024971\n",
            "[2023-01-12 16:35:12] \u001b[32mTrain: [ 14/600] Step 000/520 Loss 1.038 Prec@(1,5) (72.9%, 99.0%)\u001b[0m\n",
            "INFO:nni:Train: [ 14/600] Step 000/520 Loss 1.038 Prec@(1,5) (72.9%, 99.0%)\n",
            "[2023-01-12 16:35:16] \u001b[32mTrain: [ 14/600] Step 010/520 Loss 0.929 Prec@(1,5) (76.4%, 98.9%)\u001b[0m\n",
            "INFO:nni:Train: [ 14/600] Step 010/520 Loss 0.929 Prec@(1,5) (76.4%, 98.9%)\n",
            "[2023-01-12 16:35:21] \u001b[32mTrain: [ 14/600] Step 020/520 Loss 0.954 Prec@(1,5) (75.9%, 98.5%)\u001b[0m\n",
            "INFO:nni:Train: [ 14/600] Step 020/520 Loss 0.954 Prec@(1,5) (75.9%, 98.5%)\n",
            "[2023-01-12 16:35:25] \u001b[32mTrain: [ 14/600] Step 030/520 Loss 0.950 Prec@(1,5) (76.2%, 98.6%)\u001b[0m\n",
            "INFO:nni:Train: [ 14/600] Step 030/520 Loss 0.950 Prec@(1,5) (76.2%, 98.6%)\n",
            "[2023-01-12 16:35:30] \u001b[32mTrain: [ 14/600] Step 040/520 Loss 0.922 Prec@(1,5) (77.0%, 98.7%)\u001b[0m\n",
            "INFO:nni:Train: [ 14/600] Step 040/520 Loss 0.922 Prec@(1,5) (77.0%, 98.7%)\n",
            "[2023-01-12 16:35:34] \u001b[32mTrain: [ 14/600] Step 050/520 Loss 0.946 Prec@(1,5) (76.3%, 98.6%)\u001b[0m\n",
            "INFO:nni:Train: [ 14/600] Step 050/520 Loss 0.946 Prec@(1,5) (76.3%, 98.6%)\n",
            "[2023-01-12 16:35:39] \u001b[32mTrain: [ 14/600] Step 060/520 Loss 0.944 Prec@(1,5) (76.3%, 98.5%)\u001b[0m\n",
            "INFO:nni:Train: [ 14/600] Step 060/520 Loss 0.944 Prec@(1,5) (76.3%, 98.5%)\n",
            "[2023-01-12 16:35:43] \u001b[32mTrain: [ 14/600] Step 070/520 Loss 0.958 Prec@(1,5) (75.8%, 98.5%)\u001b[0m\n",
            "INFO:nni:Train: [ 14/600] Step 070/520 Loss 0.958 Prec@(1,5) (75.8%, 98.5%)\n",
            "[2023-01-12 16:35:48] \u001b[32mTrain: [ 14/600] Step 080/520 Loss 0.958 Prec@(1,5) (75.8%, 98.6%)\u001b[0m\n",
            "INFO:nni:Train: [ 14/600] Step 080/520 Loss 0.958 Prec@(1,5) (75.8%, 98.6%)\n",
            "[2023-01-12 16:35:52] \u001b[32mTrain: [ 14/600] Step 090/520 Loss 0.957 Prec@(1,5) (75.9%, 98.6%)\u001b[0m\n",
            "INFO:nni:Train: [ 14/600] Step 090/520 Loss 0.957 Prec@(1,5) (75.9%, 98.6%)\n",
            "[2023-01-12 16:35:57] \u001b[32mTrain: [ 14/600] Step 100/520 Loss 0.952 Prec@(1,5) (76.0%, 98.6%)\u001b[0m\n",
            "INFO:nni:Train: [ 14/600] Step 100/520 Loss 0.952 Prec@(1,5) (76.0%, 98.6%)\n",
            "[2023-01-12 16:36:01] \u001b[32mTrain: [ 14/600] Step 110/520 Loss 0.958 Prec@(1,5) (76.1%, 98.6%)\u001b[0m\n",
            "INFO:nni:Train: [ 14/600] Step 110/520 Loss 0.958 Prec@(1,5) (76.1%, 98.6%)\n",
            "[2023-01-12 16:36:06] \u001b[32mTrain: [ 14/600] Step 120/520 Loss 0.958 Prec@(1,5) (76.1%, 98.6%)\u001b[0m\n",
            "INFO:nni:Train: [ 14/600] Step 120/520 Loss 0.958 Prec@(1,5) (76.1%, 98.6%)\n",
            "[2023-01-12 16:36:10] \u001b[32mTrain: [ 14/600] Step 130/520 Loss 0.958 Prec@(1,5) (76.0%, 98.6%)\u001b[0m\n",
            "INFO:nni:Train: [ 14/600] Step 130/520 Loss 0.958 Prec@(1,5) (76.0%, 98.6%)\n",
            "[2023-01-12 16:36:15] \u001b[32mTrain: [ 14/600] Step 140/520 Loss 0.954 Prec@(1,5) (76.1%, 98.6%)\u001b[0m\n",
            "INFO:nni:Train: [ 14/600] Step 140/520 Loss 0.954 Prec@(1,5) (76.1%, 98.6%)\n",
            "[2023-01-12 16:36:19] \u001b[32mTrain: [ 14/600] Step 150/520 Loss 0.955 Prec@(1,5) (76.1%, 98.6%)\u001b[0m\n",
            "INFO:nni:Train: [ 14/600] Step 150/520 Loss 0.955 Prec@(1,5) (76.1%, 98.6%)\n",
            "[2023-01-12 16:36:24] \u001b[32mTrain: [ 14/600] Step 160/520 Loss 0.958 Prec@(1,5) (76.1%, 98.6%)\u001b[0m\n",
            "INFO:nni:Train: [ 14/600] Step 160/520 Loss 0.958 Prec@(1,5) (76.1%, 98.6%)\n",
            "[2023-01-12 16:36:28] \u001b[32mTrain: [ 14/600] Step 170/520 Loss 0.959 Prec@(1,5) (76.1%, 98.5%)\u001b[0m\n",
            "INFO:nni:Train: [ 14/600] Step 170/520 Loss 0.959 Prec@(1,5) (76.1%, 98.5%)\n",
            "[2023-01-12 16:36:33] \u001b[32mTrain: [ 14/600] Step 180/520 Loss 0.959 Prec@(1,5) (76.2%, 98.5%)\u001b[0m\n",
            "INFO:nni:Train: [ 14/600] Step 180/520 Loss 0.959 Prec@(1,5) (76.2%, 98.5%)\n",
            "[2023-01-12 16:36:38] \u001b[32mTrain: [ 14/600] Step 190/520 Loss 0.960 Prec@(1,5) (76.1%, 98.5%)\u001b[0m\n",
            "INFO:nni:Train: [ 14/600] Step 190/520 Loss 0.960 Prec@(1,5) (76.1%, 98.5%)\n",
            "[2023-01-12 16:36:42] \u001b[32mTrain: [ 14/600] Step 200/520 Loss 0.957 Prec@(1,5) (76.1%, 98.6%)\u001b[0m\n",
            "INFO:nni:Train: [ 14/600] Step 200/520 Loss 0.957 Prec@(1,5) (76.1%, 98.6%)\n",
            "[2023-01-12 16:36:47] \u001b[32mTrain: [ 14/600] Step 210/520 Loss 0.954 Prec@(1,5) (76.2%, 98.6%)\u001b[0m\n",
            "INFO:nni:Train: [ 14/600] Step 210/520 Loss 0.954 Prec@(1,5) (76.2%, 98.6%)\n",
            "[2023-01-12 16:36:51] \u001b[32mTrain: [ 14/600] Step 220/520 Loss 0.955 Prec@(1,5) (76.1%, 98.6%)\u001b[0m\n",
            "INFO:nni:Train: [ 14/600] Step 220/520 Loss 0.955 Prec@(1,5) (76.1%, 98.6%)\n",
            "[2023-01-12 16:36:56] \u001b[32mTrain: [ 14/600] Step 230/520 Loss 0.954 Prec@(1,5) (76.2%, 98.6%)\u001b[0m\n",
            "INFO:nni:Train: [ 14/600] Step 230/520 Loss 0.954 Prec@(1,5) (76.2%, 98.6%)\n",
            "[2023-01-12 16:37:00] \u001b[32mTrain: [ 14/600] Step 240/520 Loss 0.957 Prec@(1,5) (76.1%, 98.6%)\u001b[0m\n",
            "INFO:nni:Train: [ 14/600] Step 240/520 Loss 0.957 Prec@(1,5) (76.1%, 98.6%)\n",
            "[2023-01-12 16:37:05] \u001b[32mTrain: [ 14/600] Step 250/520 Loss 0.961 Prec@(1,5) (76.0%, 98.5%)\u001b[0m\n",
            "INFO:nni:Train: [ 14/600] Step 250/520 Loss 0.961 Prec@(1,5) (76.0%, 98.5%)\n",
            "[2023-01-12 16:37:09] \u001b[32mTrain: [ 14/600] Step 260/520 Loss 0.963 Prec@(1,5) (75.9%, 98.5%)\u001b[0m\n",
            "INFO:nni:Train: [ 14/600] Step 260/520 Loss 0.963 Prec@(1,5) (75.9%, 98.5%)\n",
            "[2023-01-12 16:37:14] \u001b[32mTrain: [ 14/600] Step 270/520 Loss 0.963 Prec@(1,5) (75.9%, 98.5%)\u001b[0m\n",
            "INFO:nni:Train: [ 14/600] Step 270/520 Loss 0.963 Prec@(1,5) (75.9%, 98.5%)\n",
            "[2023-01-12 16:37:18] \u001b[32mTrain: [ 14/600] Step 280/520 Loss 0.964 Prec@(1,5) (76.0%, 98.5%)\u001b[0m\n",
            "INFO:nni:Train: [ 14/600] Step 280/520 Loss 0.964 Prec@(1,5) (76.0%, 98.5%)\n",
            "[2023-01-12 16:37:23] \u001b[32mTrain: [ 14/600] Step 290/520 Loss 0.967 Prec@(1,5) (75.9%, 98.5%)\u001b[0m\n",
            "INFO:nni:Train: [ 14/600] Step 290/520 Loss 0.967 Prec@(1,5) (75.9%, 98.5%)\n",
            "[2023-01-12 16:37:27] \u001b[32mTrain: [ 14/600] Step 300/520 Loss 0.969 Prec@(1,5) (75.8%, 98.5%)\u001b[0m\n",
            "INFO:nni:Train: [ 14/600] Step 300/520 Loss 0.969 Prec@(1,5) (75.8%, 98.5%)\n",
            "[2023-01-12 16:37:32] \u001b[32mTrain: [ 14/600] Step 310/520 Loss 0.970 Prec@(1,5) (75.8%, 98.5%)\u001b[0m\n",
            "INFO:nni:Train: [ 14/600] Step 310/520 Loss 0.970 Prec@(1,5) (75.8%, 98.5%)\n",
            "[2023-01-12 16:37:36] \u001b[32mTrain: [ 14/600] Step 320/520 Loss 0.970 Prec@(1,5) (75.8%, 98.5%)\u001b[0m\n",
            "INFO:nni:Train: [ 14/600] Step 320/520 Loss 0.970 Prec@(1,5) (75.8%, 98.5%)\n",
            "[2023-01-12 16:37:41] \u001b[32mTrain: [ 14/600] Step 330/520 Loss 0.972 Prec@(1,5) (75.8%, 98.5%)\u001b[0m\n",
            "INFO:nni:Train: [ 14/600] Step 330/520 Loss 0.972 Prec@(1,5) (75.8%, 98.5%)\n",
            "[2023-01-12 16:37:45] \u001b[32mTrain: [ 14/600] Step 340/520 Loss 0.972 Prec@(1,5) (75.7%, 98.5%)\u001b[0m\n",
            "INFO:nni:Train: [ 14/600] Step 340/520 Loss 0.972 Prec@(1,5) (75.7%, 98.5%)\n",
            "[2023-01-12 16:37:50] \u001b[32mTrain: [ 14/600] Step 350/520 Loss 0.974 Prec@(1,5) (75.7%, 98.4%)\u001b[0m\n",
            "INFO:nni:Train: [ 14/600] Step 350/520 Loss 0.974 Prec@(1,5) (75.7%, 98.4%)\n",
            "[2023-01-12 16:37:54] \u001b[32mTrain: [ 14/600] Step 360/520 Loss 0.971 Prec@(1,5) (75.7%, 98.5%)\u001b[0m\n",
            "INFO:nni:Train: [ 14/600] Step 360/520 Loss 0.971 Prec@(1,5) (75.7%, 98.5%)\n",
            "[2023-01-12 16:37:59] \u001b[32mTrain: [ 14/600] Step 370/520 Loss 0.972 Prec@(1,5) (75.7%, 98.5%)\u001b[0m\n",
            "INFO:nni:Train: [ 14/600] Step 370/520 Loss 0.972 Prec@(1,5) (75.7%, 98.5%)\n",
            "[2023-01-12 16:38:03] \u001b[32mTrain: [ 14/600] Step 380/520 Loss 0.971 Prec@(1,5) (75.7%, 98.5%)\u001b[0m\n",
            "INFO:nni:Train: [ 14/600] Step 380/520 Loss 0.971 Prec@(1,5) (75.7%, 98.5%)\n",
            "[2023-01-12 16:38:08] \u001b[32mTrain: [ 14/600] Step 390/520 Loss 0.970 Prec@(1,5) (75.8%, 98.5%)\u001b[0m\n",
            "INFO:nni:Train: [ 14/600] Step 390/520 Loss 0.970 Prec@(1,5) (75.8%, 98.5%)\n",
            "[2023-01-12 16:38:12] \u001b[32mTrain: [ 14/600] Step 400/520 Loss 0.970 Prec@(1,5) (75.8%, 98.5%)\u001b[0m\n",
            "INFO:nni:Train: [ 14/600] Step 400/520 Loss 0.970 Prec@(1,5) (75.8%, 98.5%)\n",
            "[2023-01-12 16:38:17] \u001b[32mTrain: [ 14/600] Step 410/520 Loss 0.972 Prec@(1,5) (75.7%, 98.5%)\u001b[0m\n",
            "INFO:nni:Train: [ 14/600] Step 410/520 Loss 0.972 Prec@(1,5) (75.7%, 98.5%)\n",
            "[2023-01-12 16:38:21] \u001b[32mTrain: [ 14/600] Step 420/520 Loss 0.972 Prec@(1,5) (75.7%, 98.5%)\u001b[0m\n",
            "INFO:nni:Train: [ 14/600] Step 420/520 Loss 0.972 Prec@(1,5) (75.7%, 98.5%)\n",
            "[2023-01-12 16:38:26] \u001b[32mTrain: [ 14/600] Step 430/520 Loss 0.971 Prec@(1,5) (75.7%, 98.4%)\u001b[0m\n",
            "INFO:nni:Train: [ 14/600] Step 430/520 Loss 0.971 Prec@(1,5) (75.7%, 98.4%)\n",
            "[2023-01-12 16:38:30] \u001b[32mTrain: [ 14/600] Step 440/520 Loss 0.973 Prec@(1,5) (75.7%, 98.4%)\u001b[0m\n",
            "INFO:nni:Train: [ 14/600] Step 440/520 Loss 0.973 Prec@(1,5) (75.7%, 98.4%)\n",
            "[2023-01-12 16:38:35] \u001b[32mTrain: [ 14/600] Step 450/520 Loss 0.975 Prec@(1,5) (75.6%, 98.4%)\u001b[0m\n",
            "INFO:nni:Train: [ 14/600] Step 450/520 Loss 0.975 Prec@(1,5) (75.6%, 98.4%)\n",
            "[2023-01-12 16:38:39] \u001b[32mTrain: [ 14/600] Step 460/520 Loss 0.975 Prec@(1,5) (75.6%, 98.4%)\u001b[0m\n",
            "INFO:nni:Train: [ 14/600] Step 460/520 Loss 0.975 Prec@(1,5) (75.6%, 98.4%)\n",
            "[2023-01-12 16:38:44] \u001b[32mTrain: [ 14/600] Step 470/520 Loss 0.974 Prec@(1,5) (75.7%, 98.4%)\u001b[0m\n",
            "INFO:nni:Train: [ 14/600] Step 470/520 Loss 0.974 Prec@(1,5) (75.7%, 98.4%)\n",
            "[2023-01-12 16:38:48] \u001b[32mTrain: [ 14/600] Step 480/520 Loss 0.973 Prec@(1,5) (75.7%, 98.4%)\u001b[0m\n",
            "INFO:nni:Train: [ 14/600] Step 480/520 Loss 0.973 Prec@(1,5) (75.7%, 98.4%)\n",
            "[2023-01-12 16:38:53] \u001b[32mTrain: [ 14/600] Step 490/520 Loss 0.972 Prec@(1,5) (75.7%, 98.5%)\u001b[0m\n",
            "INFO:nni:Train: [ 14/600] Step 490/520 Loss 0.972 Prec@(1,5) (75.7%, 98.5%)\n",
            "[2023-01-12 16:38:57] \u001b[32mTrain: [ 14/600] Step 500/520 Loss 0.970 Prec@(1,5) (75.7%, 98.5%)\u001b[0m\n",
            "INFO:nni:Train: [ 14/600] Step 500/520 Loss 0.970 Prec@(1,5) (75.7%, 98.5%)\n",
            "[2023-01-12 16:39:02] \u001b[32mTrain: [ 14/600] Step 510/520 Loss 0.970 Prec@(1,5) (75.8%, 98.5%)\u001b[0m\n",
            "INFO:nni:Train: [ 14/600] Step 510/520 Loss 0.970 Prec@(1,5) (75.8%, 98.5%)\n",
            "[2023-01-12 16:39:06] \u001b[32mTrain: [ 14/600] Step 520/520 Loss 0.970 Prec@(1,5) (75.7%, 98.5%)\u001b[0m\n",
            "INFO:nni:Train: [ 14/600] Step 520/520 Loss 0.970 Prec@(1,5) (75.7%, 98.5%)\n",
            "[2023-01-12 16:39:07] \u001b[32mTrain: [ 14/600] Final Prec@1 75.7480%\u001b[0m\n",
            "INFO:nni:Train: [ 14/600] Final Prec@1 75.7480%\n",
            "[2023-01-12 16:39:07] \u001b[32mValid: [ 14/600] Step 000/104 Loss 0.537 Prec@(1,5) (81.2%, 99.0%)\u001b[0m\n",
            "INFO:nni:Valid: [ 14/600] Step 000/104 Loss 0.537 Prec@(1,5) (81.2%, 99.0%)\n",
            "[2023-01-12 16:39:08] \u001b[32mValid: [ 14/600] Step 010/104 Loss 0.608 Prec@(1,5) (78.7%, 98.4%)\u001b[0m\n",
            "INFO:nni:Valid: [ 14/600] Step 010/104 Loss 0.608 Prec@(1,5) (78.7%, 98.4%)\n",
            "[2023-01-12 16:39:10] \u001b[32mValid: [ 14/600] Step 020/104 Loss 0.608 Prec@(1,5) (78.4%, 98.7%)\u001b[0m\n",
            "INFO:nni:Valid: [ 14/600] Step 020/104 Loss 0.608 Prec@(1,5) (78.4%, 98.7%)\n",
            "[2023-01-12 16:39:11] \u001b[32mValid: [ 14/600] Step 030/104 Loss 0.610 Prec@(1,5) (78.8%, 98.7%)\u001b[0m\n",
            "INFO:nni:Valid: [ 14/600] Step 030/104 Loss 0.610 Prec@(1,5) (78.8%, 98.7%)\n",
            "[2023-01-12 16:39:13] \u001b[32mValid: [ 14/600] Step 040/104 Loss 0.619 Prec@(1,5) (78.7%, 98.5%)\u001b[0m\n",
            "INFO:nni:Valid: [ 14/600] Step 040/104 Loss 0.619 Prec@(1,5) (78.7%, 98.5%)\n",
            "[2023-01-12 16:39:14] \u001b[32mValid: [ 14/600] Step 050/104 Loss 0.611 Prec@(1,5) (79.1%, 98.6%)\u001b[0m\n",
            "INFO:nni:Valid: [ 14/600] Step 050/104 Loss 0.611 Prec@(1,5) (79.1%, 98.6%)\n",
            "[2023-01-12 16:39:15] \u001b[32mValid: [ 14/600] Step 060/104 Loss 0.615 Prec@(1,5) (78.8%, 98.7%)\u001b[0m\n",
            "INFO:nni:Valid: [ 14/600] Step 060/104 Loss 0.615 Prec@(1,5) (78.8%, 98.7%)\n",
            "[2023-01-12 16:39:17] \u001b[32mValid: [ 14/600] Step 070/104 Loss 0.619 Prec@(1,5) (78.8%, 98.7%)\u001b[0m\n",
            "INFO:nni:Valid: [ 14/600] Step 070/104 Loss 0.619 Prec@(1,5) (78.8%, 98.7%)\n",
            "[2023-01-12 16:39:18] \u001b[32mValid: [ 14/600] Step 080/104 Loss 0.623 Prec@(1,5) (78.7%, 98.6%)\u001b[0m\n",
            "INFO:nni:Valid: [ 14/600] Step 080/104 Loss 0.623 Prec@(1,5) (78.7%, 98.6%)\n",
            "[2023-01-12 16:39:20] \u001b[32mValid: [ 14/600] Step 090/104 Loss 0.624 Prec@(1,5) (78.6%, 98.7%)\u001b[0m\n",
            "INFO:nni:Valid: [ 14/600] Step 090/104 Loss 0.624 Prec@(1,5) (78.6%, 98.7%)\n",
            "[2023-01-12 16:39:21] \u001b[32mValid: [ 14/600] Step 100/104 Loss 0.618 Prec@(1,5) (78.9%, 98.7%)\u001b[0m\n",
            "INFO:nni:Valid: [ 14/600] Step 100/104 Loss 0.618 Prec@(1,5) (78.9%, 98.7%)\n",
            "[2023-01-12 16:39:22] \u001b[32mValid: [ 14/600] Step 104/104 Loss 0.620 Prec@(1,5) (78.8%, 98.7%)\u001b[0m\n",
            "INFO:nni:Valid: [ 14/600] Step 104/104 Loss 0.620 Prec@(1,5) (78.8%, 98.7%)\n",
            "[2023-01-12 16:39:22] \u001b[32mValid: [ 14/600] Final Prec@1 78.7700%\u001b[0m\n",
            "INFO:nni:Valid: [ 14/600] Final Prec@1 78.7700%\n",
            "[2023-01-12 16:39:22] \u001b[32mEpoch 14 LR 0.024966\u001b[0m\n",
            "INFO:nni:Epoch 14 LR 0.024966\n",
            "[2023-01-12 16:39:23] \u001b[32mTrain: [ 15/600] Step 000/520 Loss 0.630 Prec@(1,5) (83.3%, 100.0%)\u001b[0m\n",
            "INFO:nni:Train: [ 15/600] Step 000/520 Loss 0.630 Prec@(1,5) (83.3%, 100.0%)\n",
            "[2023-01-12 16:39:27] \u001b[32mTrain: [ 15/600] Step 010/520 Loss 0.961 Prec@(1,5) (75.9%, 98.1%)\u001b[0m\n",
            "INFO:nni:Train: [ 15/600] Step 010/520 Loss 0.961 Prec@(1,5) (75.9%, 98.1%)\n",
            "[2023-01-12 16:39:32] \u001b[32mTrain: [ 15/600] Step 020/520 Loss 0.928 Prec@(1,5) (77.2%, 98.4%)\u001b[0m\n",
            "INFO:nni:Train: [ 15/600] Step 020/520 Loss 0.928 Prec@(1,5) (77.2%, 98.4%)\n",
            "[2023-01-12 16:39:36] \u001b[32mTrain: [ 15/600] Step 030/520 Loss 0.900 Prec@(1,5) (77.9%, 98.5%)\u001b[0m\n",
            "INFO:nni:Train: [ 15/600] Step 030/520 Loss 0.900 Prec@(1,5) (77.9%, 98.5%)\n",
            "[2023-01-12 16:39:41] \u001b[32mTrain: [ 15/600] Step 040/520 Loss 0.917 Prec@(1,5) (77.8%, 98.5%)\u001b[0m\n",
            "INFO:nni:Train: [ 15/600] Step 040/520 Loss 0.917 Prec@(1,5) (77.8%, 98.5%)\n",
            "[2023-01-12 16:39:45] \u001b[32mTrain: [ 15/600] Step 050/520 Loss 0.940 Prec@(1,5) (77.1%, 98.4%)\u001b[0m\n",
            "INFO:nni:Train: [ 15/600] Step 050/520 Loss 0.940 Prec@(1,5) (77.1%, 98.4%)\n",
            "[2023-01-12 16:39:50] \u001b[32mTrain: [ 15/600] Step 060/520 Loss 0.933 Prec@(1,5) (77.3%, 98.5%)\u001b[0m\n",
            "INFO:nni:Train: [ 15/600] Step 060/520 Loss 0.933 Prec@(1,5) (77.3%, 98.5%)\n",
            "[2023-01-12 16:39:54] \u001b[32mTrain: [ 15/600] Step 070/520 Loss 0.946 Prec@(1,5) (76.9%, 98.5%)\u001b[0m\n",
            "INFO:nni:Train: [ 15/600] Step 070/520 Loss 0.946 Prec@(1,5) (76.9%, 98.5%)\n",
            "[2023-01-12 16:39:59] \u001b[32mTrain: [ 15/600] Step 080/520 Loss 0.948 Prec@(1,5) (76.9%, 98.5%)\u001b[0m\n",
            "INFO:nni:Train: [ 15/600] Step 080/520 Loss 0.948 Prec@(1,5) (76.9%, 98.5%)\n",
            "[2023-01-12 16:40:03] \u001b[32mTrain: [ 15/600] Step 090/520 Loss 0.944 Prec@(1,5) (77.0%, 98.4%)\u001b[0m\n",
            "INFO:nni:Train: [ 15/600] Step 090/520 Loss 0.944 Prec@(1,5) (77.0%, 98.4%)\n",
            "[2023-01-12 16:40:08] \u001b[32mTrain: [ 15/600] Step 100/520 Loss 0.936 Prec@(1,5) (77.2%, 98.5%)\u001b[0m\n",
            "INFO:nni:Train: [ 15/600] Step 100/520 Loss 0.936 Prec@(1,5) (77.2%, 98.5%)\n",
            "[2023-01-12 16:40:12] \u001b[32mTrain: [ 15/600] Step 110/520 Loss 0.942 Prec@(1,5) (77.0%, 98.5%)\u001b[0m\n",
            "INFO:nni:Train: [ 15/600] Step 110/520 Loss 0.942 Prec@(1,5) (77.0%, 98.5%)\n",
            "[2023-01-12 16:40:17] \u001b[32mTrain: [ 15/600] Step 120/520 Loss 0.937 Prec@(1,5) (77.1%, 98.5%)\u001b[0m\n",
            "INFO:nni:Train: [ 15/600] Step 120/520 Loss 0.937 Prec@(1,5) (77.1%, 98.5%)\n",
            "[2023-01-12 16:40:21] \u001b[32mTrain: [ 15/600] Step 130/520 Loss 0.930 Prec@(1,5) (77.4%, 98.5%)\u001b[0m\n",
            "INFO:nni:Train: [ 15/600] Step 130/520 Loss 0.930 Prec@(1,5) (77.4%, 98.5%)\n",
            "[2023-01-12 16:40:26] \u001b[32mTrain: [ 15/600] Step 140/520 Loss 0.931 Prec@(1,5) (77.2%, 98.5%)\u001b[0m\n",
            "INFO:nni:Train: [ 15/600] Step 140/520 Loss 0.931 Prec@(1,5) (77.2%, 98.5%)\n",
            "[2023-01-12 16:40:30] \u001b[32mTrain: [ 15/600] Step 150/520 Loss 0.935 Prec@(1,5) (77.0%, 98.6%)\u001b[0m\n",
            "INFO:nni:Train: [ 15/600] Step 150/520 Loss 0.935 Prec@(1,5) (77.0%, 98.6%)\n",
            "[2023-01-12 16:40:35] \u001b[32mTrain: [ 15/600] Step 160/520 Loss 0.937 Prec@(1,5) (76.9%, 98.6%)\u001b[0m\n",
            "INFO:nni:Train: [ 15/600] Step 160/520 Loss 0.937 Prec@(1,5) (76.9%, 98.6%)\n",
            "[2023-01-12 16:40:39] \u001b[32mTrain: [ 15/600] Step 170/520 Loss 0.937 Prec@(1,5) (76.9%, 98.6%)\u001b[0m\n",
            "INFO:nni:Train: [ 15/600] Step 170/520 Loss 0.937 Prec@(1,5) (76.9%, 98.6%)\n",
            "[2023-01-12 16:40:44] \u001b[32mTrain: [ 15/600] Step 180/520 Loss 0.934 Prec@(1,5) (76.9%, 98.6%)\u001b[0m\n",
            "INFO:nni:Train: [ 15/600] Step 180/520 Loss 0.934 Prec@(1,5) (76.9%, 98.6%)\n",
            "[2023-01-12 16:40:48] \u001b[32mTrain: [ 15/600] Step 190/520 Loss 0.935 Prec@(1,5) (76.9%, 98.6%)\u001b[0m\n",
            "INFO:nni:Train: [ 15/600] Step 190/520 Loss 0.935 Prec@(1,5) (76.9%, 98.6%)\n",
            "[2023-01-12 16:40:53] \u001b[32mTrain: [ 15/600] Step 200/520 Loss 0.933 Prec@(1,5) (77.0%, 98.6%)\u001b[0m\n",
            "INFO:nni:Train: [ 15/600] Step 200/520 Loss 0.933 Prec@(1,5) (77.0%, 98.6%)\n",
            "[2023-01-12 16:40:57] \u001b[32mTrain: [ 15/600] Step 210/520 Loss 0.931 Prec@(1,5) (76.9%, 98.6%)\u001b[0m\n",
            "INFO:nni:Train: [ 15/600] Step 210/520 Loss 0.931 Prec@(1,5) (76.9%, 98.6%)\n",
            "[2023-01-12 16:41:02] \u001b[32mTrain: [ 15/600] Step 220/520 Loss 0.926 Prec@(1,5) (77.1%, 98.6%)\u001b[0m\n",
            "INFO:nni:Train: [ 15/600] Step 220/520 Loss 0.926 Prec@(1,5) (77.1%, 98.6%)\n",
            "[2023-01-12 16:41:06] \u001b[32mTrain: [ 15/600] Step 230/520 Loss 0.927 Prec@(1,5) (77.0%, 98.6%)\u001b[0m\n",
            "INFO:nni:Train: [ 15/600] Step 230/520 Loss 0.927 Prec@(1,5) (77.0%, 98.6%)\n",
            "[2023-01-12 16:41:11] \u001b[32mTrain: [ 15/600] Step 240/520 Loss 0.931 Prec@(1,5) (76.9%, 98.6%)\u001b[0m\n",
            "INFO:nni:Train: [ 15/600] Step 240/520 Loss 0.931 Prec@(1,5) (76.9%, 98.6%)\n",
            "[2023-01-12 16:41:15] \u001b[32mTrain: [ 15/600] Step 250/520 Loss 0.931 Prec@(1,5) (76.9%, 98.6%)\u001b[0m\n",
            "INFO:nni:Train: [ 15/600] Step 250/520 Loss 0.931 Prec@(1,5) (76.9%, 98.6%)\n",
            "[2023-01-12 16:41:20] \u001b[32mTrain: [ 15/600] Step 260/520 Loss 0.932 Prec@(1,5) (76.9%, 98.6%)\u001b[0m\n",
            "INFO:nni:Train: [ 15/600] Step 260/520 Loss 0.932 Prec@(1,5) (76.9%, 98.6%)\n",
            "[2023-01-12 16:41:25] \u001b[32mTrain: [ 15/600] Step 270/520 Loss 0.933 Prec@(1,5) (76.9%, 98.6%)\u001b[0m\n",
            "INFO:nni:Train: [ 15/600] Step 270/520 Loss 0.933 Prec@(1,5) (76.9%, 98.6%)\n",
            "[2023-01-12 16:41:29] \u001b[32mTrain: [ 15/600] Step 280/520 Loss 0.936 Prec@(1,5) (76.8%, 98.6%)\u001b[0m\n",
            "INFO:nni:Train: [ 15/600] Step 280/520 Loss 0.936 Prec@(1,5) (76.8%, 98.6%)\n",
            "[2023-01-12 16:41:34] \u001b[32mTrain: [ 15/600] Step 290/520 Loss 0.939 Prec@(1,5) (76.8%, 98.6%)\u001b[0m\n",
            "INFO:nni:Train: [ 15/600] Step 290/520 Loss 0.939 Prec@(1,5) (76.8%, 98.6%)\n",
            "[2023-01-12 16:41:38] \u001b[32mTrain: [ 15/600] Step 300/520 Loss 0.939 Prec@(1,5) (76.8%, 98.6%)\u001b[0m\n",
            "INFO:nni:Train: [ 15/600] Step 300/520 Loss 0.939 Prec@(1,5) (76.8%, 98.6%)\n",
            "[2023-01-12 16:41:43] \u001b[32mTrain: [ 15/600] Step 310/520 Loss 0.939 Prec@(1,5) (76.8%, 98.6%)\u001b[0m\n",
            "INFO:nni:Train: [ 15/600] Step 310/520 Loss 0.939 Prec@(1,5) (76.8%, 98.6%)\n",
            "[2023-01-12 16:41:47] \u001b[32mTrain: [ 15/600] Step 320/520 Loss 0.940 Prec@(1,5) (76.8%, 98.6%)\u001b[0m\n",
            "INFO:nni:Train: [ 15/600] Step 320/520 Loss 0.940 Prec@(1,5) (76.8%, 98.6%)\n",
            "[2023-01-12 16:41:52] \u001b[32mTrain: [ 15/600] Step 330/520 Loss 0.942 Prec@(1,5) (76.7%, 98.6%)\u001b[0m\n",
            "INFO:nni:Train: [ 15/600] Step 330/520 Loss 0.942 Prec@(1,5) (76.7%, 98.6%)\n",
            "[2023-01-12 16:41:56] \u001b[32mTrain: [ 15/600] Step 340/520 Loss 0.941 Prec@(1,5) (76.7%, 98.6%)\u001b[0m\n",
            "INFO:nni:Train: [ 15/600] Step 340/520 Loss 0.941 Prec@(1,5) (76.7%, 98.6%)\n",
            "[2023-01-12 16:42:01] \u001b[32mTrain: [ 15/600] Step 350/520 Loss 0.941 Prec@(1,5) (76.7%, 98.6%)\u001b[0m\n",
            "INFO:nni:Train: [ 15/600] Step 350/520 Loss 0.941 Prec@(1,5) (76.7%, 98.6%)\n",
            "[2023-01-12 16:42:05] \u001b[32mTrain: [ 15/600] Step 360/520 Loss 0.941 Prec@(1,5) (76.7%, 98.6%)\u001b[0m\n",
            "INFO:nni:Train: [ 15/600] Step 360/520 Loss 0.941 Prec@(1,5) (76.7%, 98.6%)\n",
            "[2023-01-12 16:42:10] \u001b[32mTrain: [ 15/600] Step 370/520 Loss 0.940 Prec@(1,5) (76.8%, 98.6%)\u001b[0m\n",
            "INFO:nni:Train: [ 15/600] Step 370/520 Loss 0.940 Prec@(1,5) (76.8%, 98.6%)\n",
            "[2023-01-12 16:42:14] \u001b[32mTrain: [ 15/600] Step 380/520 Loss 0.939 Prec@(1,5) (76.8%, 98.6%)\u001b[0m\n",
            "INFO:nni:Train: [ 15/600] Step 380/520 Loss 0.939 Prec@(1,5) (76.8%, 98.6%)\n",
            "[2023-01-12 16:42:19] \u001b[32mTrain: [ 15/600] Step 390/520 Loss 0.943 Prec@(1,5) (76.7%, 98.6%)\u001b[0m\n",
            "INFO:nni:Train: [ 15/600] Step 390/520 Loss 0.943 Prec@(1,5) (76.7%, 98.6%)\n",
            "[2023-01-12 16:42:23] \u001b[32mTrain: [ 15/600] Step 400/520 Loss 0.941 Prec@(1,5) (76.7%, 98.6%)\u001b[0m\n",
            "INFO:nni:Train: [ 15/600] Step 400/520 Loss 0.941 Prec@(1,5) (76.7%, 98.6%)\n",
            "[2023-01-12 16:42:28] \u001b[32mTrain: [ 15/600] Step 410/520 Loss 0.941 Prec@(1,5) (76.7%, 98.6%)\u001b[0m\n",
            "INFO:nni:Train: [ 15/600] Step 410/520 Loss 0.941 Prec@(1,5) (76.7%, 98.6%)\n",
            "[2023-01-12 16:42:32] \u001b[32mTrain: [ 15/600] Step 420/520 Loss 0.941 Prec@(1,5) (76.8%, 98.6%)\u001b[0m\n",
            "INFO:nni:Train: [ 15/600] Step 420/520 Loss 0.941 Prec@(1,5) (76.8%, 98.6%)\n",
            "[2023-01-12 16:42:37] \u001b[32mTrain: [ 15/600] Step 430/520 Loss 0.939 Prec@(1,5) (76.8%, 98.6%)\u001b[0m\n",
            "INFO:nni:Train: [ 15/600] Step 430/520 Loss 0.939 Prec@(1,5) (76.8%, 98.6%)\n",
            "[2023-01-12 16:42:41] \u001b[32mTrain: [ 15/600] Step 440/520 Loss 0.942 Prec@(1,5) (76.7%, 98.6%)\u001b[0m\n",
            "INFO:nni:Train: [ 15/600] Step 440/520 Loss 0.942 Prec@(1,5) (76.7%, 98.6%)\n",
            "[2023-01-12 16:42:46] \u001b[32mTrain: [ 15/600] Step 450/520 Loss 0.942 Prec@(1,5) (76.7%, 98.6%)\u001b[0m\n",
            "INFO:nni:Train: [ 15/600] Step 450/520 Loss 0.942 Prec@(1,5) (76.7%, 98.6%)\n",
            "[2023-01-12 16:42:50] \u001b[32mTrain: [ 15/600] Step 460/520 Loss 0.941 Prec@(1,5) (76.8%, 98.6%)\u001b[0m\n",
            "INFO:nni:Train: [ 15/600] Step 460/520 Loss 0.941 Prec@(1,5) (76.8%, 98.6%)\n",
            "[2023-01-12 16:42:55] \u001b[32mTrain: [ 15/600] Step 470/520 Loss 0.943 Prec@(1,5) (76.7%, 98.6%)\u001b[0m\n",
            "INFO:nni:Train: [ 15/600] Step 470/520 Loss 0.943 Prec@(1,5) (76.7%, 98.6%)\n",
            "[2023-01-12 16:42:59] \u001b[32mTrain: [ 15/600] Step 480/520 Loss 0.944 Prec@(1,5) (76.7%, 98.6%)\u001b[0m\n",
            "INFO:nni:Train: [ 15/600] Step 480/520 Loss 0.944 Prec@(1,5) (76.7%, 98.6%)\n",
            "[2023-01-12 16:43:04] \u001b[32mTrain: [ 15/600] Step 490/520 Loss 0.943 Prec@(1,5) (76.7%, 98.6%)\u001b[0m\n",
            "INFO:nni:Train: [ 15/600] Step 490/520 Loss 0.943 Prec@(1,5) (76.7%, 98.6%)\n",
            "[2023-01-12 16:43:08] \u001b[32mTrain: [ 15/600] Step 500/520 Loss 0.942 Prec@(1,5) (76.7%, 98.6%)\u001b[0m\n",
            "INFO:nni:Train: [ 15/600] Step 500/520 Loss 0.942 Prec@(1,5) (76.7%, 98.6%)\n",
            "[2023-01-12 16:43:13] \u001b[32mTrain: [ 15/600] Step 510/520 Loss 0.943 Prec@(1,5) (76.6%, 98.6%)\u001b[0m\n",
            "INFO:nni:Train: [ 15/600] Step 510/520 Loss 0.943 Prec@(1,5) (76.6%, 98.6%)\n",
            "[2023-01-12 16:43:17] \u001b[32mTrain: [ 15/600] Step 520/520 Loss 0.944 Prec@(1,5) (76.6%, 98.6%)\u001b[0m\n",
            "INFO:nni:Train: [ 15/600] Step 520/520 Loss 0.944 Prec@(1,5) (76.6%, 98.6%)\n",
            "[2023-01-12 16:43:18] \u001b[32mTrain: [ 15/600] Final Prec@1 76.6080%\u001b[0m\n",
            "INFO:nni:Train: [ 15/600] Final Prec@1 76.6080%\n",
            "[2023-01-12 16:43:18] \u001b[32mValid: [ 15/600] Step 000/104 Loss 0.643 Prec@(1,5) (78.1%, 97.9%)\u001b[0m\n",
            "INFO:nni:Valid: [ 15/600] Step 000/104 Loss 0.643 Prec@(1,5) (78.1%, 97.9%)\n",
            "[2023-01-12 16:43:19] \u001b[32mValid: [ 15/600] Step 010/104 Loss 0.557 Prec@(1,5) (79.8%, 99.2%)\u001b[0m\n",
            "INFO:nni:Valid: [ 15/600] Step 010/104 Loss 0.557 Prec@(1,5) (79.8%, 99.2%)\n",
            "[2023-01-12 16:43:21] \u001b[32mValid: [ 15/600] Step 020/104 Loss 0.527 Prec@(1,5) (81.2%, 99.2%)\u001b[0m\n",
            "INFO:nni:Valid: [ 15/600] Step 020/104 Loss 0.527 Prec@(1,5) (81.2%, 99.2%)\n",
            "[2023-01-12 16:43:22] \u001b[32mValid: [ 15/600] Step 030/104 Loss 0.553 Prec@(1,5) (80.4%, 99.2%)\u001b[0m\n",
            "INFO:nni:Valid: [ 15/600] Step 030/104 Loss 0.553 Prec@(1,5) (80.4%, 99.2%)\n",
            "[2023-01-12 16:43:24] \u001b[32mValid: [ 15/600] Step 040/104 Loss 0.562 Prec@(1,5) (80.2%, 99.0%)\u001b[0m\n",
            "INFO:nni:Valid: [ 15/600] Step 040/104 Loss 0.562 Prec@(1,5) (80.2%, 99.0%)\n",
            "[2023-01-12 16:43:25] \u001b[32mValid: [ 15/600] Step 050/104 Loss 0.557 Prec@(1,5) (80.5%, 99.0%)\u001b[0m\n",
            "INFO:nni:Valid: [ 15/600] Step 050/104 Loss 0.557 Prec@(1,5) (80.5%, 99.0%)\n",
            "[2023-01-12 16:43:26] \u001b[32mValid: [ 15/600] Step 060/104 Loss 0.552 Prec@(1,5) (80.9%, 99.0%)\u001b[0m\n",
            "INFO:nni:Valid: [ 15/600] Step 060/104 Loss 0.552 Prec@(1,5) (80.9%, 99.0%)\n",
            "[2023-01-12 16:43:28] \u001b[32mValid: [ 15/600] Step 070/104 Loss 0.555 Prec@(1,5) (80.9%, 99.0%)\u001b[0m\n",
            "INFO:nni:Valid: [ 15/600] Step 070/104 Loss 0.555 Prec@(1,5) (80.9%, 99.0%)\n",
            "[2023-01-12 16:43:29] \u001b[32mValid: [ 15/600] Step 080/104 Loss 0.561 Prec@(1,5) (80.7%, 99.0%)\u001b[0m\n",
            "INFO:nni:Valid: [ 15/600] Step 080/104 Loss 0.561 Prec@(1,5) (80.7%, 99.0%)\n",
            "[2023-01-12 16:43:31] \u001b[32mValid: [ 15/600] Step 090/104 Loss 0.564 Prec@(1,5) (80.6%, 99.0%)\u001b[0m\n",
            "INFO:nni:Valid: [ 15/600] Step 090/104 Loss 0.564 Prec@(1,5) (80.6%, 99.0%)\n",
            "[2023-01-12 16:43:32] \u001b[32mValid: [ 15/600] Step 100/104 Loss 0.562 Prec@(1,5) (80.6%, 99.0%)\u001b[0m\n",
            "INFO:nni:Valid: [ 15/600] Step 100/104 Loss 0.562 Prec@(1,5) (80.6%, 99.0%)\n",
            "[2023-01-12 16:43:32] \u001b[32mValid: [ 15/600] Step 104/104 Loss 0.563 Prec@(1,5) (80.6%, 99.0%)\u001b[0m\n",
            "INFO:nni:Valid: [ 15/600] Step 104/104 Loss 0.563 Prec@(1,5) (80.6%, 99.0%)\n",
            "[2023-01-12 16:43:33] \u001b[32mValid: [ 15/600] Final Prec@1 80.5800%\u001b[0m\n",
            "INFO:nni:Valid: [ 15/600] Final Prec@1 80.5800%\n",
            "[2023-01-12 16:43:33] \u001b[32mEpoch 15 LR 0.024961\u001b[0m\n",
            "INFO:nni:Epoch 15 LR 0.024961\n",
            "[2023-01-12 16:43:34] \u001b[32mTrain: [ 16/600] Step 000/520 Loss 0.933 Prec@(1,5) (75.0%, 99.0%)\u001b[0m\n",
            "INFO:nni:Train: [ 16/600] Step 000/520 Loss 0.933 Prec@(1,5) (75.0%, 99.0%)\n",
            "[2023-01-12 16:43:38] \u001b[32mTrain: [ 16/600] Step 010/520 Loss 0.898 Prec@(1,5) (79.1%, 98.2%)\u001b[0m\n",
            "INFO:nni:Train: [ 16/600] Step 010/520 Loss 0.898 Prec@(1,5) (79.1%, 98.2%)\n",
            "[2023-01-12 16:43:43] \u001b[32mTrain: [ 16/600] Step 020/520 Loss 0.884 Prec@(1,5) (77.8%, 98.6%)\u001b[0m\n",
            "INFO:nni:Train: [ 16/600] Step 020/520 Loss 0.884 Prec@(1,5) (77.8%, 98.6%)\n",
            "[2023-01-12 16:43:47] \u001b[32mTrain: [ 16/600] Step 030/520 Loss 0.864 Prec@(1,5) (78.2%, 98.7%)\u001b[0m\n",
            "INFO:nni:Train: [ 16/600] Step 030/520 Loss 0.864 Prec@(1,5) (78.2%, 98.7%)\n",
            "[2023-01-12 16:43:52] \u001b[32mTrain: [ 16/600] Step 040/520 Loss 0.873 Prec@(1,5) (78.3%, 98.6%)\u001b[0m\n",
            "INFO:nni:Train: [ 16/600] Step 040/520 Loss 0.873 Prec@(1,5) (78.3%, 98.6%)\n",
            "[2023-01-12 16:43:56] \u001b[32mTrain: [ 16/600] Step 050/520 Loss 0.878 Prec@(1,5) (78.4%, 98.6%)\u001b[0m\n",
            "INFO:nni:Train: [ 16/600] Step 050/520 Loss 0.878 Prec@(1,5) (78.4%, 98.6%)\n",
            "[2023-01-12 16:44:01] \u001b[32mTrain: [ 16/600] Step 060/520 Loss 0.874 Prec@(1,5) (78.3%, 98.7%)\u001b[0m\n",
            "INFO:nni:Train: [ 16/600] Step 060/520 Loss 0.874 Prec@(1,5) (78.3%, 98.7%)\n",
            "[2023-01-12 16:44:05] \u001b[32mTrain: [ 16/600] Step 070/520 Loss 0.881 Prec@(1,5) (77.9%, 98.7%)\u001b[0m\n",
            "INFO:nni:Train: [ 16/600] Step 070/520 Loss 0.881 Prec@(1,5) (77.9%, 98.7%)\n",
            "[2023-01-12 16:44:10] \u001b[32mTrain: [ 16/600] Step 080/520 Loss 0.896 Prec@(1,5) (77.8%, 98.7%)\u001b[0m\n",
            "INFO:nni:Train: [ 16/600] Step 080/520 Loss 0.896 Prec@(1,5) (77.8%, 98.7%)\n",
            "[2023-01-12 16:44:14] \u001b[32mTrain: [ 16/600] Step 090/520 Loss 0.901 Prec@(1,5) (77.7%, 98.7%)\u001b[0m\n",
            "INFO:nni:Train: [ 16/600] Step 090/520 Loss 0.901 Prec@(1,5) (77.7%, 98.7%)\n",
            "[2023-01-12 16:44:19] \u001b[32mTrain: [ 16/600] Step 100/520 Loss 0.902 Prec@(1,5) (77.8%, 98.7%)\u001b[0m\n",
            "INFO:nni:Train: [ 16/600] Step 100/520 Loss 0.902 Prec@(1,5) (77.8%, 98.7%)\n",
            "[2023-01-12 16:44:23] \u001b[32mTrain: [ 16/600] Step 110/520 Loss 0.909 Prec@(1,5) (77.7%, 98.7%)\u001b[0m\n",
            "INFO:nni:Train: [ 16/600] Step 110/520 Loss 0.909 Prec@(1,5) (77.7%, 98.7%)\n",
            "[2023-01-12 16:44:28] \u001b[32mTrain: [ 16/600] Step 120/520 Loss 0.903 Prec@(1,5) (77.8%, 98.7%)\u001b[0m\n",
            "INFO:nni:Train: [ 16/600] Step 120/520 Loss 0.903 Prec@(1,5) (77.8%, 98.7%)\n",
            "[2023-01-12 16:44:32] \u001b[32mTrain: [ 16/600] Step 130/520 Loss 0.904 Prec@(1,5) (77.8%, 98.7%)\u001b[0m\n",
            "INFO:nni:Train: [ 16/600] Step 130/520 Loss 0.904 Prec@(1,5) (77.8%, 98.7%)\n",
            "[2023-01-12 16:44:37] \u001b[32mTrain: [ 16/600] Step 140/520 Loss 0.901 Prec@(1,5) (77.9%, 98.7%)\u001b[0m\n",
            "INFO:nni:Train: [ 16/600] Step 140/520 Loss 0.901 Prec@(1,5) (77.9%, 98.7%)\n",
            "[2023-01-12 16:44:41] \u001b[32mTrain: [ 16/600] Step 150/520 Loss 0.902 Prec@(1,5) (77.9%, 98.7%)\u001b[0m\n",
            "INFO:nni:Train: [ 16/600] Step 150/520 Loss 0.902 Prec@(1,5) (77.9%, 98.7%)\n",
            "[2023-01-12 16:44:46] \u001b[32mTrain: [ 16/600] Step 160/520 Loss 0.904 Prec@(1,5) (77.9%, 98.7%)\u001b[0m\n",
            "INFO:nni:Train: [ 16/600] Step 160/520 Loss 0.904 Prec@(1,5) (77.9%, 98.7%)\n",
            "[2023-01-12 16:44:50] \u001b[32mTrain: [ 16/600] Step 170/520 Loss 0.909 Prec@(1,5) (77.8%, 98.7%)\u001b[0m\n",
            "INFO:nni:Train: [ 16/600] Step 170/520 Loss 0.909 Prec@(1,5) (77.8%, 98.7%)\n",
            "[2023-01-12 16:44:55] \u001b[32mTrain: [ 16/600] Step 180/520 Loss 0.910 Prec@(1,5) (77.8%, 98.7%)\u001b[0m\n",
            "INFO:nni:Train: [ 16/600] Step 180/520 Loss 0.910 Prec@(1,5) (77.8%, 98.7%)\n",
            "[2023-01-12 16:44:59] \u001b[32mTrain: [ 16/600] Step 190/520 Loss 0.910 Prec@(1,5) (77.9%, 98.7%)\u001b[0m\n",
            "INFO:nni:Train: [ 16/600] Step 190/520 Loss 0.910 Prec@(1,5) (77.9%, 98.7%)\n",
            "[2023-01-12 16:45:04] \u001b[32mTrain: [ 16/600] Step 200/520 Loss 0.909 Prec@(1,5) (77.9%, 98.7%)\u001b[0m\n",
            "INFO:nni:Train: [ 16/600] Step 200/520 Loss 0.909 Prec@(1,5) (77.9%, 98.7%)\n",
            "[2023-01-12 16:45:08] \u001b[32mTrain: [ 16/600] Step 210/520 Loss 0.912 Prec@(1,5) (77.8%, 98.7%)\u001b[0m\n",
            "INFO:nni:Train: [ 16/600] Step 210/520 Loss 0.912 Prec@(1,5) (77.8%, 98.7%)\n",
            "[2023-01-12 16:45:13] \u001b[32mTrain: [ 16/600] Step 220/520 Loss 0.913 Prec@(1,5) (77.8%, 98.7%)\u001b[0m\n",
            "INFO:nni:Train: [ 16/600] Step 220/520 Loss 0.913 Prec@(1,5) (77.8%, 98.7%)\n",
            "[2023-01-12 16:45:17] \u001b[32mTrain: [ 16/600] Step 230/520 Loss 0.914 Prec@(1,5) (77.7%, 98.7%)\u001b[0m\n",
            "INFO:nni:Train: [ 16/600] Step 230/520 Loss 0.914 Prec@(1,5) (77.7%, 98.7%)\n",
            "[2023-01-12 16:45:22] \u001b[32mTrain: [ 16/600] Step 240/520 Loss 0.914 Prec@(1,5) (77.7%, 98.7%)\u001b[0m\n",
            "INFO:nni:Train: [ 16/600] Step 240/520 Loss 0.914 Prec@(1,5) (77.7%, 98.7%)\n",
            "[2023-01-12 16:45:26] \u001b[32mTrain: [ 16/600] Step 250/520 Loss 0.917 Prec@(1,5) (77.7%, 98.6%)\u001b[0m\n",
            "INFO:nni:Train: [ 16/600] Step 250/520 Loss 0.917 Prec@(1,5) (77.7%, 98.6%)\n",
            "[2023-01-12 16:45:31] \u001b[32mTrain: [ 16/600] Step 260/520 Loss 0.916 Prec@(1,5) (77.7%, 98.7%)\u001b[0m\n",
            "INFO:nni:Train: [ 16/600] Step 260/520 Loss 0.916 Prec@(1,5) (77.7%, 98.7%)\n",
            "[2023-01-12 16:45:36] \u001b[32mTrain: [ 16/600] Step 270/520 Loss 0.916 Prec@(1,5) (77.7%, 98.7%)\u001b[0m\n",
            "INFO:nni:Train: [ 16/600] Step 270/520 Loss 0.916 Prec@(1,5) (77.7%, 98.7%)\n",
            "[2023-01-12 16:45:40] \u001b[32mTrain: [ 16/600] Step 280/520 Loss 0.914 Prec@(1,5) (77.7%, 98.6%)\u001b[0m\n",
            "INFO:nni:Train: [ 16/600] Step 280/520 Loss 0.914 Prec@(1,5) (77.7%, 98.6%)\n",
            "[2023-01-12 16:45:45] \u001b[32mTrain: [ 16/600] Step 290/520 Loss 0.913 Prec@(1,5) (77.7%, 98.6%)\u001b[0m\n",
            "INFO:nni:Train: [ 16/600] Step 290/520 Loss 0.913 Prec@(1,5) (77.7%, 98.6%)\n",
            "[2023-01-12 16:45:49] \u001b[32mTrain: [ 16/600] Step 300/520 Loss 0.916 Prec@(1,5) (77.6%, 98.6%)\u001b[0m\n",
            "INFO:nni:Train: [ 16/600] Step 300/520 Loss 0.916 Prec@(1,5) (77.6%, 98.6%)\n",
            "[2023-01-12 16:45:54] \u001b[32mTrain: [ 16/600] Step 310/520 Loss 0.916 Prec@(1,5) (77.6%, 98.6%)\u001b[0m\n",
            "INFO:nni:Train: [ 16/600] Step 310/520 Loss 0.916 Prec@(1,5) (77.6%, 98.6%)\n",
            "[2023-01-12 16:45:58] \u001b[32mTrain: [ 16/600] Step 320/520 Loss 0.915 Prec@(1,5) (77.7%, 98.6%)\u001b[0m\n",
            "INFO:nni:Train: [ 16/600] Step 320/520 Loss 0.915 Prec@(1,5) (77.7%, 98.6%)\n",
            "[2023-01-12 16:46:03] \u001b[32mTrain: [ 16/600] Step 330/520 Loss 0.919 Prec@(1,5) (77.6%, 98.6%)\u001b[0m\n",
            "INFO:nni:Train: [ 16/600] Step 330/520 Loss 0.919 Prec@(1,5) (77.6%, 98.6%)\n",
            "[2023-01-12 16:46:07] \u001b[32mTrain: [ 16/600] Step 340/520 Loss 0.921 Prec@(1,5) (77.5%, 98.6%)\u001b[0m\n",
            "INFO:nni:Train: [ 16/600] Step 340/520 Loss 0.921 Prec@(1,5) (77.5%, 98.6%)\n",
            "[2023-01-12 16:46:12] \u001b[32mTrain: [ 16/600] Step 350/520 Loss 0.920 Prec@(1,5) (77.5%, 98.6%)\u001b[0m\n",
            "INFO:nni:Train: [ 16/600] Step 350/520 Loss 0.920 Prec@(1,5) (77.5%, 98.6%)\n",
            "[2023-01-12 16:46:16] \u001b[32mTrain: [ 16/600] Step 360/520 Loss 0.920 Prec@(1,5) (77.5%, 98.6%)\u001b[0m\n",
            "INFO:nni:Train: [ 16/600] Step 360/520 Loss 0.920 Prec@(1,5) (77.5%, 98.6%)\n",
            "[2023-01-12 16:46:21] \u001b[32mTrain: [ 16/600] Step 370/520 Loss 0.919 Prec@(1,5) (77.5%, 98.6%)\u001b[0m\n",
            "INFO:nni:Train: [ 16/600] Step 370/520 Loss 0.919 Prec@(1,5) (77.5%, 98.6%)\n",
            "[2023-01-12 16:46:25] \u001b[32mTrain: [ 16/600] Step 380/520 Loss 0.919 Prec@(1,5) (77.5%, 98.6%)\u001b[0m\n",
            "INFO:nni:Train: [ 16/600] Step 380/520 Loss 0.919 Prec@(1,5) (77.5%, 98.6%)\n",
            "[2023-01-12 16:46:30] \u001b[32mTrain: [ 16/600] Step 390/520 Loss 0.919 Prec@(1,5) (77.5%, 98.6%)\u001b[0m\n",
            "INFO:nni:Train: [ 16/600] Step 390/520 Loss 0.919 Prec@(1,5) (77.5%, 98.6%)\n",
            "[2023-01-12 16:46:34] \u001b[32mTrain: [ 16/600] Step 400/520 Loss 0.916 Prec@(1,5) (77.6%, 98.6%)\u001b[0m\n",
            "INFO:nni:Train: [ 16/600] Step 400/520 Loss 0.916 Prec@(1,5) (77.6%, 98.6%)\n",
            "[2023-01-12 16:46:39] \u001b[32mTrain: [ 16/600] Step 410/520 Loss 0.914 Prec@(1,5) (77.6%, 98.7%)\u001b[0m\n",
            "INFO:nni:Train: [ 16/600] Step 410/520 Loss 0.914 Prec@(1,5) (77.6%, 98.7%)\n",
            "[2023-01-12 16:46:43] \u001b[32mTrain: [ 16/600] Step 420/520 Loss 0.914 Prec@(1,5) (77.6%, 98.7%)\u001b[0m\n",
            "INFO:nni:Train: [ 16/600] Step 420/520 Loss 0.914 Prec@(1,5) (77.6%, 98.7%)\n",
            "[2023-01-12 16:46:48] \u001b[32mTrain: [ 16/600] Step 430/520 Loss 0.915 Prec@(1,5) (77.6%, 98.7%)\u001b[0m\n",
            "INFO:nni:Train: [ 16/600] Step 430/520 Loss 0.915 Prec@(1,5) (77.6%, 98.7%)\n",
            "[2023-01-12 16:46:52] \u001b[32mTrain: [ 16/600] Step 440/520 Loss 0.915 Prec@(1,5) (77.6%, 98.6%)\u001b[0m\n",
            "INFO:nni:Train: [ 16/600] Step 440/520 Loss 0.915 Prec@(1,5) (77.6%, 98.6%)\n",
            "[2023-01-12 16:46:57] \u001b[32mTrain: [ 16/600] Step 450/520 Loss 0.915 Prec@(1,5) (77.6%, 98.6%)\u001b[0m\n",
            "INFO:nni:Train: [ 16/600] Step 450/520 Loss 0.915 Prec@(1,5) (77.6%, 98.6%)\n",
            "[2023-01-12 16:47:01] \u001b[32mTrain: [ 16/600] Step 460/520 Loss 0.914 Prec@(1,5) (77.7%, 98.6%)\u001b[0m\n",
            "INFO:nni:Train: [ 16/600] Step 460/520 Loss 0.914 Prec@(1,5) (77.7%, 98.6%)\n",
            "[2023-01-12 16:47:06] \u001b[32mTrain: [ 16/600] Step 470/520 Loss 0.914 Prec@(1,5) (77.7%, 98.6%)\u001b[0m\n",
            "INFO:nni:Train: [ 16/600] Step 470/520 Loss 0.914 Prec@(1,5) (77.7%, 98.6%)\n",
            "[2023-01-12 16:47:10] \u001b[32mTrain: [ 16/600] Step 480/520 Loss 0.915 Prec@(1,5) (77.6%, 98.6%)\u001b[0m\n",
            "INFO:nni:Train: [ 16/600] Step 480/520 Loss 0.915 Prec@(1,5) (77.6%, 98.6%)\n",
            "[2023-01-12 16:47:15] \u001b[32mTrain: [ 16/600] Step 490/520 Loss 0.916 Prec@(1,5) (77.6%, 98.6%)\u001b[0m\n",
            "INFO:nni:Train: [ 16/600] Step 490/520 Loss 0.916 Prec@(1,5) (77.6%, 98.6%)\n",
            "[2023-01-12 16:47:19] \u001b[32mTrain: [ 16/600] Step 500/520 Loss 0.917 Prec@(1,5) (77.6%, 98.6%)\u001b[0m\n",
            "INFO:nni:Train: [ 16/600] Step 500/520 Loss 0.917 Prec@(1,5) (77.6%, 98.6%)\n",
            "[2023-01-12 16:47:24] \u001b[32mTrain: [ 16/600] Step 510/520 Loss 0.917 Prec@(1,5) (77.6%, 98.6%)\u001b[0m\n",
            "INFO:nni:Train: [ 16/600] Step 510/520 Loss 0.917 Prec@(1,5) (77.6%, 98.6%)\n",
            "[2023-01-12 16:47:28] \u001b[32mTrain: [ 16/600] Step 520/520 Loss 0.917 Prec@(1,5) (77.6%, 98.6%)\u001b[0m\n",
            "INFO:nni:Train: [ 16/600] Step 520/520 Loss 0.917 Prec@(1,5) (77.6%, 98.6%)\n",
            "[2023-01-12 16:47:29] \u001b[32mTrain: [ 16/600] Final Prec@1 77.5940%\u001b[0m\n",
            "INFO:nni:Train: [ 16/600] Final Prec@1 77.5940%\n",
            "[2023-01-12 16:47:29] \u001b[32mValid: [ 16/600] Step 000/104 Loss 0.547 Prec@(1,5) (79.2%, 99.0%)\u001b[0m\n",
            "INFO:nni:Valid: [ 16/600] Step 000/104 Loss 0.547 Prec@(1,5) (79.2%, 99.0%)\n",
            "[2023-01-12 16:47:30] \u001b[32mValid: [ 16/600] Step 010/104 Loss 0.557 Prec@(1,5) (80.9%, 99.1%)\u001b[0m\n",
            "INFO:nni:Valid: [ 16/600] Step 010/104 Loss 0.557 Prec@(1,5) (80.9%, 99.1%)\n",
            "[2023-01-12 16:47:32] \u001b[32mValid: [ 16/600] Step 020/104 Loss 0.535 Prec@(1,5) (81.3%, 99.3%)\u001b[0m\n",
            "INFO:nni:Valid: [ 16/600] Step 020/104 Loss 0.535 Prec@(1,5) (81.3%, 99.3%)\n",
            "[2023-01-12 16:47:33] \u001b[32mValid: [ 16/600] Step 030/104 Loss 0.542 Prec@(1,5) (81.6%, 99.0%)\u001b[0m\n",
            "INFO:nni:Valid: [ 16/600] Step 030/104 Loss 0.542 Prec@(1,5) (81.6%, 99.0%)\n",
            "[2023-01-12 16:47:35] \u001b[32mValid: [ 16/600] Step 040/104 Loss 0.549 Prec@(1,5) (81.2%, 98.9%)\u001b[0m\n",
            "INFO:nni:Valid: [ 16/600] Step 040/104 Loss 0.549 Prec@(1,5) (81.2%, 98.9%)\n",
            "[2023-01-12 16:47:36] \u001b[32mValid: [ 16/600] Step 050/104 Loss 0.541 Prec@(1,5) (81.5%, 98.9%)\u001b[0m\n",
            "INFO:nni:Valid: [ 16/600] Step 050/104 Loss 0.541 Prec@(1,5) (81.5%, 98.9%)\n",
            "[2023-01-12 16:47:37] \u001b[32mValid: [ 16/600] Step 060/104 Loss 0.540 Prec@(1,5) (81.6%, 99.0%)\u001b[0m\n",
            "INFO:nni:Valid: [ 16/600] Step 060/104 Loss 0.540 Prec@(1,5) (81.6%, 99.0%)\n",
            "[2023-01-12 16:47:39] \u001b[32mValid: [ 16/600] Step 070/104 Loss 0.544 Prec@(1,5) (81.6%, 99.0%)\u001b[0m\n",
            "INFO:nni:Valid: [ 16/600] Step 070/104 Loss 0.544 Prec@(1,5) (81.6%, 99.0%)\n",
            "[2023-01-12 16:47:40] \u001b[32mValid: [ 16/600] Step 080/104 Loss 0.546 Prec@(1,5) (81.6%, 99.1%)\u001b[0m\n",
            "INFO:nni:Valid: [ 16/600] Step 080/104 Loss 0.546 Prec@(1,5) (81.6%, 99.1%)\n",
            "[2023-01-12 16:47:42] \u001b[32mValid: [ 16/600] Step 090/104 Loss 0.545 Prec@(1,5) (81.5%, 99.2%)\u001b[0m\n",
            "INFO:nni:Valid: [ 16/600] Step 090/104 Loss 0.545 Prec@(1,5) (81.5%, 99.2%)\n",
            "[2023-01-12 16:47:43] \u001b[32mValid: [ 16/600] Step 100/104 Loss 0.538 Prec@(1,5) (81.7%, 99.1%)\u001b[0m\n",
            "INFO:nni:Valid: [ 16/600] Step 100/104 Loss 0.538 Prec@(1,5) (81.7%, 99.1%)\n",
            "[2023-01-12 16:47:44] \u001b[32mValid: [ 16/600] Step 104/104 Loss 0.538 Prec@(1,5) (81.6%, 99.2%)\u001b[0m\n",
            "INFO:nni:Valid: [ 16/600] Step 104/104 Loss 0.538 Prec@(1,5) (81.6%, 99.2%)\n",
            "[2023-01-12 16:47:44] \u001b[32mValid: [ 16/600] Final Prec@1 81.6100%\u001b[0m\n",
            "INFO:nni:Valid: [ 16/600] Final Prec@1 81.6100%\n",
            "[2023-01-12 16:47:44] \u001b[32mEpoch 16 LR 0.024956\u001b[0m\n",
            "INFO:nni:Epoch 16 LR 0.024956\n",
            "[2023-01-12 16:47:45] \u001b[32mTrain: [ 17/600] Step 000/520 Loss 0.955 Prec@(1,5) (80.2%, 99.0%)\u001b[0m\n",
            "INFO:nni:Train: [ 17/600] Step 000/520 Loss 0.955 Prec@(1,5) (80.2%, 99.0%)\n",
            "[2023-01-12 16:47:49] \u001b[32mTrain: [ 17/600] Step 010/520 Loss 0.919 Prec@(1,5) (76.9%, 99.1%)\u001b[0m\n",
            "INFO:nni:Train: [ 17/600] Step 010/520 Loss 0.919 Prec@(1,5) (76.9%, 99.1%)\n",
            "[2023-01-12 16:47:54] \u001b[32mTrain: [ 17/600] Step 020/520 Loss 0.912 Prec@(1,5) (77.4%, 98.8%)\u001b[0m\n",
            "INFO:nni:Train: [ 17/600] Step 020/520 Loss 0.912 Prec@(1,5) (77.4%, 98.8%)\n",
            "[2023-01-12 16:47:58] \u001b[32mTrain: [ 17/600] Step 030/520 Loss 0.903 Prec@(1,5) (77.3%, 98.9%)\u001b[0m\n",
            "INFO:nni:Train: [ 17/600] Step 030/520 Loss 0.903 Prec@(1,5) (77.3%, 98.9%)\n",
            "[2023-01-12 16:48:03] \u001b[32mTrain: [ 17/600] Step 040/520 Loss 0.892 Prec@(1,5) (78.0%, 98.8%)\u001b[0m\n",
            "INFO:nni:Train: [ 17/600] Step 040/520 Loss 0.892 Prec@(1,5) (78.0%, 98.8%)\n",
            "[2023-01-12 16:48:07] \u001b[32mTrain: [ 17/600] Step 050/520 Loss 0.874 Prec@(1,5) (78.3%, 98.9%)\u001b[0m\n",
            "INFO:nni:Train: [ 17/600] Step 050/520 Loss 0.874 Prec@(1,5) (78.3%, 98.9%)\n",
            "[2023-01-12 16:48:12] \u001b[32mTrain: [ 17/600] Step 060/520 Loss 0.895 Prec@(1,5) (77.9%, 98.8%)\u001b[0m\n",
            "INFO:nni:Train: [ 17/600] Step 060/520 Loss 0.895 Prec@(1,5) (77.9%, 98.8%)\n",
            "[2023-01-12 16:48:16] \u001b[32mTrain: [ 17/600] Step 070/520 Loss 0.904 Prec@(1,5) (77.6%, 98.8%)\u001b[0m\n",
            "INFO:nni:Train: [ 17/600] Step 070/520 Loss 0.904 Prec@(1,5) (77.6%, 98.8%)\n",
            "[2023-01-12 16:48:21] \u001b[32mTrain: [ 17/600] Step 080/520 Loss 0.907 Prec@(1,5) (77.5%, 98.8%)\u001b[0m\n",
            "INFO:nni:Train: [ 17/600] Step 080/520 Loss 0.907 Prec@(1,5) (77.5%, 98.8%)\n",
            "[2023-01-12 16:48:25] \u001b[32mTrain: [ 17/600] Step 090/520 Loss 0.919 Prec@(1,5) (77.2%, 98.7%)\u001b[0m\n",
            "INFO:nni:Train: [ 17/600] Step 090/520 Loss 0.919 Prec@(1,5) (77.2%, 98.7%)\n",
            "[2023-01-12 16:48:30] \u001b[32mTrain: [ 17/600] Step 100/520 Loss 0.911 Prec@(1,5) (77.4%, 98.7%)\u001b[0m\n",
            "INFO:nni:Train: [ 17/600] Step 100/520 Loss 0.911 Prec@(1,5) (77.4%, 98.7%)\n",
            "[2023-01-12 16:48:34] \u001b[32mTrain: [ 17/600] Step 110/520 Loss 0.909 Prec@(1,5) (77.5%, 98.8%)\u001b[0m\n",
            "INFO:nni:Train: [ 17/600] Step 110/520 Loss 0.909 Prec@(1,5) (77.5%, 98.8%)\n",
            "[2023-01-12 16:48:39] \u001b[32mTrain: [ 17/600] Step 120/520 Loss 0.904 Prec@(1,5) (77.6%, 98.8%)\u001b[0m\n",
            "INFO:nni:Train: [ 17/600] Step 120/520 Loss 0.904 Prec@(1,5) (77.6%, 98.8%)\n",
            "[2023-01-12 16:48:43] \u001b[32mTrain: [ 17/600] Step 130/520 Loss 0.903 Prec@(1,5) (77.7%, 98.7%)\u001b[0m\n",
            "INFO:nni:Train: [ 17/600] Step 130/520 Loss 0.903 Prec@(1,5) (77.7%, 98.7%)\n",
            "[2023-01-12 16:48:48] \u001b[32mTrain: [ 17/600] Step 140/520 Loss 0.901 Prec@(1,5) (77.7%, 98.7%)\u001b[0m\n",
            "INFO:nni:Train: [ 17/600] Step 140/520 Loss 0.901 Prec@(1,5) (77.7%, 98.7%)\n",
            "[2023-01-12 16:48:52] \u001b[32mTrain: [ 17/600] Step 150/520 Loss 0.899 Prec@(1,5) (77.8%, 98.8%)\u001b[0m\n",
            "INFO:nni:Train: [ 17/600] Step 150/520 Loss 0.899 Prec@(1,5) (77.8%, 98.8%)\n",
            "[2023-01-12 16:48:57] \u001b[32mTrain: [ 17/600] Step 160/520 Loss 0.896 Prec@(1,5) (77.8%, 98.8%)\u001b[0m\n",
            "INFO:nni:Train: [ 17/600] Step 160/520 Loss 0.896 Prec@(1,5) (77.8%, 98.8%)\n",
            "[2023-01-12 16:49:01] \u001b[32mTrain: [ 17/600] Step 170/520 Loss 0.896 Prec@(1,5) (77.9%, 98.8%)\u001b[0m\n",
            "INFO:nni:Train: [ 17/600] Step 170/520 Loss 0.896 Prec@(1,5) (77.9%, 98.8%)\n",
            "[2023-01-12 16:49:06] \u001b[32mTrain: [ 17/600] Step 180/520 Loss 0.894 Prec@(1,5) (77.9%, 98.8%)\u001b[0m\n",
            "INFO:nni:Train: [ 17/600] Step 180/520 Loss 0.894 Prec@(1,5) (77.9%, 98.8%)\n",
            "[2023-01-12 16:49:10] \u001b[32mTrain: [ 17/600] Step 190/520 Loss 0.895 Prec@(1,5) (77.8%, 98.8%)\u001b[0m\n",
            "INFO:nni:Train: [ 17/600] Step 190/520 Loss 0.895 Prec@(1,5) (77.8%, 98.8%)\n",
            "[2023-01-12 16:49:15] \u001b[32mTrain: [ 17/600] Step 200/520 Loss 0.892 Prec@(1,5) (77.8%, 98.8%)\u001b[0m\n",
            "INFO:nni:Train: [ 17/600] Step 200/520 Loss 0.892 Prec@(1,5) (77.8%, 98.8%)\n",
            "[2023-01-12 16:49:19] \u001b[32mTrain: [ 17/600] Step 210/520 Loss 0.894 Prec@(1,5) (77.7%, 98.8%)\u001b[0m\n",
            "INFO:nni:Train: [ 17/600] Step 210/520 Loss 0.894 Prec@(1,5) (77.7%, 98.8%)\n",
            "[2023-01-12 16:49:24] \u001b[32mTrain: [ 17/600] Step 220/520 Loss 0.895 Prec@(1,5) (77.8%, 98.8%)\u001b[0m\n",
            "INFO:nni:Train: [ 17/600] Step 220/520 Loss 0.895 Prec@(1,5) (77.8%, 98.8%)\n",
            "[2023-01-12 16:49:28] \u001b[32mTrain: [ 17/600] Step 230/520 Loss 0.896 Prec@(1,5) (77.7%, 98.8%)\u001b[0m\n",
            "INFO:nni:Train: [ 17/600] Step 230/520 Loss 0.896 Prec@(1,5) (77.7%, 98.8%)\n",
            "[2023-01-12 16:49:33] \u001b[32mTrain: [ 17/600] Step 240/520 Loss 0.899 Prec@(1,5) (77.7%, 98.8%)\u001b[0m\n",
            "INFO:nni:Train: [ 17/600] Step 240/520 Loss 0.899 Prec@(1,5) (77.7%, 98.8%)\n",
            "[2023-01-12 16:49:37] \u001b[32mTrain: [ 17/600] Step 250/520 Loss 0.899 Prec@(1,5) (77.7%, 98.8%)\u001b[0m\n",
            "INFO:nni:Train: [ 17/600] Step 250/520 Loss 0.899 Prec@(1,5) (77.7%, 98.8%)\n",
            "[2023-01-12 16:49:42] \u001b[32mTrain: [ 17/600] Step 260/520 Loss 0.898 Prec@(1,5) (77.7%, 98.7%)\u001b[0m\n",
            "INFO:nni:Train: [ 17/600] Step 260/520 Loss 0.898 Prec@(1,5) (77.7%, 98.7%)\n",
            "[2023-01-12 16:49:47] \u001b[32mTrain: [ 17/600] Step 270/520 Loss 0.900 Prec@(1,5) (77.7%, 98.7%)\u001b[0m\n",
            "INFO:nni:Train: [ 17/600] Step 270/520 Loss 0.900 Prec@(1,5) (77.7%, 98.7%)\n",
            "[2023-01-12 16:49:51] \u001b[32mTrain: [ 17/600] Step 280/520 Loss 0.898 Prec@(1,5) (77.7%, 98.7%)\u001b[0m\n",
            "INFO:nni:Train: [ 17/600] Step 280/520 Loss 0.898 Prec@(1,5) (77.7%, 98.7%)\n",
            "[2023-01-12 16:49:56] \u001b[32mTrain: [ 17/600] Step 290/520 Loss 0.898 Prec@(1,5) (77.7%, 98.7%)\u001b[0m\n",
            "INFO:nni:Train: [ 17/600] Step 290/520 Loss 0.898 Prec@(1,5) (77.7%, 98.7%)\n",
            "[2023-01-12 16:50:00] \u001b[32mTrain: [ 17/600] Step 300/520 Loss 0.897 Prec@(1,5) (77.8%, 98.7%)\u001b[0m\n",
            "INFO:nni:Train: [ 17/600] Step 300/520 Loss 0.897 Prec@(1,5) (77.8%, 98.7%)\n",
            "[2023-01-12 16:50:05] \u001b[32mTrain: [ 17/600] Step 310/520 Loss 0.897 Prec@(1,5) (77.7%, 98.7%)\u001b[0m\n",
            "INFO:nni:Train: [ 17/600] Step 310/520 Loss 0.897 Prec@(1,5) (77.7%, 98.7%)\n",
            "[2023-01-12 16:50:09] \u001b[32mTrain: [ 17/600] Step 320/520 Loss 0.896 Prec@(1,5) (77.7%, 98.8%)\u001b[0m\n",
            "INFO:nni:Train: [ 17/600] Step 320/520 Loss 0.896 Prec@(1,5) (77.7%, 98.8%)\n",
            "[2023-01-12 16:50:14] \u001b[32mTrain: [ 17/600] Step 330/520 Loss 0.895 Prec@(1,5) (77.7%, 98.8%)\u001b[0m\n",
            "INFO:nni:Train: [ 17/600] Step 330/520 Loss 0.895 Prec@(1,5) (77.7%, 98.8%)\n",
            "[2023-01-12 16:50:18] \u001b[32mTrain: [ 17/600] Step 340/520 Loss 0.895 Prec@(1,5) (77.7%, 98.8%)\u001b[0m\n",
            "INFO:nni:Train: [ 17/600] Step 340/520 Loss 0.895 Prec@(1,5) (77.7%, 98.8%)\n",
            "[2023-01-12 16:50:23] \u001b[32mTrain: [ 17/600] Step 350/520 Loss 0.895 Prec@(1,5) (77.7%, 98.8%)\u001b[0m\n",
            "INFO:nni:Train: [ 17/600] Step 350/520 Loss 0.895 Prec@(1,5) (77.7%, 98.8%)\n",
            "[2023-01-12 16:50:27] \u001b[32mTrain: [ 17/600] Step 360/520 Loss 0.894 Prec@(1,5) (77.8%, 98.8%)\u001b[0m\n",
            "INFO:nni:Train: [ 17/600] Step 360/520 Loss 0.894 Prec@(1,5) (77.8%, 98.8%)\n",
            "[2023-01-12 16:50:32] \u001b[32mTrain: [ 17/600] Step 370/520 Loss 0.895 Prec@(1,5) (77.7%, 98.8%)\u001b[0m\n",
            "INFO:nni:Train: [ 17/600] Step 370/520 Loss 0.895 Prec@(1,5) (77.7%, 98.8%)\n",
            "[2023-01-12 16:50:36] \u001b[32mTrain: [ 17/600] Step 380/520 Loss 0.895 Prec@(1,5) (77.8%, 98.8%)\u001b[0m\n",
            "INFO:nni:Train: [ 17/600] Step 380/520 Loss 0.895 Prec@(1,5) (77.8%, 98.8%)\n",
            "[2023-01-12 16:50:41] \u001b[32mTrain: [ 17/600] Step 390/520 Loss 0.897 Prec@(1,5) (77.7%, 98.7%)\u001b[0m\n",
            "INFO:nni:Train: [ 17/600] Step 390/520 Loss 0.897 Prec@(1,5) (77.7%, 98.7%)\n",
            "[2023-01-12 16:50:45] \u001b[32mTrain: [ 17/600] Step 400/520 Loss 0.898 Prec@(1,5) (77.7%, 98.7%)\u001b[0m\n",
            "INFO:nni:Train: [ 17/600] Step 400/520 Loss 0.898 Prec@(1,5) (77.7%, 98.7%)\n",
            "[2023-01-12 16:50:50] \u001b[32mTrain: [ 17/600] Step 410/520 Loss 0.901 Prec@(1,5) (77.6%, 98.7%)\u001b[0m\n",
            "INFO:nni:Train: [ 17/600] Step 410/520 Loss 0.901 Prec@(1,5) (77.6%, 98.7%)\n",
            "[2023-01-12 16:50:54] \u001b[32mTrain: [ 17/600] Step 420/520 Loss 0.902 Prec@(1,5) (77.6%, 98.7%)\u001b[0m\n",
            "INFO:nni:Train: [ 17/600] Step 420/520 Loss 0.902 Prec@(1,5) (77.6%, 98.7%)\n",
            "[2023-01-12 16:50:59] \u001b[32mTrain: [ 17/600] Step 430/520 Loss 0.903 Prec@(1,5) (77.6%, 98.7%)\u001b[0m\n",
            "INFO:nni:Train: [ 17/600] Step 430/520 Loss 0.903 Prec@(1,5) (77.6%, 98.7%)\n",
            "[2023-01-12 16:51:03] \u001b[32mTrain: [ 17/600] Step 440/520 Loss 0.903 Prec@(1,5) (77.6%, 98.7%)\u001b[0m\n",
            "INFO:nni:Train: [ 17/600] Step 440/520 Loss 0.903 Prec@(1,5) (77.6%, 98.7%)\n",
            "[2023-01-12 16:51:08] \u001b[32mTrain: [ 17/600] Step 450/520 Loss 0.903 Prec@(1,5) (77.6%, 98.7%)\u001b[0m\n",
            "INFO:nni:Train: [ 17/600] Step 450/520 Loss 0.903 Prec@(1,5) (77.6%, 98.7%)\n",
            "[2023-01-12 16:51:12] \u001b[32mTrain: [ 17/600] Step 460/520 Loss 0.902 Prec@(1,5) (77.6%, 98.7%)\u001b[0m\n",
            "INFO:nni:Train: [ 17/600] Step 460/520 Loss 0.902 Prec@(1,5) (77.6%, 98.7%)\n",
            "[2023-01-12 16:51:17] \u001b[32mTrain: [ 17/600] Step 470/520 Loss 0.902 Prec@(1,5) (77.6%, 98.7%)\u001b[0m\n",
            "INFO:nni:Train: [ 17/600] Step 470/520 Loss 0.902 Prec@(1,5) (77.6%, 98.7%)\n",
            "[2023-01-12 16:51:21] \u001b[32mTrain: [ 17/600] Step 480/520 Loss 0.902 Prec@(1,5) (77.6%, 98.7%)\u001b[0m\n",
            "INFO:nni:Train: [ 17/600] Step 480/520 Loss 0.902 Prec@(1,5) (77.6%, 98.7%)\n",
            "[2023-01-12 16:51:26] \u001b[32mTrain: [ 17/600] Step 490/520 Loss 0.901 Prec@(1,5) (77.7%, 98.7%)\u001b[0m\n",
            "INFO:nni:Train: [ 17/600] Step 490/520 Loss 0.901 Prec@(1,5) (77.7%, 98.7%)\n",
            "[2023-01-12 16:51:30] \u001b[32mTrain: [ 17/600] Step 500/520 Loss 0.900 Prec@(1,5) (77.7%, 98.7%)\u001b[0m\n",
            "INFO:nni:Train: [ 17/600] Step 500/520 Loss 0.900 Prec@(1,5) (77.7%, 98.7%)\n",
            "[2023-01-12 16:51:35] \u001b[32mTrain: [ 17/600] Step 510/520 Loss 0.899 Prec@(1,5) (77.7%, 98.7%)\u001b[0m\n",
            "INFO:nni:Train: [ 17/600] Step 510/520 Loss 0.899 Prec@(1,5) (77.7%, 98.7%)\n",
            "[2023-01-12 16:51:39] \u001b[32mTrain: [ 17/600] Step 520/520 Loss 0.900 Prec@(1,5) (77.7%, 98.7%)\u001b[0m\n",
            "INFO:nni:Train: [ 17/600] Step 520/520 Loss 0.900 Prec@(1,5) (77.7%, 98.7%)\n",
            "[2023-01-12 16:51:39] \u001b[32mTrain: [ 17/600] Final Prec@1 77.6960%\u001b[0m\n",
            "INFO:nni:Train: [ 17/600] Final Prec@1 77.6960%\n",
            "[2023-01-12 16:51:40] \u001b[32mValid: [ 17/600] Step 000/104 Loss 0.602 Prec@(1,5) (80.2%, 99.0%)\u001b[0m\n",
            "INFO:nni:Valid: [ 17/600] Step 000/104 Loss 0.602 Prec@(1,5) (80.2%, 99.0%)\n",
            "[2023-01-12 16:51:41] \u001b[32mValid: [ 17/600] Step 010/104 Loss 0.558 Prec@(1,5) (80.8%, 99.2%)\u001b[0m\n",
            "INFO:nni:Valid: [ 17/600] Step 010/104 Loss 0.558 Prec@(1,5) (80.8%, 99.2%)\n",
            "[2023-01-12 16:51:43] \u001b[32mValid: [ 17/600] Step 020/104 Loss 0.549 Prec@(1,5) (81.3%, 99.3%)\u001b[0m\n",
            "INFO:nni:Valid: [ 17/600] Step 020/104 Loss 0.549 Prec@(1,5) (81.3%, 99.3%)\n",
            "[2023-01-12 16:51:44] \u001b[32mValid: [ 17/600] Step 030/104 Loss 0.544 Prec@(1,5) (81.9%, 99.1%)\u001b[0m\n",
            "INFO:nni:Valid: [ 17/600] Step 030/104 Loss 0.544 Prec@(1,5) (81.9%, 99.1%)\n",
            "[2023-01-12 16:51:46] \u001b[32mValid: [ 17/600] Step 040/104 Loss 0.558 Prec@(1,5) (81.7%, 99.0%)\u001b[0m\n",
            "INFO:nni:Valid: [ 17/600] Step 040/104 Loss 0.558 Prec@(1,5) (81.7%, 99.0%)\n",
            "[2023-01-12 16:51:47] \u001b[32mValid: [ 17/600] Step 050/104 Loss 0.550 Prec@(1,5) (81.9%, 98.9%)\u001b[0m\n",
            "INFO:nni:Valid: [ 17/600] Step 050/104 Loss 0.550 Prec@(1,5) (81.9%, 98.9%)\n",
            "[2023-01-12 16:51:48] \u001b[32mValid: [ 17/600] Step 060/104 Loss 0.556 Prec@(1,5) (81.7%, 99.0%)\u001b[0m\n",
            "INFO:nni:Valid: [ 17/600] Step 060/104 Loss 0.556 Prec@(1,5) (81.7%, 99.0%)\n",
            "[2023-01-12 16:51:50] \u001b[32mValid: [ 17/600] Step 070/104 Loss 0.555 Prec@(1,5) (81.5%, 99.0%)\u001b[0m\n",
            "INFO:nni:Valid: [ 17/600] Step 070/104 Loss 0.555 Prec@(1,5) (81.5%, 99.0%)\n",
            "[2023-01-12 16:51:51] \u001b[32mValid: [ 17/600] Step 080/104 Loss 0.554 Prec@(1,5) (81.5%, 99.1%)\u001b[0m\n",
            "INFO:nni:Valid: [ 17/600] Step 080/104 Loss 0.554 Prec@(1,5) (81.5%, 99.1%)\n",
            "[2023-01-12 16:51:53] \u001b[32mValid: [ 17/600] Step 090/104 Loss 0.554 Prec@(1,5) (81.4%, 99.1%)\u001b[0m\n",
            "INFO:nni:Valid: [ 17/600] Step 090/104 Loss 0.554 Prec@(1,5) (81.4%, 99.1%)\n",
            "[2023-01-12 16:51:54] \u001b[32mValid: [ 17/600] Step 100/104 Loss 0.550 Prec@(1,5) (81.6%, 99.1%)\u001b[0m\n",
            "INFO:nni:Valid: [ 17/600] Step 100/104 Loss 0.550 Prec@(1,5) (81.6%, 99.1%)\n",
            "[2023-01-12 16:51:54] \u001b[32mValid: [ 17/600] Step 104/104 Loss 0.550 Prec@(1,5) (81.6%, 99.1%)\u001b[0m\n",
            "INFO:nni:Valid: [ 17/600] Step 104/104 Loss 0.550 Prec@(1,5) (81.6%, 99.1%)\n",
            "[2023-01-12 16:51:55] \u001b[32mValid: [ 17/600] Final Prec@1 81.5500%\u001b[0m\n",
            "INFO:nni:Valid: [ 17/600] Final Prec@1 81.5500%\n",
            "[2023-01-12 16:51:55] \u001b[32mEpoch 17 LR 0.024951\u001b[0m\n",
            "INFO:nni:Epoch 17 LR 0.024951\n",
            "[2023-01-12 16:51:55] \u001b[32mTrain: [ 18/600] Step 000/520 Loss 1.241 Prec@(1,5) (70.8%, 97.9%)\u001b[0m\n",
            "INFO:nni:Train: [ 18/600] Step 000/520 Loss 1.241 Prec@(1,5) (70.8%, 97.9%)\n",
            "[2023-01-12 16:52:00] \u001b[32mTrain: [ 18/600] Step 010/520 Loss 0.839 Prec@(1,5) (79.3%, 98.7%)\u001b[0m\n",
            "INFO:nni:Train: [ 18/600] Step 010/520 Loss 0.839 Prec@(1,5) (79.3%, 98.7%)\n",
            "[2023-01-12 16:52:04] \u001b[32mTrain: [ 18/600] Step 020/520 Loss 0.836 Prec@(1,5) (79.5%, 98.8%)\u001b[0m\n",
            "INFO:nni:Train: [ 18/600] Step 020/520 Loss 0.836 Prec@(1,5) (79.5%, 98.8%)\n",
            "[2023-01-12 16:52:09] \u001b[32mTrain: [ 18/600] Step 030/520 Loss 0.831 Prec@(1,5) (78.8%, 98.8%)\u001b[0m\n",
            "INFO:nni:Train: [ 18/600] Step 030/520 Loss 0.831 Prec@(1,5) (78.8%, 98.8%)\n",
            "[2023-01-12 16:52:13] \u001b[32mTrain: [ 18/600] Step 040/520 Loss 0.824 Prec@(1,5) (79.3%, 98.8%)\u001b[0m\n",
            "INFO:nni:Train: [ 18/600] Step 040/520 Loss 0.824 Prec@(1,5) (79.3%, 98.8%)\n",
            "[2023-01-12 16:52:18] \u001b[32mTrain: [ 18/600] Step 050/520 Loss 0.835 Prec@(1,5) (78.8%, 98.8%)\u001b[0m\n",
            "INFO:nni:Train: [ 18/600] Step 050/520 Loss 0.835 Prec@(1,5) (78.8%, 98.8%)\n",
            "[2023-01-12 16:52:23] \u001b[32mTrain: [ 18/600] Step 060/520 Loss 0.824 Prec@(1,5) (79.5%, 98.8%)\u001b[0m\n",
            "INFO:nni:Train: [ 18/600] Step 060/520 Loss 0.824 Prec@(1,5) (79.5%, 98.8%)\n",
            "[2023-01-12 16:52:27] \u001b[32mTrain: [ 18/600] Step 070/520 Loss 0.821 Prec@(1,5) (79.5%, 98.7%)\u001b[0m\n",
            "INFO:nni:Train: [ 18/600] Step 070/520 Loss 0.821 Prec@(1,5) (79.5%, 98.7%)\n",
            "[2023-01-12 16:52:32] \u001b[32mTrain: [ 18/600] Step 080/520 Loss 0.818 Prec@(1,5) (79.4%, 98.8%)\u001b[0m\n",
            "INFO:nni:Train: [ 18/600] Step 080/520 Loss 0.818 Prec@(1,5) (79.4%, 98.8%)\n",
            "[2023-01-12 16:52:36] \u001b[32mTrain: [ 18/600] Step 090/520 Loss 0.819 Prec@(1,5) (79.4%, 98.8%)\u001b[0m\n",
            "INFO:nni:Train: [ 18/600] Step 090/520 Loss 0.819 Prec@(1,5) (79.4%, 98.8%)\n",
            "[2023-01-12 16:52:41] \u001b[32mTrain: [ 18/600] Step 100/520 Loss 0.825 Prec@(1,5) (79.4%, 98.8%)\u001b[0m\n",
            "INFO:nni:Train: [ 18/600] Step 100/520 Loss 0.825 Prec@(1,5) (79.4%, 98.8%)\n",
            "[2023-01-12 16:52:45] \u001b[32mTrain: [ 18/600] Step 110/520 Loss 0.825 Prec@(1,5) (79.5%, 98.8%)\u001b[0m\n",
            "INFO:nni:Train: [ 18/600] Step 110/520 Loss 0.825 Prec@(1,5) (79.5%, 98.8%)\n",
            "[2023-01-12 16:52:50] \u001b[32mTrain: [ 18/600] Step 120/520 Loss 0.829 Prec@(1,5) (79.5%, 98.8%)\u001b[0m\n",
            "INFO:nni:Train: [ 18/600] Step 120/520 Loss 0.829 Prec@(1,5) (79.5%, 98.8%)\n",
            "[2023-01-12 16:52:54] \u001b[32mTrain: [ 18/600] Step 130/520 Loss 0.835 Prec@(1,5) (79.3%, 98.8%)\u001b[0m\n",
            "INFO:nni:Train: [ 18/600] Step 130/520 Loss 0.835 Prec@(1,5) (79.3%, 98.8%)\n",
            "[2023-01-12 16:52:59] \u001b[32mTrain: [ 18/600] Step 140/520 Loss 0.841 Prec@(1,5) (79.1%, 98.8%)\u001b[0m\n",
            "INFO:nni:Train: [ 18/600] Step 140/520 Loss 0.841 Prec@(1,5) (79.1%, 98.8%)\n",
            "[2023-01-12 16:53:03] \u001b[32mTrain: [ 18/600] Step 150/520 Loss 0.845 Prec@(1,5) (79.0%, 98.8%)\u001b[0m\n",
            "INFO:nni:Train: [ 18/600] Step 150/520 Loss 0.845 Prec@(1,5) (79.0%, 98.8%)\n",
            "[2023-01-12 16:53:08] \u001b[32mTrain: [ 18/600] Step 160/520 Loss 0.841 Prec@(1,5) (79.1%, 98.8%)\u001b[0m\n",
            "INFO:nni:Train: [ 18/600] Step 160/520 Loss 0.841 Prec@(1,5) (79.1%, 98.8%)\n",
            "[2023-01-12 16:53:12] \u001b[32mTrain: [ 18/600] Step 170/520 Loss 0.843 Prec@(1,5) (79.0%, 98.8%)\u001b[0m\n",
            "INFO:nni:Train: [ 18/600] Step 170/520 Loss 0.843 Prec@(1,5) (79.0%, 98.8%)\n",
            "[2023-01-12 16:53:17] \u001b[32mTrain: [ 18/600] Step 180/520 Loss 0.840 Prec@(1,5) (79.1%, 98.8%)\u001b[0m\n",
            "INFO:nni:Train: [ 18/600] Step 180/520 Loss 0.840 Prec@(1,5) (79.1%, 98.8%)\n",
            "[2023-01-12 16:53:21] \u001b[32mTrain: [ 18/600] Step 190/520 Loss 0.842 Prec@(1,5) (79.1%, 98.8%)\u001b[0m\n",
            "INFO:nni:Train: [ 18/600] Step 190/520 Loss 0.842 Prec@(1,5) (79.1%, 98.8%)\n",
            "[2023-01-12 16:53:26] \u001b[32mTrain: [ 18/600] Step 200/520 Loss 0.844 Prec@(1,5) (79.0%, 98.8%)\u001b[0m\n",
            "INFO:nni:Train: [ 18/600] Step 200/520 Loss 0.844 Prec@(1,5) (79.0%, 98.8%)\n",
            "[2023-01-12 16:53:30] \u001b[32mTrain: [ 18/600] Step 210/520 Loss 0.845 Prec@(1,5) (79.0%, 98.8%)\u001b[0m\n",
            "INFO:nni:Train: [ 18/600] Step 210/520 Loss 0.845 Prec@(1,5) (79.0%, 98.8%)\n",
            "[2023-01-12 16:53:35] \u001b[32mTrain: [ 18/600] Step 220/520 Loss 0.847 Prec@(1,5) (79.0%, 98.8%)\u001b[0m\n",
            "INFO:nni:Train: [ 18/600] Step 220/520 Loss 0.847 Prec@(1,5) (79.0%, 98.8%)\n",
            "[2023-01-12 16:53:39] \u001b[32mTrain: [ 18/600] Step 230/520 Loss 0.845 Prec@(1,5) (79.0%, 98.8%)\u001b[0m\n",
            "INFO:nni:Train: [ 18/600] Step 230/520 Loss 0.845 Prec@(1,5) (79.0%, 98.8%)\n",
            "[2023-01-12 16:53:44] \u001b[32mTrain: [ 18/600] Step 240/520 Loss 0.849 Prec@(1,5) (79.0%, 98.8%)\u001b[0m\n",
            "INFO:nni:Train: [ 18/600] Step 240/520 Loss 0.849 Prec@(1,5) (79.0%, 98.8%)\n",
            "[2023-01-12 16:53:48] \u001b[32mTrain: [ 18/600] Step 250/520 Loss 0.852 Prec@(1,5) (78.9%, 98.8%)\u001b[0m\n",
            "INFO:nni:Train: [ 18/600] Step 250/520 Loss 0.852 Prec@(1,5) (78.9%, 98.8%)\n",
            "[2023-01-12 16:53:53] \u001b[32mTrain: [ 18/600] Step 260/520 Loss 0.853 Prec@(1,5) (78.9%, 98.8%)\u001b[0m\n",
            "INFO:nni:Train: [ 18/600] Step 260/520 Loss 0.853 Prec@(1,5) (78.9%, 98.8%)\n",
            "[2023-01-12 16:53:57] \u001b[32mTrain: [ 18/600] Step 270/520 Loss 0.855 Prec@(1,5) (78.9%, 98.8%)\u001b[0m\n",
            "INFO:nni:Train: [ 18/600] Step 270/520 Loss 0.855 Prec@(1,5) (78.9%, 98.8%)\n",
            "[2023-01-12 16:54:02] \u001b[32mTrain: [ 18/600] Step 280/520 Loss 0.855 Prec@(1,5) (78.9%, 98.8%)\u001b[0m\n",
            "INFO:nni:Train: [ 18/600] Step 280/520 Loss 0.855 Prec@(1,5) (78.9%, 98.8%)\n",
            "[2023-01-12 16:54:06] \u001b[32mTrain: [ 18/600] Step 290/520 Loss 0.856 Prec@(1,5) (78.9%, 98.8%)\u001b[0m\n",
            "INFO:nni:Train: [ 18/600] Step 290/520 Loss 0.856 Prec@(1,5) (78.9%, 98.8%)\n",
            "[2023-01-12 16:54:11] \u001b[32mTrain: [ 18/600] Step 300/520 Loss 0.857 Prec@(1,5) (78.8%, 98.8%)\u001b[0m\n",
            "INFO:nni:Train: [ 18/600] Step 300/520 Loss 0.857 Prec@(1,5) (78.8%, 98.8%)\n",
            "[2023-01-12 16:54:15] \u001b[32mTrain: [ 18/600] Step 310/520 Loss 0.859 Prec@(1,5) (78.8%, 98.7%)\u001b[0m\n",
            "INFO:nni:Train: [ 18/600] Step 310/520 Loss 0.859 Prec@(1,5) (78.8%, 98.7%)\n",
            "[2023-01-12 16:54:20] \u001b[32mTrain: [ 18/600] Step 320/520 Loss 0.862 Prec@(1,5) (78.7%, 98.7%)\u001b[0m\n",
            "INFO:nni:Train: [ 18/600] Step 320/520 Loss 0.862 Prec@(1,5) (78.7%, 98.7%)\n",
            "[2023-01-12 16:54:24] \u001b[32mTrain: [ 18/600] Step 330/520 Loss 0.861 Prec@(1,5) (78.7%, 98.7%)\u001b[0m\n",
            "INFO:nni:Train: [ 18/600] Step 330/520 Loss 0.861 Prec@(1,5) (78.7%, 98.7%)\n",
            "[2023-01-12 16:54:29] \u001b[32mTrain: [ 18/600] Step 340/520 Loss 0.862 Prec@(1,5) (78.7%, 98.7%)\u001b[0m\n",
            "INFO:nni:Train: [ 18/600] Step 340/520 Loss 0.862 Prec@(1,5) (78.7%, 98.7%)\n",
            "[2023-01-12 16:54:33] \u001b[32mTrain: [ 18/600] Step 350/520 Loss 0.864 Prec@(1,5) (78.7%, 98.7%)\u001b[0m\n",
            "INFO:nni:Train: [ 18/600] Step 350/520 Loss 0.864 Prec@(1,5) (78.7%, 98.7%)\n",
            "[2023-01-12 16:54:38] \u001b[32mTrain: [ 18/600] Step 360/520 Loss 0.864 Prec@(1,5) (78.6%, 98.7%)\u001b[0m\n",
            "INFO:nni:Train: [ 18/600] Step 360/520 Loss 0.864 Prec@(1,5) (78.6%, 98.7%)\n",
            "[2023-01-12 16:54:42] \u001b[32mTrain: [ 18/600] Step 370/520 Loss 0.864 Prec@(1,5) (78.6%, 98.7%)\u001b[0m\n",
            "INFO:nni:Train: [ 18/600] Step 370/520 Loss 0.864 Prec@(1,5) (78.6%, 98.7%)\n",
            "[2023-01-12 16:54:47] \u001b[32mTrain: [ 18/600] Step 380/520 Loss 0.866 Prec@(1,5) (78.6%, 98.7%)\u001b[0m\n",
            "INFO:nni:Train: [ 18/600] Step 380/520 Loss 0.866 Prec@(1,5) (78.6%, 98.7%)\n",
            "[2023-01-12 16:54:52] \u001b[32mTrain: [ 18/600] Step 390/520 Loss 0.869 Prec@(1,5) (78.5%, 98.7%)\u001b[0m\n",
            "INFO:nni:Train: [ 18/600] Step 390/520 Loss 0.869 Prec@(1,5) (78.5%, 98.7%)\n",
            "[2023-01-12 16:54:56] \u001b[32mTrain: [ 18/600] Step 400/520 Loss 0.869 Prec@(1,5) (78.5%, 98.7%)\u001b[0m\n",
            "INFO:nni:Train: [ 18/600] Step 400/520 Loss 0.869 Prec@(1,5) (78.5%, 98.7%)\n",
            "[2023-01-12 16:55:01] \u001b[32mTrain: [ 18/600] Step 410/520 Loss 0.867 Prec@(1,5) (78.6%, 98.7%)\u001b[0m\n",
            "INFO:nni:Train: [ 18/600] Step 410/520 Loss 0.867 Prec@(1,5) (78.6%, 98.7%)\n",
            "[2023-01-12 16:55:05] \u001b[32mTrain: [ 18/600] Step 420/520 Loss 0.865 Prec@(1,5) (78.6%, 98.7%)\u001b[0m\n",
            "INFO:nni:Train: [ 18/600] Step 420/520 Loss 0.865 Prec@(1,5) (78.6%, 98.7%)\n",
            "[2023-01-12 16:55:10] \u001b[32mTrain: [ 18/600] Step 430/520 Loss 0.865 Prec@(1,5) (78.6%, 98.7%)\u001b[0m\n",
            "INFO:nni:Train: [ 18/600] Step 430/520 Loss 0.865 Prec@(1,5) (78.6%, 98.7%)\n",
            "[2023-01-12 16:55:14] \u001b[32mTrain: [ 18/600] Step 440/520 Loss 0.865 Prec@(1,5) (78.6%, 98.7%)\u001b[0m\n",
            "INFO:nni:Train: [ 18/600] Step 440/520 Loss 0.865 Prec@(1,5) (78.6%, 98.7%)\n",
            "[2023-01-12 16:55:19] \u001b[32mTrain: [ 18/600] Step 450/520 Loss 0.863 Prec@(1,5) (78.7%, 98.7%)\u001b[0m\n",
            "INFO:nni:Train: [ 18/600] Step 450/520 Loss 0.863 Prec@(1,5) (78.7%, 98.7%)\n",
            "[2023-01-12 16:55:23] \u001b[32mTrain: [ 18/600] Step 460/520 Loss 0.862 Prec@(1,5) (78.7%, 98.7%)\u001b[0m\n",
            "INFO:nni:Train: [ 18/600] Step 460/520 Loss 0.862 Prec@(1,5) (78.7%, 98.7%)\n",
            "[2023-01-12 16:55:28] \u001b[32mTrain: [ 18/600] Step 470/520 Loss 0.862 Prec@(1,5) (78.7%, 98.7%)\u001b[0m\n",
            "INFO:nni:Train: [ 18/600] Step 470/520 Loss 0.862 Prec@(1,5) (78.7%, 98.7%)\n",
            "[2023-01-12 16:55:32] \u001b[32mTrain: [ 18/600] Step 480/520 Loss 0.862 Prec@(1,5) (78.7%, 98.7%)\u001b[0m\n",
            "INFO:nni:Train: [ 18/600] Step 480/520 Loss 0.862 Prec@(1,5) (78.7%, 98.7%)\n",
            "[2023-01-12 16:55:37] \u001b[32mTrain: [ 18/600] Step 490/520 Loss 0.863 Prec@(1,5) (78.7%, 98.7%)\u001b[0m\n",
            "INFO:nni:Train: [ 18/600] Step 490/520 Loss 0.863 Prec@(1,5) (78.7%, 98.7%)\n",
            "[2023-01-12 16:55:41] \u001b[32mTrain: [ 18/600] Step 500/520 Loss 0.863 Prec@(1,5) (78.6%, 98.7%)\u001b[0m\n",
            "INFO:nni:Train: [ 18/600] Step 500/520 Loss 0.863 Prec@(1,5) (78.6%, 98.7%)\n",
            "[2023-01-12 16:55:46] \u001b[32mTrain: [ 18/600] Step 510/520 Loss 0.865 Prec@(1,5) (78.6%, 98.7%)\u001b[0m\n",
            "INFO:nni:Train: [ 18/600] Step 510/520 Loss 0.865 Prec@(1,5) (78.6%, 98.7%)\n",
            "[2023-01-12 16:55:50] \u001b[32mTrain: [ 18/600] Step 520/520 Loss 0.864 Prec@(1,5) (78.6%, 98.7%)\u001b[0m\n",
            "INFO:nni:Train: [ 18/600] Step 520/520 Loss 0.864 Prec@(1,5) (78.6%, 98.7%)\n",
            "[2023-01-12 16:55:50] \u001b[32mTrain: [ 18/600] Final Prec@1 78.6440%\u001b[0m\n",
            "INFO:nni:Train: [ 18/600] Final Prec@1 78.6440%\n",
            "[2023-01-12 16:55:51] \u001b[32mValid: [ 18/600] Step 000/104 Loss 0.521 Prec@(1,5) (83.3%, 97.9%)\u001b[0m\n",
            "INFO:nni:Valid: [ 18/600] Step 000/104 Loss 0.521 Prec@(1,5) (83.3%, 97.9%)\n",
            "[2023-01-12 16:55:52] \u001b[32mValid: [ 18/600] Step 010/104 Loss 0.515 Prec@(1,5) (82.4%, 99.1%)\u001b[0m\n",
            "INFO:nni:Valid: [ 18/600] Step 010/104 Loss 0.515 Prec@(1,5) (82.4%, 99.1%)\n",
            "[2023-01-12 16:55:54] \u001b[32mValid: [ 18/600] Step 020/104 Loss 0.518 Prec@(1,5) (82.2%, 99.1%)\u001b[0m\n",
            "INFO:nni:Valid: [ 18/600] Step 020/104 Loss 0.518 Prec@(1,5) (82.2%, 99.1%)\n",
            "[2023-01-12 16:55:55] \u001b[32mValid: [ 18/600] Step 030/104 Loss 0.519 Prec@(1,5) (82.5%, 99.1%)\u001b[0m\n",
            "INFO:nni:Valid: [ 18/600] Step 030/104 Loss 0.519 Prec@(1,5) (82.5%, 99.1%)\n",
            "[2023-01-12 16:55:56] \u001b[32mValid: [ 18/600] Step 040/104 Loss 0.522 Prec@(1,5) (82.3%, 99.1%)\u001b[0m\n",
            "INFO:nni:Valid: [ 18/600] Step 040/104 Loss 0.522 Prec@(1,5) (82.3%, 99.1%)\n",
            "[2023-01-12 16:55:58] \u001b[32mValid: [ 18/600] Step 050/104 Loss 0.518 Prec@(1,5) (82.5%, 99.0%)\u001b[0m\n",
            "INFO:nni:Valid: [ 18/600] Step 050/104 Loss 0.518 Prec@(1,5) (82.5%, 99.0%)\n",
            "[2023-01-12 16:55:59] \u001b[32mValid: [ 18/600] Step 060/104 Loss 0.522 Prec@(1,5) (82.1%, 99.0%)\u001b[0m\n",
            "INFO:nni:Valid: [ 18/600] Step 060/104 Loss 0.522 Prec@(1,5) (82.1%, 99.0%)\n",
            "[2023-01-12 16:56:01] \u001b[32mValid: [ 18/600] Step 070/104 Loss 0.524 Prec@(1,5) (82.0%, 99.0%)\u001b[0m\n",
            "INFO:nni:Valid: [ 18/600] Step 070/104 Loss 0.524 Prec@(1,5) (82.0%, 99.0%)\n",
            "[2023-01-12 16:56:02] \u001b[32mValid: [ 18/600] Step 080/104 Loss 0.525 Prec@(1,5) (82.0%, 99.0%)\u001b[0m\n",
            "INFO:nni:Valid: [ 18/600] Step 080/104 Loss 0.525 Prec@(1,5) (82.0%, 99.0%)\n",
            "[2023-01-12 16:56:03] \u001b[32mValid: [ 18/600] Step 090/104 Loss 0.527 Prec@(1,5) (81.9%, 99.0%)\u001b[0m\n",
            "INFO:nni:Valid: [ 18/600] Step 090/104 Loss 0.527 Prec@(1,5) (81.9%, 99.0%)\n",
            "[2023-01-12 16:56:05] \u001b[32mValid: [ 18/600] Step 100/104 Loss 0.523 Prec@(1,5) (82.1%, 99.0%)\u001b[0m\n",
            "INFO:nni:Valid: [ 18/600] Step 100/104 Loss 0.523 Prec@(1,5) (82.1%, 99.0%)\n",
            "[2023-01-12 16:56:05] \u001b[32mValid: [ 18/600] Step 104/104 Loss 0.524 Prec@(1,5) (82.1%, 99.1%)\u001b[0m\n",
            "INFO:nni:Valid: [ 18/600] Step 104/104 Loss 0.524 Prec@(1,5) (82.1%, 99.1%)\n",
            "[2023-01-12 16:56:05] \u001b[32mValid: [ 18/600] Final Prec@1 82.0900%\u001b[0m\n",
            "INFO:nni:Valid: [ 18/600] Final Prec@1 82.0900%\n",
            "[2023-01-12 16:56:05] \u001b[32mEpoch 18 LR 0.024945\u001b[0m\n",
            "INFO:nni:Epoch 18 LR 0.024945\n",
            "[2023-01-12 16:56:06] \u001b[32mTrain: [ 19/600] Step 000/520 Loss 0.653 Prec@(1,5) (86.5%, 96.9%)\u001b[0m\n",
            "INFO:nni:Train: [ 19/600] Step 000/520 Loss 0.653 Prec@(1,5) (86.5%, 96.9%)\n",
            "[2023-01-12 16:56:11] \u001b[32mTrain: [ 19/600] Step 010/520 Loss 0.845 Prec@(1,5) (80.2%, 98.6%)\u001b[0m\n",
            "INFO:nni:Train: [ 19/600] Step 010/520 Loss 0.845 Prec@(1,5) (80.2%, 98.6%)\n",
            "[2023-01-12 16:56:15] \u001b[32mTrain: [ 19/600] Step 020/520 Loss 0.862 Prec@(1,5) (79.2%, 98.6%)\u001b[0m\n",
            "INFO:nni:Train: [ 19/600] Step 020/520 Loss 0.862 Prec@(1,5) (79.2%, 98.6%)\n",
            "[2023-01-12 16:56:20] \u001b[32mTrain: [ 19/600] Step 030/520 Loss 0.854 Prec@(1,5) (79.1%, 98.8%)\u001b[0m\n",
            "INFO:nni:Train: [ 19/600] Step 030/520 Loss 0.854 Prec@(1,5) (79.1%, 98.8%)\n",
            "[2023-01-12 16:56:24] \u001b[32mTrain: [ 19/600] Step 040/520 Loss 0.843 Prec@(1,5) (79.3%, 98.8%)\u001b[0m\n",
            "INFO:nni:Train: [ 19/600] Step 040/520 Loss 0.843 Prec@(1,5) (79.3%, 98.8%)\n",
            "[2023-01-12 16:56:29] \u001b[32mTrain: [ 19/600] Step 050/520 Loss 0.827 Prec@(1,5) (79.8%, 98.8%)\u001b[0m\n",
            "INFO:nni:Train: [ 19/600] Step 050/520 Loss 0.827 Prec@(1,5) (79.8%, 98.8%)\n",
            "[2023-01-12 16:56:33] \u001b[32mTrain: [ 19/600] Step 060/520 Loss 0.824 Prec@(1,5) (79.9%, 98.7%)\u001b[0m\n",
            "INFO:nni:Train: [ 19/600] Step 060/520 Loss 0.824 Prec@(1,5) (79.9%, 98.7%)\n",
            "[2023-01-12 16:56:38] \u001b[32mTrain: [ 19/600] Step 070/520 Loss 0.825 Prec@(1,5) (79.9%, 98.8%)\u001b[0m\n",
            "INFO:nni:Train: [ 19/600] Step 070/520 Loss 0.825 Prec@(1,5) (79.9%, 98.8%)\n",
            "[2023-01-12 16:56:42] \u001b[32mTrain: [ 19/600] Step 080/520 Loss 0.826 Prec@(1,5) (79.8%, 98.8%)\u001b[0m\n",
            "INFO:nni:Train: [ 19/600] Step 080/520 Loss 0.826 Prec@(1,5) (79.8%, 98.8%)\n",
            "[2023-01-12 16:56:47] \u001b[32mTrain: [ 19/600] Step 090/520 Loss 0.827 Prec@(1,5) (79.8%, 98.8%)\u001b[0m\n",
            "INFO:nni:Train: [ 19/600] Step 090/520 Loss 0.827 Prec@(1,5) (79.8%, 98.8%)\n",
            "[2023-01-12 16:56:51] \u001b[32mTrain: [ 19/600] Step 100/520 Loss 0.822 Prec@(1,5) (79.9%, 98.8%)\u001b[0m\n",
            "INFO:nni:Train: [ 19/600] Step 100/520 Loss 0.822 Prec@(1,5) (79.9%, 98.8%)\n",
            "[2023-01-12 16:56:56] \u001b[32mTrain: [ 19/600] Step 110/520 Loss 0.822 Prec@(1,5) (79.8%, 98.9%)\u001b[0m\n",
            "INFO:nni:Train: [ 19/600] Step 110/520 Loss 0.822 Prec@(1,5) (79.8%, 98.9%)\n",
            "[2023-01-12 16:57:00] \u001b[32mTrain: [ 19/600] Step 120/520 Loss 0.822 Prec@(1,5) (79.8%, 98.9%)\u001b[0m\n",
            "INFO:nni:Train: [ 19/600] Step 120/520 Loss 0.822 Prec@(1,5) (79.8%, 98.9%)\n",
            "[2023-01-12 16:57:05] \u001b[32mTrain: [ 19/600] Step 130/520 Loss 0.824 Prec@(1,5) (79.7%, 98.9%)\u001b[0m\n",
            "INFO:nni:Train: [ 19/600] Step 130/520 Loss 0.824 Prec@(1,5) (79.7%, 98.9%)\n",
            "[2023-01-12 16:57:09] \u001b[32mTrain: [ 19/600] Step 140/520 Loss 0.827 Prec@(1,5) (79.6%, 98.9%)\u001b[0m\n",
            "INFO:nni:Train: [ 19/600] Step 140/520 Loss 0.827 Prec@(1,5) (79.6%, 98.9%)\n",
            "[2023-01-12 16:57:14] \u001b[32mTrain: [ 19/600] Step 150/520 Loss 0.831 Prec@(1,5) (79.4%, 98.9%)\u001b[0m\n",
            "INFO:nni:Train: [ 19/600] Step 150/520 Loss 0.831 Prec@(1,5) (79.4%, 98.9%)\n",
            "[2023-01-12 16:57:18] \u001b[32mTrain: [ 19/600] Step 160/520 Loss 0.832 Prec@(1,5) (79.4%, 98.9%)\u001b[0m\n",
            "INFO:nni:Train: [ 19/600] Step 160/520 Loss 0.832 Prec@(1,5) (79.4%, 98.9%)\n",
            "[2023-01-12 16:57:23] \u001b[32mTrain: [ 19/600] Step 170/520 Loss 0.835 Prec@(1,5) (79.3%, 98.9%)\u001b[0m\n",
            "INFO:nni:Train: [ 19/600] Step 170/520 Loss 0.835 Prec@(1,5) (79.3%, 98.9%)\n",
            "[2023-01-12 16:57:28] \u001b[32mTrain: [ 19/600] Step 180/520 Loss 0.835 Prec@(1,5) (79.3%, 98.9%)\u001b[0m\n",
            "INFO:nni:Train: [ 19/600] Step 180/520 Loss 0.835 Prec@(1,5) (79.3%, 98.9%)\n",
            "[2023-01-12 16:57:32] \u001b[32mTrain: [ 19/600] Step 190/520 Loss 0.838 Prec@(1,5) (79.3%, 98.9%)\u001b[0m\n",
            "INFO:nni:Train: [ 19/600] Step 190/520 Loss 0.838 Prec@(1,5) (79.3%, 98.9%)\n",
            "[2023-01-12 16:57:37] \u001b[32mTrain: [ 19/600] Step 200/520 Loss 0.836 Prec@(1,5) (79.3%, 98.9%)\u001b[0m\n",
            "INFO:nni:Train: [ 19/600] Step 200/520 Loss 0.836 Prec@(1,5) (79.3%, 98.9%)\n",
            "[2023-01-12 16:57:41] \u001b[32mTrain: [ 19/600] Step 210/520 Loss 0.839 Prec@(1,5) (79.3%, 98.9%)\u001b[0m\n",
            "INFO:nni:Train: [ 19/600] Step 210/520 Loss 0.839 Prec@(1,5) (79.3%, 98.9%)\n",
            "[2023-01-12 16:57:46] \u001b[32mTrain: [ 19/600] Step 220/520 Loss 0.838 Prec@(1,5) (79.3%, 98.9%)\u001b[0m\n",
            "INFO:nni:Train: [ 19/600] Step 220/520 Loss 0.838 Prec@(1,5) (79.3%, 98.9%)\n",
            "[2023-01-12 16:57:50] \u001b[32mTrain: [ 19/600] Step 230/520 Loss 0.837 Prec@(1,5) (79.3%, 98.9%)\u001b[0m\n",
            "INFO:nni:Train: [ 19/600] Step 230/520 Loss 0.837 Prec@(1,5) (79.3%, 98.9%)\n",
            "[2023-01-12 16:57:55] \u001b[32mTrain: [ 19/600] Step 240/520 Loss 0.834 Prec@(1,5) (79.4%, 98.9%)\u001b[0m\n",
            "INFO:nni:Train: [ 19/600] Step 240/520 Loss 0.834 Prec@(1,5) (79.4%, 98.9%)\n",
            "[2023-01-12 16:57:59] \u001b[32mTrain: [ 19/600] Step 250/520 Loss 0.832 Prec@(1,5) (79.5%, 98.9%)\u001b[0m\n",
            "INFO:nni:Train: [ 19/600] Step 250/520 Loss 0.832 Prec@(1,5) (79.5%, 98.9%)\n",
            "[2023-01-12 16:58:04] \u001b[32mTrain: [ 19/600] Step 260/520 Loss 0.828 Prec@(1,5) (79.6%, 98.9%)\u001b[0m\n",
            "INFO:nni:Train: [ 19/600] Step 260/520 Loss 0.828 Prec@(1,5) (79.6%, 98.9%)\n",
            "[2023-01-12 16:58:08] \u001b[32mTrain: [ 19/600] Step 270/520 Loss 0.830 Prec@(1,5) (79.5%, 98.9%)\u001b[0m\n",
            "INFO:nni:Train: [ 19/600] Step 270/520 Loss 0.830 Prec@(1,5) (79.5%, 98.9%)\n",
            "[2023-01-12 16:58:13] \u001b[32mTrain: [ 19/600] Step 280/520 Loss 0.830 Prec@(1,5) (79.5%, 98.9%)\u001b[0m\n",
            "INFO:nni:Train: [ 19/600] Step 280/520 Loss 0.830 Prec@(1,5) (79.5%, 98.9%)\n",
            "[2023-01-12 16:58:17] \u001b[32mTrain: [ 19/600] Step 290/520 Loss 0.831 Prec@(1,5) (79.5%, 98.9%)\u001b[0m\n",
            "INFO:nni:Train: [ 19/600] Step 290/520 Loss 0.831 Prec@(1,5) (79.5%, 98.9%)\n",
            "[2023-01-12 16:58:22] \u001b[32mTrain: [ 19/600] Step 300/520 Loss 0.833 Prec@(1,5) (79.5%, 98.9%)\u001b[0m\n",
            "INFO:nni:Train: [ 19/600] Step 300/520 Loss 0.833 Prec@(1,5) (79.5%, 98.9%)\n",
            "[2023-01-12 16:58:26] \u001b[32mTrain: [ 19/600] Step 310/520 Loss 0.830 Prec@(1,5) (79.6%, 98.9%)\u001b[0m\n",
            "INFO:nni:Train: [ 19/600] Step 310/520 Loss 0.830 Prec@(1,5) (79.6%, 98.9%)\n",
            "[2023-01-12 16:58:31] \u001b[32mTrain: [ 19/600] Step 320/520 Loss 0.831 Prec@(1,5) (79.6%, 98.9%)\u001b[0m\n",
            "INFO:nni:Train: [ 19/600] Step 320/520 Loss 0.831 Prec@(1,5) (79.6%, 98.9%)\n",
            "[2023-01-12 16:58:35] \u001b[32mTrain: [ 19/600] Step 330/520 Loss 0.831 Prec@(1,5) (79.6%, 98.9%)\u001b[0m\n",
            "INFO:nni:Train: [ 19/600] Step 330/520 Loss 0.831 Prec@(1,5) (79.6%, 98.9%)\n",
            "[2023-01-12 16:58:40] \u001b[32mTrain: [ 19/600] Step 340/520 Loss 0.832 Prec@(1,5) (79.5%, 98.9%)\u001b[0m\n",
            "INFO:nni:Train: [ 19/600] Step 340/520 Loss 0.832 Prec@(1,5) (79.5%, 98.9%)\n",
            "[2023-01-12 16:58:44] \u001b[32mTrain: [ 19/600] Step 350/520 Loss 0.833 Prec@(1,5) (79.5%, 98.9%)\u001b[0m\n",
            "INFO:nni:Train: [ 19/600] Step 350/520 Loss 0.833 Prec@(1,5) (79.5%, 98.9%)\n",
            "[2023-01-12 16:58:49] \u001b[32mTrain: [ 19/600] Step 360/520 Loss 0.834 Prec@(1,5) (79.5%, 98.9%)\u001b[0m\n",
            "INFO:nni:Train: [ 19/600] Step 360/520 Loss 0.834 Prec@(1,5) (79.5%, 98.9%)\n",
            "[2023-01-12 16:58:53] \u001b[32mTrain: [ 19/600] Step 370/520 Loss 0.835 Prec@(1,5) (79.5%, 98.9%)\u001b[0m\n",
            "INFO:nni:Train: [ 19/600] Step 370/520 Loss 0.835 Prec@(1,5) (79.5%, 98.9%)\n",
            "[2023-01-12 16:58:58] \u001b[32mTrain: [ 19/600] Step 380/520 Loss 0.831 Prec@(1,5) (79.5%, 98.9%)\u001b[0m\n",
            "INFO:nni:Train: [ 19/600] Step 380/520 Loss 0.831 Prec@(1,5) (79.5%, 98.9%)\n",
            "[2023-01-12 16:59:02] \u001b[32mTrain: [ 19/600] Step 390/520 Loss 0.832 Prec@(1,5) (79.5%, 98.9%)\u001b[0m\n",
            "INFO:nni:Train: [ 19/600] Step 390/520 Loss 0.832 Prec@(1,5) (79.5%, 98.9%)\n",
            "[2023-01-12 16:59:07] \u001b[32mTrain: [ 19/600] Step 400/520 Loss 0.833 Prec@(1,5) (79.6%, 98.9%)\u001b[0m\n",
            "INFO:nni:Train: [ 19/600] Step 400/520 Loss 0.833 Prec@(1,5) (79.6%, 98.9%)\n",
            "[2023-01-12 16:59:11] \u001b[32mTrain: [ 19/600] Step 410/520 Loss 0.832 Prec@(1,5) (79.6%, 98.9%)\u001b[0m\n",
            "INFO:nni:Train: [ 19/600] Step 410/520 Loss 0.832 Prec@(1,5) (79.6%, 98.9%)\n",
            "[2023-01-12 16:59:16] \u001b[32mTrain: [ 19/600] Step 420/520 Loss 0.832 Prec@(1,5) (79.6%, 98.9%)\u001b[0m\n",
            "INFO:nni:Train: [ 19/600] Step 420/520 Loss 0.832 Prec@(1,5) (79.6%, 98.9%)\n",
            "[2023-01-12 16:59:20] \u001b[32mTrain: [ 19/600] Step 430/520 Loss 0.832 Prec@(1,5) (79.6%, 98.9%)\u001b[0m\n",
            "INFO:nni:Train: [ 19/600] Step 430/520 Loss 0.832 Prec@(1,5) (79.6%, 98.9%)\n",
            "[2023-01-12 16:59:25] \u001b[32mTrain: [ 19/600] Step 440/520 Loss 0.832 Prec@(1,5) (79.6%, 98.9%)\u001b[0m\n",
            "INFO:nni:Train: [ 19/600] Step 440/520 Loss 0.832 Prec@(1,5) (79.6%, 98.9%)\n",
            "[2023-01-12 16:59:30] \u001b[32mTrain: [ 19/600] Step 450/520 Loss 0.834 Prec@(1,5) (79.6%, 98.9%)\u001b[0m\n",
            "INFO:nni:Train: [ 19/600] Step 450/520 Loss 0.834 Prec@(1,5) (79.6%, 98.9%)\n",
            "[2023-01-12 16:59:34] \u001b[32mTrain: [ 19/600] Step 460/520 Loss 0.833 Prec@(1,5) (79.6%, 98.9%)\u001b[0m\n",
            "INFO:nni:Train: [ 19/600] Step 460/520 Loss 0.833 Prec@(1,5) (79.6%, 98.9%)\n",
            "[2023-01-12 16:59:39] \u001b[32mTrain: [ 19/600] Step 470/520 Loss 0.833 Prec@(1,5) (79.6%, 98.9%)\u001b[0m\n",
            "INFO:nni:Train: [ 19/600] Step 470/520 Loss 0.833 Prec@(1,5) (79.6%, 98.9%)\n",
            "[2023-01-12 16:59:43] \u001b[32mTrain: [ 19/600] Step 480/520 Loss 0.833 Prec@(1,5) (79.6%, 98.9%)\u001b[0m\n",
            "INFO:nni:Train: [ 19/600] Step 480/520 Loss 0.833 Prec@(1,5) (79.6%, 98.9%)\n",
            "[2023-01-12 16:59:48] \u001b[32mTrain: [ 19/600] Step 490/520 Loss 0.835 Prec@(1,5) (79.5%, 98.9%)\u001b[0m\n",
            "INFO:nni:Train: [ 19/600] Step 490/520 Loss 0.835 Prec@(1,5) (79.5%, 98.9%)\n",
            "[2023-01-12 16:59:52] \u001b[32mTrain: [ 19/600] Step 500/520 Loss 0.834 Prec@(1,5) (79.5%, 98.9%)\u001b[0m\n",
            "INFO:nni:Train: [ 19/600] Step 500/520 Loss 0.834 Prec@(1,5) (79.5%, 98.9%)\n",
            "[2023-01-12 16:59:57] \u001b[32mTrain: [ 19/600] Step 510/520 Loss 0.833 Prec@(1,5) (79.6%, 98.9%)\u001b[0m\n",
            "INFO:nni:Train: [ 19/600] Step 510/520 Loss 0.833 Prec@(1,5) (79.6%, 98.9%)\n",
            "[2023-01-12 17:00:01] \u001b[32mTrain: [ 19/600] Step 520/520 Loss 0.835 Prec@(1,5) (79.6%, 98.9%)\u001b[0m\n",
            "INFO:nni:Train: [ 19/600] Step 520/520 Loss 0.835 Prec@(1,5) (79.6%, 98.9%)\n",
            "[2023-01-12 17:00:01] \u001b[32mTrain: [ 19/600] Final Prec@1 79.5500%\u001b[0m\n",
            "INFO:nni:Train: [ 19/600] Final Prec@1 79.5500%\n",
            "[2023-01-12 17:00:02] \u001b[32mValid: [ 19/600] Step 000/104 Loss 0.663 Prec@(1,5) (79.2%, 97.9%)\u001b[0m\n",
            "INFO:nni:Valid: [ 19/600] Step 000/104 Loss 0.663 Prec@(1,5) (79.2%, 97.9%)\n",
            "[2023-01-12 17:00:03] \u001b[32mValid: [ 19/600] Step 010/104 Loss 0.655 Prec@(1,5) (80.6%, 99.1%)\u001b[0m\n",
            "INFO:nni:Valid: [ 19/600] Step 010/104 Loss 0.655 Prec@(1,5) (80.6%, 99.1%)\n",
            "[2023-01-12 17:00:04] \u001b[32mValid: [ 19/600] Step 020/104 Loss 0.671 Prec@(1,5) (80.6%, 99.1%)\u001b[0m\n",
            "INFO:nni:Valid: [ 19/600] Step 020/104 Loss 0.671 Prec@(1,5) (80.6%, 99.1%)\n",
            "[2023-01-12 17:00:06] \u001b[32mValid: [ 19/600] Step 030/104 Loss 0.672 Prec@(1,5) (80.7%, 99.0%)\u001b[0m\n",
            "INFO:nni:Valid: [ 19/600] Step 030/104 Loss 0.672 Prec@(1,5) (80.7%, 99.0%)\n",
            "[2023-01-12 17:00:07] \u001b[32mValid: [ 19/600] Step 040/104 Loss 0.688 Prec@(1,5) (80.3%, 98.9%)\u001b[0m\n",
            "INFO:nni:Valid: [ 19/600] Step 040/104 Loss 0.688 Prec@(1,5) (80.3%, 98.9%)\n",
            "[2023-01-12 17:00:09] \u001b[32mValid: [ 19/600] Step 050/104 Loss 0.686 Prec@(1,5) (80.8%, 99.0%)\u001b[0m\n",
            "INFO:nni:Valid: [ 19/600] Step 050/104 Loss 0.686 Prec@(1,5) (80.8%, 99.0%)\n",
            "[2023-01-12 17:00:10] \u001b[32mValid: [ 19/600] Step 060/104 Loss 0.686 Prec@(1,5) (81.0%, 99.0%)\u001b[0m\n",
            "INFO:nni:Valid: [ 19/600] Step 060/104 Loss 0.686 Prec@(1,5) (81.0%, 99.0%)\n",
            "[2023-01-12 17:00:11] \u001b[32mValid: [ 19/600] Step 070/104 Loss 0.677 Prec@(1,5) (81.3%, 99.1%)\u001b[0m\n",
            "INFO:nni:Valid: [ 19/600] Step 070/104 Loss 0.677 Prec@(1,5) (81.3%, 99.1%)\n",
            "[2023-01-12 17:00:13] \u001b[32mValid: [ 19/600] Step 080/104 Loss 0.685 Prec@(1,5) (81.3%, 99.1%)\u001b[0m\n",
            "INFO:nni:Valid: [ 19/600] Step 080/104 Loss 0.685 Prec@(1,5) (81.3%, 99.1%)\n",
            "[2023-01-12 17:00:14] \u001b[32mValid: [ 19/600] Step 090/104 Loss 0.685 Prec@(1,5) (81.4%, 99.1%)\u001b[0m\n",
            "INFO:nni:Valid: [ 19/600] Step 090/104 Loss 0.685 Prec@(1,5) (81.4%, 99.1%)\n",
            "[2023-01-12 17:00:16] \u001b[32mValid: [ 19/600] Step 100/104 Loss 0.684 Prec@(1,5) (81.4%, 99.1%)\u001b[0m\n",
            "INFO:nni:Valid: [ 19/600] Step 100/104 Loss 0.684 Prec@(1,5) (81.4%, 99.1%)\n",
            "[2023-01-12 17:00:16] \u001b[32mValid: [ 19/600] Step 104/104 Loss 0.685 Prec@(1,5) (81.4%, 99.2%)\u001b[0m\n",
            "INFO:nni:Valid: [ 19/600] Step 104/104 Loss 0.685 Prec@(1,5) (81.4%, 99.2%)\n",
            "[2023-01-12 17:00:16] \u001b[32mValid: [ 19/600] Final Prec@1 81.3800%\u001b[0m\n",
            "INFO:nni:Valid: [ 19/600] Final Prec@1 81.3800%\n",
            "[2023-01-12 17:00:16] \u001b[32mEpoch 19 LR 0.024938\u001b[0m\n",
            "INFO:nni:Epoch 19 LR 0.024938\n",
            "[2023-01-12 17:00:17] \u001b[32mTrain: [ 20/600] Step 000/520 Loss 0.651 Prec@(1,5) (80.2%, 97.9%)\u001b[0m\n",
            "INFO:nni:Train: [ 20/600] Step 000/520 Loss 0.651 Prec@(1,5) (80.2%, 97.9%)\n",
            "[2023-01-12 17:00:22] \u001b[32mTrain: [ 20/600] Step 010/520 Loss 0.790 Prec@(1,5) (80.3%, 99.0%)\u001b[0m\n",
            "INFO:nni:Train: [ 20/600] Step 010/520 Loss 0.790 Prec@(1,5) (80.3%, 99.0%)\n",
            "[2023-01-12 17:00:26] \u001b[32mTrain: [ 20/600] Step 020/520 Loss 0.826 Prec@(1,5) (80.3%, 98.9%)\u001b[0m\n",
            "INFO:nni:Train: [ 20/600] Step 020/520 Loss 0.826 Prec@(1,5) (80.3%, 98.9%)\n",
            "[2023-01-12 17:00:31] \u001b[32mTrain: [ 20/600] Step 030/520 Loss 0.820 Prec@(1,5) (80.3%, 99.0%)\u001b[0m\n",
            "INFO:nni:Train: [ 20/600] Step 030/520 Loss 0.820 Prec@(1,5) (80.3%, 99.0%)\n",
            "[2023-01-12 17:00:35] \u001b[32mTrain: [ 20/600] Step 040/520 Loss 0.808 Prec@(1,5) (80.7%, 99.0%)\u001b[0m\n",
            "INFO:nni:Train: [ 20/600] Step 040/520 Loss 0.808 Prec@(1,5) (80.7%, 99.0%)\n",
            "[2023-01-12 17:00:40] \u001b[32mTrain: [ 20/600] Step 050/520 Loss 0.806 Prec@(1,5) (80.7%, 99.0%)\u001b[0m\n",
            "INFO:nni:Train: [ 20/600] Step 050/520 Loss 0.806 Prec@(1,5) (80.7%, 99.0%)\n",
            "[2023-01-12 17:00:44] \u001b[32mTrain: [ 20/600] Step 060/520 Loss 0.811 Prec@(1,5) (80.5%, 99.0%)\u001b[0m\n",
            "INFO:nni:Train: [ 20/600] Step 060/520 Loss 0.811 Prec@(1,5) (80.5%, 99.0%)\n",
            "[2023-01-12 17:00:49] \u001b[32mTrain: [ 20/600] Step 070/520 Loss 0.828 Prec@(1,5) (80.1%, 98.9%)\u001b[0m\n",
            "INFO:nni:Train: [ 20/600] Step 070/520 Loss 0.828 Prec@(1,5) (80.1%, 98.9%)\n",
            "[2023-01-12 17:00:53] \u001b[32mTrain: [ 20/600] Step 080/520 Loss 0.826 Prec@(1,5) (80.1%, 98.9%)\u001b[0m\n",
            "INFO:nni:Train: [ 20/600] Step 080/520 Loss 0.826 Prec@(1,5) (80.1%, 98.9%)\n",
            "[2023-01-12 17:00:58] \u001b[32mTrain: [ 20/600] Step 090/520 Loss 0.829 Prec@(1,5) (79.9%, 98.9%)\u001b[0m\n",
            "INFO:nni:Train: [ 20/600] Step 090/520 Loss 0.829 Prec@(1,5) (79.9%, 98.9%)\n",
            "[2023-01-12 17:01:02] \u001b[32mTrain: [ 20/600] Step 100/520 Loss 0.830 Prec@(1,5) (79.7%, 98.9%)\u001b[0m\n",
            "INFO:nni:Train: [ 20/600] Step 100/520 Loss 0.830 Prec@(1,5) (79.7%, 98.9%)\n",
            "[2023-01-12 17:01:07] \u001b[32mTrain: [ 20/600] Step 110/520 Loss 0.825 Prec@(1,5) (79.8%, 98.9%)\u001b[0m\n",
            "INFO:nni:Train: [ 20/600] Step 110/520 Loss 0.825 Prec@(1,5) (79.8%, 98.9%)\n",
            "[2023-01-12 17:01:11] \u001b[32mTrain: [ 20/600] Step 120/520 Loss 0.827 Prec@(1,5) (79.9%, 98.8%)\u001b[0m\n",
            "INFO:nni:Train: [ 20/600] Step 120/520 Loss 0.827 Prec@(1,5) (79.9%, 98.8%)\n",
            "[2023-01-12 17:01:16] \u001b[32mTrain: [ 20/600] Step 130/520 Loss 0.821 Prec@(1,5) (80.0%, 98.9%)\u001b[0m\n",
            "INFO:nni:Train: [ 20/600] Step 130/520 Loss 0.821 Prec@(1,5) (80.0%, 98.9%)\n",
            "[2023-01-12 17:01:20] \u001b[32mTrain: [ 20/600] Step 140/520 Loss 0.822 Prec@(1,5) (80.0%, 98.9%)\u001b[0m\n",
            "INFO:nni:Train: [ 20/600] Step 140/520 Loss 0.822 Prec@(1,5) (80.0%, 98.9%)\n",
            "[2023-01-12 17:01:25] \u001b[32mTrain: [ 20/600] Step 150/520 Loss 0.824 Prec@(1,5) (80.0%, 98.9%)\u001b[0m\n",
            "INFO:nni:Train: [ 20/600] Step 150/520 Loss 0.824 Prec@(1,5) (80.0%, 98.9%)\n",
            "[2023-01-12 17:01:29] \u001b[32mTrain: [ 20/600] Step 160/520 Loss 0.821 Prec@(1,5) (80.0%, 98.9%)\u001b[0m\n",
            "INFO:nni:Train: [ 20/600] Step 160/520 Loss 0.821 Prec@(1,5) (80.0%, 98.9%)\n",
            "[2023-01-12 17:01:34] \u001b[32mTrain: [ 20/600] Step 170/520 Loss 0.822 Prec@(1,5) (80.0%, 98.9%)\u001b[0m\n",
            "INFO:nni:Train: [ 20/600] Step 170/520 Loss 0.822 Prec@(1,5) (80.0%, 98.9%)\n",
            "[2023-01-12 17:01:38] \u001b[32mTrain: [ 20/600] Step 180/520 Loss 0.824 Prec@(1,5) (79.9%, 98.9%)\u001b[0m\n",
            "INFO:nni:Train: [ 20/600] Step 180/520 Loss 0.824 Prec@(1,5) (79.9%, 98.9%)\n",
            "[2023-01-12 17:01:43] \u001b[32mTrain: [ 20/600] Step 190/520 Loss 0.825 Prec@(1,5) (79.8%, 98.9%)\u001b[0m\n",
            "INFO:nni:Train: [ 20/600] Step 190/520 Loss 0.825 Prec@(1,5) (79.8%, 98.9%)\n",
            "[2023-01-12 17:01:47] \u001b[32mTrain: [ 20/600] Step 200/520 Loss 0.827 Prec@(1,5) (79.7%, 98.9%)\u001b[0m\n",
            "INFO:nni:Train: [ 20/600] Step 200/520 Loss 0.827 Prec@(1,5) (79.7%, 98.9%)\n",
            "[2023-01-12 17:01:52] \u001b[32mTrain: [ 20/600] Step 210/520 Loss 0.827 Prec@(1,5) (79.7%, 98.9%)\u001b[0m\n",
            "INFO:nni:Train: [ 20/600] Step 210/520 Loss 0.827 Prec@(1,5) (79.7%, 98.9%)\n",
            "[2023-01-12 17:01:57] \u001b[32mTrain: [ 20/600] Step 220/520 Loss 0.825 Prec@(1,5) (79.8%, 98.9%)\u001b[0m\n",
            "INFO:nni:Train: [ 20/600] Step 220/520 Loss 0.825 Prec@(1,5) (79.8%, 98.9%)\n",
            "[2023-01-12 17:02:01] \u001b[32mTrain: [ 20/600] Step 230/520 Loss 0.825 Prec@(1,5) (79.9%, 98.9%)\u001b[0m\n",
            "INFO:nni:Train: [ 20/600] Step 230/520 Loss 0.825 Prec@(1,5) (79.9%, 98.9%)\n",
            "[2023-01-12 17:02:06] \u001b[32mTrain: [ 20/600] Step 240/520 Loss 0.826 Prec@(1,5) (79.8%, 98.9%)\u001b[0m\n",
            "INFO:nni:Train: [ 20/600] Step 240/520 Loss 0.826 Prec@(1,5) (79.8%, 98.9%)\n",
            "[2023-01-12 17:02:10] \u001b[32mTrain: [ 20/600] Step 250/520 Loss 0.827 Prec@(1,5) (79.7%, 99.0%)\u001b[0m\n",
            "INFO:nni:Train: [ 20/600] Step 250/520 Loss 0.827 Prec@(1,5) (79.7%, 99.0%)\n",
            "[2023-01-12 17:02:15] \u001b[32mTrain: [ 20/600] Step 260/520 Loss 0.824 Prec@(1,5) (79.7%, 99.0%)\u001b[0m\n",
            "INFO:nni:Train: [ 20/600] Step 260/520 Loss 0.824 Prec@(1,5) (79.7%, 99.0%)\n",
            "[2023-01-12 17:02:19] \u001b[32mTrain: [ 20/600] Step 270/520 Loss 0.825 Prec@(1,5) (79.7%, 99.0%)\u001b[0m\n",
            "INFO:nni:Train: [ 20/600] Step 270/520 Loss 0.825 Prec@(1,5) (79.7%, 99.0%)\n",
            "[2023-01-12 17:02:24] \u001b[32mTrain: [ 20/600] Step 280/520 Loss 0.825 Prec@(1,5) (79.7%, 99.0%)\u001b[0m\n",
            "INFO:nni:Train: [ 20/600] Step 280/520 Loss 0.825 Prec@(1,5) (79.7%, 99.0%)\n",
            "[2023-01-12 17:02:28] \u001b[32mTrain: [ 20/600] Step 290/520 Loss 0.824 Prec@(1,5) (79.7%, 99.0%)\u001b[0m\n",
            "INFO:nni:Train: [ 20/600] Step 290/520 Loss 0.824 Prec@(1,5) (79.7%, 99.0%)\n",
            "[2023-01-12 17:02:33] \u001b[32mTrain: [ 20/600] Step 300/520 Loss 0.827 Prec@(1,5) (79.7%, 99.0%)\u001b[0m\n",
            "INFO:nni:Train: [ 20/600] Step 300/520 Loss 0.827 Prec@(1,5) (79.7%, 99.0%)\n",
            "[2023-01-12 17:02:37] \u001b[32mTrain: [ 20/600] Step 310/520 Loss 0.827 Prec@(1,5) (79.7%, 99.0%)\u001b[0m\n",
            "INFO:nni:Train: [ 20/600] Step 310/520 Loss 0.827 Prec@(1,5) (79.7%, 99.0%)\n",
            "[2023-01-12 17:02:42] \u001b[32mTrain: [ 20/600] Step 320/520 Loss 0.827 Prec@(1,5) (79.7%, 98.9%)\u001b[0m\n",
            "INFO:nni:Train: [ 20/600] Step 320/520 Loss 0.827 Prec@(1,5) (79.7%, 98.9%)\n",
            "[2023-01-12 17:02:46] \u001b[32mTrain: [ 20/600] Step 330/520 Loss 0.826 Prec@(1,5) (79.7%, 98.9%)\u001b[0m\n",
            "INFO:nni:Train: [ 20/600] Step 330/520 Loss 0.826 Prec@(1,5) (79.7%, 98.9%)\n",
            "[2023-01-12 17:02:51] \u001b[32mTrain: [ 20/600] Step 340/520 Loss 0.824 Prec@(1,5) (79.8%, 98.9%)\u001b[0m\n",
            "INFO:nni:Train: [ 20/600] Step 340/520 Loss 0.824 Prec@(1,5) (79.8%, 98.9%)\n",
            "[2023-01-12 17:02:55] \u001b[32mTrain: [ 20/600] Step 350/520 Loss 0.823 Prec@(1,5) (79.8%, 98.9%)\u001b[0m\n",
            "INFO:nni:Train: [ 20/600] Step 350/520 Loss 0.823 Prec@(1,5) (79.8%, 98.9%)\n",
            "[2023-01-12 17:03:00] \u001b[32mTrain: [ 20/600] Step 360/520 Loss 0.821 Prec@(1,5) (79.9%, 99.0%)\u001b[0m\n",
            "INFO:nni:Train: [ 20/600] Step 360/520 Loss 0.821 Prec@(1,5) (79.9%, 99.0%)\n",
            "[2023-01-12 17:03:04] \u001b[32mTrain: [ 20/600] Step 370/520 Loss 0.820 Prec@(1,5) (79.9%, 98.9%)\u001b[0m\n",
            "INFO:nni:Train: [ 20/600] Step 370/520 Loss 0.820 Prec@(1,5) (79.9%, 98.9%)\n",
            "[2023-01-12 17:03:09] \u001b[32mTrain: [ 20/600] Step 380/520 Loss 0.820 Prec@(1,5) (79.9%, 98.9%)\u001b[0m\n",
            "INFO:nni:Train: [ 20/600] Step 380/520 Loss 0.820 Prec@(1,5) (79.9%, 98.9%)\n",
            "[2023-01-12 17:03:13] \u001b[32mTrain: [ 20/600] Step 390/520 Loss 0.818 Prec@(1,5) (80.0%, 98.9%)\u001b[0m\n",
            "INFO:nni:Train: [ 20/600] Step 390/520 Loss 0.818 Prec@(1,5) (80.0%, 98.9%)\n",
            "[2023-01-12 17:03:18] \u001b[32mTrain: [ 20/600] Step 400/520 Loss 0.817 Prec@(1,5) (80.0%, 98.9%)\u001b[0m\n",
            "INFO:nni:Train: [ 20/600] Step 400/520 Loss 0.817 Prec@(1,5) (80.0%, 98.9%)\n",
            "[2023-01-12 17:03:22] \u001b[32mTrain: [ 20/600] Step 410/520 Loss 0.819 Prec@(1,5) (80.0%, 98.9%)\u001b[0m\n",
            "INFO:nni:Train: [ 20/600] Step 410/520 Loss 0.819 Prec@(1,5) (80.0%, 98.9%)\n",
            "[2023-01-12 17:03:27] \u001b[32mTrain: [ 20/600] Step 420/520 Loss 0.818 Prec@(1,5) (80.0%, 98.9%)\u001b[0m\n",
            "INFO:nni:Train: [ 20/600] Step 420/520 Loss 0.818 Prec@(1,5) (80.0%, 98.9%)\n",
            "[2023-01-12 17:03:31] \u001b[32mTrain: [ 20/600] Step 430/520 Loss 0.816 Prec@(1,5) (80.1%, 98.9%)\u001b[0m\n",
            "INFO:nni:Train: [ 20/600] Step 430/520 Loss 0.816 Prec@(1,5) (80.1%, 98.9%)\n",
            "[2023-01-12 17:03:36] \u001b[32mTrain: [ 20/600] Step 440/520 Loss 0.817 Prec@(1,5) (80.1%, 98.9%)\u001b[0m\n",
            "INFO:nni:Train: [ 20/600] Step 440/520 Loss 0.817 Prec@(1,5) (80.1%, 98.9%)\n",
            "[2023-01-12 17:03:40] \u001b[32mTrain: [ 20/600] Step 450/520 Loss 0.817 Prec@(1,5) (80.1%, 98.9%)\u001b[0m\n",
            "INFO:nni:Train: [ 20/600] Step 450/520 Loss 0.817 Prec@(1,5) (80.1%, 98.9%)\n",
            "[2023-01-12 17:03:45] \u001b[32mTrain: [ 20/600] Step 460/520 Loss 0.816 Prec@(1,5) (80.1%, 98.9%)\u001b[0m\n",
            "INFO:nni:Train: [ 20/600] Step 460/520 Loss 0.816 Prec@(1,5) (80.1%, 98.9%)\n",
            "[2023-01-12 17:03:50] \u001b[32mTrain: [ 20/600] Step 470/520 Loss 0.817 Prec@(1,5) (80.1%, 98.9%)\u001b[0m\n",
            "INFO:nni:Train: [ 20/600] Step 470/520 Loss 0.817 Prec@(1,5) (80.1%, 98.9%)\n",
            "[2023-01-12 17:03:54] \u001b[32mTrain: [ 20/600] Step 480/520 Loss 0.817 Prec@(1,5) (80.1%, 98.9%)\u001b[0m\n",
            "INFO:nni:Train: [ 20/600] Step 480/520 Loss 0.817 Prec@(1,5) (80.1%, 98.9%)\n",
            "[2023-01-12 17:03:59] \u001b[32mTrain: [ 20/600] Step 490/520 Loss 0.817 Prec@(1,5) (80.1%, 98.9%)\u001b[0m\n",
            "INFO:nni:Train: [ 20/600] Step 490/520 Loss 0.817 Prec@(1,5) (80.1%, 98.9%)\n",
            "[2023-01-12 17:04:03] \u001b[32mTrain: [ 20/600] Step 500/520 Loss 0.817 Prec@(1,5) (80.1%, 98.9%)\u001b[0m\n",
            "INFO:nni:Train: [ 20/600] Step 500/520 Loss 0.817 Prec@(1,5) (80.1%, 98.9%)\n",
            "[2023-01-12 17:04:08] \u001b[32mTrain: [ 20/600] Step 510/520 Loss 0.816 Prec@(1,5) (80.1%, 98.9%)\u001b[0m\n",
            "INFO:nni:Train: [ 20/600] Step 510/520 Loss 0.816 Prec@(1,5) (80.1%, 98.9%)\n",
            "[2023-01-12 17:04:12] \u001b[32mTrain: [ 20/600] Step 520/520 Loss 0.816 Prec@(1,5) (80.1%, 98.9%)\u001b[0m\n",
            "INFO:nni:Train: [ 20/600] Step 520/520 Loss 0.816 Prec@(1,5) (80.1%, 98.9%)\n",
            "[2023-01-12 17:04:12] \u001b[32mTrain: [ 20/600] Final Prec@1 80.1340%\u001b[0m\n",
            "INFO:nni:Train: [ 20/600] Final Prec@1 80.1340%\n",
            "[2023-01-12 17:04:13] \u001b[32mValid: [ 20/600] Step 000/104 Loss 0.415 Prec@(1,5) (82.3%, 100.0%)\u001b[0m\n",
            "INFO:nni:Valid: [ 20/600] Step 000/104 Loss 0.415 Prec@(1,5) (82.3%, 100.0%)\n",
            "[2023-01-12 17:04:14] \u001b[32mValid: [ 20/600] Step 010/104 Loss 0.486 Prec@(1,5) (82.6%, 99.3%)\u001b[0m\n",
            "INFO:nni:Valid: [ 20/600] Step 010/104 Loss 0.486 Prec@(1,5) (82.6%, 99.3%)\n",
            "[2023-01-12 17:04:15] \u001b[32mValid: [ 20/600] Step 020/104 Loss 0.482 Prec@(1,5) (83.3%, 99.1%)\u001b[0m\n",
            "INFO:nni:Valid: [ 20/600] Step 020/104 Loss 0.482 Prec@(1,5) (83.3%, 99.1%)\n",
            "[2023-01-12 17:04:17] \u001b[32mValid: [ 20/600] Step 030/104 Loss 0.485 Prec@(1,5) (83.6%, 99.2%)\u001b[0m\n",
            "INFO:nni:Valid: [ 20/600] Step 030/104 Loss 0.485 Prec@(1,5) (83.6%, 99.2%)\n",
            "[2023-01-12 17:04:18] \u001b[32mValid: [ 20/600] Step 040/104 Loss 0.490 Prec@(1,5) (83.3%, 99.2%)\u001b[0m\n",
            "INFO:nni:Valid: [ 20/600] Step 040/104 Loss 0.490 Prec@(1,5) (83.3%, 99.2%)\n",
            "[2023-01-12 17:04:20] \u001b[32mValid: [ 20/600] Step 050/104 Loss 0.486 Prec@(1,5) (83.5%, 99.2%)\u001b[0m\n",
            "INFO:nni:Valid: [ 20/600] Step 050/104 Loss 0.486 Prec@(1,5) (83.5%, 99.2%)\n",
            "[2023-01-12 17:04:21] \u001b[32mValid: [ 20/600] Step 060/104 Loss 0.488 Prec@(1,5) (83.6%, 99.2%)\u001b[0m\n",
            "INFO:nni:Valid: [ 20/600] Step 060/104 Loss 0.488 Prec@(1,5) (83.6%, 99.2%)\n",
            "[2023-01-12 17:04:22] \u001b[32mValid: [ 20/600] Step 070/104 Loss 0.494 Prec@(1,5) (83.4%, 99.2%)\u001b[0m\n",
            "INFO:nni:Valid: [ 20/600] Step 070/104 Loss 0.494 Prec@(1,5) (83.4%, 99.2%)\n",
            "[2023-01-12 17:04:24] \u001b[32mValid: [ 20/600] Step 080/104 Loss 0.495 Prec@(1,5) (83.3%, 99.3%)\u001b[0m\n",
            "INFO:nni:Valid: [ 20/600] Step 080/104 Loss 0.495 Prec@(1,5) (83.3%, 99.3%)\n",
            "[2023-01-12 17:04:25] \u001b[32mValid: [ 20/600] Step 090/104 Loss 0.495 Prec@(1,5) (83.3%, 99.3%)\u001b[0m\n",
            "INFO:nni:Valid: [ 20/600] Step 090/104 Loss 0.495 Prec@(1,5) (83.3%, 99.3%)\n",
            "[2023-01-12 17:04:27] \u001b[32mValid: [ 20/600] Step 100/104 Loss 0.490 Prec@(1,5) (83.5%, 99.3%)\u001b[0m\n",
            "INFO:nni:Valid: [ 20/600] Step 100/104 Loss 0.490 Prec@(1,5) (83.5%, 99.3%)\n",
            "[2023-01-12 17:04:27] \u001b[32mValid: [ 20/600] Step 104/104 Loss 0.490 Prec@(1,5) (83.5%, 99.3%)\u001b[0m\n",
            "INFO:nni:Valid: [ 20/600] Step 104/104 Loss 0.490 Prec@(1,5) (83.5%, 99.3%)\n",
            "[2023-01-12 17:04:27] \u001b[32mValid: [ 20/600] Final Prec@1 83.4700%\u001b[0m\n",
            "INFO:nni:Valid: [ 20/600] Final Prec@1 83.4700%\n",
            "[2023-01-12 17:04:27] \u001b[32mEpoch 20 LR 0.024932\u001b[0m\n",
            "INFO:nni:Epoch 20 LR 0.024932\n",
            "[2023-01-12 17:04:28] \u001b[32mTrain: [ 21/600] Step 000/520 Loss 0.682 Prec@(1,5) (79.2%, 100.0%)\u001b[0m\n",
            "INFO:nni:Train: [ 21/600] Step 000/520 Loss 0.682 Prec@(1,5) (79.2%, 100.0%)\n",
            "[2023-01-12 17:04:33] \u001b[32mTrain: [ 21/600] Step 010/520 Loss 0.772 Prec@(1,5) (80.6%, 99.1%)\u001b[0m\n",
            "INFO:nni:Train: [ 21/600] Step 010/520 Loss 0.772 Prec@(1,5) (80.6%, 99.1%)\n",
            "[2023-01-12 17:04:37] \u001b[32mTrain: [ 21/600] Step 020/520 Loss 0.741 Prec@(1,5) (81.9%, 99.3%)\u001b[0m\n",
            "INFO:nni:Train: [ 21/600] Step 020/520 Loss 0.741 Prec@(1,5) (81.9%, 99.3%)\n",
            "[2023-01-12 17:04:42] \u001b[32mTrain: [ 21/600] Step 030/520 Loss 0.733 Prec@(1,5) (81.8%, 99.1%)\u001b[0m\n",
            "INFO:nni:Train: [ 21/600] Step 030/520 Loss 0.733 Prec@(1,5) (81.8%, 99.1%)\n",
            "[2023-01-12 17:04:46] \u001b[32mTrain: [ 21/600] Step 040/520 Loss 0.754 Prec@(1,5) (81.5%, 99.2%)\u001b[0m\n",
            "INFO:nni:Train: [ 21/600] Step 040/520 Loss 0.754 Prec@(1,5) (81.5%, 99.2%)\n",
            "[2023-01-12 17:04:51] \u001b[32mTrain: [ 21/600] Step 050/520 Loss 0.764 Prec@(1,5) (81.2%, 99.1%)\u001b[0m\n",
            "INFO:nni:Train: [ 21/600] Step 050/520 Loss 0.764 Prec@(1,5) (81.2%, 99.1%)\n",
            "[2023-01-12 17:04:55] \u001b[32mTrain: [ 21/600] Step 060/520 Loss 0.777 Prec@(1,5) (81.1%, 99.1%)\u001b[0m\n",
            "INFO:nni:Train: [ 21/600] Step 060/520 Loss 0.777 Prec@(1,5) (81.1%, 99.1%)\n",
            "[2023-01-12 17:05:00] \u001b[32mTrain: [ 21/600] Step 070/520 Loss 0.782 Prec@(1,5) (80.7%, 99.1%)\u001b[0m\n",
            "INFO:nni:Train: [ 21/600] Step 070/520 Loss 0.782 Prec@(1,5) (80.7%, 99.1%)\n",
            "[2023-01-12 17:05:04] \u001b[32mTrain: [ 21/600] Step 080/520 Loss 0.784 Prec@(1,5) (80.6%, 99.1%)\u001b[0m\n",
            "INFO:nni:Train: [ 21/600] Step 080/520 Loss 0.784 Prec@(1,5) (80.6%, 99.1%)\n",
            "[2023-01-12 17:05:09] \u001b[32mTrain: [ 21/600] Step 090/520 Loss 0.781 Prec@(1,5) (80.6%, 99.1%)\u001b[0m\n",
            "INFO:nni:Train: [ 21/600] Step 090/520 Loss 0.781 Prec@(1,5) (80.6%, 99.1%)\n",
            "[2023-01-12 17:05:13] \u001b[32mTrain: [ 21/600] Step 100/520 Loss 0.777 Prec@(1,5) (80.8%, 99.1%)\u001b[0m\n",
            "INFO:nni:Train: [ 21/600] Step 100/520 Loss 0.777 Prec@(1,5) (80.8%, 99.1%)\n",
            "[2023-01-12 17:05:18] \u001b[32mTrain: [ 21/600] Step 110/520 Loss 0.774 Prec@(1,5) (80.9%, 99.1%)\u001b[0m\n",
            "INFO:nni:Train: [ 21/600] Step 110/520 Loss 0.774 Prec@(1,5) (80.9%, 99.1%)\n",
            "[2023-01-12 17:05:22] \u001b[32mTrain: [ 21/600] Step 120/520 Loss 0.776 Prec@(1,5) (80.9%, 99.0%)\u001b[0m\n",
            "INFO:nni:Train: [ 21/600] Step 120/520 Loss 0.776 Prec@(1,5) (80.9%, 99.0%)\n",
            "[2023-01-12 17:05:27] \u001b[32mTrain: [ 21/600] Step 130/520 Loss 0.778 Prec@(1,5) (80.9%, 99.0%)\u001b[0m\n",
            "INFO:nni:Train: [ 21/600] Step 130/520 Loss 0.778 Prec@(1,5) (80.9%, 99.0%)\n",
            "[2023-01-12 17:05:31] \u001b[32mTrain: [ 21/600] Step 140/520 Loss 0.777 Prec@(1,5) (80.9%, 99.0%)\u001b[0m\n",
            "INFO:nni:Train: [ 21/600] Step 140/520 Loss 0.777 Prec@(1,5) (80.9%, 99.0%)\n",
            "[2023-01-12 17:05:36] \u001b[32mTrain: [ 21/600] Step 150/520 Loss 0.775 Prec@(1,5) (80.8%, 99.0%)\u001b[0m\n",
            "INFO:nni:Train: [ 21/600] Step 150/520 Loss 0.775 Prec@(1,5) (80.8%, 99.0%)\n",
            "[2023-01-12 17:05:40] \u001b[32mTrain: [ 21/600] Step 160/520 Loss 0.777 Prec@(1,5) (80.8%, 99.0%)\u001b[0m\n",
            "INFO:nni:Train: [ 21/600] Step 160/520 Loss 0.777 Prec@(1,5) (80.8%, 99.0%)\n",
            "[2023-01-12 17:05:45] \u001b[32mTrain: [ 21/600] Step 170/520 Loss 0.778 Prec@(1,5) (80.7%, 99.0%)\u001b[0m\n",
            "INFO:nni:Train: [ 21/600] Step 170/520 Loss 0.778 Prec@(1,5) (80.7%, 99.0%)\n",
            "[2023-01-12 17:05:49] \u001b[32mTrain: [ 21/600] Step 180/520 Loss 0.780 Prec@(1,5) (80.7%, 99.0%)\u001b[0m\n",
            "INFO:nni:Train: [ 21/600] Step 180/520 Loss 0.780 Prec@(1,5) (80.7%, 99.0%)\n",
            "[2023-01-12 17:05:54] \u001b[32mTrain: [ 21/600] Step 190/520 Loss 0.783 Prec@(1,5) (80.6%, 99.0%)\u001b[0m\n",
            "INFO:nni:Train: [ 21/600] Step 190/520 Loss 0.783 Prec@(1,5) (80.6%, 99.0%)\n",
            "[2023-01-12 17:05:58] \u001b[32mTrain: [ 21/600] Step 200/520 Loss 0.784 Prec@(1,5) (80.5%, 99.0%)\u001b[0m\n",
            "INFO:nni:Train: [ 21/600] Step 200/520 Loss 0.784 Prec@(1,5) (80.5%, 99.0%)\n",
            "[2023-01-12 17:06:03] \u001b[32mTrain: [ 21/600] Step 210/520 Loss 0.780 Prec@(1,5) (80.6%, 99.0%)\u001b[0m\n",
            "INFO:nni:Train: [ 21/600] Step 210/520 Loss 0.780 Prec@(1,5) (80.6%, 99.0%)\n",
            "[2023-01-12 17:06:07] \u001b[32mTrain: [ 21/600] Step 220/520 Loss 0.779 Prec@(1,5) (80.7%, 99.0%)\u001b[0m\n",
            "INFO:nni:Train: [ 21/600] Step 220/520 Loss 0.779 Prec@(1,5) (80.7%, 99.0%)\n",
            "[2023-01-12 17:06:12] \u001b[32mTrain: [ 21/600] Step 230/520 Loss 0.778 Prec@(1,5) (80.7%, 99.0%)\u001b[0m\n",
            "INFO:nni:Train: [ 21/600] Step 230/520 Loss 0.778 Prec@(1,5) (80.7%, 99.0%)\n",
            "[2023-01-12 17:06:17] \u001b[32mTrain: [ 21/600] Step 240/520 Loss 0.777 Prec@(1,5) (80.7%, 99.0%)\u001b[0m\n",
            "INFO:nni:Train: [ 21/600] Step 240/520 Loss 0.777 Prec@(1,5) (80.7%, 99.0%)\n",
            "[2023-01-12 17:06:21] \u001b[32mTrain: [ 21/600] Step 250/520 Loss 0.777 Prec@(1,5) (80.7%, 99.0%)\u001b[0m\n",
            "INFO:nni:Train: [ 21/600] Step 250/520 Loss 0.777 Prec@(1,5) (80.7%, 99.0%)\n",
            "[2023-01-12 17:06:26] \u001b[32mTrain: [ 21/600] Step 260/520 Loss 0.777 Prec@(1,5) (80.7%, 99.0%)\u001b[0m\n",
            "INFO:nni:Train: [ 21/600] Step 260/520 Loss 0.777 Prec@(1,5) (80.7%, 99.0%)\n",
            "[2023-01-12 17:06:30] \u001b[32mTrain: [ 21/600] Step 270/520 Loss 0.777 Prec@(1,5) (80.7%, 99.0%)\u001b[0m\n",
            "INFO:nni:Train: [ 21/600] Step 270/520 Loss 0.777 Prec@(1,5) (80.7%, 99.0%)\n",
            "[2023-01-12 17:06:35] \u001b[32mTrain: [ 21/600] Step 280/520 Loss 0.779 Prec@(1,5) (80.7%, 99.0%)\u001b[0m\n",
            "INFO:nni:Train: [ 21/600] Step 280/520 Loss 0.779 Prec@(1,5) (80.7%, 99.0%)\n",
            "[2023-01-12 17:06:39] \u001b[32mTrain: [ 21/600] Step 290/520 Loss 0.779 Prec@(1,5) (80.7%, 99.0%)\u001b[0m\n",
            "INFO:nni:Train: [ 21/600] Step 290/520 Loss 0.779 Prec@(1,5) (80.7%, 99.0%)\n",
            "[2023-01-12 17:06:44] \u001b[32mTrain: [ 21/600] Step 300/520 Loss 0.781 Prec@(1,5) (80.6%, 99.0%)\u001b[0m\n",
            "INFO:nni:Train: [ 21/600] Step 300/520 Loss 0.781 Prec@(1,5) (80.6%, 99.0%)\n",
            "[2023-01-12 17:06:48] \u001b[32mTrain: [ 21/600] Step 310/520 Loss 0.779 Prec@(1,5) (80.6%, 99.0%)\u001b[0m\n",
            "INFO:nni:Train: [ 21/600] Step 310/520 Loss 0.779 Prec@(1,5) (80.6%, 99.0%)\n",
            "[2023-01-12 17:06:53] \u001b[32mTrain: [ 21/600] Step 320/520 Loss 0.782 Prec@(1,5) (80.6%, 99.0%)\u001b[0m\n",
            "INFO:nni:Train: [ 21/600] Step 320/520 Loss 0.782 Prec@(1,5) (80.6%, 99.0%)\n",
            "[2023-01-12 17:06:57] \u001b[32mTrain: [ 21/600] Step 330/520 Loss 0.781 Prec@(1,5) (80.6%, 99.0%)\u001b[0m\n",
            "INFO:nni:Train: [ 21/600] Step 330/520 Loss 0.781 Prec@(1,5) (80.6%, 99.0%)\n",
            "[2023-01-12 17:07:02] \u001b[32mTrain: [ 21/600] Step 340/520 Loss 0.784 Prec@(1,5) (80.6%, 99.0%)\u001b[0m\n",
            "INFO:nni:Train: [ 21/600] Step 340/520 Loss 0.784 Prec@(1,5) (80.6%, 99.0%)\n",
            "[2023-01-12 17:07:06] \u001b[32mTrain: [ 21/600] Step 350/520 Loss 0.786 Prec@(1,5) (80.5%, 99.0%)\u001b[0m\n",
            "INFO:nni:Train: [ 21/600] Step 350/520 Loss 0.786 Prec@(1,5) (80.5%, 99.0%)\n",
            "[2023-01-12 17:07:11] \u001b[32mTrain: [ 21/600] Step 360/520 Loss 0.788 Prec@(1,5) (80.5%, 99.0%)\u001b[0m\n",
            "INFO:nni:Train: [ 21/600] Step 360/520 Loss 0.788 Prec@(1,5) (80.5%, 99.0%)\n",
            "[2023-01-12 17:07:15] \u001b[32mTrain: [ 21/600] Step 370/520 Loss 0.789 Prec@(1,5) (80.4%, 99.0%)\u001b[0m\n",
            "INFO:nni:Train: [ 21/600] Step 370/520 Loss 0.789 Prec@(1,5) (80.4%, 99.0%)\n",
            "[2023-01-12 17:07:20] \u001b[32mTrain: [ 21/600] Step 380/520 Loss 0.790 Prec@(1,5) (80.4%, 99.0%)\u001b[0m\n",
            "INFO:nni:Train: [ 21/600] Step 380/520 Loss 0.790 Prec@(1,5) (80.4%, 99.0%)\n",
            "[2023-01-12 17:07:24] \u001b[32mTrain: [ 21/600] Step 390/520 Loss 0.791 Prec@(1,5) (80.4%, 99.0%)\u001b[0m\n",
            "INFO:nni:Train: [ 21/600] Step 390/520 Loss 0.791 Prec@(1,5) (80.4%, 99.0%)\n",
            "[2023-01-12 17:07:29] \u001b[32mTrain: [ 21/600] Step 400/520 Loss 0.792 Prec@(1,5) (80.4%, 99.0%)\u001b[0m\n",
            "INFO:nni:Train: [ 21/600] Step 400/520 Loss 0.792 Prec@(1,5) (80.4%, 99.0%)\n",
            "[2023-01-12 17:07:33] \u001b[32mTrain: [ 21/600] Step 410/520 Loss 0.792 Prec@(1,5) (80.4%, 99.0%)\u001b[0m\n",
            "INFO:nni:Train: [ 21/600] Step 410/520 Loss 0.792 Prec@(1,5) (80.4%, 99.0%)\n",
            "[2023-01-12 17:07:38] \u001b[32mTrain: [ 21/600] Step 420/520 Loss 0.793 Prec@(1,5) (80.4%, 99.0%)\u001b[0m\n",
            "INFO:nni:Train: [ 21/600] Step 420/520 Loss 0.793 Prec@(1,5) (80.4%, 99.0%)\n",
            "[2023-01-12 17:07:42] \u001b[32mTrain: [ 21/600] Step 430/520 Loss 0.793 Prec@(1,5) (80.3%, 99.0%)\u001b[0m\n",
            "INFO:nni:Train: [ 21/600] Step 430/520 Loss 0.793 Prec@(1,5) (80.3%, 99.0%)\n",
            "[2023-01-12 17:07:47] \u001b[32mTrain: [ 21/600] Step 440/520 Loss 0.793 Prec@(1,5) (80.4%, 99.0%)\u001b[0m\n",
            "INFO:nni:Train: [ 21/600] Step 440/520 Loss 0.793 Prec@(1,5) (80.4%, 99.0%)\n",
            "[2023-01-12 17:07:51] \u001b[32mTrain: [ 21/600] Step 450/520 Loss 0.791 Prec@(1,5) (80.4%, 99.0%)\u001b[0m\n",
            "INFO:nni:Train: [ 21/600] Step 450/520 Loss 0.791 Prec@(1,5) (80.4%, 99.0%)\n",
            "[2023-01-12 17:07:56] \u001b[32mTrain: [ 21/600] Step 460/520 Loss 0.792 Prec@(1,5) (80.4%, 99.0%)\u001b[0m\n",
            "INFO:nni:Train: [ 21/600] Step 460/520 Loss 0.792 Prec@(1,5) (80.4%, 99.0%)\n",
            "[2023-01-12 17:08:00] \u001b[32mTrain: [ 21/600] Step 470/520 Loss 0.793 Prec@(1,5) (80.4%, 99.0%)\u001b[0m\n",
            "INFO:nni:Train: [ 21/600] Step 470/520 Loss 0.793 Prec@(1,5) (80.4%, 99.0%)\n",
            "[2023-01-12 17:08:05] \u001b[32mTrain: [ 21/600] Step 480/520 Loss 0.793 Prec@(1,5) (80.4%, 99.0%)\u001b[0m\n",
            "INFO:nni:Train: [ 21/600] Step 480/520 Loss 0.793 Prec@(1,5) (80.4%, 99.0%)\n",
            "[2023-01-12 17:08:10] \u001b[32mTrain: [ 21/600] Step 490/520 Loss 0.794 Prec@(1,5) (80.3%, 99.0%)\u001b[0m\n",
            "INFO:nni:Train: [ 21/600] Step 490/520 Loss 0.794 Prec@(1,5) (80.3%, 99.0%)\n",
            "[2023-01-12 17:08:14] \u001b[32mTrain: [ 21/600] Step 500/520 Loss 0.795 Prec@(1,5) (80.3%, 99.0%)\u001b[0m\n",
            "INFO:nni:Train: [ 21/600] Step 500/520 Loss 0.795 Prec@(1,5) (80.3%, 99.0%)\n",
            "[2023-01-12 17:08:19] \u001b[32mTrain: [ 21/600] Step 510/520 Loss 0.797 Prec@(1,5) (80.3%, 99.0%)\u001b[0m\n",
            "INFO:nni:Train: [ 21/600] Step 510/520 Loss 0.797 Prec@(1,5) (80.3%, 99.0%)\n",
            "[2023-01-12 17:08:23] \u001b[32mTrain: [ 21/600] Step 520/520 Loss 0.798 Prec@(1,5) (80.2%, 99.0%)\u001b[0m\n",
            "INFO:nni:Train: [ 21/600] Step 520/520 Loss 0.798 Prec@(1,5) (80.2%, 99.0%)\n",
            "[2023-01-12 17:08:23] \u001b[32mTrain: [ 21/600] Final Prec@1 80.2040%\u001b[0m\n",
            "INFO:nni:Train: [ 21/600] Final Prec@1 80.2040%\n",
            "[2023-01-12 17:08:24] \u001b[32mValid: [ 21/600] Step 000/104 Loss 0.484 Prec@(1,5) (83.3%, 99.0%)\u001b[0m\n",
            "INFO:nni:Valid: [ 21/600] Step 000/104 Loss 0.484 Prec@(1,5) (83.3%, 99.0%)\n",
            "[2023-01-12 17:08:25] \u001b[32mValid: [ 21/600] Step 010/104 Loss 0.503 Prec@(1,5) (83.7%, 99.3%)\u001b[0m\n",
            "INFO:nni:Valid: [ 21/600] Step 010/104 Loss 0.503 Prec@(1,5) (83.7%, 99.3%)\n",
            "[2023-01-12 17:08:26] \u001b[32mValid: [ 21/600] Step 020/104 Loss 0.494 Prec@(1,5) (83.6%, 99.2%)\u001b[0m\n",
            "INFO:nni:Valid: [ 21/600] Step 020/104 Loss 0.494 Prec@(1,5) (83.6%, 99.2%)\n",
            "[2023-01-12 17:08:28] \u001b[32mValid: [ 21/600] Step 030/104 Loss 0.507 Prec@(1,5) (83.5%, 99.0%)\u001b[0m\n",
            "INFO:nni:Valid: [ 21/600] Step 030/104 Loss 0.507 Prec@(1,5) (83.5%, 99.0%)\n",
            "[2023-01-12 17:08:29] \u001b[32mValid: [ 21/600] Step 040/104 Loss 0.516 Prec@(1,5) (83.1%, 98.9%)\u001b[0m\n",
            "INFO:nni:Valid: [ 21/600] Step 040/104 Loss 0.516 Prec@(1,5) (83.1%, 98.9%)\n",
            "[2023-01-12 17:08:31] \u001b[32mValid: [ 21/600] Step 050/104 Loss 0.508 Prec@(1,5) (83.5%, 98.9%)\u001b[0m\n",
            "INFO:nni:Valid: [ 21/600] Step 050/104 Loss 0.508 Prec@(1,5) (83.5%, 98.9%)\n",
            "[2023-01-12 17:08:32] \u001b[32mValid: [ 21/600] Step 060/104 Loss 0.507 Prec@(1,5) (83.6%, 98.9%)\u001b[0m\n",
            "INFO:nni:Valid: [ 21/600] Step 060/104 Loss 0.507 Prec@(1,5) (83.6%, 98.9%)\n",
            "[2023-01-12 17:08:33] \u001b[32mValid: [ 21/600] Step 070/104 Loss 0.507 Prec@(1,5) (83.7%, 99.0%)\u001b[0m\n",
            "INFO:nni:Valid: [ 21/600] Step 070/104 Loss 0.507 Prec@(1,5) (83.7%, 99.0%)\n",
            "[2023-01-12 17:08:35] \u001b[32mValid: [ 21/600] Step 080/104 Loss 0.508 Prec@(1,5) (83.6%, 99.0%)\u001b[0m\n",
            "INFO:nni:Valid: [ 21/600] Step 080/104 Loss 0.508 Prec@(1,5) (83.6%, 99.0%)\n",
            "[2023-01-12 17:08:36] \u001b[32mValid: [ 21/600] Step 090/104 Loss 0.511 Prec@(1,5) (83.3%, 99.0%)\u001b[0m\n",
            "INFO:nni:Valid: [ 21/600] Step 090/104 Loss 0.511 Prec@(1,5) (83.3%, 99.0%)\n",
            "[2023-01-12 17:08:38] \u001b[32mValid: [ 21/600] Step 100/104 Loss 0.506 Prec@(1,5) (83.4%, 99.1%)\u001b[0m\n",
            "INFO:nni:Valid: [ 21/600] Step 100/104 Loss 0.506 Prec@(1,5) (83.4%, 99.1%)\n",
            "[2023-01-12 17:08:38] \u001b[32mValid: [ 21/600] Step 104/104 Loss 0.507 Prec@(1,5) (83.4%, 99.1%)\u001b[0m\n",
            "INFO:nni:Valid: [ 21/600] Step 104/104 Loss 0.507 Prec@(1,5) (83.4%, 99.1%)\n",
            "[2023-01-12 17:08:38] \u001b[32mValid: [ 21/600] Final Prec@1 83.3800%\u001b[0m\n",
            "INFO:nni:Valid: [ 21/600] Final Prec@1 83.3800%\n",
            "[2023-01-12 17:08:38] \u001b[32mEpoch 21 LR 0.024925\u001b[0m\n",
            "INFO:nni:Epoch 21 LR 0.024925\n",
            "[2023-01-12 17:08:39] \u001b[32mTrain: [ 22/600] Step 000/520 Loss 0.868 Prec@(1,5) (78.1%, 97.9%)\u001b[0m\n",
            "INFO:nni:Train: [ 22/600] Step 000/520 Loss 0.868 Prec@(1,5) (78.1%, 97.9%)\n",
            "[2023-01-12 17:08:44] \u001b[32mTrain: [ 22/600] Step 010/520 Loss 0.787 Prec@(1,5) (80.2%, 99.2%)\u001b[0m\n",
            "INFO:nni:Train: [ 22/600] Step 010/520 Loss 0.787 Prec@(1,5) (80.2%, 99.2%)\n",
            "[2023-01-12 17:08:48] \u001b[32mTrain: [ 22/600] Step 020/520 Loss 0.771 Prec@(1,5) (80.3%, 99.4%)\u001b[0m\n",
            "INFO:nni:Train: [ 22/600] Step 020/520 Loss 0.771 Prec@(1,5) (80.3%, 99.4%)\n",
            "[2023-01-12 17:08:53] \u001b[32mTrain: [ 22/600] Step 030/520 Loss 0.760 Prec@(1,5) (80.7%, 99.4%)\u001b[0m\n",
            "INFO:nni:Train: [ 22/600] Step 030/520 Loss 0.760 Prec@(1,5) (80.7%, 99.4%)\n",
            "[2023-01-12 17:08:57] \u001b[32mTrain: [ 22/600] Step 040/520 Loss 0.748 Prec@(1,5) (81.1%, 99.4%)\u001b[0m\n",
            "INFO:nni:Train: [ 22/600] Step 040/520 Loss 0.748 Prec@(1,5) (81.1%, 99.4%)\n",
            "[2023-01-12 17:09:02] \u001b[32mTrain: [ 22/600] Step 050/520 Loss 0.744 Prec@(1,5) (81.2%, 99.3%)\u001b[0m\n",
            "INFO:nni:Train: [ 22/600] Step 050/520 Loss 0.744 Prec@(1,5) (81.2%, 99.3%)\n",
            "[2023-01-12 17:09:06] \u001b[32mTrain: [ 22/600] Step 060/520 Loss 0.750 Prec@(1,5) (81.6%, 99.2%)\u001b[0m\n",
            "INFO:nni:Train: [ 22/600] Step 060/520 Loss 0.750 Prec@(1,5) (81.6%, 99.2%)\n",
            "[2023-01-12 17:09:11] \u001b[32mTrain: [ 22/600] Step 070/520 Loss 0.746 Prec@(1,5) (81.6%, 99.2%)\u001b[0m\n",
            "INFO:nni:Train: [ 22/600] Step 070/520 Loss 0.746 Prec@(1,5) (81.6%, 99.2%)\n",
            "[2023-01-12 17:09:15] \u001b[32mTrain: [ 22/600] Step 080/520 Loss 0.749 Prec@(1,5) (81.6%, 99.3%)\u001b[0m\n",
            "INFO:nni:Train: [ 22/600] Step 080/520 Loss 0.749 Prec@(1,5) (81.6%, 99.3%)\n",
            "[2023-01-12 17:09:20] \u001b[32mTrain: [ 22/600] Step 090/520 Loss 0.756 Prec@(1,5) (81.3%, 99.2%)\u001b[0m\n",
            "INFO:nni:Train: [ 22/600] Step 090/520 Loss 0.756 Prec@(1,5) (81.3%, 99.2%)\n",
            "[2023-01-12 17:09:24] \u001b[32mTrain: [ 22/600] Step 100/520 Loss 0.753 Prec@(1,5) (81.4%, 99.2%)\u001b[0m\n",
            "INFO:nni:Train: [ 22/600] Step 100/520 Loss 0.753 Prec@(1,5) (81.4%, 99.2%)\n",
            "[2023-01-12 17:09:29] \u001b[32mTrain: [ 22/600] Step 110/520 Loss 0.752 Prec@(1,5) (81.5%, 99.2%)\u001b[0m\n",
            "INFO:nni:Train: [ 22/600] Step 110/520 Loss 0.752 Prec@(1,5) (81.5%, 99.2%)\n",
            "[2023-01-12 17:09:33] \u001b[32mTrain: [ 22/600] Step 120/520 Loss 0.753 Prec@(1,5) (81.4%, 99.2%)\u001b[0m\n",
            "INFO:nni:Train: [ 22/600] Step 120/520 Loss 0.753 Prec@(1,5) (81.4%, 99.2%)\n",
            "[2023-01-12 17:09:38] \u001b[32mTrain: [ 22/600] Step 130/520 Loss 0.756 Prec@(1,5) (81.3%, 99.2%)\u001b[0m\n",
            "INFO:nni:Train: [ 22/600] Step 130/520 Loss 0.756 Prec@(1,5) (81.3%, 99.2%)\n",
            "[2023-01-12 17:09:42] \u001b[32mTrain: [ 22/600] Step 140/520 Loss 0.761 Prec@(1,5) (81.2%, 99.2%)\u001b[0m\n",
            "INFO:nni:Train: [ 22/600] Step 140/520 Loss 0.761 Prec@(1,5) (81.2%, 99.2%)\n",
            "[2023-01-12 17:09:47] \u001b[32mTrain: [ 22/600] Step 150/520 Loss 0.764 Prec@(1,5) (81.1%, 99.1%)\u001b[0m\n",
            "INFO:nni:Train: [ 22/600] Step 150/520 Loss 0.764 Prec@(1,5) (81.1%, 99.1%)\n",
            "[2023-01-12 17:09:51] \u001b[32mTrain: [ 22/600] Step 160/520 Loss 0.765 Prec@(1,5) (81.1%, 99.2%)\u001b[0m\n",
            "INFO:nni:Train: [ 22/600] Step 160/520 Loss 0.765 Prec@(1,5) (81.1%, 99.2%)\n",
            "[2023-01-12 17:09:56] \u001b[32mTrain: [ 22/600] Step 170/520 Loss 0.766 Prec@(1,5) (81.0%, 99.2%)\u001b[0m\n",
            "INFO:nni:Train: [ 22/600] Step 170/520 Loss 0.766 Prec@(1,5) (81.0%, 99.2%)\n",
            "[2023-01-12 17:10:00] \u001b[32mTrain: [ 22/600] Step 180/520 Loss 0.764 Prec@(1,5) (81.0%, 99.2%)\u001b[0m\n",
            "INFO:nni:Train: [ 22/600] Step 180/520 Loss 0.764 Prec@(1,5) (81.0%, 99.2%)\n",
            "[2023-01-12 17:10:05] \u001b[32mTrain: [ 22/600] Step 190/520 Loss 0.762 Prec@(1,5) (81.1%, 99.2%)\u001b[0m\n",
            "INFO:nni:Train: [ 22/600] Step 190/520 Loss 0.762 Prec@(1,5) (81.1%, 99.2%)\n",
            "[2023-01-12 17:10:09] \u001b[32mTrain: [ 22/600] Step 200/520 Loss 0.768 Prec@(1,5) (81.0%, 99.1%)\u001b[0m\n",
            "INFO:nni:Train: [ 22/600] Step 200/520 Loss 0.768 Prec@(1,5) (81.0%, 99.1%)\n",
            "[2023-01-12 17:10:14] \u001b[32mTrain: [ 22/600] Step 210/520 Loss 0.769 Prec@(1,5) (80.9%, 99.1%)\u001b[0m\n",
            "INFO:nni:Train: [ 22/600] Step 210/520 Loss 0.769 Prec@(1,5) (80.9%, 99.1%)\n",
            "[2023-01-12 17:10:19] \u001b[32mTrain: [ 22/600] Step 220/520 Loss 0.772 Prec@(1,5) (80.9%, 99.1%)\u001b[0m\n",
            "INFO:nni:Train: [ 22/600] Step 220/520 Loss 0.772 Prec@(1,5) (80.9%, 99.1%)\n",
            "[2023-01-12 17:10:23] \u001b[32mTrain: [ 22/600] Step 230/520 Loss 0.772 Prec@(1,5) (80.9%, 99.1%)\u001b[0m\n",
            "INFO:nni:Train: [ 22/600] Step 230/520 Loss 0.772 Prec@(1,5) (80.9%, 99.1%)\n",
            "[2023-01-12 17:10:28] \u001b[32mTrain: [ 22/600] Step 240/520 Loss 0.770 Prec@(1,5) (80.9%, 99.1%)\u001b[0m\n",
            "INFO:nni:Train: [ 22/600] Step 240/520 Loss 0.770 Prec@(1,5) (80.9%, 99.1%)\n",
            "[2023-01-12 17:10:32] \u001b[32mTrain: [ 22/600] Step 250/520 Loss 0.767 Prec@(1,5) (81.0%, 99.1%)\u001b[0m\n",
            "INFO:nni:Train: [ 22/600] Step 250/520 Loss 0.767 Prec@(1,5) (81.0%, 99.1%)\n",
            "[2023-01-12 17:10:37] \u001b[32mTrain: [ 22/600] Step 260/520 Loss 0.766 Prec@(1,5) (81.0%, 99.1%)\u001b[0m\n",
            "INFO:nni:Train: [ 22/600] Step 260/520 Loss 0.766 Prec@(1,5) (81.0%, 99.1%)\n",
            "[2023-01-12 17:10:41] \u001b[32mTrain: [ 22/600] Step 270/520 Loss 0.767 Prec@(1,5) (81.0%, 99.1%)\u001b[0m\n",
            "INFO:nni:Train: [ 22/600] Step 270/520 Loss 0.767 Prec@(1,5) (81.0%, 99.1%)\n",
            "[2023-01-12 17:10:46] \u001b[32mTrain: [ 22/600] Step 280/520 Loss 0.770 Prec@(1,5) (81.0%, 99.1%)\u001b[0m\n",
            "INFO:nni:Train: [ 22/600] Step 280/520 Loss 0.770 Prec@(1,5) (81.0%, 99.1%)\n",
            "[2023-01-12 17:10:50] \u001b[32mTrain: [ 22/600] Step 290/520 Loss 0.771 Prec@(1,5) (80.9%, 99.1%)\u001b[0m\n",
            "INFO:nni:Train: [ 22/600] Step 290/520 Loss 0.771 Prec@(1,5) (80.9%, 99.1%)\n",
            "[2023-01-12 17:10:55] \u001b[32mTrain: [ 22/600] Step 300/520 Loss 0.770 Prec@(1,5) (81.0%, 99.1%)\u001b[0m\n",
            "INFO:nni:Train: [ 22/600] Step 300/520 Loss 0.770 Prec@(1,5) (81.0%, 99.1%)\n",
            "[2023-01-12 17:10:59] \u001b[32mTrain: [ 22/600] Step 310/520 Loss 0.769 Prec@(1,5) (81.0%, 99.1%)\u001b[0m\n",
            "INFO:nni:Train: [ 22/600] Step 310/520 Loss 0.769 Prec@(1,5) (81.0%, 99.1%)\n",
            "[2023-01-12 17:11:04] \u001b[32mTrain: [ 22/600] Step 320/520 Loss 0.768 Prec@(1,5) (81.1%, 99.1%)\u001b[0m\n",
            "INFO:nni:Train: [ 22/600] Step 320/520 Loss 0.768 Prec@(1,5) (81.1%, 99.1%)\n",
            "[2023-01-12 17:11:08] \u001b[32mTrain: [ 22/600] Step 330/520 Loss 0.771 Prec@(1,5) (81.0%, 99.1%)\u001b[0m\n",
            "INFO:nni:Train: [ 22/600] Step 330/520 Loss 0.771 Prec@(1,5) (81.0%, 99.1%)\n",
            "[2023-01-12 17:11:13] \u001b[32mTrain: [ 22/600] Step 340/520 Loss 0.769 Prec@(1,5) (81.0%, 99.1%)\u001b[0m\n",
            "INFO:nni:Train: [ 22/600] Step 340/520 Loss 0.769 Prec@(1,5) (81.0%, 99.1%)\n",
            "[2023-01-12 17:11:17] \u001b[32mTrain: [ 22/600] Step 350/520 Loss 0.767 Prec@(1,5) (81.1%, 99.1%)\u001b[0m\n",
            "INFO:nni:Train: [ 22/600] Step 350/520 Loss 0.767 Prec@(1,5) (81.1%, 99.1%)\n",
            "[2023-01-12 17:11:22] \u001b[32mTrain: [ 22/600] Step 360/520 Loss 0.768 Prec@(1,5) (81.0%, 99.1%)\u001b[0m\n",
            "INFO:nni:Train: [ 22/600] Step 360/520 Loss 0.768 Prec@(1,5) (81.0%, 99.1%)\n",
            "[2023-01-12 17:11:26] \u001b[32mTrain: [ 22/600] Step 370/520 Loss 0.768 Prec@(1,5) (81.0%, 99.1%)\u001b[0m\n",
            "INFO:nni:Train: [ 22/600] Step 370/520 Loss 0.768 Prec@(1,5) (81.0%, 99.1%)\n",
            "[2023-01-12 17:11:31] \u001b[32mTrain: [ 22/600] Step 380/520 Loss 0.770 Prec@(1,5) (81.0%, 99.1%)\u001b[0m\n",
            "INFO:nni:Train: [ 22/600] Step 380/520 Loss 0.770 Prec@(1,5) (81.0%, 99.1%)\n",
            "[2023-01-12 17:11:35] \u001b[32mTrain: [ 22/600] Step 390/520 Loss 0.770 Prec@(1,5) (81.0%, 99.1%)\u001b[0m\n",
            "INFO:nni:Train: [ 22/600] Step 390/520 Loss 0.770 Prec@(1,5) (81.0%, 99.1%)\n",
            "[2023-01-12 17:11:40] \u001b[32mTrain: [ 22/600] Step 400/520 Loss 0.772 Prec@(1,5) (81.0%, 99.1%)\u001b[0m\n",
            "INFO:nni:Train: [ 22/600] Step 400/520 Loss 0.772 Prec@(1,5) (81.0%, 99.1%)\n",
            "[2023-01-12 17:11:44] \u001b[32mTrain: [ 22/600] Step 410/520 Loss 0.773 Prec@(1,5) (80.9%, 99.1%)\u001b[0m\n",
            "INFO:nni:Train: [ 22/600] Step 410/520 Loss 0.773 Prec@(1,5) (80.9%, 99.1%)\n",
            "[2023-01-12 17:11:49] \u001b[32mTrain: [ 22/600] Step 420/520 Loss 0.776 Prec@(1,5) (80.8%, 99.1%)\u001b[0m\n",
            "INFO:nni:Train: [ 22/600] Step 420/520 Loss 0.776 Prec@(1,5) (80.8%, 99.1%)\n",
            "[2023-01-12 17:11:53] \u001b[32mTrain: [ 22/600] Step 430/520 Loss 0.777 Prec@(1,5) (80.8%, 99.1%)\u001b[0m\n",
            "INFO:nni:Train: [ 22/600] Step 430/520 Loss 0.777 Prec@(1,5) (80.8%, 99.1%)\n",
            "[2023-01-12 17:11:58] \u001b[32mTrain: [ 22/600] Step 440/520 Loss 0.777 Prec@(1,5) (80.8%, 99.1%)\u001b[0m\n",
            "INFO:nni:Train: [ 22/600] Step 440/520 Loss 0.777 Prec@(1,5) (80.8%, 99.1%)\n",
            "[2023-01-12 17:12:02] \u001b[32mTrain: [ 22/600] Step 450/520 Loss 0.776 Prec@(1,5) (80.9%, 99.1%)\u001b[0m\n",
            "INFO:nni:Train: [ 22/600] Step 450/520 Loss 0.776 Prec@(1,5) (80.9%, 99.1%)\n",
            "[2023-01-12 17:12:07] \u001b[32mTrain: [ 22/600] Step 460/520 Loss 0.775 Prec@(1,5) (80.9%, 99.1%)\u001b[0m\n",
            "INFO:nni:Train: [ 22/600] Step 460/520 Loss 0.775 Prec@(1,5) (80.9%, 99.1%)\n",
            "[2023-01-12 17:12:11] \u001b[32mTrain: [ 22/600] Step 470/520 Loss 0.774 Prec@(1,5) (80.9%, 99.1%)\u001b[0m\n",
            "INFO:nni:Train: [ 22/600] Step 470/520 Loss 0.774 Prec@(1,5) (80.9%, 99.1%)\n",
            "[2023-01-12 17:12:16] \u001b[32mTrain: [ 22/600] Step 480/520 Loss 0.773 Prec@(1,5) (80.9%, 99.1%)\u001b[0m\n",
            "INFO:nni:Train: [ 22/600] Step 480/520 Loss 0.773 Prec@(1,5) (80.9%, 99.1%)\n",
            "[2023-01-12 17:12:21] \u001b[32mTrain: [ 22/600] Step 490/520 Loss 0.775 Prec@(1,5) (80.9%, 99.1%)\u001b[0m\n",
            "INFO:nni:Train: [ 22/600] Step 490/520 Loss 0.775 Prec@(1,5) (80.9%, 99.1%)\n",
            "[2023-01-12 17:12:25] \u001b[32mTrain: [ 22/600] Step 500/520 Loss 0.774 Prec@(1,5) (80.9%, 99.1%)\u001b[0m\n",
            "INFO:nni:Train: [ 22/600] Step 500/520 Loss 0.774 Prec@(1,5) (80.9%, 99.1%)\n",
            "[2023-01-12 17:12:30] \u001b[32mTrain: [ 22/600] Step 510/520 Loss 0.775 Prec@(1,5) (80.9%, 99.1%)\u001b[0m\n",
            "INFO:nni:Train: [ 22/600] Step 510/520 Loss 0.775 Prec@(1,5) (80.9%, 99.1%)\n",
            "[2023-01-12 17:12:34] \u001b[32mTrain: [ 22/600] Step 520/520 Loss 0.776 Prec@(1,5) (80.9%, 99.1%)\u001b[0m\n",
            "INFO:nni:Train: [ 22/600] Step 520/520 Loss 0.776 Prec@(1,5) (80.9%, 99.1%)\n",
            "[2023-01-12 17:12:34] \u001b[32mTrain: [ 22/600] Final Prec@1 80.8740%\u001b[0m\n",
            "INFO:nni:Train: [ 22/600] Final Prec@1 80.8740%\n",
            "[2023-01-12 17:12:34] \u001b[32mValid: [ 22/600] Step 000/104 Loss 0.530 Prec@(1,5) (80.2%, 97.9%)\u001b[0m\n",
            "INFO:nni:Valid: [ 22/600] Step 000/104 Loss 0.530 Prec@(1,5) (80.2%, 97.9%)\n",
            "[2023-01-12 17:12:36] \u001b[32mValid: [ 22/600] Step 010/104 Loss 0.486 Prec@(1,5) (82.7%, 99.1%)\u001b[0m\n",
            "INFO:nni:Valid: [ 22/600] Step 010/104 Loss 0.486 Prec@(1,5) (82.7%, 99.1%)\n",
            "[2023-01-12 17:12:37] \u001b[32mValid: [ 22/600] Step 020/104 Loss 0.501 Prec@(1,5) (83.4%, 99.0%)\u001b[0m\n",
            "INFO:nni:Valid: [ 22/600] Step 020/104 Loss 0.501 Prec@(1,5) (83.4%, 99.0%)\n",
            "[2023-01-12 17:12:39] \u001b[32mValid: [ 22/600] Step 030/104 Loss 0.509 Prec@(1,5) (83.3%, 99.1%)\u001b[0m\n",
            "INFO:nni:Valid: [ 22/600] Step 030/104 Loss 0.509 Prec@(1,5) (83.3%, 99.1%)\n",
            "[2023-01-12 17:12:40] \u001b[32mValid: [ 22/600] Step 040/104 Loss 0.512 Prec@(1,5) (83.2%, 99.1%)\u001b[0m\n",
            "INFO:nni:Valid: [ 22/600] Step 040/104 Loss 0.512 Prec@(1,5) (83.2%, 99.1%)\n",
            "[2023-01-12 17:12:42] \u001b[32mValid: [ 22/600] Step 050/104 Loss 0.506 Prec@(1,5) (83.2%, 99.0%)\u001b[0m\n",
            "INFO:nni:Valid: [ 22/600] Step 050/104 Loss 0.506 Prec@(1,5) (83.2%, 99.0%)\n",
            "[2023-01-12 17:12:43] \u001b[32mValid: [ 22/600] Step 060/104 Loss 0.502 Prec@(1,5) (83.3%, 99.1%)\u001b[0m\n",
            "INFO:nni:Valid: [ 22/600] Step 060/104 Loss 0.502 Prec@(1,5) (83.3%, 99.1%)\n",
            "[2023-01-12 17:12:44] \u001b[32mValid: [ 22/600] Step 070/104 Loss 0.502 Prec@(1,5) (83.3%, 99.1%)\u001b[0m\n",
            "INFO:nni:Valid: [ 22/600] Step 070/104 Loss 0.502 Prec@(1,5) (83.3%, 99.1%)\n",
            "[2023-01-12 17:12:46] \u001b[32mValid: [ 22/600] Step 080/104 Loss 0.501 Prec@(1,5) (83.3%, 99.2%)\u001b[0m\n",
            "INFO:nni:Valid: [ 22/600] Step 080/104 Loss 0.501 Prec@(1,5) (83.3%, 99.2%)\n",
            "[2023-01-12 17:12:47] \u001b[32mValid: [ 22/600] Step 090/104 Loss 0.500 Prec@(1,5) (83.3%, 99.2%)\u001b[0m\n",
            "INFO:nni:Valid: [ 22/600] Step 090/104 Loss 0.500 Prec@(1,5) (83.3%, 99.2%)\n",
            "[2023-01-12 17:12:49] \u001b[32mValid: [ 22/600] Step 100/104 Loss 0.499 Prec@(1,5) (83.3%, 99.2%)\u001b[0m\n",
            "INFO:nni:Valid: [ 22/600] Step 100/104 Loss 0.499 Prec@(1,5) (83.3%, 99.2%)\n",
            "[2023-01-12 17:12:49] \u001b[32mValid: [ 22/600] Step 104/104 Loss 0.500 Prec@(1,5) (83.2%, 99.3%)\u001b[0m\n",
            "INFO:nni:Valid: [ 22/600] Step 104/104 Loss 0.500 Prec@(1,5) (83.2%, 99.3%)\n",
            "[2023-01-12 17:12:49] \u001b[32mValid: [ 22/600] Final Prec@1 83.2300%\u001b[0m\n",
            "INFO:nni:Valid: [ 22/600] Final Prec@1 83.2300%\n",
            "[2023-01-12 17:12:49] \u001b[32mEpoch 22 LR 0.024917\u001b[0m\n",
            "INFO:nni:Epoch 22 LR 0.024917\n",
            "[2023-01-12 17:12:50] \u001b[32mTrain: [ 23/600] Step 000/520 Loss 0.897 Prec@(1,5) (80.2%, 99.0%)\u001b[0m\n",
            "INFO:nni:Train: [ 23/600] Step 000/520 Loss 0.897 Prec@(1,5) (80.2%, 99.0%)\n",
            "[2023-01-12 17:12:55] \u001b[32mTrain: [ 23/600] Step 010/520 Loss 0.823 Prec@(1,5) (80.8%, 99.1%)\u001b[0m\n",
            "INFO:nni:Train: [ 23/600] Step 010/520 Loss 0.823 Prec@(1,5) (80.8%, 99.1%)\n",
            "[2023-01-12 17:12:59] \u001b[32mTrain: [ 23/600] Step 020/520 Loss 0.737 Prec@(1,5) (82.3%, 99.4%)\u001b[0m\n",
            "INFO:nni:Train: [ 23/600] Step 020/520 Loss 0.737 Prec@(1,5) (82.3%, 99.4%)\n",
            "[2023-01-12 17:13:04] \u001b[32mTrain: [ 23/600] Step 030/520 Loss 0.740 Prec@(1,5) (82.2%, 99.2%)\u001b[0m\n",
            "INFO:nni:Train: [ 23/600] Step 030/520 Loss 0.740 Prec@(1,5) (82.2%, 99.2%)\n",
            "[2023-01-12 17:13:08] \u001b[32mTrain: [ 23/600] Step 040/520 Loss 0.742 Prec@(1,5) (82.1%, 99.2%)\u001b[0m\n",
            "INFO:nni:Train: [ 23/600] Step 040/520 Loss 0.742 Prec@(1,5) (82.1%, 99.2%)\n",
            "[2023-01-12 17:13:13] \u001b[32mTrain: [ 23/600] Step 050/520 Loss 0.736 Prec@(1,5) (82.4%, 99.1%)\u001b[0m\n",
            "INFO:nni:Train: [ 23/600] Step 050/520 Loss 0.736 Prec@(1,5) (82.4%, 99.1%)\n",
            "[2023-01-12 17:13:17] \u001b[32mTrain: [ 23/600] Step 060/520 Loss 0.734 Prec@(1,5) (82.3%, 99.2%)\u001b[0m\n",
            "INFO:nni:Train: [ 23/600] Step 060/520 Loss 0.734 Prec@(1,5) (82.3%, 99.2%)\n",
            "[2023-01-12 17:13:22] \u001b[32mTrain: [ 23/600] Step 070/520 Loss 0.734 Prec@(1,5) (82.1%, 99.3%)\u001b[0m\n",
            "INFO:nni:Train: [ 23/600] Step 070/520 Loss 0.734 Prec@(1,5) (82.1%, 99.3%)\n",
            "[2023-01-12 17:13:26] \u001b[32mTrain: [ 23/600] Step 080/520 Loss 0.733 Prec@(1,5) (82.0%, 99.2%)\u001b[0m\n",
            "INFO:nni:Train: [ 23/600] Step 080/520 Loss 0.733 Prec@(1,5) (82.0%, 99.2%)\n",
            "[2023-01-12 17:13:31] \u001b[32mTrain: [ 23/600] Step 090/520 Loss 0.739 Prec@(1,5) (81.8%, 99.2%)\u001b[0m\n",
            "INFO:nni:Train: [ 23/600] Step 090/520 Loss 0.739 Prec@(1,5) (81.8%, 99.2%)\n",
            "[2023-01-12 17:13:35] \u001b[32mTrain: [ 23/600] Step 100/520 Loss 0.727 Prec@(1,5) (82.2%, 99.2%)\u001b[0m\n",
            "INFO:nni:Train: [ 23/600] Step 100/520 Loss 0.727 Prec@(1,5) (82.2%, 99.2%)\n",
            "[2023-01-12 17:13:40] \u001b[32mTrain: [ 23/600] Step 110/520 Loss 0.723 Prec@(1,5) (82.3%, 99.2%)\u001b[0m\n",
            "INFO:nni:Train: [ 23/600] Step 110/520 Loss 0.723 Prec@(1,5) (82.3%, 99.2%)\n",
            "[2023-01-12 17:13:44] \u001b[32mTrain: [ 23/600] Step 120/520 Loss 0.722 Prec@(1,5) (82.4%, 99.2%)\u001b[0m\n",
            "INFO:nni:Train: [ 23/600] Step 120/520 Loss 0.722 Prec@(1,5) (82.4%, 99.2%)\n",
            "[2023-01-12 17:13:49] \u001b[32mTrain: [ 23/600] Step 130/520 Loss 0.724 Prec@(1,5) (82.2%, 99.2%)\u001b[0m\n",
            "INFO:nni:Train: [ 23/600] Step 130/520 Loss 0.724 Prec@(1,5) (82.2%, 99.2%)\n",
            "[2023-01-12 17:13:53] \u001b[32mTrain: [ 23/600] Step 140/520 Loss 0.721 Prec@(1,5) (82.3%, 99.2%)\u001b[0m\n",
            "INFO:nni:Train: [ 23/600] Step 140/520 Loss 0.721 Prec@(1,5) (82.3%, 99.2%)\n",
            "[2023-01-12 17:13:58] \u001b[32mTrain: [ 23/600] Step 150/520 Loss 0.725 Prec@(1,5) (82.2%, 99.2%)\u001b[0m\n",
            "INFO:nni:Train: [ 23/600] Step 150/520 Loss 0.725 Prec@(1,5) (82.2%, 99.2%)\n",
            "[2023-01-12 17:14:02] \u001b[32mTrain: [ 23/600] Step 160/520 Loss 0.729 Prec@(1,5) (82.1%, 99.2%)\u001b[0m\n",
            "INFO:nni:Train: [ 23/600] Step 160/520 Loss 0.729 Prec@(1,5) (82.1%, 99.2%)\n",
            "[2023-01-12 17:14:07] \u001b[32mTrain: [ 23/600] Step 170/520 Loss 0.730 Prec@(1,5) (82.0%, 99.3%)\u001b[0m\n",
            "INFO:nni:Train: [ 23/600] Step 170/520 Loss 0.730 Prec@(1,5) (82.0%, 99.3%)\n",
            "[2023-01-12 17:14:11] \u001b[32mTrain: [ 23/600] Step 180/520 Loss 0.736 Prec@(1,5) (81.8%, 99.2%)\u001b[0m\n",
            "INFO:nni:Train: [ 23/600] Step 180/520 Loss 0.736 Prec@(1,5) (81.8%, 99.2%)\n",
            "[2023-01-12 17:14:16] \u001b[32mTrain: [ 23/600] Step 190/520 Loss 0.739 Prec@(1,5) (81.7%, 99.2%)\u001b[0m\n",
            "INFO:nni:Train: [ 23/600] Step 190/520 Loss 0.739 Prec@(1,5) (81.7%, 99.2%)\n",
            "[2023-01-12 17:14:20] \u001b[32mTrain: [ 23/600] Step 200/520 Loss 0.737 Prec@(1,5) (81.8%, 99.2%)\u001b[0m\n",
            "INFO:nni:Train: [ 23/600] Step 200/520 Loss 0.737 Prec@(1,5) (81.8%, 99.2%)\n",
            "[2023-01-12 17:14:25] \u001b[32mTrain: [ 23/600] Step 210/520 Loss 0.741 Prec@(1,5) (81.8%, 99.2%)\u001b[0m\n",
            "INFO:nni:Train: [ 23/600] Step 210/520 Loss 0.741 Prec@(1,5) (81.8%, 99.2%)\n",
            "[2023-01-12 17:14:29] \u001b[32mTrain: [ 23/600] Step 220/520 Loss 0.742 Prec@(1,5) (81.7%, 99.2%)\u001b[0m\n",
            "INFO:nni:Train: [ 23/600] Step 220/520 Loss 0.742 Prec@(1,5) (81.7%, 99.2%)\n",
            "[2023-01-12 17:14:34] \u001b[32mTrain: [ 23/600] Step 230/520 Loss 0.743 Prec@(1,5) (81.7%, 99.2%)\u001b[0m\n",
            "INFO:nni:Train: [ 23/600] Step 230/520 Loss 0.743 Prec@(1,5) (81.7%, 99.2%)\n",
            "[2023-01-12 17:14:38] \u001b[32mTrain: [ 23/600] Step 240/520 Loss 0.747 Prec@(1,5) (81.6%, 99.2%)\u001b[0m\n",
            "INFO:nni:Train: [ 23/600] Step 240/520 Loss 0.747 Prec@(1,5) (81.6%, 99.2%)\n",
            "[2023-01-12 17:14:43] \u001b[32mTrain: [ 23/600] Step 250/520 Loss 0.750 Prec@(1,5) (81.6%, 99.2%)\u001b[0m\n",
            "INFO:nni:Train: [ 23/600] Step 250/520 Loss 0.750 Prec@(1,5) (81.6%, 99.2%)\n",
            "[2023-01-12 17:14:47] \u001b[32mTrain: [ 23/600] Step 260/520 Loss 0.753 Prec@(1,5) (81.5%, 99.1%)\u001b[0m\n",
            "INFO:nni:Train: [ 23/600] Step 260/520 Loss 0.753 Prec@(1,5) (81.5%, 99.1%)\n",
            "[2023-01-12 17:14:52] \u001b[32mTrain: [ 23/600] Step 270/520 Loss 0.756 Prec@(1,5) (81.4%, 99.1%)\u001b[0m\n",
            "INFO:nni:Train: [ 23/600] Step 270/520 Loss 0.756 Prec@(1,5) (81.4%, 99.1%)\n",
            "[2023-01-12 17:14:56] \u001b[32mTrain: [ 23/600] Step 280/520 Loss 0.754 Prec@(1,5) (81.4%, 99.1%)\u001b[0m\n",
            "INFO:nni:Train: [ 23/600] Step 280/520 Loss 0.754 Prec@(1,5) (81.4%, 99.1%)\n",
            "[2023-01-12 17:15:01] \u001b[32mTrain: [ 23/600] Step 290/520 Loss 0.754 Prec@(1,5) (81.4%, 99.1%)\u001b[0m\n",
            "INFO:nni:Train: [ 23/600] Step 290/520 Loss 0.754 Prec@(1,5) (81.4%, 99.1%)\n",
            "[2023-01-12 17:15:06] \u001b[32mTrain: [ 23/600] Step 300/520 Loss 0.754 Prec@(1,5) (81.4%, 99.1%)\u001b[0m\n",
            "INFO:nni:Train: [ 23/600] Step 300/520 Loss 0.754 Prec@(1,5) (81.4%, 99.1%)\n",
            "[2023-01-12 17:15:10] \u001b[32mTrain: [ 23/600] Step 310/520 Loss 0.756 Prec@(1,5) (81.4%, 99.1%)\u001b[0m\n",
            "INFO:nni:Train: [ 23/600] Step 310/520 Loss 0.756 Prec@(1,5) (81.4%, 99.1%)\n",
            "[2023-01-12 17:15:15] \u001b[32mTrain: [ 23/600] Step 320/520 Loss 0.756 Prec@(1,5) (81.4%, 99.1%)\u001b[0m\n",
            "INFO:nni:Train: [ 23/600] Step 320/520 Loss 0.756 Prec@(1,5) (81.4%, 99.1%)\n",
            "[2023-01-12 17:15:19] \u001b[32mTrain: [ 23/600] Step 330/520 Loss 0.758 Prec@(1,5) (81.3%, 99.1%)\u001b[0m\n",
            "INFO:nni:Train: [ 23/600] Step 330/520 Loss 0.758 Prec@(1,5) (81.3%, 99.1%)\n",
            "[2023-01-12 17:15:24] \u001b[32mTrain: [ 23/600] Step 340/520 Loss 0.759 Prec@(1,5) (81.3%, 99.1%)\u001b[0m\n",
            "INFO:nni:Train: [ 23/600] Step 340/520 Loss 0.759 Prec@(1,5) (81.3%, 99.1%)\n",
            "[2023-01-12 17:15:28] \u001b[32mTrain: [ 23/600] Step 350/520 Loss 0.760 Prec@(1,5) (81.2%, 99.1%)\u001b[0m\n",
            "INFO:nni:Train: [ 23/600] Step 350/520 Loss 0.760 Prec@(1,5) (81.2%, 99.1%)\n",
            "[2023-01-12 17:15:33] \u001b[32mTrain: [ 23/600] Step 360/520 Loss 0.761 Prec@(1,5) (81.2%, 99.1%)\u001b[0m\n",
            "INFO:nni:Train: [ 23/600] Step 360/520 Loss 0.761 Prec@(1,5) (81.2%, 99.1%)\n",
            "[2023-01-12 17:15:37] \u001b[32mTrain: [ 23/600] Step 370/520 Loss 0.760 Prec@(1,5) (81.3%, 99.1%)\u001b[0m\n",
            "INFO:nni:Train: [ 23/600] Step 370/520 Loss 0.760 Prec@(1,5) (81.3%, 99.1%)\n",
            "[2023-01-12 17:15:42] \u001b[32mTrain: [ 23/600] Step 380/520 Loss 0.762 Prec@(1,5) (81.2%, 99.1%)\u001b[0m\n",
            "INFO:nni:Train: [ 23/600] Step 380/520 Loss 0.762 Prec@(1,5) (81.2%, 99.1%)\n",
            "[2023-01-12 17:15:46] \u001b[32mTrain: [ 23/600] Step 390/520 Loss 0.764 Prec@(1,5) (81.2%, 99.1%)\u001b[0m\n",
            "INFO:nni:Train: [ 23/600] Step 390/520 Loss 0.764 Prec@(1,5) (81.2%, 99.1%)\n",
            "[2023-01-12 17:15:51] \u001b[32mTrain: [ 23/600] Step 400/520 Loss 0.765 Prec@(1,5) (81.1%, 99.1%)\u001b[0m\n",
            "INFO:nni:Train: [ 23/600] Step 400/520 Loss 0.765 Prec@(1,5) (81.1%, 99.1%)\n",
            "[2023-01-12 17:15:55] \u001b[32mTrain: [ 23/600] Step 410/520 Loss 0.765 Prec@(1,5) (81.2%, 99.1%)\u001b[0m\n",
            "INFO:nni:Train: [ 23/600] Step 410/520 Loss 0.765 Prec@(1,5) (81.2%, 99.1%)\n",
            "[2023-01-12 17:16:00] \u001b[32mTrain: [ 23/600] Step 420/520 Loss 0.765 Prec@(1,5) (81.1%, 99.1%)\u001b[0m\n",
            "INFO:nni:Train: [ 23/600] Step 420/520 Loss 0.765 Prec@(1,5) (81.1%, 99.1%)\n",
            "[2023-01-12 17:16:04] \u001b[32mTrain: [ 23/600] Step 430/520 Loss 0.766 Prec@(1,5) (81.1%, 99.1%)\u001b[0m\n",
            "INFO:nni:Train: [ 23/600] Step 430/520 Loss 0.766 Prec@(1,5) (81.1%, 99.1%)\n",
            "[2023-01-12 17:16:09] \u001b[32mTrain: [ 23/600] Step 440/520 Loss 0.767 Prec@(1,5) (81.1%, 99.1%)\u001b[0m\n",
            "INFO:nni:Train: [ 23/600] Step 440/520 Loss 0.767 Prec@(1,5) (81.1%, 99.1%)\n",
            "[2023-01-12 17:16:13] \u001b[32mTrain: [ 23/600] Step 450/520 Loss 0.768 Prec@(1,5) (81.1%, 99.1%)\u001b[0m\n",
            "INFO:nni:Train: [ 23/600] Step 450/520 Loss 0.768 Prec@(1,5) (81.1%, 99.1%)\n",
            "[2023-01-12 17:16:18] \u001b[32mTrain: [ 23/600] Step 460/520 Loss 0.765 Prec@(1,5) (81.2%, 99.1%)\u001b[0m\n",
            "INFO:nni:Train: [ 23/600] Step 460/520 Loss 0.765 Prec@(1,5) (81.2%, 99.1%)\n",
            "[2023-01-12 17:16:22] \u001b[32mTrain: [ 23/600] Step 470/520 Loss 0.764 Prec@(1,5) (81.2%, 99.1%)\u001b[0m\n",
            "INFO:nni:Train: [ 23/600] Step 470/520 Loss 0.764 Prec@(1,5) (81.2%, 99.1%)\n",
            "[2023-01-12 17:16:27] \u001b[32mTrain: [ 23/600] Step 480/520 Loss 0.765 Prec@(1,5) (81.2%, 99.1%)\u001b[0m\n",
            "INFO:nni:Train: [ 23/600] Step 480/520 Loss 0.765 Prec@(1,5) (81.2%, 99.1%)\n",
            "[2023-01-12 17:16:31] \u001b[32mTrain: [ 23/600] Step 490/520 Loss 0.766 Prec@(1,5) (81.2%, 99.1%)\u001b[0m\n",
            "INFO:nni:Train: [ 23/600] Step 490/520 Loss 0.766 Prec@(1,5) (81.2%, 99.1%)\n",
            "[2023-01-12 17:16:36] \u001b[32mTrain: [ 23/600] Step 500/520 Loss 0.768 Prec@(1,5) (81.1%, 99.1%)\u001b[0m\n",
            "INFO:nni:Train: [ 23/600] Step 500/520 Loss 0.768 Prec@(1,5) (81.1%, 99.1%)\n",
            "[2023-01-12 17:16:40] \u001b[32mTrain: [ 23/600] Step 510/520 Loss 0.767 Prec@(1,5) (81.1%, 99.1%)\u001b[0m\n",
            "INFO:nni:Train: [ 23/600] Step 510/520 Loss 0.767 Prec@(1,5) (81.1%, 99.1%)\n",
            "[2023-01-12 17:16:45] \u001b[32mTrain: [ 23/600] Step 520/520 Loss 0.765 Prec@(1,5) (81.2%, 99.1%)\u001b[0m\n",
            "INFO:nni:Train: [ 23/600] Step 520/520 Loss 0.765 Prec@(1,5) (81.2%, 99.1%)\n",
            "[2023-01-12 17:16:45] \u001b[32mTrain: [ 23/600] Final Prec@1 81.1880%\u001b[0m\n",
            "INFO:nni:Train: [ 23/600] Final Prec@1 81.1880%\n",
            "[2023-01-12 17:16:45] \u001b[32mValid: [ 23/600] Step 000/104 Loss 0.368 Prec@(1,5) (88.5%, 99.0%)\u001b[0m\n",
            "INFO:nni:Valid: [ 23/600] Step 000/104 Loss 0.368 Prec@(1,5) (88.5%, 99.0%)\n",
            "[2023-01-12 17:16:47] \u001b[32mValid: [ 23/600] Step 010/104 Loss 0.430 Prec@(1,5) (85.7%, 99.1%)\u001b[0m\n",
            "INFO:nni:Valid: [ 23/600] Step 010/104 Loss 0.430 Prec@(1,5) (85.7%, 99.1%)\n",
            "[2023-01-12 17:16:48] \u001b[32mValid: [ 23/600] Step 020/104 Loss 0.449 Prec@(1,5) (84.9%, 98.9%)\u001b[0m\n",
            "INFO:nni:Valid: [ 23/600] Step 020/104 Loss 0.449 Prec@(1,5) (84.9%, 98.9%)\n",
            "[2023-01-12 17:16:50] \u001b[32mValid: [ 23/600] Step 030/104 Loss 0.455 Prec@(1,5) (85.0%, 98.9%)\u001b[0m\n",
            "INFO:nni:Valid: [ 23/600] Step 030/104 Loss 0.455 Prec@(1,5) (85.0%, 98.9%)\n",
            "[2023-01-12 17:16:51] \u001b[32mValid: [ 23/600] Step 040/104 Loss 0.449 Prec@(1,5) (85.1%, 99.0%)\u001b[0m\n",
            "INFO:nni:Valid: [ 23/600] Step 040/104 Loss 0.449 Prec@(1,5) (85.1%, 99.0%)\n",
            "[2023-01-12 17:16:52] \u001b[32mValid: [ 23/600] Step 050/104 Loss 0.444 Prec@(1,5) (85.4%, 99.1%)\u001b[0m\n",
            "INFO:nni:Valid: [ 23/600] Step 050/104 Loss 0.444 Prec@(1,5) (85.4%, 99.1%)\n",
            "[2023-01-12 17:16:54] \u001b[32mValid: [ 23/600] Step 060/104 Loss 0.443 Prec@(1,5) (85.4%, 99.1%)\u001b[0m\n",
            "INFO:nni:Valid: [ 23/600] Step 060/104 Loss 0.443 Prec@(1,5) (85.4%, 99.1%)\n",
            "[2023-01-12 17:16:55] \u001b[32mValid: [ 23/600] Step 070/104 Loss 0.441 Prec@(1,5) (85.4%, 99.2%)\u001b[0m\n",
            "INFO:nni:Valid: [ 23/600] Step 070/104 Loss 0.441 Prec@(1,5) (85.4%, 99.2%)\n",
            "[2023-01-12 17:16:57] \u001b[32mValid: [ 23/600] Step 080/104 Loss 0.443 Prec@(1,5) (85.2%, 99.2%)\u001b[0m\n",
            "INFO:nni:Valid: [ 23/600] Step 080/104 Loss 0.443 Prec@(1,5) (85.2%, 99.2%)\n",
            "[2023-01-12 17:16:58] \u001b[32mValid: [ 23/600] Step 090/104 Loss 0.442 Prec@(1,5) (85.2%, 99.3%)\u001b[0m\n",
            "INFO:nni:Valid: [ 23/600] Step 090/104 Loss 0.442 Prec@(1,5) (85.2%, 99.3%)\n",
            "[2023-01-12 17:17:00] \u001b[32mValid: [ 23/600] Step 100/104 Loss 0.439 Prec@(1,5) (85.2%, 99.3%)\u001b[0m\n",
            "INFO:nni:Valid: [ 23/600] Step 100/104 Loss 0.439 Prec@(1,5) (85.2%, 99.3%)\n",
            "[2023-01-12 17:17:00] \u001b[32mValid: [ 23/600] Step 104/104 Loss 0.442 Prec@(1,5) (85.2%, 99.3%)\u001b[0m\n",
            "INFO:nni:Valid: [ 23/600] Step 104/104 Loss 0.442 Prec@(1,5) (85.2%, 99.3%)\n",
            "[2023-01-12 17:17:00] \u001b[32mValid: [ 23/600] Final Prec@1 85.1800%\u001b[0m\n",
            "INFO:nni:Valid: [ 23/600] Final Prec@1 85.1800%\n",
            "[2023-01-12 17:17:00] \u001b[32mEpoch 23 LR 0.024909\u001b[0m\n",
            "INFO:nni:Epoch 23 LR 0.024909\n",
            "[2023-01-12 17:17:01] \u001b[32mTrain: [ 24/600] Step 000/520 Loss 1.067 Prec@(1,5) (79.2%, 100.0%)\u001b[0m\n",
            "INFO:nni:Train: [ 24/600] Step 000/520 Loss 1.067 Prec@(1,5) (79.2%, 100.0%)\n",
            "[2023-01-12 17:17:05] \u001b[32mTrain: [ 24/600] Step 010/520 Loss 0.748 Prec@(1,5) (81.2%, 99.3%)\u001b[0m\n",
            "INFO:nni:Train: [ 24/600] Step 010/520 Loss 0.748 Prec@(1,5) (81.2%, 99.3%)\n",
            "[2023-01-12 17:17:10] \u001b[32mTrain: [ 24/600] Step 020/520 Loss 0.728 Prec@(1,5) (82.0%, 99.2%)\u001b[0m\n",
            "INFO:nni:Train: [ 24/600] Step 020/520 Loss 0.728 Prec@(1,5) (82.0%, 99.2%)\n",
            "[2023-01-12 17:17:14] \u001b[32mTrain: [ 24/600] Step 030/520 Loss 0.736 Prec@(1,5) (81.7%, 99.2%)\u001b[0m\n",
            "INFO:nni:Train: [ 24/600] Step 030/520 Loss 0.736 Prec@(1,5) (81.7%, 99.2%)\n",
            "[2023-01-12 17:17:19] \u001b[32mTrain: [ 24/600] Step 040/520 Loss 0.749 Prec@(1,5) (81.1%, 99.2%)\u001b[0m\n",
            "INFO:nni:Train: [ 24/600] Step 040/520 Loss 0.749 Prec@(1,5) (81.1%, 99.2%)\n",
            "[2023-01-12 17:17:24] \u001b[32mTrain: [ 24/600] Step 050/520 Loss 0.753 Prec@(1,5) (81.1%, 99.2%)\u001b[0m\n",
            "INFO:nni:Train: [ 24/600] Step 050/520 Loss 0.753 Prec@(1,5) (81.1%, 99.2%)\n",
            "[2023-01-12 17:17:28] \u001b[32mTrain: [ 24/600] Step 060/520 Loss 0.740 Prec@(1,5) (81.5%, 99.2%)\u001b[0m\n",
            "INFO:nni:Train: [ 24/600] Step 060/520 Loss 0.740 Prec@(1,5) (81.5%, 99.2%)\n",
            "[2023-01-12 17:17:33] \u001b[32mTrain: [ 24/600] Step 070/520 Loss 0.738 Prec@(1,5) (81.6%, 99.2%)\u001b[0m\n",
            "INFO:nni:Train: [ 24/600] Step 070/520 Loss 0.738 Prec@(1,5) (81.6%, 99.2%)\n",
            "[2023-01-12 17:17:37] \u001b[32mTrain: [ 24/600] Step 080/520 Loss 0.739 Prec@(1,5) (81.6%, 99.1%)\u001b[0m\n",
            "INFO:nni:Train: [ 24/600] Step 080/520 Loss 0.739 Prec@(1,5) (81.6%, 99.1%)\n",
            "[2023-01-12 17:17:42] \u001b[32mTrain: [ 24/600] Step 090/520 Loss 0.732 Prec@(1,5) (81.8%, 99.1%)\u001b[0m\n",
            "INFO:nni:Train: [ 24/600] Step 090/520 Loss 0.732 Prec@(1,5) (81.8%, 99.1%)\n",
            "[2023-01-12 17:17:46] \u001b[32mTrain: [ 24/600] Step 100/520 Loss 0.733 Prec@(1,5) (81.9%, 99.1%)\u001b[0m\n",
            "INFO:nni:Train: [ 24/600] Step 100/520 Loss 0.733 Prec@(1,5) (81.9%, 99.1%)\n",
            "[2023-01-12 17:17:51] \u001b[32mTrain: [ 24/600] Step 110/520 Loss 0.734 Prec@(1,5) (81.9%, 99.1%)\u001b[0m\n",
            "INFO:nni:Train: [ 24/600] Step 110/520 Loss 0.734 Prec@(1,5) (81.9%, 99.1%)\n",
            "[2023-01-12 17:17:55] \u001b[32mTrain: [ 24/600] Step 120/520 Loss 0.731 Prec@(1,5) (82.1%, 99.2%)\u001b[0m\n",
            "INFO:nni:Train: [ 24/600] Step 120/520 Loss 0.731 Prec@(1,5) (82.1%, 99.2%)\n",
            "[2023-01-12 17:18:00] \u001b[32mTrain: [ 24/600] Step 130/520 Loss 0.730 Prec@(1,5) (82.2%, 99.2%)\u001b[0m\n",
            "INFO:nni:Train: [ 24/600] Step 130/520 Loss 0.730 Prec@(1,5) (82.2%, 99.2%)\n",
            "[2023-01-12 17:18:04] \u001b[32mTrain: [ 24/600] Step 140/520 Loss 0.732 Prec@(1,5) (82.2%, 99.1%)\u001b[0m\n",
            "INFO:nni:Train: [ 24/600] Step 140/520 Loss 0.732 Prec@(1,5) (82.2%, 99.1%)\n",
            "[2023-01-12 17:18:09] \u001b[32mTrain: [ 24/600] Step 150/520 Loss 0.733 Prec@(1,5) (82.2%, 99.1%)\u001b[0m\n",
            "INFO:nni:Train: [ 24/600] Step 150/520 Loss 0.733 Prec@(1,5) (82.2%, 99.1%)\n",
            "[2023-01-12 17:18:13] \u001b[32mTrain: [ 24/600] Step 160/520 Loss 0.735 Prec@(1,5) (82.1%, 99.2%)\u001b[0m\n",
            "INFO:nni:Train: [ 24/600] Step 160/520 Loss 0.735 Prec@(1,5) (82.1%, 99.2%)\n",
            "[2023-01-12 17:18:18] \u001b[32mTrain: [ 24/600] Step 170/520 Loss 0.739 Prec@(1,5) (82.0%, 99.2%)\u001b[0m\n",
            "INFO:nni:Train: [ 24/600] Step 170/520 Loss 0.739 Prec@(1,5) (82.0%, 99.2%)\n",
            "[2023-01-12 17:18:22] \u001b[32mTrain: [ 24/600] Step 180/520 Loss 0.739 Prec@(1,5) (82.0%, 99.2%)\u001b[0m\n",
            "INFO:nni:Train: [ 24/600] Step 180/520 Loss 0.739 Prec@(1,5) (82.0%, 99.2%)\n",
            "[2023-01-12 17:18:27] \u001b[32mTrain: [ 24/600] Step 190/520 Loss 0.739 Prec@(1,5) (81.9%, 99.2%)\u001b[0m\n",
            "INFO:nni:Train: [ 24/600] Step 190/520 Loss 0.739 Prec@(1,5) (81.9%, 99.2%)\n",
            "[2023-01-12 17:18:31] \u001b[32mTrain: [ 24/600] Step 200/520 Loss 0.735 Prec@(1,5) (82.0%, 99.2%)\u001b[0m\n",
            "INFO:nni:Train: [ 24/600] Step 200/520 Loss 0.735 Prec@(1,5) (82.0%, 99.2%)\n",
            "[2023-01-12 17:18:36] \u001b[32mTrain: [ 24/600] Step 210/520 Loss 0.732 Prec@(1,5) (82.0%, 99.2%)\u001b[0m\n",
            "INFO:nni:Train: [ 24/600] Step 210/520 Loss 0.732 Prec@(1,5) (82.0%, 99.2%)\n",
            "[2023-01-12 17:18:40] \u001b[32mTrain: [ 24/600] Step 220/520 Loss 0.734 Prec@(1,5) (82.0%, 99.2%)\u001b[0m\n",
            "INFO:nni:Train: [ 24/600] Step 220/520 Loss 0.734 Prec@(1,5) (82.0%, 99.2%)\n",
            "[2023-01-12 17:18:45] \u001b[32mTrain: [ 24/600] Step 230/520 Loss 0.733 Prec@(1,5) (81.9%, 99.2%)\u001b[0m\n",
            "INFO:nni:Train: [ 24/600] Step 230/520 Loss 0.733 Prec@(1,5) (81.9%, 99.2%)\n",
            "[2023-01-12 17:18:49] \u001b[32mTrain: [ 24/600] Step 240/520 Loss 0.734 Prec@(1,5) (81.9%, 99.2%)\u001b[0m\n",
            "INFO:nni:Train: [ 24/600] Step 240/520 Loss 0.734 Prec@(1,5) (81.9%, 99.2%)\n",
            "[2023-01-12 17:18:54] \u001b[32mTrain: [ 24/600] Step 250/520 Loss 0.735 Prec@(1,5) (81.8%, 99.2%)\u001b[0m\n",
            "INFO:nni:Train: [ 24/600] Step 250/520 Loss 0.735 Prec@(1,5) (81.8%, 99.2%)\n",
            "[2023-01-12 17:18:58] \u001b[32mTrain: [ 24/600] Step 260/520 Loss 0.736 Prec@(1,5) (81.8%, 99.2%)\u001b[0m\n",
            "INFO:nni:Train: [ 24/600] Step 260/520 Loss 0.736 Prec@(1,5) (81.8%, 99.2%)\n",
            "[2023-01-12 17:19:03] \u001b[32mTrain: [ 24/600] Step 270/520 Loss 0.735 Prec@(1,5) (81.8%, 99.2%)\u001b[0m\n",
            "INFO:nni:Train: [ 24/600] Step 270/520 Loss 0.735 Prec@(1,5) (81.8%, 99.2%)\n",
            "[2023-01-12 17:19:07] \u001b[32mTrain: [ 24/600] Step 280/520 Loss 0.741 Prec@(1,5) (81.7%, 99.2%)\u001b[0m\n",
            "INFO:nni:Train: [ 24/600] Step 280/520 Loss 0.741 Prec@(1,5) (81.7%, 99.2%)\n",
            "[2023-01-12 17:19:12] \u001b[32mTrain: [ 24/600] Step 290/520 Loss 0.743 Prec@(1,5) (81.6%, 99.2%)\u001b[0m\n",
            "INFO:nni:Train: [ 24/600] Step 290/520 Loss 0.743 Prec@(1,5) (81.6%, 99.2%)\n",
            "[2023-01-12 17:19:16] \u001b[32mTrain: [ 24/600] Step 300/520 Loss 0.745 Prec@(1,5) (81.6%, 99.2%)\u001b[0m\n",
            "INFO:nni:Train: [ 24/600] Step 300/520 Loss 0.745 Prec@(1,5) (81.6%, 99.2%)\n",
            "[2023-01-12 17:19:21] \u001b[32mTrain: [ 24/600] Step 310/520 Loss 0.743 Prec@(1,5) (81.6%, 99.2%)\u001b[0m\n",
            "INFO:nni:Train: [ 24/600] Step 310/520 Loss 0.743 Prec@(1,5) (81.6%, 99.2%)\n",
            "[2023-01-12 17:19:26] \u001b[32mTrain: [ 24/600] Step 320/520 Loss 0.744 Prec@(1,5) (81.6%, 99.2%)\u001b[0m\n",
            "INFO:nni:Train: [ 24/600] Step 320/520 Loss 0.744 Prec@(1,5) (81.6%, 99.2%)\n",
            "[2023-01-12 17:19:30] \u001b[32mTrain: [ 24/600] Step 330/520 Loss 0.748 Prec@(1,5) (81.6%, 99.1%)\u001b[0m\n",
            "INFO:nni:Train: [ 24/600] Step 330/520 Loss 0.748 Prec@(1,5) (81.6%, 99.1%)\n",
            "[2023-01-12 17:19:35] \u001b[32mTrain: [ 24/600] Step 340/520 Loss 0.748 Prec@(1,5) (81.6%, 99.1%)\u001b[0m\n",
            "INFO:nni:Train: [ 24/600] Step 340/520 Loss 0.748 Prec@(1,5) (81.6%, 99.1%)\n",
            "[2023-01-12 17:19:39] \u001b[32mTrain: [ 24/600] Step 350/520 Loss 0.747 Prec@(1,5) (81.6%, 99.1%)\u001b[0m\n",
            "INFO:nni:Train: [ 24/600] Step 350/520 Loss 0.747 Prec@(1,5) (81.6%, 99.1%)\n",
            "[2023-01-12 17:19:44] \u001b[32mTrain: [ 24/600] Step 360/520 Loss 0.747 Prec@(1,5) (81.6%, 99.2%)\u001b[0m\n",
            "INFO:nni:Train: [ 24/600] Step 360/520 Loss 0.747 Prec@(1,5) (81.6%, 99.2%)\n",
            "[2023-01-12 17:19:48] \u001b[32mTrain: [ 24/600] Step 370/520 Loss 0.747 Prec@(1,5) (81.6%, 99.2%)\u001b[0m\n",
            "INFO:nni:Train: [ 24/600] Step 370/520 Loss 0.747 Prec@(1,5) (81.6%, 99.2%)\n",
            "[2023-01-12 17:19:53] \u001b[32mTrain: [ 24/600] Step 380/520 Loss 0.747 Prec@(1,5) (81.6%, 99.2%)\u001b[0m\n",
            "INFO:nni:Train: [ 24/600] Step 380/520 Loss 0.747 Prec@(1,5) (81.6%, 99.2%)\n",
            "[2023-01-12 17:19:57] \u001b[32mTrain: [ 24/600] Step 390/520 Loss 0.748 Prec@(1,5) (81.5%, 99.1%)\u001b[0m\n",
            "INFO:nni:Train: [ 24/600] Step 390/520 Loss 0.748 Prec@(1,5) (81.5%, 99.1%)\n",
            "[2023-01-12 17:20:02] \u001b[32mTrain: [ 24/600] Step 400/520 Loss 0.750 Prec@(1,5) (81.5%, 99.2%)\u001b[0m\n",
            "INFO:nni:Train: [ 24/600] Step 400/520 Loss 0.750 Prec@(1,5) (81.5%, 99.2%)\n",
            "[2023-01-12 17:20:06] \u001b[32mTrain: [ 24/600] Step 410/520 Loss 0.749 Prec@(1,5) (81.5%, 99.2%)\u001b[0m\n",
            "INFO:nni:Train: [ 24/600] Step 410/520 Loss 0.749 Prec@(1,5) (81.5%, 99.2%)\n",
            "[2023-01-12 17:20:11] \u001b[32mTrain: [ 24/600] Step 420/520 Loss 0.749 Prec@(1,5) (81.5%, 99.2%)\u001b[0m\n",
            "INFO:nni:Train: [ 24/600] Step 420/520 Loss 0.749 Prec@(1,5) (81.5%, 99.2%)\n",
            "[2023-01-12 17:20:15] \u001b[32mTrain: [ 24/600] Step 430/520 Loss 0.751 Prec@(1,5) (81.5%, 99.1%)\u001b[0m\n",
            "INFO:nni:Train: [ 24/600] Step 430/520 Loss 0.751 Prec@(1,5) (81.5%, 99.1%)\n",
            "[2023-01-12 17:20:20] \u001b[32mTrain: [ 24/600] Step 440/520 Loss 0.750 Prec@(1,5) (81.5%, 99.1%)\u001b[0m\n",
            "INFO:nni:Train: [ 24/600] Step 440/520 Loss 0.750 Prec@(1,5) (81.5%, 99.1%)\n",
            "[2023-01-12 17:20:24] \u001b[32mTrain: [ 24/600] Step 450/520 Loss 0.750 Prec@(1,5) (81.5%, 99.1%)\u001b[0m\n",
            "INFO:nni:Train: [ 24/600] Step 450/520 Loss 0.750 Prec@(1,5) (81.5%, 99.1%)\n",
            "[2023-01-12 17:20:29] \u001b[32mTrain: [ 24/600] Step 460/520 Loss 0.749 Prec@(1,5) (81.5%, 99.1%)\u001b[0m\n",
            "INFO:nni:Train: [ 24/600] Step 460/520 Loss 0.749 Prec@(1,5) (81.5%, 99.1%)\n",
            "[2023-01-12 17:20:33] \u001b[32mTrain: [ 24/600] Step 470/520 Loss 0.748 Prec@(1,5) (81.5%, 99.1%)\u001b[0m\n",
            "INFO:nni:Train: [ 24/600] Step 470/520 Loss 0.748 Prec@(1,5) (81.5%, 99.1%)\n",
            "[2023-01-12 17:20:38] \u001b[32mTrain: [ 24/600] Step 480/520 Loss 0.749 Prec@(1,5) (81.5%, 99.1%)\u001b[0m\n",
            "INFO:nni:Train: [ 24/600] Step 480/520 Loss 0.749 Prec@(1,5) (81.5%, 99.1%)\n",
            "[2023-01-12 17:20:42] \u001b[32mTrain: [ 24/600] Step 490/520 Loss 0.749 Prec@(1,5) (81.5%, 99.1%)\u001b[0m\n",
            "INFO:nni:Train: [ 24/600] Step 490/520 Loss 0.749 Prec@(1,5) (81.5%, 99.1%)\n",
            "[2023-01-12 17:20:47] \u001b[32mTrain: [ 24/600] Step 500/520 Loss 0.749 Prec@(1,5) (81.5%, 99.1%)\u001b[0m\n",
            "INFO:nni:Train: [ 24/600] Step 500/520 Loss 0.749 Prec@(1,5) (81.5%, 99.1%)\n",
            "[2023-01-12 17:20:51] \u001b[32mTrain: [ 24/600] Step 510/520 Loss 0.749 Prec@(1,5) (81.5%, 99.1%)\u001b[0m\n",
            "INFO:nni:Train: [ 24/600] Step 510/520 Loss 0.749 Prec@(1,5) (81.5%, 99.1%)\n",
            "[2023-01-12 17:20:56] \u001b[32mTrain: [ 24/600] Step 520/520 Loss 0.750 Prec@(1,5) (81.5%, 99.1%)\u001b[0m\n",
            "INFO:nni:Train: [ 24/600] Step 520/520 Loss 0.750 Prec@(1,5) (81.5%, 99.1%)\n",
            "[2023-01-12 17:20:56] \u001b[32mTrain: [ 24/600] Final Prec@1 81.5020%\u001b[0m\n",
            "INFO:nni:Train: [ 24/600] Final Prec@1 81.5020%\n",
            "[2023-01-12 17:20:56] \u001b[32mValid: [ 24/600] Step 000/104 Loss 0.711 Prec@(1,5) (77.1%, 96.9%)\u001b[0m\n",
            "INFO:nni:Valid: [ 24/600] Step 000/104 Loss 0.711 Prec@(1,5) (77.1%, 96.9%)\n",
            "[2023-01-12 17:20:58] \u001b[32mValid: [ 24/600] Step 010/104 Loss 0.548 Prec@(1,5) (81.4%, 98.8%)\u001b[0m\n",
            "INFO:nni:Valid: [ 24/600] Step 010/104 Loss 0.548 Prec@(1,5) (81.4%, 98.8%)\n",
            "[2023-01-12 17:20:59] \u001b[32mValid: [ 24/600] Step 020/104 Loss 0.552 Prec@(1,5) (81.7%, 98.8%)\u001b[0m\n",
            "INFO:nni:Valid: [ 24/600] Step 020/104 Loss 0.552 Prec@(1,5) (81.7%, 98.8%)\n",
            "[2023-01-12 17:21:01] \u001b[32mValid: [ 24/600] Step 030/104 Loss 0.544 Prec@(1,5) (81.5%, 99.0%)\u001b[0m\n",
            "INFO:nni:Valid: [ 24/600] Step 030/104 Loss 0.544 Prec@(1,5) (81.5%, 99.0%)\n",
            "[2023-01-12 17:21:02] \u001b[32mValid: [ 24/600] Step 040/104 Loss 0.545 Prec@(1,5) (81.5%, 98.9%)\u001b[0m\n",
            "INFO:nni:Valid: [ 24/600] Step 040/104 Loss 0.545 Prec@(1,5) (81.5%, 98.9%)\n",
            "[2023-01-12 17:21:03] \u001b[32mValid: [ 24/600] Step 050/104 Loss 0.546 Prec@(1,5) (81.7%, 99.0%)\u001b[0m\n",
            "INFO:nni:Valid: [ 24/600] Step 050/104 Loss 0.546 Prec@(1,5) (81.7%, 99.0%)\n",
            "[2023-01-12 17:21:05] \u001b[32mValid: [ 24/600] Step 060/104 Loss 0.551 Prec@(1,5) (81.4%, 99.1%)\u001b[0m\n",
            "INFO:nni:Valid: [ 24/600] Step 060/104 Loss 0.551 Prec@(1,5) (81.4%, 99.1%)\n",
            "[2023-01-12 17:21:06] \u001b[32mValid: [ 24/600] Step 070/104 Loss 0.551 Prec@(1,5) (81.5%, 99.0%)\u001b[0m\n",
            "INFO:nni:Valid: [ 24/600] Step 070/104 Loss 0.551 Prec@(1,5) (81.5%, 99.0%)\n",
            "[2023-01-12 17:21:08] \u001b[32mValid: [ 24/600] Step 080/104 Loss 0.553 Prec@(1,5) (81.5%, 99.1%)\u001b[0m\n",
            "INFO:nni:Valid: [ 24/600] Step 080/104 Loss 0.553 Prec@(1,5) (81.5%, 99.1%)\n",
            "[2023-01-12 17:21:09] \u001b[32mValid: [ 24/600] Step 090/104 Loss 0.553 Prec@(1,5) (81.3%, 99.1%)\u001b[0m\n",
            "INFO:nni:Valid: [ 24/600] Step 090/104 Loss 0.553 Prec@(1,5) (81.3%, 99.1%)\n",
            "[2023-01-12 17:21:10] \u001b[32mValid: [ 24/600] Step 100/104 Loss 0.551 Prec@(1,5) (81.4%, 99.1%)\u001b[0m\n",
            "INFO:nni:Valid: [ 24/600] Step 100/104 Loss 0.551 Prec@(1,5) (81.4%, 99.1%)\n",
            "[2023-01-12 17:21:11] \u001b[32mValid: [ 24/600] Step 104/104 Loss 0.552 Prec@(1,5) (81.4%, 99.1%)\u001b[0m\n",
            "INFO:nni:Valid: [ 24/600] Step 104/104 Loss 0.552 Prec@(1,5) (81.4%, 99.1%)\n",
            "[2023-01-12 17:21:11] \u001b[32mValid: [ 24/600] Final Prec@1 81.3500%\u001b[0m\n",
            "INFO:nni:Valid: [ 24/600] Final Prec@1 81.3500%\n",
            "[2023-01-12 17:21:11] \u001b[32mEpoch 24 LR 0.024901\u001b[0m\n",
            "INFO:nni:Epoch 24 LR 0.024901\n",
            "[2023-01-12 17:21:12] \u001b[32mTrain: [ 25/600] Step 000/520 Loss 0.735 Prec@(1,5) (81.2%, 100.0%)\u001b[0m\n",
            "INFO:nni:Train: [ 25/600] Step 000/520 Loss 0.735 Prec@(1,5) (81.2%, 100.0%)\n",
            "[2023-01-12 17:21:16] \u001b[32mTrain: [ 25/600] Step 010/520 Loss 0.804 Prec@(1,5) (79.9%, 99.3%)\u001b[0m\n",
            "INFO:nni:Train: [ 25/600] Step 010/520 Loss 0.804 Prec@(1,5) (79.9%, 99.3%)\n",
            "[2023-01-12 17:21:21] \u001b[32mTrain: [ 25/600] Step 020/520 Loss 0.772 Prec@(1,5) (81.2%, 99.3%)\u001b[0m\n",
            "INFO:nni:Train: [ 25/600] Step 020/520 Loss 0.772 Prec@(1,5) (81.2%, 99.3%)\n",
            "[2023-01-12 17:21:25] \u001b[32mTrain: [ 25/600] Step 030/520 Loss 0.760 Prec@(1,5) (81.3%, 99.2%)\u001b[0m\n",
            "INFO:nni:Train: [ 25/600] Step 030/520 Loss 0.760 Prec@(1,5) (81.3%, 99.2%)\n",
            "[2023-01-12 17:21:30] \u001b[32mTrain: [ 25/600] Step 040/520 Loss 0.751 Prec@(1,5) (81.7%, 99.2%)\u001b[0m\n",
            "INFO:nni:Train: [ 25/600] Step 040/520 Loss 0.751 Prec@(1,5) (81.7%, 99.2%)\n",
            "[2023-01-12 17:21:34] \u001b[32mTrain: [ 25/600] Step 050/520 Loss 0.742 Prec@(1,5) (81.8%, 99.2%)\u001b[0m\n",
            "INFO:nni:Train: [ 25/600] Step 050/520 Loss 0.742 Prec@(1,5) (81.8%, 99.2%)\n",
            "[2023-01-12 17:21:39] \u001b[32mTrain: [ 25/600] Step 060/520 Loss 0.739 Prec@(1,5) (81.8%, 99.2%)\u001b[0m\n",
            "INFO:nni:Train: [ 25/600] Step 060/520 Loss 0.739 Prec@(1,5) (81.8%, 99.2%)\n",
            "[2023-01-12 17:21:44] \u001b[32mTrain: [ 25/600] Step 070/520 Loss 0.739 Prec@(1,5) (81.8%, 99.2%)\u001b[0m\n",
            "INFO:nni:Train: [ 25/600] Step 070/520 Loss 0.739 Prec@(1,5) (81.8%, 99.2%)\n",
            "[2023-01-12 17:21:48] \u001b[32mTrain: [ 25/600] Step 080/520 Loss 0.742 Prec@(1,5) (81.6%, 99.2%)\u001b[0m\n",
            "INFO:nni:Train: [ 25/600] Step 080/520 Loss 0.742 Prec@(1,5) (81.6%, 99.2%)\n",
            "[2023-01-12 17:21:53] \u001b[32mTrain: [ 25/600] Step 090/520 Loss 0.737 Prec@(1,5) (81.8%, 99.2%)\u001b[0m\n",
            "INFO:nni:Train: [ 25/600] Step 090/520 Loss 0.737 Prec@(1,5) (81.8%, 99.2%)\n",
            "[2023-01-12 17:21:57] \u001b[32mTrain: [ 25/600] Step 100/520 Loss 0.739 Prec@(1,5) (81.7%, 99.2%)\u001b[0m\n",
            "INFO:nni:Train: [ 25/600] Step 100/520 Loss 0.739 Prec@(1,5) (81.7%, 99.2%)\n",
            "[2023-01-12 17:22:02] \u001b[32mTrain: [ 25/600] Step 110/520 Loss 0.740 Prec@(1,5) (81.7%, 99.2%)\u001b[0m\n",
            "INFO:nni:Train: [ 25/600] Step 110/520 Loss 0.740 Prec@(1,5) (81.7%, 99.2%)\n",
            "[2023-01-12 17:22:06] \u001b[32mTrain: [ 25/600] Step 120/520 Loss 0.740 Prec@(1,5) (81.7%, 99.2%)\u001b[0m\n",
            "INFO:nni:Train: [ 25/600] Step 120/520 Loss 0.740 Prec@(1,5) (81.7%, 99.2%)\n",
            "[2023-01-12 17:22:11] \u001b[32mTrain: [ 25/600] Step 130/520 Loss 0.734 Prec@(1,5) (81.9%, 99.2%)\u001b[0m\n",
            "INFO:nni:Train: [ 25/600] Step 130/520 Loss 0.734 Prec@(1,5) (81.9%, 99.2%)\n",
            "[2023-01-12 17:22:15] \u001b[32mTrain: [ 25/600] Step 140/520 Loss 0.736 Prec@(1,5) (81.8%, 99.2%)\u001b[0m\n",
            "INFO:nni:Train: [ 25/600] Step 140/520 Loss 0.736 Prec@(1,5) (81.8%, 99.2%)\n",
            "[2023-01-12 17:22:20] \u001b[32mTrain: [ 25/600] Step 150/520 Loss 0.740 Prec@(1,5) (81.8%, 99.2%)\u001b[0m\n",
            "INFO:nni:Train: [ 25/600] Step 150/520 Loss 0.740 Prec@(1,5) (81.8%, 99.2%)\n",
            "[2023-01-12 17:22:24] \u001b[32mTrain: [ 25/600] Step 160/520 Loss 0.742 Prec@(1,5) (81.7%, 99.2%)\u001b[0m\n",
            "INFO:nni:Train: [ 25/600] Step 160/520 Loss 0.742 Prec@(1,5) (81.7%, 99.2%)\n",
            "[2023-01-12 17:22:29] \u001b[32mTrain: [ 25/600] Step 170/520 Loss 0.743 Prec@(1,5) (81.7%, 99.2%)\u001b[0m\n",
            "INFO:nni:Train: [ 25/600] Step 170/520 Loss 0.743 Prec@(1,5) (81.7%, 99.2%)\n",
            "[2023-01-12 17:22:33] \u001b[32mTrain: [ 25/600] Step 180/520 Loss 0.744 Prec@(1,5) (81.7%, 99.2%)\u001b[0m\n",
            "INFO:nni:Train: [ 25/600] Step 180/520 Loss 0.744 Prec@(1,5) (81.7%, 99.2%)\n",
            "[2023-01-12 17:22:38] \u001b[32mTrain: [ 25/600] Step 190/520 Loss 0.741 Prec@(1,5) (81.8%, 99.2%)\u001b[0m\n",
            "INFO:nni:Train: [ 25/600] Step 190/520 Loss 0.741 Prec@(1,5) (81.8%, 99.2%)\n",
            "[2023-01-12 17:22:42] \u001b[32mTrain: [ 25/600] Step 200/520 Loss 0.737 Prec@(1,5) (81.8%, 99.2%)\u001b[0m\n",
            "INFO:nni:Train: [ 25/600] Step 200/520 Loss 0.737 Prec@(1,5) (81.8%, 99.2%)\n",
            "[2023-01-12 17:22:47] \u001b[32mTrain: [ 25/600] Step 210/520 Loss 0.734 Prec@(1,5) (81.9%, 99.2%)\u001b[0m\n",
            "INFO:nni:Train: [ 25/600] Step 210/520 Loss 0.734 Prec@(1,5) (81.9%, 99.2%)\n",
            "[2023-01-12 17:22:51] \u001b[32mTrain: [ 25/600] Step 220/520 Loss 0.736 Prec@(1,5) (81.8%, 99.2%)\u001b[0m\n",
            "INFO:nni:Train: [ 25/600] Step 220/520 Loss 0.736 Prec@(1,5) (81.8%, 99.2%)\n",
            "[2023-01-12 17:22:56] \u001b[32mTrain: [ 25/600] Step 230/520 Loss 0.738 Prec@(1,5) (81.9%, 99.1%)\u001b[0m\n",
            "INFO:nni:Train: [ 25/600] Step 230/520 Loss 0.738 Prec@(1,5) (81.9%, 99.1%)\n",
            "[2023-01-12 17:23:00] \u001b[32mTrain: [ 25/600] Step 240/520 Loss 0.735 Prec@(1,5) (82.0%, 99.1%)\u001b[0m\n",
            "INFO:nni:Train: [ 25/600] Step 240/520 Loss 0.735 Prec@(1,5) (82.0%, 99.1%)\n",
            "[2023-01-12 17:23:05] \u001b[32mTrain: [ 25/600] Step 250/520 Loss 0.732 Prec@(1,5) (82.1%, 99.2%)\u001b[0m\n",
            "INFO:nni:Train: [ 25/600] Step 250/520 Loss 0.732 Prec@(1,5) (82.1%, 99.2%)\n",
            "[2023-01-12 17:23:09] \u001b[32mTrain: [ 25/600] Step 260/520 Loss 0.733 Prec@(1,5) (82.0%, 99.2%)\u001b[0m\n",
            "INFO:nni:Train: [ 25/600] Step 260/520 Loss 0.733 Prec@(1,5) (82.0%, 99.2%)\n",
            "[2023-01-12 17:23:14] \u001b[32mTrain: [ 25/600] Step 270/520 Loss 0.732 Prec@(1,5) (82.0%, 99.2%)\u001b[0m\n",
            "INFO:nni:Train: [ 25/600] Step 270/520 Loss 0.732 Prec@(1,5) (82.0%, 99.2%)\n",
            "[2023-01-12 17:23:18] \u001b[32mTrain: [ 25/600] Step 280/520 Loss 0.733 Prec@(1,5) (82.0%, 99.2%)\u001b[0m\n",
            "INFO:nni:Train: [ 25/600] Step 280/520 Loss 0.733 Prec@(1,5) (82.0%, 99.2%)\n",
            "[2023-01-12 17:23:23] \u001b[32mTrain: [ 25/600] Step 290/520 Loss 0.737 Prec@(1,5) (81.9%, 99.2%)\u001b[0m\n",
            "INFO:nni:Train: [ 25/600] Step 290/520 Loss 0.737 Prec@(1,5) (81.9%, 99.2%)\n",
            "[2023-01-12 17:23:27] \u001b[32mTrain: [ 25/600] Step 300/520 Loss 0.737 Prec@(1,5) (81.8%, 99.2%)\u001b[0m\n",
            "INFO:nni:Train: [ 25/600] Step 300/520 Loss 0.737 Prec@(1,5) (81.8%, 99.2%)\n",
            "[2023-01-12 17:23:32] \u001b[32mTrain: [ 25/600] Step 310/520 Loss 0.739 Prec@(1,5) (81.8%, 99.2%)\u001b[0m\n",
            "INFO:nni:Train: [ 25/600] Step 310/520 Loss 0.739 Prec@(1,5) (81.8%, 99.2%)\n",
            "[2023-01-12 17:23:36] \u001b[32mTrain: [ 25/600] Step 320/520 Loss 0.738 Prec@(1,5) (81.8%, 99.2%)\u001b[0m\n",
            "INFO:nni:Train: [ 25/600] Step 320/520 Loss 0.738 Prec@(1,5) (81.8%, 99.2%)\n",
            "[2023-01-12 17:23:41] \u001b[32mTrain: [ 25/600] Step 330/520 Loss 0.739 Prec@(1,5) (81.8%, 99.2%)\u001b[0m\n",
            "INFO:nni:Train: [ 25/600] Step 330/520 Loss 0.739 Prec@(1,5) (81.8%, 99.2%)\n",
            "[2023-01-12 17:23:46] \u001b[32mTrain: [ 25/600] Step 340/520 Loss 0.738 Prec@(1,5) (81.8%, 99.2%)\u001b[0m\n",
            "INFO:nni:Train: [ 25/600] Step 340/520 Loss 0.738 Prec@(1,5) (81.8%, 99.2%)\n",
            "[2023-01-12 17:23:50] \u001b[32mTrain: [ 25/600] Step 350/520 Loss 0.737 Prec@(1,5) (81.8%, 99.2%)\u001b[0m\n",
            "INFO:nni:Train: [ 25/600] Step 350/520 Loss 0.737 Prec@(1,5) (81.8%, 99.2%)\n",
            "[2023-01-12 17:23:55] \u001b[32mTrain: [ 25/600] Step 360/520 Loss 0.737 Prec@(1,5) (81.8%, 99.2%)\u001b[0m\n",
            "INFO:nni:Train: [ 25/600] Step 360/520 Loss 0.737 Prec@(1,5) (81.8%, 99.2%)\n",
            "[2023-01-12 17:23:59] \u001b[32mTrain: [ 25/600] Step 370/520 Loss 0.737 Prec@(1,5) (81.8%, 99.2%)\u001b[0m\n",
            "INFO:nni:Train: [ 25/600] Step 370/520 Loss 0.737 Prec@(1,5) (81.8%, 99.2%)\n",
            "[2023-01-12 17:24:04] \u001b[32mTrain: [ 25/600] Step 380/520 Loss 0.738 Prec@(1,5) (81.8%, 99.2%)\u001b[0m\n",
            "INFO:nni:Train: [ 25/600] Step 380/520 Loss 0.738 Prec@(1,5) (81.8%, 99.2%)\n",
            "[2023-01-12 17:24:08] \u001b[32mTrain: [ 25/600] Step 390/520 Loss 0.739 Prec@(1,5) (81.8%, 99.2%)\u001b[0m\n",
            "INFO:nni:Train: [ 25/600] Step 390/520 Loss 0.739 Prec@(1,5) (81.8%, 99.2%)\n",
            "[2023-01-12 17:24:13] \u001b[32mTrain: [ 25/600] Step 400/520 Loss 0.738 Prec@(1,5) (81.8%, 99.2%)\u001b[0m\n",
            "INFO:nni:Train: [ 25/600] Step 400/520 Loss 0.738 Prec@(1,5) (81.8%, 99.2%)\n",
            "[2023-01-12 17:24:17] \u001b[32mTrain: [ 25/600] Step 410/520 Loss 0.740 Prec@(1,5) (81.8%, 99.2%)\u001b[0m\n",
            "INFO:nni:Train: [ 25/600] Step 410/520 Loss 0.740 Prec@(1,5) (81.8%, 99.2%)\n",
            "[2023-01-12 17:24:22] \u001b[32mTrain: [ 25/600] Step 420/520 Loss 0.738 Prec@(1,5) (81.8%, 99.1%)\u001b[0m\n",
            "INFO:nni:Train: [ 25/600] Step 420/520 Loss 0.738 Prec@(1,5) (81.8%, 99.1%)\n",
            "[2023-01-12 17:24:26] \u001b[32mTrain: [ 25/600] Step 430/520 Loss 0.737 Prec@(1,5) (81.9%, 99.1%)\u001b[0m\n",
            "INFO:nni:Train: [ 25/600] Step 430/520 Loss 0.737 Prec@(1,5) (81.9%, 99.1%)\n",
            "[2023-01-12 17:24:31] \u001b[32mTrain: [ 25/600] Step 440/520 Loss 0.739 Prec@(1,5) (81.8%, 99.1%)\u001b[0m\n",
            "INFO:nni:Train: [ 25/600] Step 440/520 Loss 0.739 Prec@(1,5) (81.8%, 99.1%)\n",
            "[2023-01-12 17:24:35] \u001b[32mTrain: [ 25/600] Step 450/520 Loss 0.739 Prec@(1,5) (81.8%, 99.1%)\u001b[0m\n",
            "INFO:nni:Train: [ 25/600] Step 450/520 Loss 0.739 Prec@(1,5) (81.8%, 99.1%)\n",
            "[2023-01-12 17:24:40] \u001b[32mTrain: [ 25/600] Step 460/520 Loss 0.739 Prec@(1,5) (81.8%, 99.1%)\u001b[0m\n",
            "INFO:nni:Train: [ 25/600] Step 460/520 Loss 0.739 Prec@(1,5) (81.8%, 99.1%)\n",
            "[2023-01-12 17:24:44] \u001b[32mTrain: [ 25/600] Step 470/520 Loss 0.740 Prec@(1,5) (81.7%, 99.1%)\u001b[0m\n",
            "INFO:nni:Train: [ 25/600] Step 470/520 Loss 0.740 Prec@(1,5) (81.7%, 99.1%)\n",
            "[2023-01-12 17:24:49] \u001b[32mTrain: [ 25/600] Step 480/520 Loss 0.739 Prec@(1,5) (81.7%, 99.1%)\u001b[0m\n",
            "INFO:nni:Train: [ 25/600] Step 480/520 Loss 0.739 Prec@(1,5) (81.7%, 99.1%)\n",
            "[2023-01-12 17:24:53] \u001b[32mTrain: [ 25/600] Step 490/520 Loss 0.741 Prec@(1,5) (81.7%, 99.1%)\u001b[0m\n",
            "INFO:nni:Train: [ 25/600] Step 490/520 Loss 0.741 Prec@(1,5) (81.7%, 99.1%)\n",
            "[2023-01-12 17:24:58] \u001b[32mTrain: [ 25/600] Step 500/520 Loss 0.743 Prec@(1,5) (81.7%, 99.1%)\u001b[0m\n",
            "INFO:nni:Train: [ 25/600] Step 500/520 Loss 0.743 Prec@(1,5) (81.7%, 99.1%)\n",
            "[2023-01-12 17:25:02] \u001b[32mTrain: [ 25/600] Step 510/520 Loss 0.743 Prec@(1,5) (81.7%, 99.1%)\u001b[0m\n",
            "INFO:nni:Train: [ 25/600] Step 510/520 Loss 0.743 Prec@(1,5) (81.7%, 99.1%)\n",
            "[2023-01-12 17:25:07] \u001b[32mTrain: [ 25/600] Step 520/520 Loss 0.741 Prec@(1,5) (81.7%, 99.1%)\u001b[0m\n",
            "INFO:nni:Train: [ 25/600] Step 520/520 Loss 0.741 Prec@(1,5) (81.7%, 99.1%)\n",
            "[2023-01-12 17:25:07] \u001b[32mTrain: [ 25/600] Final Prec@1 81.7040%\u001b[0m\n",
            "INFO:nni:Train: [ 25/600] Final Prec@1 81.7040%\n",
            "[2023-01-12 17:25:07] \u001b[32mValid: [ 25/600] Step 000/104 Loss 0.443 Prec@(1,5) (84.4%, 100.0%)\u001b[0m\n",
            "INFO:nni:Valid: [ 25/600] Step 000/104 Loss 0.443 Prec@(1,5) (84.4%, 100.0%)\n",
            "[2023-01-12 17:25:09] \u001b[32mValid: [ 25/600] Step 010/104 Loss 0.440 Prec@(1,5) (84.5%, 99.4%)\u001b[0m\n",
            "INFO:nni:Valid: [ 25/600] Step 010/104 Loss 0.440 Prec@(1,5) (84.5%, 99.4%)\n",
            "[2023-01-12 17:25:10] \u001b[32mValid: [ 25/600] Step 020/104 Loss 0.442 Prec@(1,5) (84.6%, 99.2%)\u001b[0m\n",
            "INFO:nni:Valid: [ 25/600] Step 020/104 Loss 0.442 Prec@(1,5) (84.6%, 99.2%)\n",
            "[2023-01-12 17:25:11] \u001b[32mValid: [ 25/600] Step 030/104 Loss 0.451 Prec@(1,5) (84.7%, 99.3%)\u001b[0m\n",
            "INFO:nni:Valid: [ 25/600] Step 030/104 Loss 0.451 Prec@(1,5) (84.7%, 99.3%)\n",
            "[2023-01-12 17:25:13] \u001b[32mValid: [ 25/600] Step 040/104 Loss 0.453 Prec@(1,5) (84.6%, 99.3%)\u001b[0m\n",
            "INFO:nni:Valid: [ 25/600] Step 040/104 Loss 0.453 Prec@(1,5) (84.6%, 99.3%)\n",
            "[2023-01-12 17:25:14] \u001b[32mValid: [ 25/600] Step 050/104 Loss 0.451 Prec@(1,5) (84.8%, 99.3%)\u001b[0m\n",
            "INFO:nni:Valid: [ 25/600] Step 050/104 Loss 0.451 Prec@(1,5) (84.8%, 99.3%)\n",
            "[2023-01-12 17:25:16] \u001b[32mValid: [ 25/600] Step 060/104 Loss 0.449 Prec@(1,5) (85.0%, 99.3%)\u001b[0m\n",
            "INFO:nni:Valid: [ 25/600] Step 060/104 Loss 0.449 Prec@(1,5) (85.0%, 99.3%)\n",
            "[2023-01-12 17:25:17] \u001b[32mValid: [ 25/600] Step 070/104 Loss 0.454 Prec@(1,5) (84.7%, 99.3%)\u001b[0m\n",
            "INFO:nni:Valid: [ 25/600] Step 070/104 Loss 0.454 Prec@(1,5) (84.7%, 99.3%)\n",
            "[2023-01-12 17:25:19] \u001b[32mValid: [ 25/600] Step 080/104 Loss 0.455 Prec@(1,5) (84.7%, 99.3%)\u001b[0m\n",
            "INFO:nni:Valid: [ 25/600] Step 080/104 Loss 0.455 Prec@(1,5) (84.7%, 99.3%)\n",
            "[2023-01-12 17:25:20] \u001b[32mValid: [ 25/600] Step 090/104 Loss 0.454 Prec@(1,5) (84.6%, 99.4%)\u001b[0m\n",
            "INFO:nni:Valid: [ 25/600] Step 090/104 Loss 0.454 Prec@(1,5) (84.6%, 99.4%)\n",
            "[2023-01-12 17:25:21] \u001b[32mValid: [ 25/600] Step 100/104 Loss 0.454 Prec@(1,5) (84.6%, 99.4%)\u001b[0m\n",
            "INFO:nni:Valid: [ 25/600] Step 100/104 Loss 0.454 Prec@(1,5) (84.6%, 99.4%)\n",
            "[2023-01-12 17:25:22] \u001b[32mValid: [ 25/600] Step 104/104 Loss 0.454 Prec@(1,5) (84.6%, 99.4%)\u001b[0m\n",
            "INFO:nni:Valid: [ 25/600] Step 104/104 Loss 0.454 Prec@(1,5) (84.6%, 99.4%)\n",
            "[2023-01-12 17:25:22] \u001b[32mValid: [ 25/600] Final Prec@1 84.5900%\u001b[0m\n",
            "INFO:nni:Valid: [ 25/600] Final Prec@1 84.5900%\n",
            "[2023-01-12 17:25:22] \u001b[32mEpoch 25 LR 0.024893\u001b[0m\n",
            "INFO:nni:Epoch 25 LR 0.024893\n",
            "[2023-01-12 17:25:23] \u001b[32mTrain: [ 26/600] Step 000/520 Loss 0.488 Prec@(1,5) (87.5%, 100.0%)\u001b[0m\n",
            "INFO:nni:Train: [ 26/600] Step 000/520 Loss 0.488 Prec@(1,5) (87.5%, 100.0%)\n",
            "[2023-01-12 17:25:27] \u001b[32mTrain: [ 26/600] Step 010/520 Loss 0.723 Prec@(1,5) (80.3%, 99.7%)\u001b[0m\n",
            "INFO:nni:Train: [ 26/600] Step 010/520 Loss 0.723 Prec@(1,5) (80.3%, 99.7%)\n",
            "[2023-01-12 17:25:32] \u001b[32mTrain: [ 26/600] Step 020/520 Loss 0.677 Prec@(1,5) (82.6%, 99.4%)\u001b[0m\n",
            "INFO:nni:Train: [ 26/600] Step 020/520 Loss 0.677 Prec@(1,5) (82.6%, 99.4%)\n",
            "[2023-01-12 17:25:36] \u001b[32mTrain: [ 26/600] Step 030/520 Loss 0.656 Prec@(1,5) (83.1%, 99.4%)\u001b[0m\n",
            "INFO:nni:Train: [ 26/600] Step 030/520 Loss 0.656 Prec@(1,5) (83.1%, 99.4%)\n",
            "[2023-01-12 17:25:41] \u001b[32mTrain: [ 26/600] Step 040/520 Loss 0.667 Prec@(1,5) (83.1%, 99.3%)\u001b[0m\n",
            "INFO:nni:Train: [ 26/600] Step 040/520 Loss 0.667 Prec@(1,5) (83.1%, 99.3%)\n",
            "[2023-01-12 17:25:45] \u001b[32mTrain: [ 26/600] Step 050/520 Loss 0.668 Prec@(1,5) (83.3%, 99.3%)\u001b[0m\n",
            "INFO:nni:Train: [ 26/600] Step 050/520 Loss 0.668 Prec@(1,5) (83.3%, 99.3%)\n",
            "[2023-01-12 17:25:50] \u001b[32mTrain: [ 26/600] Step 060/520 Loss 0.671 Prec@(1,5) (83.2%, 99.2%)\u001b[0m\n",
            "INFO:nni:Train: [ 26/600] Step 060/520 Loss 0.671 Prec@(1,5) (83.2%, 99.2%)\n",
            "[2023-01-12 17:25:54] \u001b[32mTrain: [ 26/600] Step 070/520 Loss 0.679 Prec@(1,5) (82.9%, 99.2%)\u001b[0m\n",
            "INFO:nni:Train: [ 26/600] Step 070/520 Loss 0.679 Prec@(1,5) (82.9%, 99.2%)\n",
            "[2023-01-12 17:25:59] \u001b[32mTrain: [ 26/600] Step 080/520 Loss 0.678 Prec@(1,5) (82.8%, 99.2%)\u001b[0m\n",
            "INFO:nni:Train: [ 26/600] Step 080/520 Loss 0.678 Prec@(1,5) (82.8%, 99.2%)\n",
            "[2023-01-12 17:26:03] \u001b[32mTrain: [ 26/600] Step 090/520 Loss 0.690 Prec@(1,5) (82.5%, 99.2%)\u001b[0m\n",
            "INFO:nni:Train: [ 26/600] Step 090/520 Loss 0.690 Prec@(1,5) (82.5%, 99.2%)\n",
            "[2023-01-12 17:26:08] \u001b[32mTrain: [ 26/600] Step 100/520 Loss 0.700 Prec@(1,5) (82.2%, 99.2%)\u001b[0m\n",
            "INFO:nni:Train: [ 26/600] Step 100/520 Loss 0.700 Prec@(1,5) (82.2%, 99.2%)\n",
            "[2023-01-12 17:26:12] \u001b[32mTrain: [ 26/600] Step 110/520 Loss 0.705 Prec@(1,5) (82.1%, 99.2%)\u001b[0m\n",
            "INFO:nni:Train: [ 26/600] Step 110/520 Loss 0.705 Prec@(1,5) (82.1%, 99.2%)\n",
            "[2023-01-12 17:26:17] \u001b[32mTrain: [ 26/600] Step 120/520 Loss 0.710 Prec@(1,5) (82.0%, 99.2%)\u001b[0m\n",
            "INFO:nni:Train: [ 26/600] Step 120/520 Loss 0.710 Prec@(1,5) (82.0%, 99.2%)\n",
            "[2023-01-12 17:26:22] \u001b[32mTrain: [ 26/600] Step 130/520 Loss 0.713 Prec@(1,5) (82.0%, 99.2%)\u001b[0m\n",
            "INFO:nni:Train: [ 26/600] Step 130/520 Loss 0.713 Prec@(1,5) (82.0%, 99.2%)\n",
            "[2023-01-12 17:26:26] \u001b[32mTrain: [ 26/600] Step 140/520 Loss 0.719 Prec@(1,5) (81.9%, 99.2%)\u001b[0m\n",
            "INFO:nni:Train: [ 26/600] Step 140/520 Loss 0.719 Prec@(1,5) (81.9%, 99.2%)\n",
            "[2023-01-12 17:26:31] \u001b[32mTrain: [ 26/600] Step 150/520 Loss 0.730 Prec@(1,5) (81.7%, 99.1%)\u001b[0m\n",
            "INFO:nni:Train: [ 26/600] Step 150/520 Loss 0.730 Prec@(1,5) (81.7%, 99.1%)\n",
            "[2023-01-12 17:26:35] \u001b[32mTrain: [ 26/600] Step 160/520 Loss 0.735 Prec@(1,5) (81.6%, 99.1%)\u001b[0m\n",
            "INFO:nni:Train: [ 26/600] Step 160/520 Loss 0.735 Prec@(1,5) (81.6%, 99.1%)\n",
            "[2023-01-12 17:26:40] \u001b[32mTrain: [ 26/600] Step 170/520 Loss 0.740 Prec@(1,5) (81.5%, 99.1%)\u001b[0m\n",
            "INFO:nni:Train: [ 26/600] Step 170/520 Loss 0.740 Prec@(1,5) (81.5%, 99.1%)\n",
            "[2023-01-12 17:26:44] \u001b[32mTrain: [ 26/600] Step 180/520 Loss 0.742 Prec@(1,5) (81.4%, 99.1%)\u001b[0m\n",
            "INFO:nni:Train: [ 26/600] Step 180/520 Loss 0.742 Prec@(1,5) (81.4%, 99.1%)\n",
            "[2023-01-12 17:26:49] \u001b[32mTrain: [ 26/600] Step 190/520 Loss 0.748 Prec@(1,5) (81.3%, 99.1%)\u001b[0m\n",
            "INFO:nni:Train: [ 26/600] Step 190/520 Loss 0.748 Prec@(1,5) (81.3%, 99.1%)\n",
            "[2023-01-12 17:26:53] \u001b[32mTrain: [ 26/600] Step 200/520 Loss 0.750 Prec@(1,5) (81.2%, 99.1%)\u001b[0m\n",
            "INFO:nni:Train: [ 26/600] Step 200/520 Loss 0.750 Prec@(1,5) (81.2%, 99.1%)\n",
            "[2023-01-12 17:26:58] \u001b[32mTrain: [ 26/600] Step 210/520 Loss 0.753 Prec@(1,5) (81.2%, 99.1%)\u001b[0m\n",
            "INFO:nni:Train: [ 26/600] Step 210/520 Loss 0.753 Prec@(1,5) (81.2%, 99.1%)\n",
            "[2023-01-12 17:27:02] \u001b[32mTrain: [ 26/600] Step 220/520 Loss 0.750 Prec@(1,5) (81.2%, 99.1%)\u001b[0m\n",
            "INFO:nni:Train: [ 26/600] Step 220/520 Loss 0.750 Prec@(1,5) (81.2%, 99.1%)\n",
            "[2023-01-12 17:27:07] \u001b[32mTrain: [ 26/600] Step 230/520 Loss 0.747 Prec@(1,5) (81.3%, 99.1%)\u001b[0m\n",
            "INFO:nni:Train: [ 26/600] Step 230/520 Loss 0.747 Prec@(1,5) (81.3%, 99.1%)\n",
            "[2023-01-12 17:27:11] \u001b[32mTrain: [ 26/600] Step 240/520 Loss 0.744 Prec@(1,5) (81.3%, 99.1%)\u001b[0m\n",
            "INFO:nni:Train: [ 26/600] Step 240/520 Loss 0.744 Prec@(1,5) (81.3%, 99.1%)\n",
            "[2023-01-12 17:27:16] \u001b[32mTrain: [ 26/600] Step 250/520 Loss 0.746 Prec@(1,5) (81.3%, 99.1%)\u001b[0m\n",
            "INFO:nni:Train: [ 26/600] Step 250/520 Loss 0.746 Prec@(1,5) (81.3%, 99.1%)\n",
            "[2023-01-12 17:27:20] \u001b[32mTrain: [ 26/600] Step 260/520 Loss 0.748 Prec@(1,5) (81.3%, 99.1%)\u001b[0m\n",
            "INFO:nni:Train: [ 26/600] Step 260/520 Loss 0.748 Prec@(1,5) (81.3%, 99.1%)\n",
            "[2023-01-12 17:27:25] \u001b[32mTrain: [ 26/600] Step 270/520 Loss 0.749 Prec@(1,5) (81.3%, 99.1%)\u001b[0m\n",
            "INFO:nni:Train: [ 26/600] Step 270/520 Loss 0.749 Prec@(1,5) (81.3%, 99.1%)\n",
            "[2023-01-12 17:27:29] \u001b[32mTrain: [ 26/600] Step 280/520 Loss 0.749 Prec@(1,5) (81.3%, 99.1%)\u001b[0m\n",
            "INFO:nni:Train: [ 26/600] Step 280/520 Loss 0.749 Prec@(1,5) (81.3%, 99.1%)\n",
            "[2023-01-12 17:27:34] \u001b[32mTrain: [ 26/600] Step 290/520 Loss 0.749 Prec@(1,5) (81.4%, 99.1%)\u001b[0m\n",
            "INFO:nni:Train: [ 26/600] Step 290/520 Loss 0.749 Prec@(1,5) (81.4%, 99.1%)\n",
            "[2023-01-12 17:27:38] \u001b[32mTrain: [ 26/600] Step 300/520 Loss 0.748 Prec@(1,5) (81.4%, 99.1%)\u001b[0m\n",
            "INFO:nni:Train: [ 26/600] Step 300/520 Loss 0.748 Prec@(1,5) (81.4%, 99.1%)\n",
            "[2023-01-12 17:27:43] \u001b[32mTrain: [ 26/600] Step 310/520 Loss 0.746 Prec@(1,5) (81.4%, 99.1%)\u001b[0m\n",
            "INFO:nni:Train: [ 26/600] Step 310/520 Loss 0.746 Prec@(1,5) (81.4%, 99.1%)\n",
            "[2023-01-12 17:27:47] \u001b[32mTrain: [ 26/600] Step 320/520 Loss 0.743 Prec@(1,5) (81.5%, 99.1%)\u001b[0m\n",
            "INFO:nni:Train: [ 26/600] Step 320/520 Loss 0.743 Prec@(1,5) (81.5%, 99.1%)\n",
            "[2023-01-12 17:27:52] \u001b[32mTrain: [ 26/600] Step 330/520 Loss 0.745 Prec@(1,5) (81.5%, 99.1%)\u001b[0m\n",
            "INFO:nni:Train: [ 26/600] Step 330/520 Loss 0.745 Prec@(1,5) (81.5%, 99.1%)\n",
            "[2023-01-12 17:27:56] \u001b[32mTrain: [ 26/600] Step 340/520 Loss 0.746 Prec@(1,5) (81.4%, 99.1%)\u001b[0m\n",
            "INFO:nni:Train: [ 26/600] Step 340/520 Loss 0.746 Prec@(1,5) (81.4%, 99.1%)\n",
            "[2023-01-12 17:28:01] \u001b[32mTrain: [ 26/600] Step 350/520 Loss 0.744 Prec@(1,5) (81.5%, 99.1%)\u001b[0m\n",
            "INFO:nni:Train: [ 26/600] Step 350/520 Loss 0.744 Prec@(1,5) (81.5%, 99.1%)\n",
            "[2023-01-12 17:28:05] \u001b[32mTrain: [ 26/600] Step 360/520 Loss 0.745 Prec@(1,5) (81.5%, 99.1%)\u001b[0m\n",
            "INFO:nni:Train: [ 26/600] Step 360/520 Loss 0.745 Prec@(1,5) (81.5%, 99.1%)\n",
            "[2023-01-12 17:28:10] \u001b[32mTrain: [ 26/600] Step 370/520 Loss 0.744 Prec@(1,5) (81.6%, 99.1%)\u001b[0m\n",
            "INFO:nni:Train: [ 26/600] Step 370/520 Loss 0.744 Prec@(1,5) (81.6%, 99.1%)\n",
            "[2023-01-12 17:28:14] \u001b[32mTrain: [ 26/600] Step 380/520 Loss 0.745 Prec@(1,5) (81.5%, 99.1%)\u001b[0m\n",
            "INFO:nni:Train: [ 26/600] Step 380/520 Loss 0.745 Prec@(1,5) (81.5%, 99.1%)\n",
            "[2023-01-12 17:28:19] \u001b[32mTrain: [ 26/600] Step 390/520 Loss 0.744 Prec@(1,5) (81.6%, 99.1%)\u001b[0m\n",
            "INFO:nni:Train: [ 26/600] Step 390/520 Loss 0.744 Prec@(1,5) (81.6%, 99.1%)\n",
            "[2023-01-12 17:28:24] \u001b[32mTrain: [ 26/600] Step 400/520 Loss 0.744 Prec@(1,5) (81.6%, 99.1%)\u001b[0m\n",
            "INFO:nni:Train: [ 26/600] Step 400/520 Loss 0.744 Prec@(1,5) (81.6%, 99.1%)\n",
            "[2023-01-12 17:28:28] \u001b[32mTrain: [ 26/600] Step 410/520 Loss 0.742 Prec@(1,5) (81.6%, 99.1%)\u001b[0m\n",
            "INFO:nni:Train: [ 26/600] Step 410/520 Loss 0.742 Prec@(1,5) (81.6%, 99.1%)\n",
            "[2023-01-12 17:28:33] \u001b[32mTrain: [ 26/600] Step 420/520 Loss 0.741 Prec@(1,5) (81.7%, 99.1%)\u001b[0m\n",
            "INFO:nni:Train: [ 26/600] Step 420/520 Loss 0.741 Prec@(1,5) (81.7%, 99.1%)\n",
            "[2023-01-12 17:28:37] \u001b[32mTrain: [ 26/600] Step 430/520 Loss 0.740 Prec@(1,5) (81.7%, 99.1%)\u001b[0m\n",
            "INFO:nni:Train: [ 26/600] Step 430/520 Loss 0.740 Prec@(1,5) (81.7%, 99.1%)\n",
            "[2023-01-12 17:28:42] \u001b[32mTrain: [ 26/600] Step 440/520 Loss 0.739 Prec@(1,5) (81.7%, 99.1%)\u001b[0m\n",
            "INFO:nni:Train: [ 26/600] Step 440/520 Loss 0.739 Prec@(1,5) (81.7%, 99.1%)\n",
            "[2023-01-12 17:28:46] \u001b[32mTrain: [ 26/600] Step 450/520 Loss 0.740 Prec@(1,5) (81.7%, 99.1%)\u001b[0m\n",
            "INFO:nni:Train: [ 26/600] Step 450/520 Loss 0.740 Prec@(1,5) (81.7%, 99.1%)\n",
            "[2023-01-12 17:28:51] \u001b[32mTrain: [ 26/600] Step 460/520 Loss 0.741 Prec@(1,5) (81.7%, 99.1%)\u001b[0m\n",
            "INFO:nni:Train: [ 26/600] Step 460/520 Loss 0.741 Prec@(1,5) (81.7%, 99.1%)\n",
            "[2023-01-12 17:28:55] \u001b[32mTrain: [ 26/600] Step 470/520 Loss 0.739 Prec@(1,5) (81.8%, 99.1%)\u001b[0m\n",
            "INFO:nni:Train: [ 26/600] Step 470/520 Loss 0.739 Prec@(1,5) (81.8%, 99.1%)\n",
            "[2023-01-12 17:29:00] \u001b[32mTrain: [ 26/600] Step 480/520 Loss 0.740 Prec@(1,5) (81.8%, 99.1%)\u001b[0m\n",
            "INFO:nni:Train: [ 26/600] Step 480/520 Loss 0.740 Prec@(1,5) (81.8%, 99.1%)\n",
            "[2023-01-12 17:29:04] \u001b[32mTrain: [ 26/600] Step 490/520 Loss 0.739 Prec@(1,5) (81.8%, 99.1%)\u001b[0m\n",
            "INFO:nni:Train: [ 26/600] Step 490/520 Loss 0.739 Prec@(1,5) (81.8%, 99.1%)\n",
            "[2023-01-12 17:29:09] \u001b[32mTrain: [ 26/600] Step 500/520 Loss 0.738 Prec@(1,5) (81.9%, 99.1%)\u001b[0m\n",
            "INFO:nni:Train: [ 26/600] Step 500/520 Loss 0.738 Prec@(1,5) (81.9%, 99.1%)\n",
            "[2023-01-12 17:29:13] \u001b[32mTrain: [ 26/600] Step 510/520 Loss 0.737 Prec@(1,5) (81.9%, 99.1%)\u001b[0m\n",
            "INFO:nni:Train: [ 26/600] Step 510/520 Loss 0.737 Prec@(1,5) (81.9%, 99.1%)\n",
            "[2023-01-12 17:29:18] \u001b[32mTrain: [ 26/600] Step 520/520 Loss 0.736 Prec@(1,5) (81.9%, 99.1%)\u001b[0m\n",
            "INFO:nni:Train: [ 26/600] Step 520/520 Loss 0.736 Prec@(1,5) (81.9%, 99.1%)\n",
            "[2023-01-12 17:29:18] \u001b[32mTrain: [ 26/600] Final Prec@1 81.9160%\u001b[0m\n",
            "INFO:nni:Train: [ 26/600] Final Prec@1 81.9160%\n",
            "[2023-01-12 17:29:18] \u001b[32mValid: [ 26/600] Step 000/104 Loss 0.539 Prec@(1,5) (79.2%, 96.9%)\u001b[0m\n",
            "INFO:nni:Valid: [ 26/600] Step 000/104 Loss 0.539 Prec@(1,5) (79.2%, 96.9%)\n",
            "[2023-01-12 17:29:20] \u001b[32mValid: [ 26/600] Step 010/104 Loss 0.413 Prec@(1,5) (85.7%, 99.4%)\u001b[0m\n",
            "INFO:nni:Valid: [ 26/600] Step 010/104 Loss 0.413 Prec@(1,5) (85.7%, 99.4%)\n",
            "[2023-01-12 17:29:21] \u001b[32mValid: [ 26/600] Step 020/104 Loss 0.427 Prec@(1,5) (85.8%, 99.2%)\u001b[0m\n",
            "INFO:nni:Valid: [ 26/600] Step 020/104 Loss 0.427 Prec@(1,5) (85.8%, 99.2%)\n",
            "[2023-01-12 17:29:22] \u001b[32mValid: [ 26/600] Step 030/104 Loss 0.439 Prec@(1,5) (85.8%, 99.2%)\u001b[0m\n",
            "INFO:nni:Valid: [ 26/600] Step 030/104 Loss 0.439 Prec@(1,5) (85.8%, 99.2%)\n",
            "[2023-01-12 17:29:24] \u001b[32mValid: [ 26/600] Step 040/104 Loss 0.445 Prec@(1,5) (85.7%, 99.2%)\u001b[0m\n",
            "INFO:nni:Valid: [ 26/600] Step 040/104 Loss 0.445 Prec@(1,5) (85.7%, 99.2%)\n",
            "[2023-01-12 17:29:25] \u001b[32mValid: [ 26/600] Step 050/104 Loss 0.445 Prec@(1,5) (85.7%, 99.3%)\u001b[0m\n",
            "INFO:nni:Valid: [ 26/600] Step 050/104 Loss 0.445 Prec@(1,5) (85.7%, 99.3%)\n",
            "[2023-01-12 17:29:27] \u001b[32mValid: [ 26/600] Step 060/104 Loss 0.438 Prec@(1,5) (85.9%, 99.2%)\u001b[0m\n",
            "INFO:nni:Valid: [ 26/600] Step 060/104 Loss 0.438 Prec@(1,5) (85.9%, 99.2%)\n",
            "[2023-01-12 17:29:28] \u001b[32mValid: [ 26/600] Step 070/104 Loss 0.444 Prec@(1,5) (85.7%, 99.3%)\u001b[0m\n",
            "INFO:nni:Valid: [ 26/600] Step 070/104 Loss 0.444 Prec@(1,5) (85.7%, 99.3%)\n",
            "[2023-01-12 17:29:29] \u001b[32mValid: [ 26/600] Step 080/104 Loss 0.448 Prec@(1,5) (85.6%, 99.3%)\u001b[0m\n",
            "INFO:nni:Valid: [ 26/600] Step 080/104 Loss 0.448 Prec@(1,5) (85.6%, 99.3%)\n",
            "[2023-01-12 17:29:31] \u001b[32mValid: [ 26/600] Step 090/104 Loss 0.445 Prec@(1,5) (85.6%, 99.3%)\u001b[0m\n",
            "INFO:nni:Valid: [ 26/600] Step 090/104 Loss 0.445 Prec@(1,5) (85.6%, 99.3%)\n",
            "[2023-01-12 17:29:32] \u001b[32mValid: [ 26/600] Step 100/104 Loss 0.441 Prec@(1,5) (85.6%, 99.4%)\u001b[0m\n",
            "INFO:nni:Valid: [ 26/600] Step 100/104 Loss 0.441 Prec@(1,5) (85.6%, 99.4%)\n",
            "[2023-01-12 17:29:33] \u001b[32mValid: [ 26/600] Step 104/104 Loss 0.441 Prec@(1,5) (85.6%, 99.4%)\u001b[0m\n",
            "INFO:nni:Valid: [ 26/600] Step 104/104 Loss 0.441 Prec@(1,5) (85.6%, 99.4%)\n",
            "[2023-01-12 17:29:33] \u001b[32mValid: [ 26/600] Final Prec@1 85.5600%\u001b[0m\n",
            "INFO:nni:Valid: [ 26/600] Final Prec@1 85.5600%\n",
            "[2023-01-12 17:29:33] \u001b[32mEpoch 26 LR 0.024884\u001b[0m\n",
            "INFO:nni:Epoch 26 LR 0.024884\n",
            "[2023-01-12 17:29:34] \u001b[32mTrain: [ 27/600] Step 000/520 Loss 0.725 Prec@(1,5) (86.5%, 97.9%)\u001b[0m\n",
            "INFO:nni:Train: [ 27/600] Step 000/520 Loss 0.725 Prec@(1,5) (86.5%, 97.9%)\n",
            "[2023-01-12 17:29:38] \u001b[32mTrain: [ 27/600] Step 010/520 Loss 0.744 Prec@(1,5) (82.4%, 99.2%)\u001b[0m\n",
            "INFO:nni:Train: [ 27/600] Step 010/520 Loss 0.744 Prec@(1,5) (82.4%, 99.2%)\n",
            "[2023-01-12 17:29:43] \u001b[32mTrain: [ 27/600] Step 020/520 Loss 0.727 Prec@(1,5) (82.2%, 99.5%)\u001b[0m\n",
            "INFO:nni:Train: [ 27/600] Step 020/520 Loss 0.727 Prec@(1,5) (82.2%, 99.5%)\n",
            "[2023-01-12 17:29:47] \u001b[32mTrain: [ 27/600] Step 030/520 Loss 0.693 Prec@(1,5) (83.2%, 99.5%)\u001b[0m\n",
            "INFO:nni:Train: [ 27/600] Step 030/520 Loss 0.693 Prec@(1,5) (83.2%, 99.5%)\n",
            "[2023-01-12 17:29:52] \u001b[32mTrain: [ 27/600] Step 040/520 Loss 0.684 Prec@(1,5) (83.3%, 99.5%)\u001b[0m\n",
            "INFO:nni:Train: [ 27/600] Step 040/520 Loss 0.684 Prec@(1,5) (83.3%, 99.5%)\n",
            "[2023-01-12 17:29:56] \u001b[32mTrain: [ 27/600] Step 050/520 Loss 0.676 Prec@(1,5) (83.5%, 99.5%)\u001b[0m\n",
            "INFO:nni:Train: [ 27/600] Step 050/520 Loss 0.676 Prec@(1,5) (83.5%, 99.5%)\n",
            "[2023-01-12 17:30:01] \u001b[32mTrain: [ 27/600] Step 060/520 Loss 0.679 Prec@(1,5) (83.4%, 99.5%)\u001b[0m\n",
            "INFO:nni:Train: [ 27/600] Step 060/520 Loss 0.679 Prec@(1,5) (83.4%, 99.5%)\n",
            "[2023-01-12 17:30:05] \u001b[32mTrain: [ 27/600] Step 070/520 Loss 0.692 Prec@(1,5) (83.2%, 99.4%)\u001b[0m\n",
            "INFO:nni:Train: [ 27/600] Step 070/520 Loss 0.692 Prec@(1,5) (83.2%, 99.4%)\n",
            "[2023-01-12 17:30:10] \u001b[32mTrain: [ 27/600] Step 080/520 Loss 0.686 Prec@(1,5) (83.2%, 99.4%)\u001b[0m\n",
            "INFO:nni:Train: [ 27/600] Step 080/520 Loss 0.686 Prec@(1,5) (83.2%, 99.4%)\n",
            "[2023-01-12 17:30:14] \u001b[32mTrain: [ 27/600] Step 090/520 Loss 0.690 Prec@(1,5) (83.0%, 99.4%)\u001b[0m\n",
            "INFO:nni:Train: [ 27/600] Step 090/520 Loss 0.690 Prec@(1,5) (83.0%, 99.4%)\n",
            "[2023-01-12 17:30:19] \u001b[32mTrain: [ 27/600] Step 100/520 Loss 0.693 Prec@(1,5) (82.9%, 99.4%)\u001b[0m\n",
            "INFO:nni:Train: [ 27/600] Step 100/520 Loss 0.693 Prec@(1,5) (82.9%, 99.4%)\n",
            "[2023-01-12 17:30:23] \u001b[32mTrain: [ 27/600] Step 110/520 Loss 0.691 Prec@(1,5) (82.9%, 99.4%)\u001b[0m\n",
            "INFO:nni:Train: [ 27/600] Step 110/520 Loss 0.691 Prec@(1,5) (82.9%, 99.4%)\n",
            "[2023-01-12 17:30:28] \u001b[32mTrain: [ 27/600] Step 120/520 Loss 0.691 Prec@(1,5) (82.8%, 99.4%)\u001b[0m\n",
            "INFO:nni:Train: [ 27/600] Step 120/520 Loss 0.691 Prec@(1,5) (82.8%, 99.4%)\n",
            "[2023-01-12 17:30:32] \u001b[32mTrain: [ 27/600] Step 130/520 Loss 0.695 Prec@(1,5) (82.7%, 99.4%)\u001b[0m\n",
            "INFO:nni:Train: [ 27/600] Step 130/520 Loss 0.695 Prec@(1,5) (82.7%, 99.4%)\n",
            "[2023-01-12 17:30:37] \u001b[32mTrain: [ 27/600] Step 140/520 Loss 0.696 Prec@(1,5) (82.7%, 99.4%)\u001b[0m\n",
            "INFO:nni:Train: [ 27/600] Step 140/520 Loss 0.696 Prec@(1,5) (82.7%, 99.4%)\n",
            "[2023-01-12 17:30:41] \u001b[32mTrain: [ 27/600] Step 150/520 Loss 0.698 Prec@(1,5) (82.7%, 99.3%)\u001b[0m\n",
            "INFO:nni:Train: [ 27/600] Step 150/520 Loss 0.698 Prec@(1,5) (82.7%, 99.3%)\n",
            "[2023-01-12 17:30:46] \u001b[32mTrain: [ 27/600] Step 160/520 Loss 0.697 Prec@(1,5) (82.7%, 99.3%)\u001b[0m\n",
            "INFO:nni:Train: [ 27/600] Step 160/520 Loss 0.697 Prec@(1,5) (82.7%, 99.3%)\n",
            "[2023-01-12 17:30:51] \u001b[32mTrain: [ 27/600] Step 170/520 Loss 0.698 Prec@(1,5) (82.6%, 99.3%)\u001b[0m\n",
            "INFO:nni:Train: [ 27/600] Step 170/520 Loss 0.698 Prec@(1,5) (82.6%, 99.3%)\n",
            "[2023-01-12 17:30:55] \u001b[32mTrain: [ 27/600] Step 180/520 Loss 0.697 Prec@(1,5) (82.6%, 99.3%)\u001b[0m\n",
            "INFO:nni:Train: [ 27/600] Step 180/520 Loss 0.697 Prec@(1,5) (82.6%, 99.3%)\n",
            "[2023-01-12 17:31:00] \u001b[32mTrain: [ 27/600] Step 190/520 Loss 0.700 Prec@(1,5) (82.6%, 99.3%)\u001b[0m\n",
            "INFO:nni:Train: [ 27/600] Step 190/520 Loss 0.700 Prec@(1,5) (82.6%, 99.3%)\n",
            "[2023-01-12 17:31:04] \u001b[32mTrain: [ 27/600] Step 200/520 Loss 0.701 Prec@(1,5) (82.6%, 99.3%)\u001b[0m\n",
            "INFO:nni:Train: [ 27/600] Step 200/520 Loss 0.701 Prec@(1,5) (82.6%, 99.3%)\n",
            "[2023-01-12 17:31:09] \u001b[32mTrain: [ 27/600] Step 210/520 Loss 0.703 Prec@(1,5) (82.5%, 99.3%)\u001b[0m\n",
            "INFO:nni:Train: [ 27/600] Step 210/520 Loss 0.703 Prec@(1,5) (82.5%, 99.3%)\n",
            "[2023-01-12 17:31:13] \u001b[32mTrain: [ 27/600] Step 220/520 Loss 0.707 Prec@(1,5) (82.5%, 99.3%)\u001b[0m\n",
            "INFO:nni:Train: [ 27/600] Step 220/520 Loss 0.707 Prec@(1,5) (82.5%, 99.3%)\n",
            "[2023-01-12 17:31:18] \u001b[32mTrain: [ 27/600] Step 230/520 Loss 0.708 Prec@(1,5) (82.5%, 99.3%)\u001b[0m\n",
            "INFO:nni:Train: [ 27/600] Step 230/520 Loss 0.708 Prec@(1,5) (82.5%, 99.3%)\n",
            "[2023-01-12 17:31:22] \u001b[32mTrain: [ 27/600] Step 240/520 Loss 0.708 Prec@(1,5) (82.5%, 99.3%)\u001b[0m\n",
            "INFO:nni:Train: [ 27/600] Step 240/520 Loss 0.708 Prec@(1,5) (82.5%, 99.3%)\n",
            "[2023-01-12 17:31:27] \u001b[32mTrain: [ 27/600] Step 250/520 Loss 0.708 Prec@(1,5) (82.5%, 99.3%)\u001b[0m\n",
            "INFO:nni:Train: [ 27/600] Step 250/520 Loss 0.708 Prec@(1,5) (82.5%, 99.3%)\n",
            "[2023-01-12 17:31:31] \u001b[32mTrain: [ 27/600] Step 260/520 Loss 0.707 Prec@(1,5) (82.5%, 99.3%)\u001b[0m\n",
            "INFO:nni:Train: [ 27/600] Step 260/520 Loss 0.707 Prec@(1,5) (82.5%, 99.3%)\n",
            "[2023-01-12 17:31:36] \u001b[32mTrain: [ 27/600] Step 270/520 Loss 0.704 Prec@(1,5) (82.6%, 99.3%)\u001b[0m\n",
            "INFO:nni:Train: [ 27/600] Step 270/520 Loss 0.704 Prec@(1,5) (82.6%, 99.3%)\n",
            "[2023-01-12 17:31:40] \u001b[32mTrain: [ 27/600] Step 280/520 Loss 0.704 Prec@(1,5) (82.5%, 99.3%)\u001b[0m\n",
            "INFO:nni:Train: [ 27/600] Step 280/520 Loss 0.704 Prec@(1,5) (82.5%, 99.3%)\n",
            "[2023-01-12 17:31:45] \u001b[32mTrain: [ 27/600] Step 290/520 Loss 0.703 Prec@(1,5) (82.6%, 99.3%)\u001b[0m\n",
            "INFO:nni:Train: [ 27/600] Step 290/520 Loss 0.703 Prec@(1,5) (82.6%, 99.3%)\n",
            "[2023-01-12 17:31:49] \u001b[32mTrain: [ 27/600] Step 300/520 Loss 0.703 Prec@(1,5) (82.6%, 99.3%)\u001b[0m\n",
            "INFO:nni:Train: [ 27/600] Step 300/520 Loss 0.703 Prec@(1,5) (82.6%, 99.3%)\n",
            "[2023-01-12 17:31:54] \u001b[32mTrain: [ 27/600] Step 310/520 Loss 0.706 Prec@(1,5) (82.6%, 99.3%)\u001b[0m\n",
            "INFO:nni:Train: [ 27/600] Step 310/520 Loss 0.706 Prec@(1,5) (82.6%, 99.3%)\n",
            "[2023-01-12 17:31:58] \u001b[32mTrain: [ 27/600] Step 320/520 Loss 0.709 Prec@(1,5) (82.5%, 99.3%)\u001b[0m\n",
            "INFO:nni:Train: [ 27/600] Step 320/520 Loss 0.709 Prec@(1,5) (82.5%, 99.3%)\n",
            "[2023-01-12 17:32:03] \u001b[32mTrain: [ 27/600] Step 330/520 Loss 0.710 Prec@(1,5) (82.4%, 99.3%)\u001b[0m\n",
            "INFO:nni:Train: [ 27/600] Step 330/520 Loss 0.710 Prec@(1,5) (82.4%, 99.3%)\n",
            "[2023-01-12 17:32:07] \u001b[32mTrain: [ 27/600] Step 340/520 Loss 0.710 Prec@(1,5) (82.5%, 99.3%)\u001b[0m\n",
            "INFO:nni:Train: [ 27/600] Step 340/520 Loss 0.710 Prec@(1,5) (82.5%, 99.3%)\n",
            "[2023-01-12 17:32:12] \u001b[32mTrain: [ 27/600] Step 350/520 Loss 0.710 Prec@(1,5) (82.5%, 99.3%)\u001b[0m\n",
            "INFO:nni:Train: [ 27/600] Step 350/520 Loss 0.710 Prec@(1,5) (82.5%, 99.3%)\n",
            "[2023-01-12 17:32:16] \u001b[32mTrain: [ 27/600] Step 360/520 Loss 0.707 Prec@(1,5) (82.6%, 99.3%)\u001b[0m\n",
            "INFO:nni:Train: [ 27/600] Step 360/520 Loss 0.707 Prec@(1,5) (82.6%, 99.3%)\n",
            "[2023-01-12 17:32:21] \u001b[32mTrain: [ 27/600] Step 370/520 Loss 0.707 Prec@(1,5) (82.5%, 99.3%)\u001b[0m\n",
            "INFO:nni:Train: [ 27/600] Step 370/520 Loss 0.707 Prec@(1,5) (82.5%, 99.3%)\n",
            "[2023-01-12 17:32:25] \u001b[32mTrain: [ 27/600] Step 380/520 Loss 0.708 Prec@(1,5) (82.5%, 99.3%)\u001b[0m\n",
            "INFO:nni:Train: [ 27/600] Step 380/520 Loss 0.708 Prec@(1,5) (82.5%, 99.3%)\n",
            "[2023-01-12 17:32:30] \u001b[32mTrain: [ 27/600] Step 390/520 Loss 0.709 Prec@(1,5) (82.5%, 99.3%)\u001b[0m\n",
            "INFO:nni:Train: [ 27/600] Step 390/520 Loss 0.709 Prec@(1,5) (82.5%, 99.3%)\n",
            "[2023-01-12 17:32:34] \u001b[32mTrain: [ 27/600] Step 400/520 Loss 0.708 Prec@(1,5) (82.5%, 99.3%)\u001b[0m\n",
            "INFO:nni:Train: [ 27/600] Step 400/520 Loss 0.708 Prec@(1,5) (82.5%, 99.3%)\n",
            "[2023-01-12 17:32:39] \u001b[32mTrain: [ 27/600] Step 410/520 Loss 0.709 Prec@(1,5) (82.5%, 99.2%)\u001b[0m\n",
            "INFO:nni:Train: [ 27/600] Step 410/520 Loss 0.709 Prec@(1,5) (82.5%, 99.2%)\n",
            "[2023-01-12 17:32:43] \u001b[32mTrain: [ 27/600] Step 420/520 Loss 0.708 Prec@(1,5) (82.5%, 99.2%)\u001b[0m\n",
            "INFO:nni:Train: [ 27/600] Step 420/520 Loss 0.708 Prec@(1,5) (82.5%, 99.2%)\n",
            "[2023-01-12 17:32:48] \u001b[32mTrain: [ 27/600] Step 430/520 Loss 0.710 Prec@(1,5) (82.5%, 99.2%)\u001b[0m\n",
            "INFO:nni:Train: [ 27/600] Step 430/520 Loss 0.710 Prec@(1,5) (82.5%, 99.2%)\n",
            "[2023-01-12 17:32:52] \u001b[32mTrain: [ 27/600] Step 440/520 Loss 0.711 Prec@(1,5) (82.4%, 99.2%)\u001b[0m\n",
            "INFO:nni:Train: [ 27/600] Step 440/520 Loss 0.711 Prec@(1,5) (82.4%, 99.2%)\n",
            "[2023-01-12 17:32:57] \u001b[32mTrain: [ 27/600] Step 450/520 Loss 0.713 Prec@(1,5) (82.4%, 99.2%)\u001b[0m\n",
            "INFO:nni:Train: [ 27/600] Step 450/520 Loss 0.713 Prec@(1,5) (82.4%, 99.2%)\n",
            "[2023-01-12 17:33:01] \u001b[32mTrain: [ 27/600] Step 460/520 Loss 0.713 Prec@(1,5) (82.4%, 99.2%)\u001b[0m\n",
            "INFO:nni:Train: [ 27/600] Step 460/520 Loss 0.713 Prec@(1,5) (82.4%, 99.2%)\n",
            "[2023-01-12 17:33:06] \u001b[32mTrain: [ 27/600] Step 470/520 Loss 0.713 Prec@(1,5) (82.4%, 99.2%)\u001b[0m\n",
            "INFO:nni:Train: [ 27/600] Step 470/520 Loss 0.713 Prec@(1,5) (82.4%, 99.2%)\n",
            "[2023-01-12 17:33:11] \u001b[32mTrain: [ 27/600] Step 480/520 Loss 0.712 Prec@(1,5) (82.4%, 99.2%)\u001b[0m\n",
            "INFO:nni:Train: [ 27/600] Step 480/520 Loss 0.712 Prec@(1,5) (82.4%, 99.2%)\n",
            "[2023-01-12 17:33:15] \u001b[32mTrain: [ 27/600] Step 490/520 Loss 0.712 Prec@(1,5) (82.5%, 99.2%)\u001b[0m\n",
            "INFO:nni:Train: [ 27/600] Step 490/520 Loss 0.712 Prec@(1,5) (82.5%, 99.2%)\n",
            "[2023-01-12 17:33:20] \u001b[32mTrain: [ 27/600] Step 500/520 Loss 0.712 Prec@(1,5) (82.5%, 99.2%)\u001b[0m\n",
            "INFO:nni:Train: [ 27/600] Step 500/520 Loss 0.712 Prec@(1,5) (82.5%, 99.2%)\n",
            "[2023-01-12 17:33:24] \u001b[32mTrain: [ 27/600] Step 510/520 Loss 0.710 Prec@(1,5) (82.5%, 99.2%)\u001b[0m\n",
            "INFO:nni:Train: [ 27/600] Step 510/520 Loss 0.710 Prec@(1,5) (82.5%, 99.2%)\n",
            "[2023-01-12 17:33:28] \u001b[32mTrain: [ 27/600] Step 520/520 Loss 0.710 Prec@(1,5) (82.5%, 99.2%)\u001b[0m\n",
            "INFO:nni:Train: [ 27/600] Step 520/520 Loss 0.710 Prec@(1,5) (82.5%, 99.2%)\n",
            "[2023-01-12 17:33:29] \u001b[32mTrain: [ 27/600] Final Prec@1 82.5120%\u001b[0m\n",
            "INFO:nni:Train: [ 27/600] Final Prec@1 82.5120%\n",
            "[2023-01-12 17:33:29] \u001b[32mValid: [ 27/600] Step 000/104 Loss 0.494 Prec@(1,5) (80.2%, 97.9%)\u001b[0m\n",
            "INFO:nni:Valid: [ 27/600] Step 000/104 Loss 0.494 Prec@(1,5) (80.2%, 97.9%)\n",
            "[2023-01-12 17:33:30] \u001b[32mValid: [ 27/600] Step 010/104 Loss 0.420 Prec@(1,5) (85.3%, 99.5%)\u001b[0m\n",
            "INFO:nni:Valid: [ 27/600] Step 010/104 Loss 0.420 Prec@(1,5) (85.3%, 99.5%)\n",
            "[2023-01-12 17:33:32] \u001b[32mValid: [ 27/600] Step 020/104 Loss 0.450 Prec@(1,5) (84.7%, 99.4%)\u001b[0m\n",
            "INFO:nni:Valid: [ 27/600] Step 020/104 Loss 0.450 Prec@(1,5) (84.7%, 99.4%)\n",
            "[2023-01-12 17:33:33] \u001b[32mValid: [ 27/600] Step 030/104 Loss 0.462 Prec@(1,5) (84.5%, 99.3%)\u001b[0m\n",
            "INFO:nni:Valid: [ 27/600] Step 030/104 Loss 0.462 Prec@(1,5) (84.5%, 99.3%)\n",
            "[2023-01-12 17:33:35] \u001b[32mValid: [ 27/600] Step 040/104 Loss 0.455 Prec@(1,5) (85.1%, 99.3%)\u001b[0m\n",
            "INFO:nni:Valid: [ 27/600] Step 040/104 Loss 0.455 Prec@(1,5) (85.1%, 99.3%)\n",
            "[2023-01-12 17:33:36] \u001b[32mValid: [ 27/600] Step 050/104 Loss 0.454 Prec@(1,5) (85.3%, 99.2%)\u001b[0m\n",
            "INFO:nni:Valid: [ 27/600] Step 050/104 Loss 0.454 Prec@(1,5) (85.3%, 99.2%)\n",
            "[2023-01-12 17:33:37] \u001b[32mValid: [ 27/600] Step 060/104 Loss 0.458 Prec@(1,5) (85.0%, 99.2%)\u001b[0m\n",
            "INFO:nni:Valid: [ 27/600] Step 060/104 Loss 0.458 Prec@(1,5) (85.0%, 99.2%)\n",
            "[2023-01-12 17:33:39] \u001b[32mValid: [ 27/600] Step 070/104 Loss 0.461 Prec@(1,5) (85.0%, 99.2%)\u001b[0m\n",
            "INFO:nni:Valid: [ 27/600] Step 070/104 Loss 0.461 Prec@(1,5) (85.0%, 99.2%)\n",
            "[2023-01-12 17:33:40] \u001b[32mValid: [ 27/600] Step 080/104 Loss 0.462 Prec@(1,5) (84.7%, 99.3%)\u001b[0m\n",
            "INFO:nni:Valid: [ 27/600] Step 080/104 Loss 0.462 Prec@(1,5) (84.7%, 99.3%)\n",
            "[2023-01-12 17:33:42] \u001b[32mValid: [ 27/600] Step 090/104 Loss 0.463 Prec@(1,5) (84.6%, 99.3%)\u001b[0m\n",
            "INFO:nni:Valid: [ 27/600] Step 090/104 Loss 0.463 Prec@(1,5) (84.6%, 99.3%)\n",
            "[2023-01-12 17:33:43] \u001b[32mValid: [ 27/600] Step 100/104 Loss 0.459 Prec@(1,5) (84.7%, 99.3%)\u001b[0m\n",
            "INFO:nni:Valid: [ 27/600] Step 100/104 Loss 0.459 Prec@(1,5) (84.7%, 99.3%)\n",
            "[2023-01-12 17:33:44] \u001b[32mValid: [ 27/600] Step 104/104 Loss 0.459 Prec@(1,5) (84.7%, 99.3%)\u001b[0m\n",
            "INFO:nni:Valid: [ 27/600] Step 104/104 Loss 0.459 Prec@(1,5) (84.7%, 99.3%)\n",
            "[2023-01-12 17:33:44] \u001b[32mValid: [ 27/600] Final Prec@1 84.6600%\u001b[0m\n",
            "INFO:nni:Valid: [ 27/600] Final Prec@1 84.6600%\n",
            "[2023-01-12 17:33:44] \u001b[32mEpoch 27 LR 0.024875\u001b[0m\n",
            "INFO:nni:Epoch 27 LR 0.024875\n",
            "[2023-01-12 17:33:45] \u001b[32mTrain: [ 28/600] Step 000/520 Loss 0.792 Prec@(1,5) (82.3%, 99.0%)\u001b[0m\n",
            "INFO:nni:Train: [ 28/600] Step 000/520 Loss 0.792 Prec@(1,5) (82.3%, 99.0%)\n",
            "[2023-01-12 17:33:49] \u001b[32mTrain: [ 28/600] Step 010/520 Loss 0.723 Prec@(1,5) (83.0%, 99.6%)\u001b[0m\n",
            "INFO:nni:Train: [ 28/600] Step 010/520 Loss 0.723 Prec@(1,5) (83.0%, 99.6%)\n",
            "[2023-01-12 17:33:54] \u001b[32mTrain: [ 28/600] Step 020/520 Loss 0.686 Prec@(1,5) (84.5%, 99.4%)\u001b[0m\n",
            "INFO:nni:Train: [ 28/600] Step 020/520 Loss 0.686 Prec@(1,5) (84.5%, 99.4%)\n",
            "[2023-01-12 17:33:58] \u001b[32mTrain: [ 28/600] Step 030/520 Loss 0.678 Prec@(1,5) (84.0%, 99.3%)\u001b[0m\n",
            "INFO:nni:Train: [ 28/600] Step 030/520 Loss 0.678 Prec@(1,5) (84.0%, 99.3%)\n",
            "[2023-01-12 17:34:03] \u001b[32mTrain: [ 28/600] Step 040/520 Loss 0.669 Prec@(1,5) (84.2%, 99.3%)\u001b[0m\n",
            "INFO:nni:Train: [ 28/600] Step 040/520 Loss 0.669 Prec@(1,5) (84.2%, 99.3%)\n",
            "[2023-01-12 17:34:07] \u001b[32mTrain: [ 28/600] Step 050/520 Loss 0.667 Prec@(1,5) (84.1%, 99.3%)\u001b[0m\n",
            "INFO:nni:Train: [ 28/600] Step 050/520 Loss 0.667 Prec@(1,5) (84.1%, 99.3%)\n",
            "[2023-01-12 17:34:12] \u001b[32mTrain: [ 28/600] Step 060/520 Loss 0.678 Prec@(1,5) (83.8%, 99.2%)\u001b[0m\n",
            "INFO:nni:Train: [ 28/600] Step 060/520 Loss 0.678 Prec@(1,5) (83.8%, 99.2%)\n",
            "[2023-01-12 17:34:16] \u001b[32mTrain: [ 28/600] Step 070/520 Loss 0.681 Prec@(1,5) (83.6%, 99.3%)\u001b[0m\n",
            "INFO:nni:Train: [ 28/600] Step 070/520 Loss 0.681 Prec@(1,5) (83.6%, 99.3%)\n",
            "[2023-01-12 17:34:21] \u001b[32mTrain: [ 28/600] Step 080/520 Loss 0.682 Prec@(1,5) (83.7%, 99.3%)\u001b[0m\n",
            "INFO:nni:Train: [ 28/600] Step 080/520 Loss 0.682 Prec@(1,5) (83.7%, 99.3%)\n",
            "[2023-01-12 17:34:25] \u001b[32mTrain: [ 28/600] Step 090/520 Loss 0.681 Prec@(1,5) (83.7%, 99.3%)\u001b[0m\n",
            "INFO:nni:Train: [ 28/600] Step 090/520 Loss 0.681 Prec@(1,5) (83.7%, 99.3%)\n",
            "[2023-01-12 17:34:30] \u001b[32mTrain: [ 28/600] Step 100/520 Loss 0.680 Prec@(1,5) (83.6%, 99.3%)\u001b[0m\n",
            "INFO:nni:Train: [ 28/600] Step 100/520 Loss 0.680 Prec@(1,5) (83.6%, 99.3%)\n",
            "[2023-01-12 17:34:34] \u001b[32mTrain: [ 28/600] Step 110/520 Loss 0.688 Prec@(1,5) (83.5%, 99.3%)\u001b[0m\n",
            "INFO:nni:Train: [ 28/600] Step 110/520 Loss 0.688 Prec@(1,5) (83.5%, 99.3%)\n",
            "[2023-01-12 17:34:39] \u001b[32mTrain: [ 28/600] Step 120/520 Loss 0.698 Prec@(1,5) (83.3%, 99.3%)\u001b[0m\n",
            "INFO:nni:Train: [ 28/600] Step 120/520 Loss 0.698 Prec@(1,5) (83.3%, 99.3%)\n",
            "[2023-01-12 17:34:43] \u001b[32mTrain: [ 28/600] Step 130/520 Loss 0.701 Prec@(1,5) (83.3%, 99.3%)\u001b[0m\n",
            "INFO:nni:Train: [ 28/600] Step 130/520 Loss 0.701 Prec@(1,5) (83.3%, 99.3%)\n",
            "[2023-01-12 17:34:48] \u001b[32mTrain: [ 28/600] Step 140/520 Loss 0.700 Prec@(1,5) (83.3%, 99.2%)\u001b[0m\n",
            "INFO:nni:Train: [ 28/600] Step 140/520 Loss 0.700 Prec@(1,5) (83.3%, 99.2%)\n",
            "[2023-01-12 17:34:52] \u001b[32mTrain: [ 28/600] Step 150/520 Loss 0.697 Prec@(1,5) (83.4%, 99.2%)\u001b[0m\n",
            "INFO:nni:Train: [ 28/600] Step 150/520 Loss 0.697 Prec@(1,5) (83.4%, 99.2%)\n",
            "[2023-01-12 17:34:57] \u001b[32mTrain: [ 28/600] Step 160/520 Loss 0.698 Prec@(1,5) (83.3%, 99.2%)\u001b[0m\n",
            "INFO:nni:Train: [ 28/600] Step 160/520 Loss 0.698 Prec@(1,5) (83.3%, 99.2%)\n",
            "[2023-01-12 17:35:01] \u001b[32mTrain: [ 28/600] Step 170/520 Loss 0.698 Prec@(1,5) (83.2%, 99.2%)\u001b[0m\n",
            "INFO:nni:Train: [ 28/600] Step 170/520 Loss 0.698 Prec@(1,5) (83.2%, 99.2%)\n",
            "[2023-01-12 17:35:06] \u001b[32mTrain: [ 28/600] Step 180/520 Loss 0.699 Prec@(1,5) (83.2%, 99.2%)\u001b[0m\n",
            "INFO:nni:Train: [ 28/600] Step 180/520 Loss 0.699 Prec@(1,5) (83.2%, 99.2%)\n",
            "[2023-01-12 17:35:10] \u001b[32mTrain: [ 28/600] Step 190/520 Loss 0.701 Prec@(1,5) (83.1%, 99.2%)\u001b[0m\n",
            "INFO:nni:Train: [ 28/600] Step 190/520 Loss 0.701 Prec@(1,5) (83.1%, 99.2%)\n",
            "[2023-01-12 17:35:15] \u001b[32mTrain: [ 28/600] Step 200/520 Loss 0.706 Prec@(1,5) (83.0%, 99.2%)\u001b[0m\n",
            "INFO:nni:Train: [ 28/600] Step 200/520 Loss 0.706 Prec@(1,5) (83.0%, 99.2%)\n",
            "[2023-01-12 17:35:19] \u001b[32mTrain: [ 28/600] Step 210/520 Loss 0.709 Prec@(1,5) (82.9%, 99.2%)\u001b[0m\n",
            "INFO:nni:Train: [ 28/600] Step 210/520 Loss 0.709 Prec@(1,5) (82.9%, 99.2%)\n",
            "[2023-01-12 17:35:24] \u001b[32mTrain: [ 28/600] Step 220/520 Loss 0.706 Prec@(1,5) (82.9%, 99.2%)\u001b[0m\n",
            "INFO:nni:Train: [ 28/600] Step 220/520 Loss 0.706 Prec@(1,5) (82.9%, 99.2%)\n",
            "[2023-01-12 17:35:28] \u001b[32mTrain: [ 28/600] Step 230/520 Loss 0.706 Prec@(1,5) (82.9%, 99.2%)\u001b[0m\n",
            "INFO:nni:Train: [ 28/600] Step 230/520 Loss 0.706 Prec@(1,5) (82.9%, 99.2%)\n",
            "[2023-01-12 17:35:33] \u001b[32mTrain: [ 28/600] Step 240/520 Loss 0.703 Prec@(1,5) (82.9%, 99.2%)\u001b[0m\n",
            "INFO:nni:Train: [ 28/600] Step 240/520 Loss 0.703 Prec@(1,5) (82.9%, 99.2%)\n",
            "[2023-01-12 17:35:37] \u001b[32mTrain: [ 28/600] Step 250/520 Loss 0.702 Prec@(1,5) (82.9%, 99.2%)\u001b[0m\n",
            "INFO:nni:Train: [ 28/600] Step 250/520 Loss 0.702 Prec@(1,5) (82.9%, 99.2%)\n",
            "[2023-01-12 17:35:42] \u001b[32mTrain: [ 28/600] Step 260/520 Loss 0.703 Prec@(1,5) (82.9%, 99.2%)\u001b[0m\n",
            "INFO:nni:Train: [ 28/600] Step 260/520 Loss 0.703 Prec@(1,5) (82.9%, 99.2%)\n",
            "[2023-01-12 17:35:47] \u001b[32mTrain: [ 28/600] Step 270/520 Loss 0.702 Prec@(1,5) (83.0%, 99.2%)\u001b[0m\n",
            "INFO:nni:Train: [ 28/600] Step 270/520 Loss 0.702 Prec@(1,5) (83.0%, 99.2%)\n",
            "[2023-01-12 17:35:51] \u001b[32mTrain: [ 28/600] Step 280/520 Loss 0.701 Prec@(1,5) (83.0%, 99.2%)\u001b[0m\n",
            "INFO:nni:Train: [ 28/600] Step 280/520 Loss 0.701 Prec@(1,5) (83.0%, 99.2%)\n",
            "[2023-01-12 17:35:56] \u001b[32mTrain: [ 28/600] Step 290/520 Loss 0.701 Prec@(1,5) (82.9%, 99.2%)\u001b[0m\n",
            "INFO:nni:Train: [ 28/600] Step 290/520 Loss 0.701 Prec@(1,5) (82.9%, 99.2%)\n",
            "[2023-01-12 17:36:00] \u001b[32mTrain: [ 28/600] Step 300/520 Loss 0.699 Prec@(1,5) (83.0%, 99.2%)\u001b[0m\n",
            "INFO:nni:Train: [ 28/600] Step 300/520 Loss 0.699 Prec@(1,5) (83.0%, 99.2%)\n",
            "[2023-01-12 17:36:05] \u001b[32mTrain: [ 28/600] Step 310/520 Loss 0.701 Prec@(1,5) (82.9%, 99.2%)\u001b[0m\n",
            "INFO:nni:Train: [ 28/600] Step 310/520 Loss 0.701 Prec@(1,5) (82.9%, 99.2%)\n",
            "[2023-01-12 17:36:09] \u001b[32mTrain: [ 28/600] Step 320/520 Loss 0.700 Prec@(1,5) (82.9%, 99.2%)\u001b[0m\n",
            "INFO:nni:Train: [ 28/600] Step 320/520 Loss 0.700 Prec@(1,5) (82.9%, 99.2%)\n",
            "[2023-01-12 17:36:14] \u001b[32mTrain: [ 28/600] Step 330/520 Loss 0.700 Prec@(1,5) (82.9%, 99.2%)\u001b[0m\n",
            "INFO:nni:Train: [ 28/600] Step 330/520 Loss 0.700 Prec@(1,5) (82.9%, 99.2%)\n",
            "[2023-01-12 17:36:18] \u001b[32mTrain: [ 28/600] Step 340/520 Loss 0.703 Prec@(1,5) (82.8%, 99.2%)\u001b[0m\n",
            "INFO:nni:Train: [ 28/600] Step 340/520 Loss 0.703 Prec@(1,5) (82.8%, 99.2%)\n",
            "[2023-01-12 17:36:23] \u001b[32mTrain: [ 28/600] Step 350/520 Loss 0.704 Prec@(1,5) (82.8%, 99.2%)\u001b[0m\n",
            "INFO:nni:Train: [ 28/600] Step 350/520 Loss 0.704 Prec@(1,5) (82.8%, 99.2%)\n",
            "[2023-01-12 17:36:27] \u001b[32mTrain: [ 28/600] Step 360/520 Loss 0.703 Prec@(1,5) (82.8%, 99.2%)\u001b[0m\n",
            "INFO:nni:Train: [ 28/600] Step 360/520 Loss 0.703 Prec@(1,5) (82.8%, 99.2%)\n",
            "[2023-01-12 17:36:32] \u001b[32mTrain: [ 28/600] Step 370/520 Loss 0.705 Prec@(1,5) (82.8%, 99.2%)\u001b[0m\n",
            "INFO:nni:Train: [ 28/600] Step 370/520 Loss 0.705 Prec@(1,5) (82.8%, 99.2%)\n",
            "[2023-01-12 17:36:36] \u001b[32mTrain: [ 28/600] Step 380/520 Loss 0.705 Prec@(1,5) (82.8%, 99.2%)\u001b[0m\n",
            "INFO:nni:Train: [ 28/600] Step 380/520 Loss 0.705 Prec@(1,5) (82.8%, 99.2%)\n",
            "[2023-01-12 17:36:41] \u001b[32mTrain: [ 28/600] Step 390/520 Loss 0.705 Prec@(1,5) (82.8%, 99.2%)\u001b[0m\n",
            "INFO:nni:Train: [ 28/600] Step 390/520 Loss 0.705 Prec@(1,5) (82.8%, 99.2%)\n",
            "[2023-01-12 17:36:45] \u001b[32mTrain: [ 28/600] Step 400/520 Loss 0.706 Prec@(1,5) (82.7%, 99.2%)\u001b[0m\n",
            "INFO:nni:Train: [ 28/600] Step 400/520 Loss 0.706 Prec@(1,5) (82.7%, 99.2%)\n",
            "[2023-01-12 17:36:50] \u001b[32mTrain: [ 28/600] Step 410/520 Loss 0.707 Prec@(1,5) (82.7%, 99.2%)\u001b[0m\n",
            "INFO:nni:Train: [ 28/600] Step 410/520 Loss 0.707 Prec@(1,5) (82.7%, 99.2%)\n",
            "[2023-01-12 17:36:54] \u001b[32mTrain: [ 28/600] Step 420/520 Loss 0.707 Prec@(1,5) (82.7%, 99.2%)\u001b[0m\n",
            "INFO:nni:Train: [ 28/600] Step 420/520 Loss 0.707 Prec@(1,5) (82.7%, 99.2%)\n",
            "[2023-01-12 17:36:59] \u001b[32mTrain: [ 28/600] Step 430/520 Loss 0.707 Prec@(1,5) (82.6%, 99.2%)\u001b[0m\n",
            "INFO:nni:Train: [ 28/600] Step 430/520 Loss 0.707 Prec@(1,5) (82.6%, 99.2%)\n",
            "[2023-01-12 17:37:03] \u001b[32mTrain: [ 28/600] Step 440/520 Loss 0.706 Prec@(1,5) (82.7%, 99.2%)\u001b[0m\n",
            "INFO:nni:Train: [ 28/600] Step 440/520 Loss 0.706 Prec@(1,5) (82.7%, 99.2%)\n",
            "[2023-01-12 17:37:08] \u001b[32mTrain: [ 28/600] Step 450/520 Loss 0.706 Prec@(1,5) (82.7%, 99.2%)\u001b[0m\n",
            "INFO:nni:Train: [ 28/600] Step 450/520 Loss 0.706 Prec@(1,5) (82.7%, 99.2%)\n",
            "[2023-01-12 17:37:12] \u001b[32mTrain: [ 28/600] Step 460/520 Loss 0.706 Prec@(1,5) (82.7%, 99.2%)\u001b[0m\n",
            "INFO:nni:Train: [ 28/600] Step 460/520 Loss 0.706 Prec@(1,5) (82.7%, 99.2%)\n",
            "[2023-01-12 17:37:17] \u001b[32mTrain: [ 28/600] Step 470/520 Loss 0.707 Prec@(1,5) (82.7%, 99.2%)\u001b[0m\n",
            "INFO:nni:Train: [ 28/600] Step 470/520 Loss 0.707 Prec@(1,5) (82.7%, 99.2%)\n",
            "[2023-01-12 17:37:21] \u001b[32mTrain: [ 28/600] Step 480/520 Loss 0.706 Prec@(1,5) (82.7%, 99.2%)\u001b[0m\n",
            "INFO:nni:Train: [ 28/600] Step 480/520 Loss 0.706 Prec@(1,5) (82.7%, 99.2%)\n",
            "[2023-01-12 17:37:26] \u001b[32mTrain: [ 28/600] Step 490/520 Loss 0.708 Prec@(1,5) (82.7%, 99.2%)\u001b[0m\n",
            "INFO:nni:Train: [ 28/600] Step 490/520 Loss 0.708 Prec@(1,5) (82.7%, 99.2%)\n",
            "[2023-01-12 17:37:30] \u001b[32mTrain: [ 28/600] Step 500/520 Loss 0.709 Prec@(1,5) (82.6%, 99.2%)\u001b[0m\n",
            "INFO:nni:Train: [ 28/600] Step 500/520 Loss 0.709 Prec@(1,5) (82.6%, 99.2%)\n",
            "[2023-01-12 17:37:35] \u001b[32mTrain: [ 28/600] Step 510/520 Loss 0.709 Prec@(1,5) (82.6%, 99.2%)\u001b[0m\n",
            "INFO:nni:Train: [ 28/600] Step 510/520 Loss 0.709 Prec@(1,5) (82.6%, 99.2%)\n",
            "[2023-01-12 17:37:39] \u001b[32mTrain: [ 28/600] Step 520/520 Loss 0.709 Prec@(1,5) (82.6%, 99.2%)\u001b[0m\n",
            "INFO:nni:Train: [ 28/600] Step 520/520 Loss 0.709 Prec@(1,5) (82.6%, 99.2%)\n",
            "[2023-01-12 17:37:39] \u001b[32mTrain: [ 28/600] Final Prec@1 82.6160%\u001b[0m\n",
            "INFO:nni:Train: [ 28/600] Final Prec@1 82.6160%\n",
            "[2023-01-12 17:37:40] \u001b[32mValid: [ 28/600] Step 000/104 Loss 0.434 Prec@(1,5) (86.5%, 99.0%)\u001b[0m\n",
            "INFO:nni:Valid: [ 28/600] Step 000/104 Loss 0.434 Prec@(1,5) (86.5%, 99.0%)\n",
            "[2023-01-12 17:37:41] \u001b[32mValid: [ 28/600] Step 010/104 Loss 0.379 Prec@(1,5) (86.8%, 99.4%)\u001b[0m\n",
            "INFO:nni:Valid: [ 28/600] Step 010/104 Loss 0.379 Prec@(1,5) (86.8%, 99.4%)\n",
            "[2023-01-12 17:37:43] \u001b[32mValid: [ 28/600] Step 020/104 Loss 0.393 Prec@(1,5) (86.5%, 99.3%)\u001b[0m\n",
            "INFO:nni:Valid: [ 28/600] Step 020/104 Loss 0.393 Prec@(1,5) (86.5%, 99.3%)\n",
            "[2023-01-12 17:37:44] \u001b[32mValid: [ 28/600] Step 030/104 Loss 0.404 Prec@(1,5) (86.1%, 99.4%)\u001b[0m\n",
            "INFO:nni:Valid: [ 28/600] Step 030/104 Loss 0.404 Prec@(1,5) (86.1%, 99.4%)\n",
            "[2023-01-12 17:37:46] \u001b[32mValid: [ 28/600] Step 040/104 Loss 0.404 Prec@(1,5) (86.2%, 99.3%)\u001b[0m\n",
            "INFO:nni:Valid: [ 28/600] Step 040/104 Loss 0.404 Prec@(1,5) (86.2%, 99.3%)\n",
            "[2023-01-12 17:37:47] \u001b[32mValid: [ 28/600] Step 050/104 Loss 0.406 Prec@(1,5) (86.3%, 99.4%)\u001b[0m\n",
            "INFO:nni:Valid: [ 28/600] Step 050/104 Loss 0.406 Prec@(1,5) (86.3%, 99.4%)\n",
            "[2023-01-12 17:37:48] \u001b[32mValid: [ 28/600] Step 060/104 Loss 0.405 Prec@(1,5) (86.3%, 99.4%)\u001b[0m\n",
            "INFO:nni:Valid: [ 28/600] Step 060/104 Loss 0.405 Prec@(1,5) (86.3%, 99.4%)\n",
            "[2023-01-12 17:37:50] \u001b[32mValid: [ 28/600] Step 070/104 Loss 0.402 Prec@(1,5) (86.4%, 99.4%)\u001b[0m\n",
            "INFO:nni:Valid: [ 28/600] Step 070/104 Loss 0.402 Prec@(1,5) (86.4%, 99.4%)\n",
            "[2023-01-12 17:37:51] \u001b[32mValid: [ 28/600] Step 080/104 Loss 0.407 Prec@(1,5) (86.2%, 99.5%)\u001b[0m\n",
            "INFO:nni:Valid: [ 28/600] Step 080/104 Loss 0.407 Prec@(1,5) (86.2%, 99.5%)\n",
            "[2023-01-12 17:37:53] \u001b[32mValid: [ 28/600] Step 090/104 Loss 0.409 Prec@(1,5) (86.1%, 99.5%)\u001b[0m\n",
            "INFO:nni:Valid: [ 28/600] Step 090/104 Loss 0.409 Prec@(1,5) (86.1%, 99.5%)\n",
            "[2023-01-12 17:37:54] \u001b[32mValid: [ 28/600] Step 100/104 Loss 0.407 Prec@(1,5) (86.3%, 99.5%)\u001b[0m\n",
            "INFO:nni:Valid: [ 28/600] Step 100/104 Loss 0.407 Prec@(1,5) (86.3%, 99.5%)\n",
            "[2023-01-12 17:37:54] \u001b[32mValid: [ 28/600] Step 104/104 Loss 0.408 Prec@(1,5) (86.3%, 99.5%)\u001b[0m\n",
            "INFO:nni:Valid: [ 28/600] Step 104/104 Loss 0.408 Prec@(1,5) (86.3%, 99.5%)\n",
            "[2023-01-12 17:37:55] \u001b[32mValid: [ 28/600] Final Prec@1 86.2500%\u001b[0m\n",
            "INFO:nni:Valid: [ 28/600] Final Prec@1 86.2500%\n",
            "[2023-01-12 17:37:55] \u001b[32mEpoch 28 LR 0.024866\u001b[0m\n",
            "INFO:nni:Epoch 28 LR 0.024866\n",
            "[2023-01-12 17:37:55] \u001b[32mTrain: [ 29/600] Step 000/520 Loss 0.701 Prec@(1,5) (80.2%, 99.0%)\u001b[0m\n",
            "INFO:nni:Train: [ 29/600] Step 000/520 Loss 0.701 Prec@(1,5) (80.2%, 99.0%)\n",
            "[2023-01-12 17:38:00] \u001b[32mTrain: [ 29/600] Step 010/520 Loss 0.699 Prec@(1,5) (82.3%, 99.0%)\u001b[0m\n",
            "INFO:nni:Train: [ 29/600] Step 010/520 Loss 0.699 Prec@(1,5) (82.3%, 99.0%)\n",
            "[2023-01-12 17:38:04] \u001b[32mTrain: [ 29/600] Step 020/520 Loss 0.696 Prec@(1,5) (82.0%, 99.2%)\u001b[0m\n",
            "INFO:nni:Train: [ 29/600] Step 020/520 Loss 0.696 Prec@(1,5) (82.0%, 99.2%)\n",
            "[2023-01-12 17:38:09] \u001b[32mTrain: [ 29/600] Step 030/520 Loss 0.690 Prec@(1,5) (82.3%, 99.2%)\u001b[0m\n",
            "INFO:nni:Train: [ 29/600] Step 030/520 Loss 0.690 Prec@(1,5) (82.3%, 99.2%)\n",
            "[2023-01-12 17:38:13] \u001b[32mTrain: [ 29/600] Step 040/520 Loss 0.707 Prec@(1,5) (82.1%, 99.1%)\u001b[0m\n",
            "INFO:nni:Train: [ 29/600] Step 040/520 Loss 0.707 Prec@(1,5) (82.1%, 99.1%)\n",
            "[2023-01-12 17:38:18] \u001b[32mTrain: [ 29/600] Step 050/520 Loss 0.701 Prec@(1,5) (82.1%, 99.1%)\u001b[0m\n",
            "INFO:nni:Train: [ 29/600] Step 050/520 Loss 0.701 Prec@(1,5) (82.1%, 99.1%)\n",
            "[2023-01-12 17:38:22] \u001b[32mTrain: [ 29/600] Step 060/520 Loss 0.698 Prec@(1,5) (82.2%, 99.2%)\u001b[0m\n",
            "INFO:nni:Train: [ 29/600] Step 060/520 Loss 0.698 Prec@(1,5) (82.2%, 99.2%)\n",
            "[2023-01-12 17:38:27] \u001b[32mTrain: [ 29/600] Step 070/520 Loss 0.703 Prec@(1,5) (82.1%, 99.3%)\u001b[0m\n",
            "INFO:nni:Train: [ 29/600] Step 070/520 Loss 0.703 Prec@(1,5) (82.1%, 99.3%)\n",
            "[2023-01-12 17:38:31] \u001b[32mTrain: [ 29/600] Step 080/520 Loss 0.708 Prec@(1,5) (82.0%, 99.2%)\u001b[0m\n",
            "INFO:nni:Train: [ 29/600] Step 080/520 Loss 0.708 Prec@(1,5) (82.0%, 99.2%)\n",
            "[2023-01-12 17:38:36] \u001b[32mTrain: [ 29/600] Step 090/520 Loss 0.705 Prec@(1,5) (82.2%, 99.2%)\u001b[0m\n",
            "INFO:nni:Train: [ 29/600] Step 090/520 Loss 0.705 Prec@(1,5) (82.2%, 99.2%)\n",
            "[2023-01-12 17:38:41] \u001b[32mTrain: [ 29/600] Step 100/520 Loss 0.704 Prec@(1,5) (82.3%, 99.2%)\u001b[0m\n",
            "INFO:nni:Train: [ 29/600] Step 100/520 Loss 0.704 Prec@(1,5) (82.3%, 99.2%)\n",
            "[2023-01-12 17:38:45] \u001b[32mTrain: [ 29/600] Step 110/520 Loss 0.702 Prec@(1,5) (82.4%, 99.2%)\u001b[0m\n",
            "INFO:nni:Train: [ 29/600] Step 110/520 Loss 0.702 Prec@(1,5) (82.4%, 99.2%)\n",
            "[2023-01-12 17:38:50] \u001b[32mTrain: [ 29/600] Step 120/520 Loss 0.707 Prec@(1,5) (82.3%, 99.2%)\u001b[0m\n",
            "INFO:nni:Train: [ 29/600] Step 120/520 Loss 0.707 Prec@(1,5) (82.3%, 99.2%)\n",
            "[2023-01-12 17:38:54] \u001b[32mTrain: [ 29/600] Step 130/520 Loss 0.706 Prec@(1,5) (82.4%, 99.2%)\u001b[0m\n",
            "INFO:nni:Train: [ 29/600] Step 130/520 Loss 0.706 Prec@(1,5) (82.4%, 99.2%)\n",
            "[2023-01-12 17:38:59] \u001b[32mTrain: [ 29/600] Step 140/520 Loss 0.705 Prec@(1,5) (82.5%, 99.2%)\u001b[0m\n",
            "INFO:nni:Train: [ 29/600] Step 140/520 Loss 0.705 Prec@(1,5) (82.5%, 99.2%)\n",
            "[2023-01-12 17:39:03] \u001b[32mTrain: [ 29/600] Step 150/520 Loss 0.697 Prec@(1,5) (82.7%, 99.2%)\u001b[0m\n",
            "INFO:nni:Train: [ 29/600] Step 150/520 Loss 0.697 Prec@(1,5) (82.7%, 99.2%)\n",
            "[2023-01-12 17:39:08] \u001b[32mTrain: [ 29/600] Step 160/520 Loss 0.697 Prec@(1,5) (82.7%, 99.2%)\u001b[0m\n",
            "INFO:nni:Train: [ 29/600] Step 160/520 Loss 0.697 Prec@(1,5) (82.7%, 99.2%)\n",
            "[2023-01-12 17:39:12] \u001b[32mTrain: [ 29/600] Step 170/520 Loss 0.700 Prec@(1,5) (82.6%, 99.2%)\u001b[0m\n",
            "INFO:nni:Train: [ 29/600] Step 170/520 Loss 0.700 Prec@(1,5) (82.6%, 99.2%)\n",
            "[2023-01-12 17:39:17] \u001b[32mTrain: [ 29/600] Step 180/520 Loss 0.701 Prec@(1,5) (82.6%, 99.2%)\u001b[0m\n",
            "INFO:nni:Train: [ 29/600] Step 180/520 Loss 0.701 Prec@(1,5) (82.6%, 99.2%)\n",
            "[2023-01-12 17:39:21] \u001b[32mTrain: [ 29/600] Step 190/520 Loss 0.706 Prec@(1,5) (82.6%, 99.2%)\u001b[0m\n",
            "INFO:nni:Train: [ 29/600] Step 190/520 Loss 0.706 Prec@(1,5) (82.6%, 99.2%)\n",
            "[2023-01-12 17:39:26] \u001b[32mTrain: [ 29/600] Step 200/520 Loss 0.708 Prec@(1,5) (82.6%, 99.2%)\u001b[0m\n",
            "INFO:nni:Train: [ 29/600] Step 200/520 Loss 0.708 Prec@(1,5) (82.6%, 99.2%)\n",
            "[2023-01-12 17:39:30] \u001b[32mTrain: [ 29/600] Step 210/520 Loss 0.708 Prec@(1,5) (82.6%, 99.2%)\u001b[0m\n",
            "INFO:nni:Train: [ 29/600] Step 210/520 Loss 0.708 Prec@(1,5) (82.6%, 99.2%)\n",
            "[2023-01-12 17:39:35] \u001b[32mTrain: [ 29/600] Step 220/520 Loss 0.707 Prec@(1,5) (82.6%, 99.2%)\u001b[0m\n",
            "INFO:nni:Train: [ 29/600] Step 220/520 Loss 0.707 Prec@(1,5) (82.6%, 99.2%)\n",
            "[2023-01-12 17:39:39] \u001b[32mTrain: [ 29/600] Step 230/520 Loss 0.711 Prec@(1,5) (82.6%, 99.2%)\u001b[0m\n",
            "INFO:nni:Train: [ 29/600] Step 230/520 Loss 0.711 Prec@(1,5) (82.6%, 99.2%)\n",
            "[2023-01-12 17:39:44] \u001b[32mTrain: [ 29/600] Step 240/520 Loss 0.712 Prec@(1,5) (82.6%, 99.2%)\u001b[0m\n",
            "INFO:nni:Train: [ 29/600] Step 240/520 Loss 0.712 Prec@(1,5) (82.6%, 99.2%)\n",
            "[2023-01-12 17:39:48] \u001b[32mTrain: [ 29/600] Step 250/520 Loss 0.712 Prec@(1,5) (82.5%, 99.2%)\u001b[0m\n",
            "INFO:nni:Train: [ 29/600] Step 250/520 Loss 0.712 Prec@(1,5) (82.5%, 99.2%)\n",
            "[2023-01-12 17:39:53] \u001b[32mTrain: [ 29/600] Step 260/520 Loss 0.712 Prec@(1,5) (82.5%, 99.2%)\u001b[0m\n",
            "INFO:nni:Train: [ 29/600] Step 260/520 Loss 0.712 Prec@(1,5) (82.5%, 99.2%)\n",
            "[2023-01-12 17:39:57] \u001b[32mTrain: [ 29/600] Step 270/520 Loss 0.714 Prec@(1,5) (82.5%, 99.2%)\u001b[0m\n",
            "INFO:nni:Train: [ 29/600] Step 270/520 Loss 0.714 Prec@(1,5) (82.5%, 99.2%)\n",
            "[2023-01-12 17:40:02] \u001b[32mTrain: [ 29/600] Step 280/520 Loss 0.716 Prec@(1,5) (82.4%, 99.2%)\u001b[0m\n",
            "INFO:nni:Train: [ 29/600] Step 280/520 Loss 0.716 Prec@(1,5) (82.4%, 99.2%)\n",
            "[2023-01-12 17:40:06] \u001b[32mTrain: [ 29/600] Step 290/520 Loss 0.719 Prec@(1,5) (82.4%, 99.2%)\u001b[0m\n",
            "INFO:nni:Train: [ 29/600] Step 290/520 Loss 0.719 Prec@(1,5) (82.4%, 99.2%)\n",
            "[2023-01-12 17:40:11] \u001b[32mTrain: [ 29/600] Step 300/520 Loss 0.721 Prec@(1,5) (82.3%, 99.2%)\u001b[0m\n",
            "INFO:nni:Train: [ 29/600] Step 300/520 Loss 0.721 Prec@(1,5) (82.3%, 99.2%)\n",
            "[2023-01-12 17:40:15] \u001b[32mTrain: [ 29/600] Step 310/520 Loss 0.723 Prec@(1,5) (82.2%, 99.2%)\u001b[0m\n",
            "INFO:nni:Train: [ 29/600] Step 310/520 Loss 0.723 Prec@(1,5) (82.2%, 99.2%)\n",
            "[2023-01-12 17:40:20] \u001b[32mTrain: [ 29/600] Step 320/520 Loss 0.721 Prec@(1,5) (82.3%, 99.2%)\u001b[0m\n",
            "INFO:nni:Train: [ 29/600] Step 320/520 Loss 0.721 Prec@(1,5) (82.3%, 99.2%)\n",
            "[2023-01-12 17:40:24] \u001b[32mTrain: [ 29/600] Step 330/520 Loss 0.721 Prec@(1,5) (82.2%, 99.2%)\u001b[0m\n",
            "INFO:nni:Train: [ 29/600] Step 330/520 Loss 0.721 Prec@(1,5) (82.2%, 99.2%)\n",
            "[2023-01-12 17:40:29] \u001b[32mTrain: [ 29/600] Step 340/520 Loss 0.720 Prec@(1,5) (82.3%, 99.2%)\u001b[0m\n",
            "INFO:nni:Train: [ 29/600] Step 340/520 Loss 0.720 Prec@(1,5) (82.3%, 99.2%)\n",
            "[2023-01-12 17:40:33] \u001b[32mTrain: [ 29/600] Step 350/520 Loss 0.718 Prec@(1,5) (82.3%, 99.2%)\u001b[0m\n",
            "INFO:nni:Train: [ 29/600] Step 350/520 Loss 0.718 Prec@(1,5) (82.3%, 99.2%)\n",
            "[2023-01-12 17:40:38] \u001b[32mTrain: [ 29/600] Step 360/520 Loss 0.719 Prec@(1,5) (82.3%, 99.2%)\u001b[0m\n",
            "INFO:nni:Train: [ 29/600] Step 360/520 Loss 0.719 Prec@(1,5) (82.3%, 99.2%)\n",
            "[2023-01-12 17:40:42] \u001b[32mTrain: [ 29/600] Step 370/520 Loss 0.716 Prec@(1,5) (82.4%, 99.2%)\u001b[0m\n",
            "INFO:nni:Train: [ 29/600] Step 370/520 Loss 0.716 Prec@(1,5) (82.4%, 99.2%)\n",
            "[2023-01-12 17:40:47] \u001b[32mTrain: [ 29/600] Step 380/520 Loss 0.714 Prec@(1,5) (82.4%, 99.2%)\u001b[0m\n",
            "INFO:nni:Train: [ 29/600] Step 380/520 Loss 0.714 Prec@(1,5) (82.4%, 99.2%)\n",
            "[2023-01-12 17:40:51] \u001b[32mTrain: [ 29/600] Step 390/520 Loss 0.714 Prec@(1,5) (82.4%, 99.2%)\u001b[0m\n",
            "INFO:nni:Train: [ 29/600] Step 390/520 Loss 0.714 Prec@(1,5) (82.4%, 99.2%)\n",
            "[2023-01-12 17:40:56] \u001b[32mTrain: [ 29/600] Step 400/520 Loss 0.714 Prec@(1,5) (82.5%, 99.2%)\u001b[0m\n",
            "INFO:nni:Train: [ 29/600] Step 400/520 Loss 0.714 Prec@(1,5) (82.5%, 99.2%)\n"
          ]
        }
      ],
      "source": [
        "!python retrain.py --arc-checkpoint /content/nni/checkpoint.json"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n0z6CaPUVrBg",
        "outputId": "db98e067-4bf4-48ce-deaf-0c6d59ca777d"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/nni/nas/utils/misc.py:187: RuntimeWarning: ModelNamespace is missing. You might have forgotten to use `@model_wrapper`. Some features might not work. This will be an error in future releases.\n",
            "  warnings.warn('ModelNamespace is missing. You might have forgotten to use `@model_wrapper`. '\n"
          ]
        }
      ],
      "source": [
        "import torch.nn.functional as F\n",
        "import nni.retiarii.nn.pytorch as nn\n",
        "\n",
        "class Net(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        # self.conv1 = nn.Conv2d(3, 6, 3, padding=1)\n",
        "        self.conv1 = nn.LayerChoice([nn.Conv2d(3, 6, 3, padding=1), nn.Conv2d(3, 6, 5, padding=2)])\n",
        "        self.pool = nn.MaxPool2d(2, 2)\n",
        "        # self.conv2 = nn.Conv2d(6, 16, 3, padding=1)\n",
        "        self.conv2 = nn.LayerChoice([nn.Conv2d(6, 16, 3, padding=1), nn.Conv2d(6, 16, 5, padding=2)])\n",
        "        self.conv3 = nn.Conv2d(16, 16, 1)\n",
        "\n",
        "        self.skipconnect = nn.InputChoice(n_candidates=2)\n",
        "        self.bn = nn.BatchNorm2d(16)\n",
        "\n",
        "        self.gap = nn.AdaptiveAvgPool2d(4)\n",
        "        self.fc1 = nn.Linear(16 * 4 * 4, 120)\n",
        "        self.fc2 = nn.Linear(120, 84)\n",
        "        self.fc3 = nn.Linear(84, 10)\n",
        "\n",
        "    def forward(self, x):\n",
        "        bs = x.size(0)\n",
        "\n",
        "        x = self.pool(F.relu(self.conv1(x)))\n",
        "        x0 = F.relu(self.conv2(x))\n",
        "        x1 = F.relu(self.conv3(x0))\n",
        "\n",
        "        x1 = self.skipconnect([x1, x1+x0])\n",
        "        x = self.pool(self.bn(x1))\n",
        "\n",
        "        x = self.gap(x).view(bs, -1)\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = F.relu(self.fc2(x))\n",
        "        x = self.fc3(x)\n",
        "        return x\n",
        "    \n",
        "model = Net()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z-ahwiGTI_nW"
      },
      "source": [
        "### Execute DARTS training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yKew8jBsVxP_",
        "outputId": "c3bc3931-8218-431d-e2b0-0ab2369c2e04"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/torch/utils/data/dataloader.py:554: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[2023-01-12 14:33:25] \u001b[32mEpoch [1/1] Step [1/391]  acc1 0.093750 (0.093750)  loss 2.300292 (2.300292)\u001b[0m\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:nni.retiarii.oneshot.pytorch.darts:Epoch [1/1] Step [1/391]  acc1 0.093750 (0.093750)  loss 2.300292 (2.300292)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[2023-01-12 14:33:25] \u001b[32mEpoch [1/1] Step [11/391]  acc1 0.218750 (0.106534)  loss 2.261165 (2.296108)\u001b[0m\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:nni.retiarii.oneshot.pytorch.darts:Epoch [1/1] Step [11/391]  acc1 0.218750 (0.106534)  loss 2.261165 (2.296108)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[2023-01-12 14:33:26] \u001b[32mEpoch [1/1] Step [21/391]  acc1 0.125000 (0.096726)  loss 2.293734 (2.299968)\u001b[0m\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:nni.retiarii.oneshot.pytorch.darts:Epoch [1/1] Step [21/391]  acc1 0.125000 (0.096726)  loss 2.293734 (2.299968)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[2023-01-12 14:33:26] \u001b[32mEpoch [1/1] Step [31/391]  acc1 0.109375 (0.097278)  loss 2.277021 (2.297123)\u001b[0m\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:nni.retiarii.oneshot.pytorch.darts:Epoch [1/1] Step [31/391]  acc1 0.109375 (0.097278)  loss 2.277021 (2.297123)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[2023-01-12 14:33:27] \u001b[32mEpoch [1/1] Step [41/391]  acc1 0.187500 (0.099085)  loss 2.268831 (2.295760)\u001b[0m\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:nni.retiarii.oneshot.pytorch.darts:Epoch [1/1] Step [41/391]  acc1 0.187500 (0.099085)  loss 2.268831 (2.295760)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[2023-01-12 14:33:27] \u001b[32mEpoch [1/1] Step [51/391]  acc1 0.046875 (0.103554)  loss 2.312189 (2.294984)\u001b[0m\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:nni.retiarii.oneshot.pytorch.darts:Epoch [1/1] Step [51/391]  acc1 0.046875 (0.103554)  loss 2.312189 (2.294984)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[2023-01-12 14:33:27] \u001b[32mEpoch [1/1] Step [61/391]  acc1 0.109375 (0.105277)  loss 2.284162 (2.294082)\u001b[0m\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:nni.retiarii.oneshot.pytorch.darts:Epoch [1/1] Step [61/391]  acc1 0.109375 (0.105277)  loss 2.284162 (2.294082)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[2023-01-12 14:33:28] \u001b[32mEpoch [1/1] Step [71/391]  acc1 0.125000 (0.107835)  loss 2.300070 (2.292421)\u001b[0m\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:nni.retiarii.oneshot.pytorch.darts:Epoch [1/1] Step [71/391]  acc1 0.125000 (0.107835)  loss 2.300070 (2.292421)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[2023-01-12 14:33:28] \u001b[32mEpoch [1/1] Step [81/391]  acc1 0.125000 (0.111883)  loss 2.290054 (2.291152)\u001b[0m\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:nni.retiarii.oneshot.pytorch.darts:Epoch [1/1] Step [81/391]  acc1 0.125000 (0.111883)  loss 2.290054 (2.291152)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[2023-01-12 14:33:28] \u001b[32mEpoch [1/1] Step [91/391]  acc1 0.171875 (0.117273)  loss 2.269782 (2.288724)\u001b[0m\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:nni.retiarii.oneshot.pytorch.darts:Epoch [1/1] Step [91/391]  acc1 0.171875 (0.117273)  loss 2.269782 (2.288724)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[2023-01-12 14:33:29] \u001b[32mEpoch [1/1] Step [101/391]  acc1 0.171875 (0.121597)  loss 2.291203 (2.286670)\u001b[0m\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:nni.retiarii.oneshot.pytorch.darts:Epoch [1/1] Step [101/391]  acc1 0.171875 (0.121597)  loss 2.291203 (2.286670)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[2023-01-12 14:33:29] \u001b[32mEpoch [1/1] Step [111/391]  acc1 0.187500 (0.128660)  loss 2.256378 (2.284167)\u001b[0m\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:nni.retiarii.oneshot.pytorch.darts:Epoch [1/1] Step [111/391]  acc1 0.187500 (0.128660)  loss 2.256378 (2.284167)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[2023-01-12 14:33:29] \u001b[32mEpoch [1/1] Step [121/391]  acc1 0.218750 (0.134556)  loss 2.241804 (2.281406)\u001b[0m\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:nni.retiarii.oneshot.pytorch.darts:Epoch [1/1] Step [121/391]  acc1 0.218750 (0.134556)  loss 2.241804 (2.281406)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[2023-01-12 14:33:30] \u001b[32mEpoch [1/1] Step [131/391]  acc1 0.187500 (0.139432)  loss 2.236749 (2.279114)\u001b[0m\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:nni.retiarii.oneshot.pytorch.darts:Epoch [1/1] Step [131/391]  acc1 0.187500 (0.139432)  loss 2.236749 (2.279114)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[2023-01-12 14:33:30] \u001b[32mEpoch [1/1] Step [141/391]  acc1 0.187500 (0.141290)  loss 2.256590 (2.277198)\u001b[0m\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:nni.retiarii.oneshot.pytorch.darts:Epoch [1/1] Step [141/391]  acc1 0.187500 (0.141290)  loss 2.256590 (2.277198)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[2023-01-12 14:33:30] \u001b[32mEpoch [1/1] Step [151/391]  acc1 0.250000 (0.145695)  loss 2.195525 (2.274675)\u001b[0m\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:nni.retiarii.oneshot.pytorch.darts:Epoch [1/1] Step [151/391]  acc1 0.250000 (0.145695)  loss 2.195525 (2.274675)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[2023-01-12 14:33:31] \u001b[32mEpoch [1/1] Step [161/391]  acc1 0.250000 (0.151592)  loss 2.251632 (2.272688)\u001b[0m\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:nni.retiarii.oneshot.pytorch.darts:Epoch [1/1] Step [161/391]  acc1 0.250000 (0.151592)  loss 2.251632 (2.272688)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[2023-01-12 14:33:31] \u001b[32mEpoch [1/1] Step [171/391]  acc1 0.265625 (0.154879)  loss 2.203836 (2.270122)\u001b[0m\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:nni.retiarii.oneshot.pytorch.darts:Epoch [1/1] Step [171/391]  acc1 0.265625 (0.154879)  loss 2.203836 (2.270122)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[2023-01-12 14:33:31] \u001b[32mEpoch [1/1] Step [181/391]  acc1 0.250000 (0.157804)  loss 2.220061 (2.267156)\u001b[0m\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:nni.retiarii.oneshot.pytorch.darts:Epoch [1/1] Step [181/391]  acc1 0.250000 (0.157804)  loss 2.220061 (2.267156)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[2023-01-12 14:33:32] \u001b[32mEpoch [1/1] Step [191/391]  acc1 0.296875 (0.160586)  loss 2.175306 (2.264084)\u001b[0m\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:nni.retiarii.oneshot.pytorch.darts:Epoch [1/1] Step [191/391]  acc1 0.296875 (0.160586)  loss 2.175306 (2.264084)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[2023-01-12 14:33:32] \u001b[32mEpoch [1/1] Step [201/391]  acc1 0.234375 (0.163013)  loss 2.213983 (2.261188)\u001b[0m\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:nni.retiarii.oneshot.pytorch.darts:Epoch [1/1] Step [201/391]  acc1 0.234375 (0.163013)  loss 2.213983 (2.261188)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[2023-01-12 14:33:32] \u001b[32mEpoch [1/1] Step [211/391]  acc1 0.328125 (0.167654)  loss 2.190844 (2.257162)\u001b[0m\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:nni.retiarii.oneshot.pytorch.darts:Epoch [1/1] Step [211/391]  acc1 0.328125 (0.167654)  loss 2.190844 (2.257162)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[2023-01-12 14:33:33] \u001b[32mEpoch [1/1] Step [221/391]  acc1 0.171875 (0.171734)  loss 2.138616 (2.252832)\u001b[0m\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:nni.retiarii.oneshot.pytorch.darts:Epoch [1/1] Step [221/391]  acc1 0.171875 (0.171734)  loss 2.138616 (2.252832)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[2023-01-12 14:33:33] \u001b[32mEpoch [1/1] Step [231/391]  acc1 0.296875 (0.175663)  loss 2.130038 (2.249193)\u001b[0m\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:nni.retiarii.oneshot.pytorch.darts:Epoch [1/1] Step [231/391]  acc1 0.296875 (0.175663)  loss 2.130038 (2.249193)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[2023-01-12 14:33:34] \u001b[32mEpoch [1/1] Step [241/391]  acc1 0.265625 (0.178877)  loss 2.141471 (2.245171)\u001b[0m\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:nni.retiarii.oneshot.pytorch.darts:Epoch [1/1] Step [241/391]  acc1 0.265625 (0.178877)  loss 2.141471 (2.245171)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[2023-01-12 14:33:34] \u001b[32mEpoch [1/1] Step [251/391]  acc1 0.312500 (0.179968)  loss 2.123855 (2.242680)\u001b[0m\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:nni.retiarii.oneshot.pytorch.darts:Epoch [1/1] Step [251/391]  acc1 0.312500 (0.179968)  loss 2.123855 (2.242680)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[2023-01-12 14:33:34] \u001b[32mEpoch [1/1] Step [261/391]  acc1 0.250000 (0.182352)  loss 2.146102 (2.239180)\u001b[0m\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:nni.retiarii.oneshot.pytorch.darts:Epoch [1/1] Step [261/391]  acc1 0.250000 (0.182352)  loss 2.146102 (2.239180)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[2023-01-12 14:33:35] \u001b[32mEpoch [1/1] Step [271/391]  acc1 0.265625 (0.185136)  loss 2.164291 (2.235967)\u001b[0m\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:nni.retiarii.oneshot.pytorch.darts:Epoch [1/1] Step [271/391]  acc1 0.265625 (0.185136)  loss 2.164291 (2.235967)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[2023-01-12 14:33:35] \u001b[32mEpoch [1/1] Step [281/391]  acc1 0.234375 (0.187166)  loss 2.204459 (2.233358)\u001b[0m\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:nni.retiarii.oneshot.pytorch.darts:Epoch [1/1] Step [281/391]  acc1 0.234375 (0.187166)  loss 2.204459 (2.233358)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[2023-01-12 14:33:35] \u001b[32mEpoch [1/1] Step [291/391]  acc1 0.140625 (0.188735)  loss 2.204061 (2.229717)\u001b[0m\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:nni.retiarii.oneshot.pytorch.darts:Epoch [1/1] Step [291/391]  acc1 0.140625 (0.188735)  loss 2.204061 (2.229717)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[2023-01-12 14:33:36] \u001b[32mEpoch [1/1] Step [301/391]  acc1 0.312500 (0.191445)  loss 2.140967 (2.226083)\u001b[0m\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:nni.retiarii.oneshot.pytorch.darts:Epoch [1/1] Step [301/391]  acc1 0.312500 (0.191445)  loss 2.140967 (2.226083)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[2023-01-12 14:33:36] \u001b[32mEpoch [1/1] Step [311/391]  acc1 0.265625 (0.193227)  loss 2.084285 (2.222638)\u001b[0m\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:nni.retiarii.oneshot.pytorch.darts:Epoch [1/1] Step [311/391]  acc1 0.265625 (0.193227)  loss 2.084285 (2.222638)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[2023-01-12 14:33:36] \u001b[32mEpoch [1/1] Step [321/391]  acc1 0.203125 (0.195872)  loss 2.089456 (2.218882)\u001b[0m\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:nni.retiarii.oneshot.pytorch.darts:Epoch [1/1] Step [321/391]  acc1 0.203125 (0.195872)  loss 2.089456 (2.218882)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[2023-01-12 14:33:37] \u001b[32mEpoch [1/1] Step [331/391]  acc1 0.187500 (0.198546)  loss 2.269580 (2.215412)\u001b[0m\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:nni.retiarii.oneshot.pytorch.darts:Epoch [1/1] Step [331/391]  acc1 0.187500 (0.198546)  loss 2.269580 (2.215412)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[2023-01-12 14:33:37] \u001b[32mEpoch [1/1] Step [341/391]  acc1 0.156250 (0.199734)  loss 2.154833 (2.211977)\u001b[0m\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:nni.retiarii.oneshot.pytorch.darts:Epoch [1/1] Step [341/391]  acc1 0.156250 (0.199734)  loss 2.154833 (2.211977)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[2023-01-12 14:33:37] \u001b[32mEpoch [1/1] Step [351/391]  acc1 0.250000 (0.201344)  loss 2.155359 (2.208629)\u001b[0m\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:nni.retiarii.oneshot.pytorch.darts:Epoch [1/1] Step [351/391]  acc1 0.250000 (0.201344)  loss 2.155359 (2.208629)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[2023-01-12 14:33:38] \u001b[32mEpoch [1/1] Step [361/391]  acc1 0.171875 (0.202173)  loss 2.137960 (2.205959)\u001b[0m\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:nni.retiarii.oneshot.pytorch.darts:Epoch [1/1] Step [361/391]  acc1 0.171875 (0.202173)  loss 2.137960 (2.205959)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[2023-01-12 14:33:38] \u001b[32mEpoch [1/1] Step [371/391]  acc1 0.250000 (0.202999)  loss 2.092559 (2.202624)\u001b[0m\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:nni.retiarii.oneshot.pytorch.darts:Epoch [1/1] Step [371/391]  acc1 0.250000 (0.202999)  loss 2.092559 (2.202624)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[2023-01-12 14:33:38] \u001b[32mEpoch [1/1] Step [381/391]  acc1 0.296875 (0.205052)  loss 2.097000 (2.198930)\u001b[0m\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:nni.retiarii.oneshot.pytorch.darts:Epoch [1/1] Step [381/391]  acc1 0.296875 (0.205052)  loss 2.097000 (2.198930)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[2023-01-12 14:33:39] \u001b[32mEpoch [1/1] Step [391/391]  acc1 0.200000 (0.207153)  loss 2.082639 (2.195785)\u001b[0m\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:nni.retiarii.oneshot.pytorch.darts:Epoch [1/1] Step [391/391]  acc1 0.200000 (0.207153)  loss 2.082639 (2.195785)\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "\n",
        "from nni.retiarii.oneshot.pytorch import DartsTrainer\n",
        "\n",
        "def accuracy(output, target):\n",
        "    batch_size = target.size(0)\n",
        "    _, predicted = torch.max(output.data, 1)\n",
        "    return {\"acc1\": (predicted == target).sum().item() / batch_size}\n",
        "\n",
        "criterion = torch.nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=0.001, momentum=0.9)\n",
        "\n",
        "trainer = DartsTrainer(\n",
        "    model=model,\n",
        "    loss=criterion,\n",
        "    metrics=lambda output, target: accuracy(output, target),\n",
        "    optimizer=optimizer,\n",
        "    num_epochs=1,\n",
        "    dataset=train_dataset,\n",
        "    batch_size=64,\n",
        "    log_frequency=10\n",
        "    )\n",
        "trainer.fit()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qsnwf-LedjLK",
        "outputId": "670a385e-e845-4078-b546-00904e1a1bd3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/content/nni\n"
          ]
        }
      ],
      "source": [
        "%cd /content/nni"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nMVV86vEV72N",
        "outputId": "4cd60d25-8314-45bb-9c06-535f32deedb5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Final architecture: {'default_1': '0', 'default_2': '1', 'default_3': [1]}\n"
          ]
        }
      ],
      "source": [
        "import json\n",
        "final_architecture = trainer.export()\n",
        "print('Final architecture:', trainer.export())\n",
        "json.dump(trainer.export(), open('checkpoint.json', 'w'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ep_YXzEwaIlR",
        "outputId": "6b37c49b-d3d9-43df-c98a-fdfee5c21f67"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/content/nni/examples/nas/oneshot/darts\n"
          ]
        }
      ],
      "source": [
        "%cd /content/nni/examples/nas/oneshot/darts/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7MKBAgcL5UN0"
      },
      "outputs": [],
      "source": [
        "!rm -rf /content/nni"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y5zXpOlF3zxa",
        "outputId": "8125fedf-2c04-4669-9711-0829e2897d3e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/content/nni/examples/nas/oneshot/darts\n"
          ]
        }
      ],
      "source": [
        "# In case NNI code is not cloned. If the code is cloned already, ignore this line and enter code folder.\n",
        "#!git clone https://github.com/microsoft/nni\n",
        "\n",
        "# search the best architecture\n",
        "%cd /content/nni/examples/nas/oneshot/darts\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vZzRAIXQ6gC2",
        "outputId": "7332dab0-434f-4023-e023-069d36693898"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/content\n"
          ]
        }
      ],
      "source": [
        "%cd /content"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GkWXh25s5yZk",
        "outputId": "d2d459b2-9af8-4073-a7d8-087e9cc4009a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"/content/nni/examples/nas/oneshot/darts/search.py\", line 14, in <module>\n",
            "    from nni.nas.oneshot.pytorch.callbacks import ArchitectureCheckpoint, LRSchedulerCallback\n",
            "ModuleNotFoundError: No module named 'nni.nas.oneshot.pytorch.callbacks'\n"
          ]
        }
      ],
      "source": [
        "!python /content/nni/examples/nas/oneshot/darts/search.py"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "0aeba8524f5e4142996fc02aa4b4e4a6": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1bf3ae7f6a1940ff9626403fec836291": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "228a2886fa1547d293d8423f77020517": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "35c4a4107b1c4038bb8cdac3284d262a": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3817ed9bd11d4d4bbe9768a2ea1928e4": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "3990f04987e8493eb28834a49f508de1": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c201d78bbbe4443db2ad74ea1872925b",
            "max": 170498071,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_228a2886fa1547d293d8423f77020517",
            "value": 170498071
          }
        },
        "4c48e6d9983049f499494b114e6c9c72": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "838ac074a4044eef98c91a32f28f6825": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_a7733d25dfe24108b41bb5e195ecabf9",
              "IPY_MODEL_3990f04987e8493eb28834a49f508de1",
              "IPY_MODEL_d669faa08c284fcab3f6d229dc59df0d"
            ],
            "layout": "IPY_MODEL_4c48e6d9983049f499494b114e6c9c72"
          }
        },
        "a7733d25dfe24108b41bb5e195ecabf9": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0aeba8524f5e4142996fc02aa4b4e4a6",
            "placeholder": "​",
            "style": "IPY_MODEL_3817ed9bd11d4d4bbe9768a2ea1928e4",
            "value": "100%"
          }
        },
        "c201d78bbbe4443db2ad74ea1872925b": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d669faa08c284fcab3f6d229dc59df0d": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_35c4a4107b1c4038bb8cdac3284d262a",
            "placeholder": "​",
            "style": "IPY_MODEL_1bf3ae7f6a1940ff9626403fec836291",
            "value": " 170498071/170498071 [00:05&lt;00:00, 33501275.38it/s]"
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}