{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/swarna-kpaul/Deeep_NN/blob/master/mtl_nas.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Cloning the source repo"
      ],
      "metadata": {
        "id": "XTvrlQqKshTa"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VFr92xKKY2zJ",
        "outputId": "4de2e18c-d6c4-4500-caa6-611ed01ec63c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'MTLNAS'...\n",
            "remote: Enumerating objects: 106, done.\u001b[K\n",
            "remote: Counting objects: 100% (106/106), done.\u001b[K\n",
            "remote: Compressing objects: 100% (69/69), done.\u001b[K\n",
            "Receiving objects: 100% (106/106), 204.87 KiB | 214.00 KiB/s, done.\n",
            "Resolving deltas: 100% (54/54), done.\n",
            "remote: Total 106 (delta 54), reused 68 (delta 34), pack-reused 0\u001b[K\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/bhpfelix/MTLNAS"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd MTLNAS"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pkSmyP3B5iEu",
        "outputId": "e9cd2485-f885-4c66-9728-d2c782273329"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/MTLNAS\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Installing dependencies"
      ],
      "metadata": {
        "id": "w6UFy143sn_u"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-ihIhTpyVbJm",
        "outputId": "e425a7b3-f3ae-4780-c1cc-b199a3e25882"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting certifi==2019.11.28\n",
            "  Downloading certifi-2019.11.28-py2.py3-none-any.whl (156 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m156.0/156.0 KB\u001b[0m \u001b[31m9.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting cycler==0.10.0\n",
            "  Downloading cycler-0.10.0-py2.py3-none-any.whl (6.5 kB)\n",
            "Requirement already satisfied: decorator==4.4.2 in /usr/local/lib/python3.8/dist-packages (from -r requirements.txt (line 3)) (4.4.2)\n",
            "Collecting imageio==2.8.0\n",
            "  Downloading imageio-2.8.0-py3-none-any.whl (3.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.3/3.3 MB\u001b[0m \u001b[31m70.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting kiwisolver==1.1.0\n",
            "  Downloading kiwisolver-1.1.0-cp38-cp38-manylinux1_x86_64.whl (91 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m91.7/91.7 KB\u001b[0m \u001b[31m12.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting matplotlib==3.2.0\n",
            "  Downloading matplotlib-3.2.0-cp38-cp38-manylinux1_x86_64.whl (12.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.4/12.4 MB\u001b[0m \u001b[31m88.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting networkx==2.4\n",
            "  Downloading networkx-2.4-py3-none-any.whl (1.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m58.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting numpy==1.18.1\n",
            "  Downloading numpy-1.18.1-cp38-cp38-manylinux1_x86_64.whl (20.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m20.6/20.6 MB\u001b[0m \u001b[31m79.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting Pillow==7.0.0\n",
            "  Downloading Pillow-7.0.0-cp38-cp38-manylinux1_x86_64.whl (2.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.1/2.1 MB\u001b[0m \u001b[31m87.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting protobuf==3.11.3\n",
            "  Downloading protobuf-3.11.3-cp38-cp38-manylinux1_x86_64.whl (1.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m84.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting pyparsing==2.4.6\n",
            "  Downloading pyparsing-2.4.6-py2.py3-none-any.whl (67 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m67.7/67.7 KB\u001b[0m \u001b[31m10.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting python-dateutil==2.8.1\n",
            "  Downloading python_dateutil-2.8.1-py2.py3-none-any.whl (227 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m227.2/227.2 KB\u001b[0m \u001b[31m27.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting PyYAML==5.3\n",
            "  Downloading PyYAML-5.3.tar.gz (268 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m268.2/268.2 KB\u001b[0m \u001b[31m31.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting six==1.14.0\n",
            "  Downloading six-1.14.0-py2.py3-none-any.whl (10 kB)\n",
            "Collecting tensorboardX==2.0\n",
            "  Downloading tensorboardX-2.0-py2.py3-none-any.whl (195 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m195.7/195.7 KB\u001b[0m \u001b[31m24.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting torch==1.4.0\n",
            "  Downloading torch-1.4.0-cp38-cp38-manylinux1_x86_64.whl (753.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m753.4/753.4 MB\u001b[0m \u001b[31m2.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting torchvision==0.5.0\n",
            "  Downloading torchvision-0.5.0-cp38-cp38-manylinux1_x86_64.whl (4.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.0/4.0 MB\u001b[0m \u001b[31m95.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting tqdm==4.43.0\n",
            "  Downloading tqdm-4.43.0-py2.py3-none-any.whl (59 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m59.1/59.1 KB\u001b[0m \u001b[31m8.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting yacs==0.1.6\n",
            "  Downloading yacs-0.1.6-py3-none-any.whl (9.6 kB)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.8/dist-packages (from kiwisolver==1.1.0->-r requirements.txt (line 5)) (57.4.0)\n",
            "Building wheels for collected packages: PyYAML\n",
            "  Building wheel for PyYAML (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for PyYAML: filename=PyYAML-5.3-cp38-cp38-linux_x86_64.whl size=44243 sha256=6722e55243b91a7264438831be850c7aac9e2ad4b77605cc98ca7c604fad689e\n",
            "  Stored in directory: /root/.cache/pip/wheels/e4/94/ec/65e430f66fda7a86c08f61ce59455581adc269a65881b4ffeb\n",
            "Successfully built PyYAML\n",
            "Installing collected packages: certifi, tqdm, torch, six, PyYAML, pyparsing, Pillow, numpy, networkx, kiwisolver, yacs, torchvision, python-dateutil, protobuf, imageio, cycler, tensorboardX, matplotlib\n",
            "  Attempting uninstall: certifi\n",
            "    Found existing installation: certifi 2022.12.7\n",
            "    Uninstalling certifi-2022.12.7:\n",
            "      Successfully uninstalled certifi-2022.12.7\n",
            "  Attempting uninstall: tqdm\n",
            "    Found existing installation: tqdm 4.64.1\n",
            "    Uninstalling tqdm-4.64.1:\n",
            "      Successfully uninstalled tqdm-4.64.1\n",
            "  Attempting uninstall: torch\n",
            "    Found existing installation: torch 1.13.1+cu116\n",
            "    Uninstalling torch-1.13.1+cu116:\n",
            "      Successfully uninstalled torch-1.13.1+cu116\n",
            "  Attempting uninstall: six\n",
            "    Found existing installation: six 1.15.0\n",
            "    Uninstalling six-1.15.0:\n",
            "      Successfully uninstalled six-1.15.0\n",
            "  Attempting uninstall: PyYAML\n",
            "    Found existing installation: PyYAML 6.0\n",
            "    Uninstalling PyYAML-6.0:\n",
            "      Successfully uninstalled PyYAML-6.0\n",
            "  Attempting uninstall: pyparsing\n",
            "    Found existing installation: pyparsing 3.0.9\n",
            "    Uninstalling pyparsing-3.0.9:\n",
            "      Successfully uninstalled pyparsing-3.0.9\n",
            "  Attempting uninstall: Pillow\n",
            "    Found existing installation: Pillow 7.1.2\n",
            "    Uninstalling Pillow-7.1.2:\n",
            "      Successfully uninstalled Pillow-7.1.2\n",
            "  Attempting uninstall: numpy\n",
            "    Found existing installation: numpy 1.21.6\n",
            "    Uninstalling numpy-1.21.6:\n",
            "      Successfully uninstalled numpy-1.21.6\n",
            "  Attempting uninstall: networkx\n",
            "    Found existing installation: networkx 3.0\n",
            "    Uninstalling networkx-3.0:\n",
            "      Successfully uninstalled networkx-3.0\n",
            "  Attempting uninstall: kiwisolver\n",
            "    Found existing installation: kiwisolver 1.4.4\n",
            "    Uninstalling kiwisolver-1.4.4:\n",
            "      Successfully uninstalled kiwisolver-1.4.4\n",
            "  Attempting uninstall: torchvision\n",
            "    Found existing installation: torchvision 0.14.1+cu116\n",
            "    Uninstalling torchvision-0.14.1+cu116:\n",
            "      Successfully uninstalled torchvision-0.14.1+cu116\n",
            "  Attempting uninstall: python-dateutil\n",
            "    Found existing installation: python-dateutil 2.8.2\n",
            "    Uninstalling python-dateutil-2.8.2:\n",
            "      Successfully uninstalled python-dateutil-2.8.2\n",
            "  Attempting uninstall: protobuf\n",
            "    Found existing installation: protobuf 3.19.6\n",
            "    Uninstalling protobuf-3.19.6:\n",
            "      Successfully uninstalled protobuf-3.19.6\n",
            "  Attempting uninstall: imageio\n",
            "    Found existing installation: imageio 2.9.0\n",
            "    Uninstalling imageio-2.9.0:\n",
            "      Successfully uninstalled imageio-2.9.0\n",
            "  Attempting uninstall: cycler\n",
            "    Found existing installation: cycler 0.11.0\n",
            "    Uninstalling cycler-0.11.0:\n",
            "      Successfully uninstalled cycler-0.11.0\n",
            "  Attempting uninstall: matplotlib\n",
            "    Found existing installation: matplotlib 3.2.2\n",
            "    Uninstalling matplotlib-3.2.2:\n",
            "      Successfully uninstalled matplotlib-3.2.2\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "ipython 7.9.0 requires jedi>=0.10, which is not installed.\n",
            "xarray 2022.12.0 requires numpy>=1.20, but you have numpy 1.18.1 which is incompatible.\n",
            "xarray-einstats 0.4.0 requires numpy>=1.20, but you have numpy 1.18.1 which is incompatible.\n",
            "torchtext 0.14.1 requires torch==1.13.1, but you have torch 1.4.0 which is incompatible.\n",
            "torchaudio 0.13.1+cu116 requires torch==1.13.1, but you have torch 1.4.0 which is incompatible.\n",
            "tifffile 2022.10.10 requires numpy>=1.19.2, but you have numpy 1.18.1 which is incompatible.\n",
            "tensorflow 2.9.2 requires numpy>=1.20, but you have numpy 1.18.1 which is incompatible.\n",
            "tensorflow-metadata 1.12.0 requires protobuf<4,>=3.13, but you have protobuf 3.11.3 which is incompatible.\n",
            "tensorflow-datasets 4.8.1 requires protobuf>=3.12.2, but you have protobuf 3.11.3 which is incompatible.\n",
            "tables 3.7.0 requires numpy>=1.19.0, but you have numpy 1.18.1 which is incompatible.\n",
            "proto-plus 1.22.2 requires protobuf<5.0.0dev,>=3.19.0, but you have protobuf 3.11.3 which is incompatible.\n",
            "plotnine 0.8.0 requires numpy>=1.19.0, but you have numpy 1.18.1 which is incompatible.\n",
            "panel 0.12.1 requires tqdm>=4.48.0, but you have tqdm 4.43.0 which is incompatible.\n",
            "kapre 0.3.7 requires numpy>=1.18.5, but you have numpy 1.18.1 which is incompatible.\n",
            "jaxlib 0.3.25+cuda11.cudnn805 requires numpy>=1.20, but you have numpy 1.18.1 which is incompatible.\n",
            "jax 0.3.25 requires numpy>=1.20, but you have numpy 1.18.1 which is incompatible.\n",
            "grpcio-status 1.48.2 requires protobuf>=3.12.0, but you have protobuf 3.11.3 which is incompatible.\n",
            "googleapis-common-protos 1.58.0 requires protobuf!=3.20.0,!=3.20.1,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.19.5, but you have protobuf 3.11.3 which is incompatible.\n",
            "google-cloud-translate 3.8.4 requires protobuf!=3.20.0,!=3.20.1,!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.19.5, but you have protobuf 3.11.3 which is incompatible.\n",
            "google-cloud-language 2.6.1 requires protobuf!=3.20.0,!=3.20.1,!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.19.5, but you have protobuf 3.11.3 which is incompatible.\n",
            "google-cloud-firestore 2.7.3 requires protobuf!=3.20.0,!=3.20.1,!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.19.5, but you have protobuf 3.11.3 which is incompatible.\n",
            "google-cloud-datastore 2.11.1 requires protobuf!=3.20.0,!=3.20.1,!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.19.5, but you have protobuf 3.11.3 which is incompatible.\n",
            "google-cloud-bigquery 3.4.1 requires protobuf!=3.20.0,!=3.20.1,!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.19.5, but you have protobuf 3.11.3 which is incompatible.\n",
            "google-cloud-bigquery-storage 2.17.0 requires protobuf!=3.20.0,!=3.20.1,!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.19.5, but you have protobuf 3.11.3 which is incompatible.\n",
            "google-api-core 2.11.0 requires protobuf!=3.20.0,!=3.20.1,!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.19.5, but you have protobuf 3.11.3 which is incompatible.\n",
            "fastai 2.7.10 requires torch<1.14,>=1.7, but you have torch 1.4.0 which is incompatible.\n",
            "fastai 2.7.10 requires torchvision>=0.8.2, but you have torchvision 0.5.0 which is incompatible.\n",
            "dask 2022.2.1 requires pyyaml>=5.3.1, but you have pyyaml 5.3 which is incompatible.\n",
            "cupy-cuda11x 11.0.0 requires numpy<1.26,>=1.20, but you have numpy 1.18.1 which is incompatible.\n",
            "cmdstanpy 1.0.8 requires numpy>=1.21, but you have numpy 1.18.1 which is incompatible.\n",
            "bokeh 2.3.3 requires pillow>=7.1.0, but you have pillow 7.0.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed Pillow-7.0.0 PyYAML-5.3 certifi-2019.11.28 cycler-0.10.0 imageio-2.8.0 kiwisolver-1.1.0 matplotlib-3.2.0 networkx-2.4 numpy-1.18.1 protobuf-3.11.3 pyparsing-2.4.6 python-dateutil-2.8.1 six-1.14.0 tensorboardX-2.0 torch-1.4.0 torchvision-0.5.0 tqdm-4.43.0 yacs-0.1.6\n"
          ]
        }
      ],
      "source": [
        "!pip install -r requirements.txt # install nni"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install --upgrade --no-cache-dir gdown"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sVkwH1MJ70um",
        "outputId": "62390223-d98b-49fa-9f7d-4f2a8dc2faff"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: gdown in /usr/local/lib/python3.8/dist-packages (4.4.0)\n",
            "Collecting gdown\n",
            "  Downloading gdown-4.6.0-py3-none-any.whl (14 kB)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.8/dist-packages (from gdown) (4.43.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.8/dist-packages (from gdown) (3.9.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.8/dist-packages (from gdown) (1.14.0)\n",
            "Requirement already satisfied: requests[socks] in /usr/local/lib/python3.8/dist-packages (from gdown) (2.25.1)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.8/dist-packages (from gdown) (4.6.3)\n",
            "Requirement already satisfied: chardet<5,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests[socks]->gdown) (4.0.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests[socks]->gdown) (2019.11.28)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests[socks]->gdown) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests[socks]->gdown) (2.10)\n",
            "Requirement already satisfied: PySocks!=1.5.7,>=1.5.6 in /usr/local/lib/python3.8/dist-packages (from requests[socks]->gdown) (1.7.1)\n",
            "Installing collected packages: gdown\n",
            "  Attempting uninstall: gdown\n",
            "    Found existing installation: gdown 4.4.0\n",
            "    Uninstalling gdown-4.4.0:\n",
            "      Successfully uninstalled gdown-4.4.0\n",
            "Successfully installed gdown-4.6.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Downloading weights of base network"
      ],
      "metadata": {
        "id": "0la5HznLsuD2"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EqhFCdDi24wn",
        "outputId": "6a0b2c58-eea0-4d5d-aabb-55014cb5320a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=13caGJwskbeEgxGXYbdCH59a0FEWIWZnB\n",
            "To: /content/MTLNAS/weights_old.zip\n",
            "100% 229M/229M [00:02<00:00, 81.9MB/s]\n"
          ]
        }
      ],
      "source": [
        "!gdown 13caGJwskbeEgxGXYbdCH59a0FEWIWZnB"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Downloading dataset"
      ],
      "metadata": {
        "id": "wK3Es6XPs1Wf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!gdown 1JyTApScm6S5iz77uxH0qTaYtAhR6xxoj"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AH_LUuGP3LG5",
        "outputId": "42b8cb58-3df6-4971-e68b-29c109eccd72"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1JyTApScm6S5iz77uxH0qTaYtAhR6xxoj\n",
            "To: /content/MTLNAS/datasets.zip\n",
            "100% 983M/983M [00:12<00:00, 81.1MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Unzipping weights"
      ],
      "metadata": {
        "id": "7VXRwT5ss6fP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip weights_old.zip"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6XzAkqCE7-Tr",
        "outputId": "62774c7a-0792-4bd7-9f32-26d9fc753b1d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Archive:  weights_old.zip\n",
            "   creating: nyu_v2/\n",
            "  inflating: nyu_v2/tf_finetune_seg.pth  \n",
            "  inflating: nyu_v2/tf_finetune_normal.pth  \n",
            "   creating: vgg_deeplab_lfov/\n",
            "  inflating: vgg_deeplab_lfov/tf_deeplab.pth  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Unzipping datasets"
      ],
      "metadata": {
        "id": "UqQ8xxJms-Mn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip datasets.zip"
      ],
      "metadata": {
        "id": "ThZcybZV3WjP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Run training for NDDR"
      ],
      "metadata": {
        "id": "uy0lyypntHpN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!python tools/train.py --config-file configs/vgg/vgg_nyuv2_nddr.yaml"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n9k0gFtE9XZF",
        "outputId": "72bc7da4-6a52-4891-b7bd-13a3376fe033"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/MTLNAS\n",
            "/content/MTLNAS\n",
            "Training with Config: \n",
            "ARCH:\n",
            "  ENTROPY_PERIOD: (0.0, 1.0)\n",
            "  ENTROPY_REGULARIZATION: False\n",
            "  ENTROPY_REGULARIZATION_WEIGHT: 10.0\n",
            "  HARD_ARCH_TRAINING: True\n",
            "  HARD_EVAL: True\n",
            "  HARD_WEIGHT_TRAINING: True\n",
            "  INIT_TEMP: 1.0\n",
            "  L1_OFF: False\n",
            "  L1_PERIOD: (0.0, 1.0)\n",
            "  L1_REGULARIZATION: False\n",
            "  L1_REGULARIZATION_WEIGHT: 5.0\n",
            "  LR: 0.003\n",
            "  MIXED_DATA: True\n",
            "  OPTIMIZER: \n",
            "  SEARCHSPACE: \n",
            "  STOCHASTIC_EVAL: False\n",
            "  TEMPERATURE_PERIOD: (0.0, 1.0)\n",
            "  TEMPERATURE_POWER: 2.0\n",
            "  TRAIN_SPLIT: 0.5\n",
            "  WEIGHTED_L1: False\n",
            "  WEIGHT_DECAY: 0.001\n",
            "CUDA: True\n",
            "DATASET: nyu_v2\n",
            "EXPERIMENT_NAME: vgg_nyuv2_nddr\n",
            "LOG_DIR: run\n",
            "MODEL:\n",
            "  BACKBONE: VGG16\n",
            "  BATCH_NORM_MOMENTUM: 0.05\n",
            "  INIT: (0.9, 0.1)\n",
            "  NDDR_BN_TYPE: default\n",
            "  NDDR_TYPE: \n",
            "  NET1_CLASSES: 40\n",
            "  NET2_CLASSES: 3\n",
            "  SHAREDFEATURE: False\n",
            "  SINGLETASK: False\n",
            "  SUPERNET: False\n",
            "  ZERO_BATCH_NORM_GAMMA: False\n",
            "SAVE_DIR: ckpts\n",
            "SEED: 1\n",
            "TASK: pixel\n",
            "TEST:\n",
            "  BATCH_SIZE: 10\n",
            "  CKPT_ID: 20000\n",
            "  RANDOM_CROP: False\n",
            "  RANDOM_MIRROR: False\n",
            "  RANDOM_SCALE: False\n",
            "TRAIN:\n",
            "  APEX: False\n",
            "  AUX: False\n",
            "  AUX_LAYERS: []\n",
            "  AUX_PERIOD: (0.0, 0.0)\n",
            "  AUX_WEIGHT: 0.4\n",
            "  BATCH_SIZE: 10\n",
            "  COLOR_JITTER: True\n",
            "  EVAL_CKPT: True\n",
            "  EVAL_INTERVAL: 1000\n",
            "  FC8_BIAS_FACTOR: 20.0\n",
            "  FC8_WEIGHT_FACTOR: 10.0\n",
            "  FREEZE_BASE: False\n",
            "  LOG_INTERVAL: 500\n",
            "  LR: 0.001\n",
            "  MOMENTUM: 0.9\n",
            "  NDDR_FACTOR: 100.0\n",
            "  OUTPUT_SIZE: (321, 321)\n",
            "  POWER: 0.9\n",
            "  RANDOM_CROP: True\n",
            "  RANDOM_MIRROR: True\n",
            "  RANDOM_SCALE: True\n",
            "  SAVE_INTERVAL: 5000\n",
            "  SCHEDULE: Poly\n",
            "  STEPS: 20001\n",
            "  TASK2_FACTOR: 20.0\n",
            "  WARMUP: 0\n",
            "  WEIGHT_1: Seg\n",
            "  WEIGHT_2: Normal\n",
            "  WEIGHT_DECAY: 0.00025\n",
            "Using color jitter\n",
            "Train Step: 0 [0/795 (0%)]\tLoss: 3.725678\tLoss1: 2.531692\tLoss2: 0.059699\n",
            "/usr/local/lib/python3.8/dist-packages/torch/optim/lr_scheduler.py:224: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n",
            "  warnings.warn(\"To get the last learning rate computed by the scheduler, \"\n",
            "Mean IoU: 0.189\n",
            "Pixel Acc: 0.419\n",
            "Mean: 17.441\n",
            "Median: 15.833\n",
            "RMSE: 20.547\n",
            "11.25: 32.227\n",
            "22.5: 71.829\n",
            "30: 86.787\n",
            "45: 98.152\n",
            "Train Step: 500 [200/795 (25%)]\tLoss: 2.497943\tLoss1: 1.222728\tLoss2: 0.063761\n",
            "Train Step: 1000 [400/795 (50%)]\tLoss: 1.817573\tLoss1: 0.900720\tLoss2: 0.045843\n",
            "Train Step: 1500 [600/795 (75%)]\tLoss: 2.253451\tLoss1: 1.358696\tLoss2: 0.044738\n",
            "Train Step: 2000 [0/795 (0%)]\tLoss: 2.012001\tLoss1: 1.004705\tLoss2: 0.050365\n",
            "Train Step: 2500 [200/795 (25%)]\tLoss: 1.655727\tLoss1: 0.719433\tLoss2: 0.046815\n",
            "Train Step: 3000 [400/795 (50%)]\tLoss: 1.943268\tLoss1: 0.887120\tLoss2: 0.052807\n",
            "Train Step: 3500 [600/795 (75%)]\tLoss: 1.638226\tLoss1: 0.770618\tLoss2: 0.043380\n",
            "Train Step: 4000 [0/795 (0%)]\tLoss: 1.391195\tLoss1: 0.629712\tLoss2: 0.038074\n",
            "Traceback (most recent call last):\n",
            "  File \"tools/train.py\", line 220, in <module>\n",
            "    main()\n",
            "  File \"tools/train.py\", line 143, in main\n",
            "    for batch_idx, (image, label_1, label_2) in enumerate(train_loader):\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/torch/utils/data/dataloader.py\", line 345, in __next__\n",
            "    data = self._next_data()\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/torch/utils/data/dataloader.py\", line 385, in _next_data\n",
            "    data = self._dataset_fetcher.fetch(index)  # may raise StopIteration\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/torch/utils/data/_utils/fetch.py\", line 44, in fetch\n",
            "    data = [self.dataset[idx] for idx in possibly_batched_index]\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/torch/utils/data/_utils/fetch.py\", line 44, in <listcomp>\n",
            "    data = [self.dataset[idx] for idx in possibly_batched_index]\n",
            "  File \"/content/MTLNAS/core/data/loader.py\", line 91, in __getitem__\n",
            "    image = self.color_jitter(image)\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/torchvision/transforms/transforms.py\", line 931, in __call__\n",
            "    return transform(img)\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/torchvision/transforms/transforms.py\", line 70, in __call__\n",
            "    img = t(img)\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/torchvision/transforms/transforms.py\", line 322, in __call__\n",
            "    return self.lambd(img)\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/torchvision/transforms/transforms.py\", line 914, in <lambda>\n",
            "    transforms.append(Lambda(lambda img: F.adjust_hue(img, hue_factor)))\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py\", line 659, in adjust_hue\n",
            "    img = Image.merge('HSV', (h, s, v)).convert(input_mode)\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/PIL/Image.py\", line 995, in convert\n",
            "    im = self.im.convert(mode, dither)\n",
            "KeyboardInterrupt\n",
            "^C\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Run training for MTL-NAS"
      ],
      "metadata": {
        "id": "O0mtYJyVtNQe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!CUDA_VISIBLE_DEVICES=0 python tools/train_nas.py --config-file configs/ablation/vgg_nyuv2_default.yaml"
      ],
      "metadata": {
        "id": "8CRXwkjh3uBJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1702445c-f623-4224-f000-affb5857e12b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/MTLNAS\n",
            "/content/MTLNAS\n",
            "Training with Config: \n",
            "ARCH:\n",
            "  ENTROPY_PERIOD: (0.0, 0.0)\n",
            "  ENTROPY_REGULARIZATION: True\n",
            "  ENTROPY_REGULARIZATION_WEIGHT: 10.0\n",
            "  HARD_ARCH_TRAINING: False\n",
            "  HARD_EVAL: True\n",
            "  HARD_WEIGHT_TRAINING: True\n",
            "  INIT_TEMP: 1.0\n",
            "  L1_OFF: False\n",
            "  L1_PERIOD: (0.0, 0.0)\n",
            "  L1_REGULARIZATION: False\n",
            "  L1_REGULARIZATION_WEIGHT: 5.0\n",
            "  LR: 0.001\n",
            "  MIXED_DATA: True\n",
            "  OPTIMIZER: \n",
            "  SEARCHSPACE: GeneralizedMTLNAS\n",
            "  STOCHASTIC_EVAL: False\n",
            "  TEMPERATURE_PERIOD: (0.0, 1.0)\n",
            "  TEMPERATURE_POWER: 2.0\n",
            "  TRAIN_SPLIT: 0.5\n",
            "  WEIGHTED_L1: False\n",
            "  WEIGHT_DECAY: 0.001\n",
            "CUDA: True\n",
            "DATASET: nyu_v2\n",
            "EXPERIMENT_NAME: vgg_nyuv2_default\n",
            "LOG_DIR: run\n",
            "MODEL:\n",
            "  BACKBONE: VGG16_13_Stage\n",
            "  BATCH_NORM_MOMENTUM: 0.05\n",
            "  INIT: (1.0, 0.0)\n",
            "  NDDR_BN_TYPE: default\n",
            "  NDDR_TYPE: \n",
            "  NET1_CLASSES: 40\n",
            "  NET2_CLASSES: 3\n",
            "  SHAREDFEATURE: False\n",
            "  SINGLETASK: False\n",
            "  SUPERNET: False\n",
            "  ZERO_BATCH_NORM_GAMMA: False\n",
            "SAVE_DIR: ckpts\n",
            "SEED: 1\n",
            "TASK: pixel\n",
            "TEST:\n",
            "  BATCH_SIZE: 10\n",
            "  CKPT_ID: 20000\n",
            "  RANDOM_CROP: False\n",
            "  RANDOM_MIRROR: False\n",
            "  RANDOM_SCALE: False\n",
            "TRAIN:\n",
            "  APEX: False\n",
            "  AUX: False\n",
            "  AUX_LAYERS: []\n",
            "  AUX_PERIOD: (0.0, 0.0)\n",
            "  AUX_WEIGHT: 0.4\n",
            "  BATCH_SIZE: 10\n",
            "  COLOR_JITTER: True\n",
            "  EVAL_CKPT: True\n",
            "  EVAL_INTERVAL: 1000\n",
            "  FC8_BIAS_FACTOR: 20.0\n",
            "  FC8_WEIGHT_FACTOR: 10.0\n",
            "  FREEZE_BASE: False\n",
            "  LOG_INTERVAL: 500\n",
            "  LR: 0.001\n",
            "  MOMENTUM: 0.9\n",
            "  NDDR_FACTOR: 100.0\n",
            "  OUTPUT_SIZE: (321, 321)\n",
            "  POWER: 0.9\n",
            "  RANDOM_CROP: True\n",
            "  RANDOM_MIRROR: True\n",
            "  RANDOM_SCALE: True\n",
            "  SAVE_INTERVAL: 5000\n",
            "  SCHEDULE: Poly\n",
            "  STEPS: 20001\n",
            "  TASK2_FACTOR: 20.0\n",
            "  WARMUP: 0\n",
            "  WEIGHT_1: Seg\n",
            "  WEIGHT_2: Normal\n",
            "  WEIGHT_DECAY: 0.00025\n",
            "Using color jitter\n",
            "Model has 13 stages\n",
            "Traceback (most recent call last):\n",
            "  File \"tools/train_nas.py\", line 416, in <module>\n",
            "    main()\n",
            "  File \"tools/train_nas.py\", line 280, in main\n",
            "    arch_result = model.loss(image_search, (label_1_search, label_2_search))\n",
            "  File \"/content/MTLNAS/core/models/supernet.py\", line 95, in loss\n",
            "    result = self.forward(image)\n",
            "  File \"/content/MTLNAS/core/models/supernet.py\", line 265, in forward\n",
            "    y = self.paths['net2_paths'][stage_id](net2_fusion_input)\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py\", line 532, in __call__\n",
            "    result = self.forward(*input, **kwargs)\n",
            "  File \"/content/MTLNAS/core/models/common_layers.py\", line 211, in forward\n",
            "    out = self.activation(out)\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py\", line 532, in __call__\n",
            "    result = self.forward(*input, **kwargs)\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/torch/nn/modules/activation.py\", line 94, in forward\n",
            "    return F.relu(input, inplace=self.inplace)\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/torch/nn/functional.py\", line 914, in relu\n",
            "    result = torch.relu(input)\n",
            "RuntimeError: CUDA out of memory. Tried to allocate 64.00 MiB (GPU 0; 14.76 GiB total capacity; 13.90 GiB already allocated; 27.75 MiB free; 13.95 GiB reserved in total by PyTorch)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Run evaluation for NDDR"
      ],
      "metadata": {
        "id": "4c4a0_bUtT9A"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!CUDA_VISIBLE_DEVICES=0 python tools/eval.py --config-file configs/vgg/vgg_nyuv2_nddr.yaml"
      ],
      "metadata": {
        "id": "y3KDM1WW50DR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Run evaluation for MTL-NAS"
      ],
      "metadata": {
        "id": "kIisy27atZ1c"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!CUDA_VISIBLE_DEVICES=0 python tools/eval_nas.py --config-file configs/ablation/vgg_nyuv2_default.yaml"
      ],
      "metadata": {
        "id": "MXp5NqBX55Wf"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}